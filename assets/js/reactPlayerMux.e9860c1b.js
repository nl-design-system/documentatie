'use strict';
exports.id = 4258;
exports.ids = [4258];
exports.modules = {
 /***/ 74486: /***/ (__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {
  // ESM COMPAT FLAG
  __webpack_require__.r(__webpack_exports__);

  // EXPORTS
  __webpack_require__.d(__webpack_exports__, {
   MaxResolution: () => /* reexport */ dist_Gt,
   MediaError: () => /* reexport */ f,
   MinResolution: () => /* reexport */ dist_Xt,
   RenditionOrder: () => /* reexport */ dist_zt,
   default: () => /* binding */ mux_player_react_dist_ze,
   generatePlayerInitTime: () => /* reexport */ dist_Wr,
   playerSoftwareName: () => /* binding */ mux_player_react_dist_fe,
   playerSoftwareVersion: () => /* binding */ mux_player_react_dist_de,
  });

  // EXTERNAL MODULE: ./node_modules/.pnpm/react@18.3.1/node_modules/react/index.js
  var react = __webpack_require__(75271); // CONCATENATED MODULE: ./node_modules/.pnpm/mux-embed@5.11.0/node_modules/mux-embed/dist/mux.mjs
  var ea = Object.create;
  var ft = Object.defineProperty;
  var ta = Object.getOwnPropertyDescriptor;
  var ra = Object.getOwnPropertyNames;
  var aa = Object.getPrototypeOf,
   ia = Object.prototype.hasOwnProperty;
  var pt = function (r, e) {
   return function () {
    return r && (e = r((r = 0))), e;
   };
  };
  var B = function (r, e) {
   return function () {
    return e || r((e = { exports: {} }).exports, e), e.exports;
   };
  };
  var na = function (r, e, t, i) {
   if ((e && typeof e == 'object') || typeof e == 'function')
    for (var a = ra(e), n = 0, o = a.length, s; n < o; n++)
     (s = a[n]),
      !ia.call(r, s) &&
       s !== t &&
       ft(r, s, {
        get: function (u) {
         return e[u];
        }.bind(null, s),
        enumerable: !(i = ta(e, s)) || i.enumerable,
       });
   return r;
  };
  var V = function (r, e, t) {
   return (t = r != null ? ea(aa(r)) : {}), na(e || !r || !r.__esModule ? ft(t, 'default', { value: r, enumerable: !0 }) : t, r);
  };
  var J = B(function (Xi, yt) {
   var xe;
   typeof window != 'undefined' ? (xe = window) : typeof global != 'undefined' ? (xe = global) : typeof self != 'undefined' ? (xe = self) : (xe = {});
   yt.exports = xe;
  });
  function U(r, e) {
   return e != null && typeof Symbol != 'undefined' && e[Symbol.hasInstance] ? !!e[Symbol.hasInstance](r) : U(r, e);
  }
  var te = pt(function () {
   te();
  });
  function Le(r) {
   '@swc/helpers - typeof';
   return r && typeof Symbol != 'undefined' && r.constructor === Symbol ? 'symbol' : typeof r;
  }
  var Je = pt(function () {});
  var Ye = B(function (Os, fr) {
   var _r = Array.prototype.slice;
   fr.exports = Ca;
   function Ca(r, e) {
    for (('length' in r) || (r = [r]), r = _r.call(r); r.length; ) {
     var t = r.shift(),
      i = e(t);
     if (i) return i;
     t.childNodes && t.childNodes.length && (r = _r.call(t.childNodes).concat(r));
    }
   }
  });
  var vr = B(function (Is, pr) {
   te();
   pr.exports = me;
   function me(r, e) {
    if (!U(this, me)) return new me(r, e);
    (this.data = r), (this.nodeValue = r), (this.length = r.length), (this.ownerDocument = e || null);
   }
   me.prototype.nodeType = 8;
   me.prototype.nodeName = '#comment';
   me.prototype.toString = function () {
    return '[object Comment]';
   };
  });
  var hr = B(function (Ns, mr) {
   te();
   mr.exports = ae;
   function ae(r, e) {
    if (!U(this, ae)) return new ae(r);
    (this.data = r || ''), (this.length = this.data.length), (this.ownerDocument = e || null);
   }
   ae.prototype.type = 'DOMTextNode';
   ae.prototype.nodeType = 3;
   ae.prototype.nodeName = '#text';
   ae.prototype.toString = function () {
    return this.data;
   };
   ae.prototype.replaceData = function (e, t, i) {
    var a = this.data,
     n = a.substring(0, e),
     o = a.substring(e + t, a.length);
    (this.data = n + i + o), (this.length = this.data.length);
   };
  });
  var Xe = B(function (Cs, yr) {
   yr.exports = Ma;
   function Ma(r) {
    var e = this,
     t = r.type;
    r.target || (r.target = e), e.listeners || (e.listeners = {});
    var i = e.listeners[t];
    if (i)
     return i.forEach(function (a) {
      (r.currentTarget = e), typeof a == 'function' ? a(r) : a.handleEvent(r);
     });
    e.parentNode && e.parentNode.dispatchEvent(r);
   }
  });
  var $e = B(function (Ms, gr) {
   gr.exports = Ha;
   function Ha(r, e) {
    var t = this;
    t.listeners || (t.listeners = {}), t.listeners[r] || (t.listeners[r] = []), t.listeners[r].indexOf(e) === -1 && t.listeners[r].push(e);
   }
  });
  var Ze = B(function (Hs, br) {
   br.exports = Ba;
   function Ba(r, e) {
    var t = this;
    if (t.listeners && t.listeners[r]) {
     var i = t.listeners[r],
      a = i.indexOf(e);
     a !== -1 && i.splice(a, 1);
    }
   }
  });
  var kr = B(function (Us, Er) {
   Je();
   Er.exports = wr;
   var Ua = ['area', 'base', 'br', 'col', 'embed', 'hr', 'img', 'input', 'keygen', 'link', 'menuitem', 'meta', 'param', 'source', 'track', 'wbr'];
   function wr(r) {
    switch (r.nodeType) {
     case 3:
      return et(r.data);
     case 8:
      return '<!--' + r.data + '-->';
     default:
      return Fa(r);
    }
   }
   function Fa(r) {
    var e = [],
     t = r.tagName;
    return r.namespaceURI === 'http://www.w3.org/1999/xhtml' && (t = t.toLowerCase()), e.push('<' + t + Ga(r) + Wa(r)), Ua.indexOf(t) > -1 ? e.push(' />') : (e.push('>'), r.childNodes.length ? e.push.apply(e, r.childNodes.map(wr)) : r.textContent || r.innerText ? e.push(et(r.textContent || r.innerText)) : r.innerHTML && e.push(r.innerHTML), e.push('</' + t + '>')), e.join('');
   }
   function Va(r, e) {
    var t = Le(r[e]);
    return e === 'style' && Object.keys(r.style).length > 0 ? !0 : r.hasOwnProperty(e) && (t === 'string' || t === 'boolean' || t === 'number') && e !== 'nodeName' && e !== 'className' && e !== 'tagName' && e !== 'textContent' && e !== 'innerText' && e !== 'namespaceURI' && e !== 'innerHTML';
   }
   function ja(r) {
    if (typeof r == 'string') return r;
    var e = '';
    return (
     Object.keys(r).forEach(function (t) {
      var i = r[t];
      (t = t.replace(/[A-Z]/g, function (a) {
       return '-' + a.toLowerCase();
      })),
       (e += t + ':' + i + ';');
     }),
     e
    );
   }
   function Wa(r) {
    var e = r.dataset,
     t = [];
    for (var i in e) t.push({ name: 'data-' + i, value: e[i] });
    return t.length ? Tr(t) : '';
   }
   function Tr(r) {
    var e = [];
    return (
     r.forEach(function (t) {
      var i = t.name,
       a = t.value;
      i === 'style' && (a = ja(a)), e.push(i + '="' + Ja(a) + '"');
     }),
     e.length ? ' ' + e.join(' ') : ''
    );
   }
   function Ga(r) {
    var e = [];
    for (var t in r) Va(r, t) && e.push({ name: t, value: r[t] });
    for (var i in r._attributes)
     for (var a in r._attributes[i]) {
      var n = r._attributes[i][a],
       o = (n.prefix ? n.prefix + ':' : '') + a;
      e.push({ name: o, value: n.value });
     }
    return r.className && e.push({ name: 'class', value: r.className }), e.length ? Tr(e) : '';
   }
   function et(r) {
    var e = '';
    return typeof r == 'string' ? (e = r) : r && (e = r.toString()), e.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;');
   }
   function Ja(r) {
    return et(r).replace(/"/g, '&quot;');
   }
  });
  var rt = B(function (Vs, Dr) {
   te();
   var tt = Ye(),
    Qa = Xe(),
    za = $e(),
    Ka = Ze(),
    Ya = kr(),
    xr = 'http://www.w3.org/1999/xhtml';
   Dr.exports = I;
   function I(r, e, t) {
    if (!U(this, I)) return new I(r);
    var i = t === void 0 ? xr : t || null;
    (this.tagName = i === xr ? String(r).toUpperCase() : r), (this.nodeName = this.tagName), (this.className = ''), (this.dataset = {}), (this.childNodes = []), (this.parentNode = null), (this.style = {}), (this.ownerDocument = e || null), (this.namespaceURI = i), (this._attributes = {}), this.tagName === 'INPUT' && (this.type = 'text');
   }
   I.prototype.type = 'DOMElement';
   I.prototype.nodeType = 1;
   I.prototype.appendChild = function (e) {
    return e.parentNode && e.parentNode.removeChild(e), this.childNodes.push(e), (e.parentNode = this), e;
   };
   I.prototype.replaceChild = function (e, t) {
    e.parentNode && e.parentNode.removeChild(e);
    var i = this.childNodes.indexOf(t);
    return (t.parentNode = null), (this.childNodes[i] = e), (e.parentNode = this), t;
   };
   I.prototype.removeChild = function (e) {
    var t = this.childNodes.indexOf(e);
    return this.childNodes.splice(t, 1), (e.parentNode = null), e;
   };
   I.prototype.insertBefore = function (e, t) {
    e.parentNode && e.parentNode.removeChild(e);
    var i = t == null ? -1 : this.childNodes.indexOf(t);
    return i > -1 ? this.childNodes.splice(i, 0, e) : this.childNodes.push(e), (e.parentNode = this), e;
   };
   I.prototype.setAttributeNS = function (e, t, i) {
    var a = null,
     n = t,
     o = t.indexOf(':');
    if ((o > -1 && ((a = t.substr(0, o)), (n = t.substr(o + 1))), this.tagName === 'INPUT' && t === 'type')) this.type = i;
    else {
     var s = this._attributes[e] || (this._attributes[e] = {});
     s[n] = { value: i, prefix: a };
    }
   };
   I.prototype.getAttributeNS = function (e, t) {
    var i = this._attributes[e],
     a = i && i[t] && i[t].value;
    return this.tagName === 'INPUT' && t === 'type' ? this.type : typeof a != 'string' ? null : a;
   };
   I.prototype.removeAttributeNS = function (e, t) {
    var i = this._attributes[e];
    i && delete i[t];
   };
   I.prototype.hasAttributeNS = function (e, t) {
    var i = this._attributes[e];
    return !!i && t in i;
   };
   I.prototype.setAttribute = function (e, t) {
    return this.setAttributeNS(null, e, t);
   };
   I.prototype.getAttribute = function (e) {
    return this.getAttributeNS(null, e);
   };
   I.prototype.removeAttribute = function (e) {
    return this.removeAttributeNS(null, e);
   };
   I.prototype.hasAttribute = function (e) {
    return this.hasAttributeNS(null, e);
   };
   I.prototype.removeEventListener = Ka;
   I.prototype.addEventListener = za;
   I.prototype.dispatchEvent = Qa;
   I.prototype.focus = function () {};
   I.prototype.toString = function () {
    return Ya(this);
   };
   I.prototype.getElementsByClassName = function (e) {
    var t = e.split(' '),
     i = [];
    return (
     tt(this, function (a) {
      if (a.nodeType === 1) {
       var n = a.className || '',
        o = n.split(' ');
       t.every(function (s) {
        return o.indexOf(s) !== -1;
       }) && i.push(a);
      }
     }),
     i
    );
   };
   I.prototype.getElementsByTagName = function (e) {
    e = e.toLowerCase();
    var t = [];
    return (
     tt(this.childNodes, function (i) {
      i.nodeType === 1 && (e === '*' || i.tagName.toLowerCase() === e) && t.push(i);
     }),
     t
    );
   };
   I.prototype.contains = function (e) {
    return (
     tt(this, function (t) {
      return e === t;
     }) || !1
    );
   };
  });
  var Rr = B(function (Ws, Sr) {
   te();
   var at = rt();
   Sr.exports = K;
   function K(r) {
    if (!U(this, K)) return new K();
    (this.childNodes = []), (this.parentNode = null), (this.ownerDocument = r || null);
   }
   K.prototype.type = 'DocumentFragment';
   K.prototype.nodeType = 11;
   K.prototype.nodeName = '#document-fragment';
   K.prototype.appendChild = at.prototype.appendChild;
   K.prototype.replaceChild = at.prototype.replaceChild;
   K.prototype.removeChild = at.prototype.removeChild;
   K.prototype.toString = function () {
    return this.childNodes
     .map(function (e) {
      return String(e);
     })
     .join('');
   };
  });
  var Ar = B(function (Gs, qr) {
   qr.exports = it;
   function it(r) {}
   it.prototype.initEvent = function (e, t, i) {
    (this.type = e), (this.bubbles = t), (this.cancelable = i);
   };
   it.prototype.preventDefault = function () {};
  });
  var Pr = B(function (Qs, Or) {
   te();
   var Xa = Ye(),
    $a = vr(),
    Za = hr(),
    Re = rt(),
    ei = Rr(),
    ti = Ar(),
    ri = Xe(),
    ai = $e(),
    ii = Ze();
   Or.exports = Be;
   function Be() {
    if (!U(this, Be)) return new Be();
    (this.head = this.createElement('head')), (this.body = this.createElement('body')), (this.documentElement = this.createElement('html')), this.documentElement.appendChild(this.head), this.documentElement.appendChild(this.body), (this.childNodes = [this.documentElement]), (this.nodeType = 9);
   }
   var W = Be.prototype;
   W.createTextNode = function (e) {
    return new Za(e, this);
   };
   W.createElementNS = function (e, t) {
    var i = e === null ? null : String(e);
    return new Re(t, this, i);
   };
   W.createElement = function (e) {
    return new Re(e, this);
   };
   W.createDocumentFragment = function () {
    return new ei(this);
   };
   W.createEvent = function (e) {
    return new ti(e);
   };
   W.createComment = function (e) {
    return new $a(e, this);
   };
   W.getElementById = function (e) {
    e = String(e);
    var t = Xa(this.childNodes, function (i) {
     if (String(i.id) === e) return i;
    });
    return t || null;
   };
   W.getElementsByClassName = Re.prototype.getElementsByClassName;
   W.getElementsByTagName = Re.prototype.getElementsByTagName;
   W.contains = Re.prototype.contains;
   W.removeEventListener = ii;
   W.addEventListener = ai;
   W.dispatchEvent = ri;
  });
  var Lr = B(function (zs, Ir) {
   var ni = Pr();
   Ir.exports = new ni();
  });
  var nt = B(function (Ks, Cr) {
   var Nr = typeof global != 'undefined' ? global : typeof window != 'undefined' ? window : {},
    oi = Lr(),
    qe;
   typeof document != 'undefined' ? (qe = document) : ((qe = Nr['__GLOBAL_DOCUMENT_CACHE@4']), qe || (qe = Nr['__GLOBAL_DOCUMENT_CACHE@4'] = oi));
   Cr.exports = qe;
  });
  function vt(r) {
   if (Array.isArray(r)) return r;
  }
  function mt(r, e) {
   var t = r == null ? null : (typeof Symbol != 'undefined' && r[Symbol.iterator]) || r['@@iterator'];
   if (t != null) {
    var i = [],
     a = !0,
     n = !1,
     o,
     s;
    try {
     for (t = t.call(r); !(a = (o = t.next()).done) && (i.push(o.value), !(e && i.length === e)); a = !0);
    } catch (u) {
     (n = !0), (s = u);
    } finally {
     try {
      !a && t.return != null && t.return();
     } finally {
      if (n) throw s;
     }
    }
    return i;
   }
  }
  function ht() {
   throw new TypeError('Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.');
  }
  function ke(r, e) {
   (e == null || e > r.length) && (e = r.length);
   for (var t = 0, i = new Array(e); t < e; t++) i[t] = r[t];
   return i;
  }
  function Ae(r, e) {
   if (r) {
    if (typeof r == 'string') return ke(r, e);
    var t = Object.prototype.toString.call(r).slice(8, -1);
    if ((t === 'Object' && r.constructor && (t = r.constructor.name), t === 'Map' || t === 'Set')) return Array.from(t);
    if (t === 'Arguments' || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)) return ke(r, e);
   }
  }
  function H(r, e) {
   return vt(r) || mt(r, e) || Ae(r, e) || ht();
  }
  var be = V(J());
  var Ge = V(J());
  var gt = V(J()),
   oa = {
    now: function () {
     var r = gt.default.performance,
      e = r && r.timing,
      t = e && e.navigationStart,
      i = typeof t == 'number' && typeof r.now == 'function' ? t + r.now() : Date.now();
     return Math.round(i);
    },
   },
   A = oa;
  var ee = function () {
    var e, t, i;
    if (typeof ((e = Ge.default.crypto) === null || e === void 0 ? void 0 : e.getRandomValues) == 'function') {
     (i = new Uint8Array(32)), Ge.default.crypto.getRandomValues(i);
     for (var a = 0; a < 32; a++) i[a] = i[a] % 16;
    } else {
     i = [];
     for (var n = 0; n < 32; n++) i[n] = (Math.random() * 16) | 0;
    }
    var o = 0;
    t = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (f) {
     var g = f === 'x' ? i[o] : (i[o] & 3) | 8;
     return o++, g.toString(16);
    });
    var s = A.now(),
     u = s == null ? void 0 : s.toString(16).substring(3);
    return u ? t.substring(0, 28) + u : t;
   },
   Oe = function () {
    return ('000000' + ((Math.random() * Math.pow(36, 6)) << 0).toString(36)).slice(-6);
   };
  var Q = function (e) {
    if (e && typeof e.nodeName != 'undefined') return e.muxId || (e.muxId = Oe()), e.muxId;
    var t;
    try {
     t = document.querySelector(e);
    } catch (i) {}
    return t && !t.muxId && (t.muxId = e), (t == null ? void 0 : t.muxId) || e;
   },
   se = function (e) {
    var t;
    e && typeof e.nodeName != 'undefined' ? ((t = e), (e = Q(t))) : (t = document.querySelector(e));
    var i = t && t.nodeName ? t.nodeName.toLowerCase() : '';
    return [t, e, i];
   };
  function bt(r) {
   if (Array.isArray(r)) return ke(r);
  }
  function wt(r) {
   if ((typeof Symbol != 'undefined' && r[Symbol.iterator] != null) || r['@@iterator'] != null) return Array.from(r);
  }
  function Tt() {
   throw new TypeError('Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.');
  }
  function j(r) {
   return bt(r) || wt(r) || Ae(r) || Tt();
  }
  var Y = { TRACE: 0, DEBUG: 1, INFO: 2, WARN: 3, ERROR: 4, SILENT: 5 },
   Et = function (r) {
    var e = arguments.length > 1 && arguments[1] !== void 0 ? arguments[1] : 3,
     t,
     i,
     a,
     n,
     o,
     s = r ? [console, r] : [console],
     u = (t = console.trace).bind.apply(t, j(s)),
     f = (i = console.info).bind.apply(i, j(s)),
     g = (a = console.debug).bind.apply(a, j(s)),
     k = (n = console.warn).bind.apply(n, j(s)),
     h = (o = console.error).bind.apply(o, j(s)),
     c = e;
    return {
     trace: function () {
      for (var w = arguments.length, x = new Array(w), m = 0; m < w; m++) x[m] = arguments[m];
      if (!(c > Y.TRACE)) return u.apply(void 0, j(x));
     },
     debug: function () {
      for (var w = arguments.length, x = new Array(w), m = 0; m < w; m++) x[m] = arguments[m];
      if (!(c > Y.DEBUG)) return g.apply(void 0, j(x));
     },
     info: function () {
      for (var w = arguments.length, x = new Array(w), m = 0; m < w; m++) x[m] = arguments[m];
      if (!(c > Y.INFO)) return f.apply(void 0, j(x));
     },
     warn: function () {
      for (var w = arguments.length, x = new Array(w), m = 0; m < w; m++) x[m] = arguments[m];
      if (!(c > Y.WARN)) return k.apply(void 0, j(x));
     },
     error: function () {
      for (var w = arguments.length, x = new Array(w), m = 0; m < w; m++) x[m] = arguments[m];
      if (!(c > Y.ERROR)) return h.apply(void 0, j(x));
     },
     get level() {
      return c;
     },
     set level(v) {
      v !== this.level && (c = v != null ? v : e);
     },
    };
   };
  var q = Et('[mux]');
  var Pe = V(J());
  function ce() {
   var r = Pe.default.doNotTrack || (Pe.default.navigator && Pe.default.navigator.doNotTrack);
   return r === '1';
  }
  function b(r) {
   if (r === void 0) throw new ReferenceError("this hasn't been initialised - super() hasn't been called");
   return r;
  }
  te();
  function D(r, e) {
   if (!U(r, e)) throw new TypeError('Cannot call a class as a function');
  }
  function kt(r, e) {
   for (var t = 0; t < e.length; t++) {
    var i = e[t];
    (i.enumerable = i.enumerable || !1), (i.configurable = !0), 'value' in i && (i.writable = !0), Object.defineProperty(r, i.key, i);
   }
  }
  function N(r, e, t) {
   return e && kt(r.prototype, e), t && kt(r, t), r;
  }
  function l(r, e, t) {
   return e in r ? Object.defineProperty(r, e, { value: t, enumerable: !0, configurable: !0, writable: !0 }) : (r[e] = t), r;
  }
  function X(r) {
   return (
    (X = Object.setPrototypeOf
     ? Object.getPrototypeOf
     : function (t) {
        return t.__proto__ || Object.getPrototypeOf(t);
       }),
    X(r)
   );
  }
  function xt(r, e) {
   for (; !Object.prototype.hasOwnProperty.call(r, e) && ((r = X(r)), r !== null); );
   return r;
  }
  function De(r, e, t) {
   return (
    typeof Reflect != 'undefined' && Reflect.get
     ? (De = Reflect.get)
     : (De = function (a, n, o) {
        var s = xt(a, n);
        if (s) {
         var u = Object.getOwnPropertyDescriptor(s, n);
         return u.get ? u.get.call(o || a) : u.value;
        }
       }),
    De(r, e, t || r)
   );
  }
  function Ie(r, e) {
   return (
    (Ie =
     Object.setPrototypeOf ||
     function (i, a) {
      return (i.__proto__ = a), i;
     }),
    Ie(r, e)
   );
  }
  function Dt(r, e) {
   if (typeof e != 'function' && e !== null) throw new TypeError('Super expression must either be null or a function');
   (r.prototype = Object.create(e && e.prototype, { constructor: { value: r, writable: !0, configurable: !0 } })), e && Ie(r, e);
  }
  function St(r, e) {
   if (r == null) return {};
   var t = {},
    i = Object.keys(r),
    a,
    n;
   for (n = 0; n < i.length; n++) (a = i[n]), !(e.indexOf(a) >= 0) && (t[a] = r[a]);
   return t;
  }
  function Rt(r, e) {
   if (r == null) return {};
   var t = St(r, e),
    i,
    a;
   if (Object.getOwnPropertySymbols) {
    var n = Object.getOwnPropertySymbols(r);
    for (a = 0; a < n.length; a++) (i = n[a]), !(e.indexOf(i) >= 0) && Object.prototype.propertyIsEnumerable.call(r, i) && (t[i] = r[i]);
   }
   return t;
  }
  function qt() {
   if (typeof Reflect == 'undefined' || !Reflect.construct || Reflect.construct.sham) return !1;
   if (typeof Proxy == 'function') return !0;
   try {
    return Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})), !0;
   } catch (r) {
    return !1;
   }
  }
  Je();
  function At(r, e) {
   return e && (Le(e) === 'object' || typeof e == 'function') ? e : b(r);
  }
  function Ot(r) {
   var e = qt();
   return function () {
    var i = X(r),
     a;
    if (e) {
     var n = X(this).constructor;
     a = Reflect.construct(i, arguments, n);
    } else a = i.apply(this, arguments);
    return At(this, a);
   };
  }
  var F = function (r) {
   return re(r)[0];
  };
  var re = function (r) {
   if (typeof r != 'string' || r === '') return ['localhost'];
   var e = /^(([^:\/?#]+):)?(\/\/([^\/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?/,
    t = r.match(e) || [],
    i = t[4],
    a;
   return i && (a = (i.match(/[^\.]+\.[^\.]+$/) || [])[0]), [i, a];
  };
  var Ne = V(J()),
   sa = {
    exists: function () {
     var r = Ne.default.performance,
      e = r && r.timing;
     return e !== void 0;
    },
    domContentLoadedEventEnd: function () {
     var r = Ne.default.performance,
      e = r && r.timing;
     return e && e.domContentLoadedEventEnd;
    },
    navigationStart: function () {
     var r = Ne.default.performance,
      e = r && r.timing;
     return e && e.navigationStart;
    },
   },
   _e = sa;
  function O(r, e, t) {
   (t = t === void 0 ? 1 : t), (r[e] = r[e] || 0), (r[e] += t);
  }
  function ue(r) {
   for (var e = 1; e < arguments.length; e++) {
    var t = arguments[e] != null ? arguments[e] : {},
     i = Object.keys(t);
    typeof Object.getOwnPropertySymbols == 'function' &&
     (i = i.concat(
      Object.getOwnPropertySymbols(t).filter(function (a) {
       return Object.getOwnPropertyDescriptor(t, a).enumerable;
      }),
     )),
     i.forEach(function (a) {
      l(r, a, t[a]);
     });
   }
   return r;
  }
  function ua(r, e) {
   var t = Object.keys(r);
   if (Object.getOwnPropertySymbols) {
    var i = Object.getOwnPropertySymbols(r);
    e &&
     (i = i.filter(function (a) {
      return Object.getOwnPropertyDescriptor(r, a).enumerable;
     })),
     t.push.apply(t, i);
   }
   return t;
  }
  function fe(r, e) {
   return (
    (e = e != null ? e : {}),
    Object.getOwnPropertyDescriptors
     ? Object.defineProperties(r, Object.getOwnPropertyDescriptors(e))
     : ua(Object(e)).forEach(function (t) {
        Object.defineProperty(r, t, Object.getOwnPropertyDescriptor(e, t));
       }),
    r
   );
  }
  var da = ['x-cdn', 'content-type'],
   Pt = ['x-request-id', 'cf-ray', 'x-amz-cf-id', 'x-akamai-request-id'],
   la = da.concat(Pt);
  function pe(r) {
   r = r || '';
   var e = {},
    t = r.trim().split(/[\r\n]+/);
   return (
    t.forEach(function (i) {
     if (i) {
      var a = i.split(': '),
       n = a.shift();
      n && (la.indexOf(n.toLowerCase()) >= 0 || n.toLowerCase().indexOf('x-litix-') === 0) && (e[n] = a.join(': '));
     }
    }),
    e
   );
  }
  function de(r) {
   if (r) {
    var e = Pt.find(function (t) {
     return r[t] !== void 0;
    });
    return e ? r[e] : void 0;
   }
  }
  var ca = function (r) {
    var e = {};
    for (var t in r) {
     var i = r[t],
      a = i['DATA-ID'].search('io.litix.data.');
     if (a !== -1) {
      var n = i['DATA-ID'].replace('io.litix.data.', '');
      e[n] = i.VALUE;
     }
    }
    return e;
   },
   Ce = ca;
  var Me = function (r) {
    if (!r) return {};
    var e = _e.navigationStart(),
     t = r.loading,
     i = t ? t.start : r.trequest,
     a = t ? t.first : r.tfirst,
     n = t ? t.end : r.tload;
    return { bytesLoaded: r.total, requestStart: Math.round(e + i), responseStart: Math.round(e + a), responseEnd: Math.round(e + n) };
   },
   Se = function (r) {
    if (!(!r || typeof r.getAllResponseHeaders != 'function')) return pe(r.getAllResponseHeaders());
   },
   It = function (r, e, t) {
    var i = arguments.length > 3 && arguments[3] !== void 0 ? arguments[3] : {},
     a = arguments.length > 4 ? arguments[4] : void 0,
     n = r.log,
     o = r.utils.secondsToMs,
     s = function (m) {
      var p = parseInt(a.version),
       _;
      return p === 1 && m.programDateTime !== null && (_ = m.programDateTime), p === 0 && m.pdt !== null && (_ = m.pdt), _;
     };
    if (!_e.exists()) {
     n.warn('performance timing not supported. Not tracking HLS.js.');
     return;
    }
    var u = function (m, p) {
      return r.emit(e, m, p);
     },
     f = function (m, p) {
      var _ = p.levels,
       d = p.audioTracks,
       y = p.url,
       T = p.stats,
       E = p.networkDetails,
       S = p.sessionData,
       L = {},
       M = {};
      _.forEach(function (G, oe) {
       L[oe] = { width: G.width, height: G.height, bitrate: G.bitrate, attrs: G.attrs };
      }),
       d.forEach(function (G, oe) {
        M[oe] = { name: G.name, language: G.lang, bitrate: G.bitrate };
       });
      var P = Me(T),
       R = P.bytesLoaded,
       Z = P.requestStart,
       we = P.responseStart,
       Te = P.responseEnd;
      u('requestcompleted', fe(ue({}, Ce(S)), { request_event_type: m, request_bytes_loaded: R, request_start: Z, request_response_start: we, request_response_end: Te, request_type: 'manifest', request_hostname: F(y), request_response_headers: Se(E), request_rendition_lists: { media: L, audio: M, video: {} } }));
     };
    t.on(a.Events.MANIFEST_LOADED, f);
    var g = function (m, p) {
     var _ = p.details,
      d = p.level,
      y = p.networkDetails,
      T = p.stats,
      E = Me(T),
      S = E.bytesLoaded,
      L = E.requestStart,
      M = E.responseStart,
      P = E.responseEnd,
      R = _.fragments[_.fragments.length - 1],
      Z = s(R) + o(R.duration);
     u('requestcompleted', { request_event_type: m, request_bytes_loaded: S, request_start: L, request_response_start: M, request_response_end: P, request_current_level: d, request_type: 'manifest', request_hostname: F(_.url), request_response_headers: Se(y), video_holdback: _.holdBack && o(_.holdBack), video_part_holdback: _.partHoldBack && o(_.partHoldBack), video_part_target_duration: _.partTarget && o(_.partTarget), video_target_duration: _.targetduration && o(_.targetduration), video_source_is_live: _.live, player_manifest_newest_program_time: isNaN(Z) ? void 0 : Z });
    };
    t.on(a.Events.LEVEL_LOADED, g);
    var k = function (m, p) {
     var _ = p.details,
      d = p.networkDetails,
      y = p.stats,
      T = Me(y),
      E = T.bytesLoaded,
      S = T.requestStart,
      L = T.responseStart,
      M = T.responseEnd;
     u('requestcompleted', { request_event_type: m, request_bytes_loaded: E, request_start: S, request_response_start: L, request_response_end: M, request_type: 'manifest', request_hostname: F(_.url), request_response_headers: Se(d) });
    };
    t.on(a.Events.AUDIO_TRACK_LOADED, k);
    var h = function (m, p) {
     var _ = p.stats,
      d = p.networkDetails,
      y = p.frag;
     _ = _ || y.stats;
     var T = Me(_),
      E = T.bytesLoaded,
      S = T.requestStart,
      L = T.responseStart,
      M = T.responseEnd,
      P = d ? Se(d) : void 0,
      R = { request_event_type: m, request_bytes_loaded: E, request_start: S, request_response_start: L, request_response_end: M, request_hostname: d ? F(d.responseURL) : void 0, request_id: P ? de(P) : void 0, request_response_headers: P, request_media_duration: y.duration, request_url: d == null ? void 0 : d.responseURL };
     y.type === 'main' ? ((R.request_type = 'media'), (R.request_current_level = y.level), (R.request_video_width = (t.levels[y.level] || {}).width), (R.request_video_height = (t.levels[y.level] || {}).height), (R.request_labeled_bitrate = (t.levels[y.level] || {}).bitrate)) : (R.request_type = y.type), u('requestcompleted', R);
    };
    t.on(a.Events.FRAG_LOADED, h);
    var c = function (m, p) {
     var _ = p.frag,
      d = _.start,
      y = s(_),
      T = { currentFragmentPDT: y, currentFragmentStart: o(d) };
     u('fragmentchange', T);
    };
    t.on(a.Events.FRAG_CHANGED, c);
    var v = function (m, p) {
     var _ = p.type,
      d = p.details,
      y = p.response,
      T = p.fatal,
      E = p.frag,
      S = p.networkDetails,
      L = (E == null ? void 0 : E.url) || p.url || '',
      M = S ? Se(S) : void 0;
     if (((d === a.ErrorDetails.MANIFEST_LOAD_ERROR || d === a.ErrorDetails.MANIFEST_LOAD_TIMEOUT || d === a.ErrorDetails.FRAG_LOAD_ERROR || d === a.ErrorDetails.FRAG_LOAD_TIMEOUT || d === a.ErrorDetails.LEVEL_LOAD_ERROR || d === a.ErrorDetails.LEVEL_LOAD_TIMEOUT || d === a.ErrorDetails.AUDIO_TRACK_LOAD_ERROR || d === a.ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT || d === a.ErrorDetails.SUBTITLE_LOAD_ERROR || d === a.ErrorDetails.SUBTITLE_LOAD_TIMEOUT || d === a.ErrorDetails.KEY_LOAD_ERROR || d === a.ErrorDetails.KEY_LOAD_TIMEOUT) && u('requestfailed', { request_error: d, request_url: L, request_hostname: F(L), request_id: M ? de(M) : void 0, request_type: d === a.ErrorDetails.FRAG_LOAD_ERROR || d === a.ErrorDetails.FRAG_LOAD_TIMEOUT ? 'media' : d === a.ErrorDetails.AUDIO_TRACK_LOAD_ERROR || d === a.ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT ? 'audio' : d === a.ErrorDetails.SUBTITLE_LOAD_ERROR || d === a.ErrorDetails.SUBTITLE_LOAD_TIMEOUT ? 'subtitle' : d === a.ErrorDetails.KEY_LOAD_ERROR || d === a.ErrorDetails.KEY_LOAD_TIMEOUT ? 'encryption' : 'manifest', request_error_code: y == null ? void 0 : y.code, request_error_text: y == null ? void 0 : y.text }), T)) {
      var P,
       R = ''.concat(L ? 'url: '.concat(L, '\n') : '') + ''.concat(y && (y.code || y.text) ? 'response: '.concat(y.code, ', ').concat(y.text, '\n') : '') + ''.concat(p.reason ? 'failure reason: '.concat(p.reason, '\n') : '') + ''.concat(p.level ? 'level: '.concat(p.level, '\n') : '') + ''.concat(p.parent ? 'parent stream controller: '.concat(p.parent, '\n') : '') + ''.concat(p.buffer ? 'buffer length: '.concat(p.buffer, '\n') : '') + ''.concat(p.error ? 'error: '.concat(p.error, '\n') : '') + ''.concat(p.event ? 'event: '.concat(p.event, '\n') : '') + ''.concat(p.err ? 'error message: '.concat((P = p.err) === null || P === void 0 ? void 0 : P.message, '\n') : '');
      u('error', { player_error_code: _, player_error_message: d, player_error_context: R });
     }
    };
    t.on(a.Events.ERROR, v);
    var w = function (m, p) {
     var _ = p.frag,
      d = (_ && _._url) || '';
     u('requestcanceled', { request_event_type: m, request_url: d, request_type: 'media', request_hostname: F(d) });
    };
    t.on(a.Events.FRAG_LOAD_EMERGENCY_ABORTED, w);
    var x = function (m, p) {
     var _ = p.level,
      d = t.levels[_];
     if (d && d.attrs && d.attrs.BANDWIDTH) {
      var y = d.attrs.BANDWIDTH,
       T,
       E = parseFloat(d.attrs['FRAME-RATE']);
      isNaN(E) || (T = E), y ? u('renditionchange', { video_source_fps: T, video_source_bitrate: y, video_source_width: d.width, video_source_height: d.height, video_source_rendition_name: d.name, video_source_codec: d == null ? void 0 : d.videoCodec }) : n.warn('missing BANDWIDTH from HLS manifest parsed by HLS.js');
     }
    };
    t.on(a.Events.LEVEL_SWITCHED, x),
     (t._stopMuxMonitor = function () {
      t.off(a.Events.MANIFEST_LOADED, f), t.off(a.Events.LEVEL_LOADED, g), t.off(a.Events.AUDIO_TRACK_LOADED, k), t.off(a.Events.FRAG_LOADED, h), t.off(a.Events.FRAG_CHANGED, c), t.off(a.Events.ERROR, v), t.off(a.Events.FRAG_LOAD_EMERGENCY_ABORTED, w), t.off(a.Events.LEVEL_SWITCHED, x), t.off(a.Events.DESTROYING, t._stopMuxMonitor), delete t._stopMuxMonitor;
     }),
     t.on(a.Events.DESTROYING, t._stopMuxMonitor);
   },
   Lt = function (r) {
    r && typeof r._stopMuxMonitor == 'function' && r._stopMuxMonitor();
   };
  var Nt = function (r, e) {
    if (!r || !r.requestEndDate) return {};
    var t = F(r.url),
     i = r.url,
     a = r.bytesLoaded,
     n = new Date(r.requestStartDate).getTime(),
     o = new Date(r.firstByteDate).getTime(),
     s = new Date(r.requestEndDate).getTime(),
     u = isNaN(r.duration) ? 0 : r.duration,
     f = typeof e.getMetricsFor == 'function' ? e.getMetricsFor(r.mediaType).HttpList : e.getDashMetrics().getHttpRequests(r.mediaType),
     g;
    f.length > 0 && (g = pe(f[f.length - 1]._responseHeaders || ''));
    var k = g ? de(g) : void 0;
    return { requestStart: n, requestResponseStart: o, requestResponseEnd: s, requestBytesLoaded: a, requestResponseHeaders: g, requestMediaDuration: u, requestHostname: t, requestUrl: i, requestId: k };
   },
   _a = function (r, e) {
    var t = e.getQualityFor(r),
     i = e.getCurrentTrackFor(r).bitrateList;
    return i ? { currentLevel: t, renditionWidth: i[t].width || null, renditionHeight: i[t].height || null, renditionBitrate: i[t].bandwidth } : {};
   },
   fa = function (r) {
    var e;
    return (e = r.match(/.*codecs\*?="(.*)"/)) === null || e === void 0 ? void 0 : e[1];
   },
   pa = function (e) {
    try {
     var t,
      i,
      a =
       (i = e.getVersion) === null || i === void 0 || (t = i.call(e)) === null || t === void 0
        ? void 0
        : t.split('.').map(function (n) {
           return parseInt(n);
          })[0];
     return a;
    } catch (n) {
     return !1;
    }
   },
   Ct = function (r, e, t) {
    var i = arguments.length > 3 && arguments[3] !== void 0 ? arguments[3] : {},
     a = r.log;
    if (!t || !t.on) {
     a.warn('Invalid dash.js player reference. Monitoring blocked.');
     return;
    }
    var n = pa(t),
     o = function (_, d) {
      return r.emit(e, _, d);
     },
     s = function (_) {
      var d = _.type,
       y = _.data,
       T = (y || {}).url;
      o('requestcompleted', { request_event_type: d, request_start: 0, request_response_start: 0, request_response_end: 0, request_bytes_loaded: -1, request_type: 'manifest', request_hostname: F(T), request_url: T });
     };
    t.on('manifestLoaded', s);
    var u = {},
     f = function (_) {
      if (typeof _.getRequests != 'function') return null;
      var d = _.getRequests({ state: 'executed' });
      return d.length === 0 ? null : d[d.length - 1];
     },
     g = function (_) {
      var d = _.type,
       y = _.fragmentModel,
       T = _.chunk,
       E = f(y);
      k({ type: d, request: E, chunk: T });
     },
     k = function (_) {
      var d = _.type,
       y = _.chunk,
       T = _.request,
       E = (y || {}).mediaInfo,
       S = E || {},
       L = S.type,
       M = S.bitrateList;
      M = M || [];
      var P = {};
      M.forEach(function (Ee, z) {
       (P[z] = {}), (P[z].width = Ee.width), (P[z].height = Ee.height), (P[z].bitrate = Ee.bandwidth), (P[z].attrs = {});
      }),
       L === 'video' ? (u.video = P) : L === 'audio' ? (u.audio = P) : (u.media = P);
      var R = Nt(T, t),
       Z = R.requestStart,
       we = R.requestResponseStart,
       Te = R.requestResponseEnd,
       G = R.requestResponseHeaders,
       oe = R.requestMediaDuration,
       Ve = R.requestHostname,
       je = R.requestUrl,
       We = R.requestId;
      o('requestcompleted', { request_event_type: d, request_start: Z, request_response_start: we, request_response_end: Te, request_bytes_loaded: -1, request_type: L + '_init', request_response_headers: G, request_hostname: Ve, request_id: We, request_url: je, request_media_duration: oe, request_rendition_lists: u });
     };
    n >= 4 ? t.on('initFragmentLoaded', k) : t.on('initFragmentLoaded', g);
    var h = function (_) {
      var d = _.type,
       y = _.fragmentModel,
       T = _.chunk,
       E = f(y);
      c({ type: d, request: E, chunk: T });
     },
     c = function (_) {
      var d = _.type,
       y = _.chunk,
       T = _.request,
       E = y || {},
       S = E.mediaInfo,
       L = E.start,
       M = S || {},
       P = M.type,
       R = Nt(T, t),
       Z = R.requestStart,
       we = R.requestResponseStart,
       Te = R.requestResponseEnd,
       G = R.requestBytesLoaded,
       oe = R.requestResponseHeaders,
       Ve = R.requestMediaDuration,
       je = R.requestHostname,
       We = R.requestUrl,
       Ee = R.requestId,
       z = _a(P, t),
       Yr = z.currentLevel,
       Xr = z.renditionWidth,
       $r = z.renditionHeight,
       Zr = z.renditionBitrate;
      o('requestcompleted', { request_event_type: d, request_start: Z, request_response_start: we, request_response_end: Te, request_bytes_loaded: G, request_type: P, request_response_headers: oe, request_hostname: je, request_id: Ee, request_url: We, request_media_start_time: L, request_media_duration: Ve, request_current_level: Yr, request_labeled_bitrate: Zr, request_video_width: Xr, request_video_height: $r });
     };
    n >= 4 ? t.on('mediaFragmentLoaded', c) : t.on('mediaFragmentLoaded', h);
    var v = { video: void 0, audio: void 0, totalBitrate: void 0 },
     w = function () {
      if (v.video && typeof v.video.bitrate == 'number') {
       if (!(v.video.width && v.video.height)) {
        a.warn('have bitrate info for video but missing width/height');
        return;
       }
       var _ = v.video.bitrate;
       if ((v.audio && typeof v.audio.bitrate == 'number' && (_ += v.audio.bitrate), _ !== v.totalBitrate)) return (v.totalBitrate = _), { video_source_bitrate: _, video_source_height: v.video.height, video_source_width: v.video.width, video_source_codec: fa(v.video.codec) };
      }
     },
     x = function (_, d, y) {
      if (typeof _.newQuality != 'number') {
       a.warn('missing evt.newQuality in qualityChangeRendered event', _);
       return;
      }
      var T = _.mediaType;
      if (T === 'audio' || T === 'video') {
       var E = t.getBitrateInfoListFor(T).find(function (L) {
        var M = L.qualityIndex;
        return M === _.newQuality;
       });
       if (!(E && typeof E.bitrate == 'number')) {
        a.warn('missing bitrate info for '.concat(T));
        return;
       }
       v[T] = fe(ue({}, E), { codec: t.getCurrentTrackFor(T).codec });
       var S = w();
       S && o('renditionchange', S);
      }
     };
    t.on('qualityChangeRendered', x);
    var m = function (_) {
     var d = _.request,
      y = _.mediaType;
     (d = d || {}), o('requestcanceled', { request_event_type: d.type + '_' + d.action, request_url: d.url, request_type: y, request_hostname: F(d.url) });
    };
    t.on('fragmentLoadingAbandoned', m);
    var p = function (_) {
     var d = _.error,
      y,
      T,
      E = (d == null || (y = d.data) === null || y === void 0 ? void 0 : y.request) || {},
      S = (d == null || (T = d.data) === null || T === void 0 ? void 0 : T.response) || {};
     (d == null ? void 0 : d.code) === 27 && o('requestfailed', { request_error: E.type + '_' + E.action, request_url: E.url, request_hostname: F(E.url), request_type: E.mediaType, request_error_code: S.status, request_error_text: S.statusText });
     var L = ''.concat(E != null && E.url ? 'url: '.concat(E.url, '\n') : '') + ''.concat((S != null && S.status) || (S != null && S.statusText) ? 'response: '.concat(S == null ? void 0 : S.status, ', ').concat(S == null ? void 0 : S.statusText, '\n') : '');
     o('error', { player_error_code: d == null ? void 0 : d.code, player_error_message: d == null ? void 0 : d.message, player_error_context: L });
    };
    t.on('error', p),
     (t._stopMuxMonitor = function () {
      t.off('manifestLoaded', s), t.off('initFragmentLoaded', k), t.off('mediaFragmentLoaded', c), t.off('qualityChangeRendered', x), t.off('error', p), t.off('fragmentLoadingAbandoned', m), delete t._stopMuxMonitor;
     });
   },
   Mt = function (r) {
    r && typeof r._stopMuxMonitor == 'function' && r._stopMuxMonitor();
   };
  var Ht = 0,
   va = (function () {
    'use strict';
    function r() {
     D(this, r), l(this, '_listeners', void 0);
    }
    return (
     N(r, [
      {
       key: 'on',
       value: function (t, i, a) {
        return (i._eventEmitterGuid = i._eventEmitterGuid || ++Ht), (this._listeners = this._listeners || {}), (this._listeners[t] = this._listeners[t] || []), a && (i = i.bind(a)), this._listeners[t].push(i), i;
       },
      },
      {
       key: 'off',
       value: function (t, i) {
        var a = this._listeners && this._listeners[t];
        a &&
         a.forEach(function (n, o) {
          n._eventEmitterGuid === i._eventEmitterGuid && a.splice(o, 1);
         });
       },
      },
      {
       key: 'one',
       value: function (t, i, a) {
        var n = this;
        i._eventEmitterGuid = i._eventEmitterGuid || ++Ht;
        var o = function () {
         n.off(t, o), i.apply(a || this, arguments);
        };
        (o._eventEmitterGuid = i._eventEmitterGuid), this.on(t, o);
       },
      },
      {
       key: 'emit',
       value: function (t, i) {
        var a = this;
        if (this._listeners) {
         i = i || {};
         var n = this._listeners['before' + t] || [],
          o = this._listeners['before*'] || [],
          s = this._listeners[t] || [],
          u = this._listeners['after' + t] || [],
          f = function (g, k) {
           (g = g.slice()),
            g.forEach(function (h) {
             h.call(a, { type: t }, k);
            });
          };
         f(n, i), f(o, i), f(s, i), f(u, i);
        }
       },
      },
     ]),
     r
    );
   })(),
   Bt = va;
  var He = V(J()),
   ma = (function () {
    'use strict';
    function r(e) {
     var t = this;
     D(this, r),
      l(this, '_playbackHeartbeatInterval', void 0),
      l(this, '_playheadShouldBeProgressing', void 0),
      l(this, 'pm', void 0),
      (this.pm = e),
      (this._playbackHeartbeatInterval = null),
      (this._playheadShouldBeProgressing = !1),
      e.on('playing', function () {
       t._playheadShouldBeProgressing = !0;
      }),
      e.on('play', this._startPlaybackHeartbeatInterval.bind(this)),
      e.on('playing', this._startPlaybackHeartbeatInterval.bind(this)),
      e.on('adbreakstart', this._startPlaybackHeartbeatInterval.bind(this)),
      e.on('adplay', this._startPlaybackHeartbeatInterval.bind(this)),
      e.on('adplaying', this._startPlaybackHeartbeatInterval.bind(this)),
      e.on('devicewake', this._startPlaybackHeartbeatInterval.bind(this)),
      e.on('viewstart', this._startPlaybackHeartbeatInterval.bind(this)),
      e.on('rebufferstart', this._startPlaybackHeartbeatInterval.bind(this)),
      e.on('pause', this._stopPlaybackHeartbeatInterval.bind(this)),
      e.on('ended', this._stopPlaybackHeartbeatInterval.bind(this)),
      e.on('viewend', this._stopPlaybackHeartbeatInterval.bind(this)),
      e.on('error', this._stopPlaybackHeartbeatInterval.bind(this)),
      e.on('aderror', this._stopPlaybackHeartbeatInterval.bind(this)),
      e.on('adpause', this._stopPlaybackHeartbeatInterval.bind(this)),
      e.on('adended', this._stopPlaybackHeartbeatInterval.bind(this)),
      e.on('adbreakend', this._stopPlaybackHeartbeatInterval.bind(this)),
      e.on('seeked', function () {
       e.data.player_is_paused ? t._stopPlaybackHeartbeatInterval() : t._startPlaybackHeartbeatInterval();
      }),
      e.on('timeupdate', function () {
       t._playbackHeartbeatInterval !== null && e.emit('playbackheartbeat');
      }),
      e.on('devicesleep', function (i, a) {
       t._playbackHeartbeatInterval !== null && (He.default.clearInterval(t._playbackHeartbeatInterval), e.emit('playbackheartbeatend', { viewer_time: a.viewer_time }), (t._playbackHeartbeatInterval = null));
      });
    }
    return (
     N(r, [
      {
       key: '_startPlaybackHeartbeatInterval',
       value: function () {
        var t = this;
        this._playbackHeartbeatInterval === null &&
         (this.pm.emit('playbackheartbeat'),
         (this._playbackHeartbeatInterval = He.default.setInterval(function () {
          t.pm.emit('playbackheartbeat');
         }, this.pm.playbackHeartbeatTime)));
       },
      },
      {
       key: '_stopPlaybackHeartbeatInterval',
       value: function () {
        (this._playheadShouldBeProgressing = !1), this._playbackHeartbeatInterval !== null && (He.default.clearInterval(this._playbackHeartbeatInterval), this.pm.emit('playbackheartbeatend'), (this._playbackHeartbeatInterval = null));
       },
      },
     ]),
     r
    );
   })(),
   Ut = ma;
  var ha = function r(e) {
    'use strict';
    var t = this;
    D(this, r),
     l(this, 'viewErrored', void 0),
     e.on('viewinit', function () {
      t.viewErrored = !1;
     }),
     e.on('error', function (i, a) {
      try {
       var n = e.errorTranslator({ player_error_code: a.player_error_code, player_error_message: a.player_error_message, player_error_context: a.player_error_context, player_error_severity: a.player_error_severity, player_error_business_exception: a.player_error_business_exception });
       n && ((e.data.player_error_code = n.player_error_code || a.player_error_code), (e.data.player_error_message = n.player_error_message || a.player_error_message), (e.data.player_error_context = n.player_error_context || a.player_error_context), (e.data.player_error_severity = n.player_error_severity || a.player_error_severity), (e.data.player_error_business_exception = n.player_error_business_exception || a.player_error_business_exception), (t.viewErrored = !0));
      } catch (o) {
       e.mux.log.warn('Exception in error translator callback.', o), (t.viewErrored = !0);
      }
     }),
     e.on('aftererror', function () {
      var i, a, n, o, s;
      (i = e.data) === null || i === void 0 || delete i.player_error_code, (a = e.data) === null || a === void 0 || delete a.player_error_message, (n = e.data) === null || n === void 0 || delete n.player_error_context, (o = e.data) === null || o === void 0 || delete o.player_error_severity, (s = e.data) === null || s === void 0 || delete s.player_error_business_exception;
     });
   },
   Ft = ha;
  var ya = (function () {
    'use strict';
    function r(e) {
     D(this, r), l(this, '_watchTimeTrackerLastCheckedTime', void 0), l(this, 'pm', void 0), (this.pm = e), (this._watchTimeTrackerLastCheckedTime = null), e.on('playbackheartbeat', this._updateWatchTime.bind(this)), e.on('playbackheartbeatend', this._clearWatchTimeState.bind(this));
    }
    return (
     N(r, [
      {
       key: '_updateWatchTime',
       value: function (t, i) {
        var a = i.viewer_time;
        this._watchTimeTrackerLastCheckedTime === null && (this._watchTimeTrackerLastCheckedTime = a), O(this.pm.data, 'view_watch_time', a - this._watchTimeTrackerLastCheckedTime), (this._watchTimeTrackerLastCheckedTime = a);
       },
      },
      {
       key: '_clearWatchTimeState',
       value: function (t, i) {
        this._updateWatchTime(t, i), (this._watchTimeTrackerLastCheckedTime = null);
       },
      },
     ]),
     r
    );
   })(),
   Vt = ya;
  var ga = (function () {
    'use strict';
    function r(e) {
     var t = this;
     D(this, r), l(this, '_playbackTimeTrackerLastPlayheadPosition', void 0), l(this, '_lastTime', void 0), l(this, '_isAdPlaying', void 0), l(this, '_callbackUpdatePlaybackTime', void 0), l(this, 'pm', void 0), (this.pm = e), (this._playbackTimeTrackerLastPlayheadPosition = -1), (this._lastTime = A.now()), (this._isAdPlaying = !1), (this._callbackUpdatePlaybackTime = null);
     var i = this._startPlaybackTimeTracking.bind(this);
     e.on('playing', i), e.on('adplaying', i), e.on('seeked', i);
     var a = this._stopPlaybackTimeTracking.bind(this);
     e.on('playbackheartbeatend', a),
      e.on('seeking', a),
      e.on('adplaying', function () {
       t._isAdPlaying = !0;
      }),
      e.on('adended', function () {
       t._isAdPlaying = !1;
      }),
      e.on('adpause', function () {
       t._isAdPlaying = !1;
      }),
      e.on('adbreakstart', function () {
       t._isAdPlaying = !1;
      }),
      e.on('adbreakend', function () {
       t._isAdPlaying = !1;
      }),
      e.on('adplay', function () {
       t._isAdPlaying = !1;
      }),
      e.on('viewinit', function () {
       (t._playbackTimeTrackerLastPlayheadPosition = -1), (t._lastTime = A.now()), (t._isAdPlaying = !1), (t._callbackUpdatePlaybackTime = null);
      });
    }
    return (
     N(r, [
      {
       key: '_startPlaybackTimeTracking',
       value: function () {
        this._callbackUpdatePlaybackTime === null && ((this._callbackUpdatePlaybackTime = this._updatePlaybackTime.bind(this)), (this._playbackTimeTrackerLastPlayheadPosition = this.pm.data.player_playhead_time), this.pm.on('playbackheartbeat', this._callbackUpdatePlaybackTime));
       },
      },
      {
       key: '_stopPlaybackTimeTracking',
       value: function () {
        this._callbackUpdatePlaybackTime && (this._updatePlaybackTime(), this.pm.off('playbackheartbeat', this._callbackUpdatePlaybackTime), (this._callbackUpdatePlaybackTime = null), (this._playbackTimeTrackerLastPlayheadPosition = -1));
       },
      },
      {
       key: '_updatePlaybackTime',
       value: function () {
        var t = this.pm.data.player_playhead_time,
         i = A.now(),
         a = -1;
        this._playbackTimeTrackerLastPlayheadPosition >= 0 && t > this._playbackTimeTrackerLastPlayheadPosition ? (a = t - this._playbackTimeTrackerLastPlayheadPosition) : this._isAdPlaying && (a = i - this._lastTime), a > 0 && a <= 1e3 && O(this.pm.data, 'view_content_playback_time', a), (this._playbackTimeTrackerLastPlayheadPosition = t), (this._lastTime = i);
       },
      },
     ]),
     r
    );
   })(),
   jt = ga;
  var ba = (function () {
    'use strict';
    function r(e) {
     D(this, r), l(this, 'pm', void 0), (this.pm = e);
     var t = this._updatePlayheadTime.bind(this);
     e.on('playbackheartbeat', t),
      e.on('playbackheartbeatend', t),
      e.on('timeupdate', t),
      e.on('destroy', function () {
       e.off('timeupdate', t);
      });
    }
    return (
     N(r, [
      {
       key: '_updateMaxPlayheadPosition',
       value: function () {
        this.pm.data.view_max_playhead_position = typeof this.pm.data.view_max_playhead_position == 'undefined' ? this.pm.data.player_playhead_time : Math.max(this.pm.data.view_max_playhead_position, this.pm.data.player_playhead_time);
       },
      },
      {
       key: '_updatePlayheadTime',
       value: function (t, i) {
        var a = this,
         n = function () {
          a.pm.currentFragmentPDT && a.pm.currentFragmentStart && (a.pm.data.player_program_time = a.pm.currentFragmentPDT + a.pm.data.player_playhead_time - a.pm.currentFragmentStart);
         };
        if (i && i.player_playhead_time) (this.pm.data.player_playhead_time = i.player_playhead_time), n(), this._updateMaxPlayheadPosition();
        else if (this.pm.getPlayheadTime) {
         var o = this.pm.getPlayheadTime();
         typeof o != 'undefined' && ((this.pm.data.player_playhead_time = o), n(), this._updateMaxPlayheadPosition());
        }
       },
      },
     ]),
     r
    );
   })(),
   Wt = ba;
  var Gt = 5 * 60 * 1e3,
   wa = function r(e) {
    'use strict';
    if ((D(this, r), !e.disableRebufferTracking)) {
     var t,
      i = function (n, o) {
       a(o), (t = void 0);
      },
      a = function (n) {
       if (t) {
        var o = n.viewer_time - t;
        O(e.data, 'view_rebuffer_duration', o), (t = n.viewer_time), e.data.view_rebuffer_duration > Gt && (e.emit('viewend'), e.send('viewend'), e.mux.log.warn('Ending view after rebuffering for longer than '.concat(Gt, 'ms, future events will be ignored unless a programchange or videochange occurs.')));
       }
       e.data.view_watch_time >= 0 && e.data.view_rebuffer_count > 0 && ((e.data.view_rebuffer_frequency = e.data.view_rebuffer_count / e.data.view_watch_time), (e.data.view_rebuffer_percentage = e.data.view_rebuffer_duration / e.data.view_watch_time));
      };
     e.on('playbackheartbeat', function (n, o) {
      return a(o);
     }),
      e.on('rebufferstart', function (n, o) {
       t || (O(e.data, 'view_rebuffer_count', 1), (t = o.viewer_time), e.one('rebufferend', i));
      }),
      e.on('viewinit', function () {
       (t = void 0), e.off('rebufferend', i);
      });
    }
   },
   Jt = wa;
  var Ta = (function () {
    'use strict';
    function r(e) {
     var t = this;
     D(this, r),
      l(this, '_lastCheckedTime', void 0),
      l(this, '_lastPlayheadTime', void 0),
      l(this, '_lastPlayheadTimeUpdatedTime', void 0),
      l(this, '_rebuffering', void 0),
      l(this, 'pm', void 0),
      (this.pm = e),
      !(e.disableRebufferTracking || e.disablePlayheadRebufferTracking) &&
       ((this._lastCheckedTime = null),
       (this._lastPlayheadTime = null),
       (this._lastPlayheadTimeUpdatedTime = null),
       e.on('playbackheartbeat', this._checkIfRebuffering.bind(this)),
       e.on('playbackheartbeatend', this._cleanupRebufferTracker.bind(this)),
       e.on('seeking', function () {
        t._cleanupRebufferTracker(null, { viewer_time: A.now() });
       }));
    }
    return (
     N(r, [
      {
       key: '_checkIfRebuffering',
       value: function (t, i) {
        if (this.pm.seekingTracker.isSeeking || this.pm.adTracker.isAdBreak || !this.pm.playbackHeartbeat._playheadShouldBeProgressing) {
         this._cleanupRebufferTracker(t, i);
         return;
        }
        if (this._lastCheckedTime === null) {
         this._prepareRebufferTrackerState(i.viewer_time);
         return;
        }
        if (this._lastPlayheadTime !== this.pm.data.player_playhead_time) {
         this._cleanupRebufferTracker(t, i, !0);
         return;
        }
        var a = i.viewer_time - this._lastPlayheadTimeUpdatedTime;
        typeof this.pm.sustainedRebufferThreshold == 'number' && a >= this.pm.sustainedRebufferThreshold && (this._rebuffering || ((this._rebuffering = !0), this.pm.emit('rebufferstart', { viewer_time: this._lastPlayheadTimeUpdatedTime }))), (this._lastCheckedTime = i.viewer_time);
       },
      },
      {
       key: '_clearRebufferTrackerState',
       value: function () {
        (this._lastCheckedTime = null), (this._lastPlayheadTime = null), (this._lastPlayheadTimeUpdatedTime = null);
       },
      },
      {
       key: '_prepareRebufferTrackerState',
       value: function (t) {
        (this._lastCheckedTime = t), (this._lastPlayheadTime = this.pm.data.player_playhead_time), (this._lastPlayheadTimeUpdatedTime = t);
       },
      },
      {
       key: '_cleanupRebufferTracker',
       value: function (t, i) {
        var a = arguments.length > 2 && arguments[2] !== void 0 ? arguments[2] : !1;
        if (this._rebuffering) (this._rebuffering = !1), this.pm.emit('rebufferend', { viewer_time: i.viewer_time });
        else {
         if (this._lastCheckedTime === null) return;
         var n = this.pm.data.player_playhead_time - this._lastPlayheadTime,
          o = i.viewer_time - this._lastPlayheadTimeUpdatedTime;
         typeof this.pm.minimumRebufferDuration == 'number' && n > 0 && o - n > this.pm.minimumRebufferDuration && ((this._lastCheckedTime = null), this.pm.emit('rebufferstart', { viewer_time: this._lastPlayheadTimeUpdatedTime }), this.pm.emit('rebufferend', { viewer_time: this._lastPlayheadTimeUpdatedTime + o - n }));
        }
        a ? this._prepareRebufferTrackerState(i.viewer_time) : this._clearRebufferTrackerState();
       },
      },
     ]),
     r
    );
   })(),
   Qt = Ta;
  var Ea = (function () {
    'use strict';
    function r(e) {
     var t = this;
     D(this, r),
      l(this, 'pm', void 0),
      (this.pm = e),
      e.on('viewinit', function () {
       var i = e.data,
        a = i.view_id;
       if (!i.view_program_changed) {
        var n = function (o, s) {
         var u = s.viewer_time;
         o.type === 'playing' && typeof e.data.view_time_to_first_frame == 'undefined' ? t.calculateTimeToFirstFrame(u || A.now(), a) : o.type === 'adplaying' && (typeof e.data.view_time_to_first_frame == 'undefined' || t._inPrerollPosition()) && t.calculateTimeToFirstFrame(u || A.now(), a);
        };
        e.one('playing', n),
         e.one('adplaying', n),
         e.one('viewend', function () {
          e.off('playing', n), e.off('adplaying', n);
         });
       }
      });
    }
    return (
     N(r, [
      {
       key: '_inPrerollPosition',
       value: function () {
        return typeof this.pm.data.view_content_playback_time == 'undefined' || this.pm.data.view_content_playback_time <= 1e3;
       },
      },
      {
       key: 'calculateTimeToFirstFrame',
       value: function (t, i) {
        i === this.pm.data.view_id && (this.pm.watchTimeTracker._updateWatchTime(null, { viewer_time: t }), (this.pm.data.view_time_to_first_frame = this.pm.data.view_watch_time), (this.pm.data.player_autoplay_on || this.pm.data.video_is_autoplay) && this.pm.pageLoadInitTime && (this.pm.data.view_aggregate_startup_time = this.pm.data.view_start + this.pm.data.view_watch_time - this.pm.pageLoadInitTime));
       },
      },
     ]),
     r
    );
   })(),
   zt = Ea;
  var ka = function r(e) {
    'use strict';
    var t = this;
    D(this, r),
     l(this, '_lastPlayerHeight', void 0),
     l(this, '_lastPlayerWidth', void 0),
     l(this, '_lastPlayheadPosition', void 0),
     l(this, '_lastSourceHeight', void 0),
     l(this, '_lastSourceWidth', void 0),
     e.on('viewinit', function () {
      t._lastPlayheadPosition = -1;
     });
    var i = ['pause', 'rebufferstart', 'seeking', 'error', 'adbreakstart', 'hb', 'renditionchange', 'orientationchange', 'viewend'],
     a = ['playing', 'hb', 'renditionchange', 'orientationchange'];
    i.forEach(function (n) {
     e.on(n, function () {
      if (t._lastPlayheadPosition >= 0 && e.data.player_playhead_time >= 0 && t._lastPlayerWidth >= 0 && t._lastSourceWidth > 0 && t._lastPlayerHeight >= 0 && t._lastSourceHeight > 0) {
       var o = e.data.player_playhead_time - t._lastPlayheadPosition;
       if (o < 0) {
        t._lastPlayheadPosition = -1;
        return;
       }
       var s = Math.min(t._lastPlayerWidth / t._lastSourceWidth, t._lastPlayerHeight / t._lastSourceHeight),
        u = Math.max(0, s - 1),
        f = Math.max(0, 1 - s);
       (e.data.view_max_upscale_percentage = Math.max(e.data.view_max_upscale_percentage || 0, u)), (e.data.view_max_downscale_percentage = Math.max(e.data.view_max_downscale_percentage || 0, f)), O(e.data, 'view_total_content_playback_time', o), O(e.data, 'view_total_upscaling', u * o), O(e.data, 'view_total_downscaling', f * o);
      }
      t._lastPlayheadPosition = -1;
     });
    }),
     a.forEach(function (n) {
      e.on(n, function () {
       (t._lastPlayheadPosition = e.data.player_playhead_time), (t._lastPlayerWidth = e.data.player_width), (t._lastPlayerHeight = e.data.player_height), (t._lastSourceWidth = e.data.video_source_width), (t._lastSourceHeight = e.data.video_source_height);
      });
     });
   },
   Kt = ka;
  var xa = 2e3,
   Da = function r(e) {
    'use strict';
    var t = this;
    D(this, r), l(this, 'isSeeking', void 0), (this.isSeeking = !1);
    var i = -1,
     a = function () {
      var n = A.now(),
       o = (e.data.viewer_time || n) - (i || n);
      O(e.data, 'view_seek_duration', o), (e.data.view_max_seek_time = Math.max(e.data.view_max_seek_time || 0, o)), (t.isSeeking = !1), (i = -1);
     };
    e.on('seeking', function (n, o) {
     if ((Object.assign(e.data, o), t.isSeeking && o.viewer_time - i <= xa)) {
      i = o.viewer_time;
      return;
     }
     t.isSeeking && a(), (t.isSeeking = !0), (i = o.viewer_time), O(e.data, 'view_seek_count', 1), e.send('seeking');
    }),
     e.on('seeked', function () {
      a();
     }),
     e.on('viewend', function () {
      t.isSeeking && (a(), e.send('seeked')), (t.isSeeking = !1), (i = -1);
     });
   },
   Yt = Da;
  var Xt = function (e, t) {
    e.push(t),
     e.sort(function (i, a) {
      return i.viewer_time - a.viewer_time;
     });
   },
   Sa = ['adbreakstart', 'adrequest', 'adresponse', 'adplay', 'adplaying', 'adpause', 'adended', 'adbreakend', 'aderror', 'adclicked', 'adskipped'],
   Ra = (function () {
    'use strict';
    function r(e) {
     var t = this;
     D(this, r),
      l(this, '_adHasPlayed', void 0),
      l(this, '_adRequests', void 0),
      l(this, '_adResponses', void 0),
      l(this, '_currentAdRequestNumber', void 0),
      l(this, '_currentAdResponseNumber', void 0),
      l(this, '_prerollPlayTime', void 0),
      l(this, '_wouldBeNewAdPlay', void 0),
      l(this, 'isAdBreak', void 0),
      l(this, 'pm', void 0),
      (this.pm = e),
      e.on('viewinit', function () {
       (t.isAdBreak = !1), (t._currentAdRequestNumber = 0), (t._currentAdResponseNumber = 0), (t._adRequests = []), (t._adResponses = []), (t._adHasPlayed = !1), (t._wouldBeNewAdPlay = !0), (t._prerollPlayTime = void 0);
      }),
      Sa.forEach(function (a) {
       return e.on(a, t._updateAdData.bind(t));
      });
     var i = function () {
      t.isAdBreak = !1;
     };
     e.on('adbreakstart', function () {
      t.isAdBreak = !0;
     }),
      e.on('play', i),
      e.on('playing', i),
      e.on('viewend', i),
      e.on('adrequest', function (a, n) {
       (n = Object.assign({ ad_request_id: 'generatedAdRequestId' + t._currentAdRequestNumber++ }, n)), Xt(t._adRequests, n), O(e.data, 'view_ad_request_count'), t.inPrerollPosition() && ((e.data.view_preroll_requested = !0), t._adHasPlayed || O(e.data, 'view_preroll_request_count'));
      }),
      e.on('adresponse', function (a, n) {
       (n = Object.assign({ ad_request_id: 'generatedAdRequestId' + t._currentAdResponseNumber++ }, n)), Xt(t._adResponses, n);
       var o = t.findAdRequest(n.ad_request_id);
       o && O(e.data, 'view_ad_request_time', Math.max(0, n.viewer_time - o.viewer_time));
      }),
      e.on('adplay', function (a, n) {
       (t._adHasPlayed = !0), t._wouldBeNewAdPlay && ((t._wouldBeNewAdPlay = !1), O(e.data, 'view_ad_played_count')), t.inPrerollPosition() && !e.data.view_preroll_played && ((e.data.view_preroll_played = !0), t._adRequests.length > 0 && (e.data.view_preroll_request_time = Math.max(0, n.viewer_time - t._adRequests[0].viewer_time)), e.data.view_start && (e.data.view_startup_preroll_request_time = Math.max(0, n.viewer_time - e.data.view_start)), (t._prerollPlayTime = n.viewer_time));
      }),
      e.on('adplaying', function (a, n) {
       t.inPrerollPosition() && typeof e.data.view_preroll_load_time == 'undefined' && typeof t._prerollPlayTime != 'undefined' && ((e.data.view_preroll_load_time = n.viewer_time - t._prerollPlayTime), (e.data.view_startup_preroll_load_time = n.viewer_time - t._prerollPlayTime));
      }),
      e.on('adclicked', function (a, n) {
       t._wouldBeNewAdPlay || O(e.data, 'view_ad_clicked_count');
      }),
      e.on('adskipped', function (a, n) {
       t._wouldBeNewAdPlay || O(e.data, 'view_ad_skipped_count');
      }),
      e.on('adended', function () {
       t._wouldBeNewAdPlay = !0;
      }),
      e.on('aderror', function () {
       t._wouldBeNewAdPlay = !0;
      });
    }
    return (
     N(r, [
      {
       key: 'inPrerollPosition',
       value: function () {
        return typeof this.pm.data.view_content_playback_time == 'undefined' || this.pm.data.view_content_playback_time <= 1e3;
       },
      },
      {
       key: 'findAdRequest',
       value: function (t) {
        for (var i = 0; i < this._adRequests.length; i++) if (this._adRequests[i].ad_request_id === t) return this._adRequests[i];
       },
      },
      {
       key: '_updateAdData',
       value: function (t, i) {
        if (this.inPrerollPosition()) {
         if (!this.pm.data.view_preroll_ad_tag_hostname && i.ad_tag_url) {
          var a = H(re(i.ad_tag_url), 2),
           n = a[0],
           o = a[1];
          (this.pm.data.view_preroll_ad_tag_domain = o), (this.pm.data.view_preroll_ad_tag_hostname = n);
         }
         if (!this.pm.data.view_preroll_ad_asset_hostname && i.ad_asset_url) {
          var s = H(re(i.ad_asset_url), 2),
           u = s[0],
           f = s[1];
          (this.pm.data.view_preroll_ad_asset_domain = f), (this.pm.data.view_preroll_ad_asset_hostname = u);
         }
        }
        (this.pm.data.ad_asset_url = i == null ? void 0 : i.ad_asset_url), (this.pm.data.ad_tag_url = i == null ? void 0 : i.ad_tag_url), (this.pm.data.ad_creative_id = i == null ? void 0 : i.ad_creative_id), (this.pm.data.ad_id = i == null ? void 0 : i.ad_id), (this.pm.data.ad_universal_id = i == null ? void 0 : i.ad_universal_id);
       },
      },
     ]),
     r
    );
   })(),
   $t = Ra;
  var Qe = V(J());
  var qa = function r(e) {
    'use strict';
    D(this, r);
    var t,
     i,
     a = function () {
      e.disableRebufferTracking ||
       (O(e.data, 'view_waiting_rebuffer_count', 1),
       (t = A.now()),
       (i = Qe.default.setInterval(function () {
        if (t) {
         var f = A.now();
         O(e.data, 'view_waiting_rebuffer_duration', f - t), (t = f);
        }
       }, 250)));
     },
     n = function () {
      e.disableRebufferTracking || (t && (O(e.data, 'view_waiting_rebuffer_duration', A.now() - t), (t = !1), Qe.default.clearInterval(i)));
     },
     o = !1,
     s = function () {
      o = !0;
     },
     u = function () {
      (o = !1), n();
     };
    e.on('waiting', function () {
     o && a();
    }),
     e.on('playing', function () {
      n(), s();
     }),
     e.on('pause', u),
     e.on('seeking', u);
   },
   Zt = qa;
  var Aa = function r(e) {
    'use strict';
    var t = this;
    D(this, r), l(this, 'lastWallClockTime', void 0);
    var i = function () {
      (t.lastWallClockTime = A.now()), e.on('before*', a);
     },
     a = function (n) {
      var o = A.now(),
       s = t.lastWallClockTime;
      (t.lastWallClockTime = o), o - s > 3e4 && (e.emit('devicesleep', { viewer_time: s }), Object.assign(e.data, { viewer_time: s }), e.send('devicesleep'), e.emit('devicewake', { viewer_time: o }), Object.assign(e.data, { viewer_time: o }), e.send('devicewake'));
     };
    e.one('playbackheartbeat', i),
     e.on('playbackheartbeatend', function () {
      e.off('before*', a), e.one('playbackheartbeat', i);
     });
   },
   er = Aa;
  var Ue = V(J());
  var ze = (function (r) {
   return r();
  })(function () {
   var r = function () {
    for (var i = 0, a = {}; i < arguments.length; i++) {
     var n = arguments[i];
     for (var o in n) a[o] = n[o];
    }
    return a;
   };
   function e(t) {
    function i(a, n, o) {
     var s;
     if (typeof document != 'undefined') {
      if (arguments.length > 1) {
       if (((o = r({ path: '/' }, i.defaults, o)), typeof o.expires == 'number')) {
        var u = new Date();
        u.setMilliseconds(u.getMilliseconds() + o.expires * 864e5), (o.expires = u);
       }
       try {
        (s = JSON.stringify(n)), /^[\{\[]/.test(s) && (n = s);
       } catch (w) {}
       return t.write ? (n = t.write(n, a)) : (n = encodeURIComponent(String(n)).replace(/%(23|24|26|2B|3A|3C|3E|3D|2F|3F|40|5B|5D|5E|60|7B|7D|7C)/g, decodeURIComponent)), (a = encodeURIComponent(String(a))), (a = a.replace(/%(23|24|26|2B|5E|60|7C)/g, decodeURIComponent)), (a = a.replace(/[\(\)]/g, escape)), (document.cookie = [a, '=', n, o.expires ? '; expires=' + o.expires.toUTCString() : '', o.path ? '; path=' + o.path : '', o.domain ? '; domain=' + o.domain : '', o.secure ? '; secure' : ''].join(''));
      }
      a || (s = {});
      for (var f = document.cookie ? document.cookie.split('; ') : [], g = /(%[0-9A-Z]{2})+/g, k = 0; k < f.length; k++) {
       var h = f[k].split('='),
        c = h.slice(1).join('=');
       c.charAt(0) === '"' && (c = c.slice(1, -1));
       try {
        var v = h[0].replace(g, decodeURIComponent);
        if (((c = t.read ? t.read(c, v) : t(c, v) || c.replace(g, decodeURIComponent)), this.json))
         try {
          c = JSON.parse(c);
         } catch (w) {}
        if (a === v) {
         s = c;
         break;
        }
        a || (s[v] = c);
       } catch (w) {}
      }
      return s;
     }
    }
    return (
     (i.set = i),
     (i.get = function (a) {
      return i.call(i, a);
     }),
     (i.getJSON = function () {
      return i.apply({ json: !0 }, [].slice.call(arguments));
     }),
     (i.defaults = {}),
     (i.remove = function (a, n) {
      i(a, '', r(n, { expires: -1 }));
     }),
     (i.withConverter = e),
     i
    );
   }
   return e(function () {});
  });
  var tr = 'muxData',
   Oa = function (r) {
    return Object.entries(r)
     .map(function (e) {
      var t = H(e, 2),
       i = t[0],
       a = t[1];
      return ''.concat(i, '=').concat(a);
     })
     .join('&');
   },
   Pa = function (r) {
    return r.split('&').reduce(function (e, t) {
     var i = H(t.split('='), 2),
      a = i[0],
      n = i[1],
      o = +n,
      s = n && o == n ? o : n;
     return (e[a] = s), e;
    }, {});
   },
   rr = function () {
    var e;
    try {
     e = Pa(ze.get(tr) || '');
    } catch (t) {
     e = {};
    }
    return e;
   },
   ar = function (e) {
    try {
     ze.set(tr, Oa(e), { expires: 365 });
    } catch (t) {}
   },
   ir = function () {
    var e = rr();
    return (e.mux_viewer_id = e.mux_viewer_id || ee()), (e.msn = e.msn || Math.random()), ar(e), { mux_viewer_id: e.mux_viewer_id, mux_sample_number: e.msn };
   },
   nr = function () {
    var e = rr(),
     t = A.now();
    return e.session_start && ((e.sst = e.session_start), delete e.session_start), e.session_id && ((e.sid = e.session_id), delete e.session_id), e.session_expires && ((e.sex = e.session_expires), delete e.session_expires), (!e.sex || e.sex < t) && ((e.sid = ee()), (e.sst = t)), (e.sex = t + 25 * 60 * 1e3), ar(e), { session_id: e.sid, session_start: e.sst, session_expires: e.sex };
   };
  function Ke(r, e) {
   var t = e.beaconCollectionDomain,
    i = e.beaconDomain;
   if (t) return 'https://' + t;
   r = r || 'inferred';
   var a = i || 'litix.io';
   return r.match(/^[a-z0-9]+$/) ? 'https://' + r + '.' + a : 'https://img.litix.io/a.gif';
  }
  var or = V(J()),
   sr = function () {
    var e;
    switch (ur()) {
     case 'cellular':
      e = 'cellular';
      break;
     case 'ethernet':
      e = 'wired';
      break;
     case 'wifi':
      e = 'wifi';
      break;
     case void 0:
      break;
     default:
      e = 'other';
    }
    return e;
   },
   ur = function () {
    var e = or.default.navigator,
     t = e && (e.connection || e.mozConnection || e.webkitConnection);
    return t && t.type;
   };
  sr.getConnectionFromAPI = ur;
  var dr = sr;
  var Ia = { a: 'env', b: 'beacon', c: 'custom', d: 'ad', e: 'event', f: 'experiment', i: 'internal', m: 'mux', n: 'response', p: 'player', q: 'request', r: 'retry', s: 'session', t: 'timestamp', u: 'viewer', v: 'video', w: 'page', x: 'view', y: 'sub' },
   La = cr(Ia),
   Na = { ad: 'ad', af: 'affiliate', ag: 'aggregate', ap: 'api', al: 'application', ao: 'audio', ar: 'architecture', as: 'asset', au: 'autoplay', av: 'average', bi: 'bitrate', bn: 'brand', br: 'break', bw: 'browser', by: 'bytes', bz: 'business', ca: 'cached', cb: 'cancel', cc: 'codec', cd: 'code', cg: 'category', ch: 'changed', ci: 'client', ck: 'clicked', cl: 'canceled', cm: 'cmcd', cn: 'config', co: 'count', ce: 'counter', cp: 'complete', cq: 'creator', cr: 'creative', cs: 'captions', ct: 'content', cu: 'current', cx: 'connection', cz: 'context', dg: 'downscaling', dm: 'domain', dn: 'cdn', do: 'downscale', dr: 'drm', dp: 'dropped', du: 'duration', dv: 'device', dy: 'dynamic', eb: 'enabled', ec: 'encoding', ed: 'edge', en: 'end', eg: 'engine', em: 'embed', er: 'error', ep: 'experiments', es: 'errorcode', et: 'errortext', ee: 'event', ev: 'events', ex: 'expires', ez: 'exception', fa: 'failed', fi: 'first', fm: 'family', ft: 'format', fp: 'fps', fq: 'frequency', fr: 'frame', fs: 'fullscreen', ha: 'has', hb: 'holdback', he: 'headers', ho: 'host', hn: 'hostname', ht: 'height', id: 'id', ii: 'init', in: 'instance', ip: 'ip', is: 'is', ke: 'key', la: 'language', lb: 'labeled', le: 'level', li: 'live', ld: 'loaded', lo: 'load', ls: 'lists', lt: 'latency', ma: 'max', md: 'media', me: 'message', mf: 'manifest', mi: 'mime', ml: 'midroll', mm: 'min', mn: 'manufacturer', mo: 'model', mx: 'mux', ne: 'newest', nm: 'name', no: 'number', on: 'on', or: 'origin', os: 'os', pa: 'paused', pb: 'playback', pd: 'producer', pe: 'percentage', pf: 'played', pg: 'program', ph: 'playhead', pi: 'plugin', pl: 'preroll', pn: 'playing', po: 'poster', pp: 'pip', pr: 'preload', ps: 'position', pt: 'part', pv: 'previous', py: 'property', px: 'pop', pz: 'plan', ra: 'rate', rd: 'requested', re: 'rebuffer', rf: 'rendition', rg: 'range', rm: 'remote', ro: 'ratio', rp: 'response', rq: 'request', rs: 'requests', sa: 'sample', sd: 'skipped', se: 'session', sh: 'shift', sk: 'seek', sm: 'stream', so: 'source', sq: 'sequence', sr: 'series', ss: 'status', st: 'start', su: 'startup', sv: 'server', sw: 'software', sy: 'severity', ta: 'tag', tc: 'tech', te: 'text', tg: 'target', th: 'throughput', ti: 'time', tl: 'total', to: 'to', tt: 'title', ty: 'type', ug: 'upscaling', un: 'universal', up: 'upscale', ur: 'url', us: 'user', va: 'variant', vd: 'viewed', vi: 'video', ve: 'version', vw: 'view', vr: 'viewer', wd: 'width', wa: 'watch', wt: 'waiting' },
   lr = cr(Na);
  function cr(r) {
   var e = {};
   for (var t in r) r.hasOwnProperty(t) && (e[r[t]] = t);
   return e;
  }
  function ve(r) {
   var e = {},
    t = {};
   return (
    Object.keys(r).forEach(function (i) {
     var a = !1;
     if (r.hasOwnProperty(i) && r[i] !== void 0) {
      var n = i.split('_'),
       o = n[0],
       s = La[o];
      s || (q.info('Data key word `' + n[0] + '` not expected in ' + i), (s = o + '_')),
       n.splice(1).forEach(function (u) {
        u === 'url' && (a = !0), lr[u] ? (s += lr[u]) : Number.isInteger(Number(u)) ? (s += u) : (q.info('Data key word `' + u + '` not expected in ' + i), (s += '_' + u + '_'));
       }),
       a ? (t[s] = r[i]) : (e[s] = r[i]);
     }
    }),
    Object.assign(e, t)
   );
  }
  var ie = V(J()),
   Mr = V(nt());
  var si = { maxBeaconSize: 300, maxQueueLength: 3600, baseTimeBetweenBeacons: 1e4, maxPayloadKBSize: 500 },
   ui = 56 * 1024,
   di = ['hb', 'requestcompleted', 'requestfailed', 'requestcanceled'],
   li = 'https://img.litix.io',
   $ = function (e) {
    var t = arguments.length > 1 && arguments[1] !== void 0 ? arguments[1] : {};
    (this._beaconUrl = e || li), (this._eventQueue = []), (this._postInFlight = !1), (this._resendAfterPost = !1), (this._failureCount = 0), (this._sendTimeout = !1), (this._options = Object.assign({}, si, t));
   };
  $.prototype.queueEvent = function (r, e) {
   var t = Object.assign({}, e);
   return this._eventQueue.length <= this._options.maxQueueLength || r === 'eventrateexceeded' ? (this._eventQueue.push(t), this._sendTimeout || this._startBeaconSending(), this._eventQueue.length <= this._options.maxQueueLength) : !1;
  };
  $.prototype.flushEvents = function () {
   var r = arguments.length > 0 && arguments[0] !== void 0 ? arguments[0] : !1;
   if (r && this._eventQueue.length === 1) {
    this._eventQueue.pop();
    return;
   }
   this._eventQueue.length && this._sendBeaconQueue(), this._startBeaconSending();
  };
  $.prototype.destroy = function () {
   var r = arguments.length > 0 && arguments[0] !== void 0 ? arguments[0] : !1;
   (this.destroyed = !0), r ? this._clearBeaconQueue() : this.flushEvents(), ie.default.clearTimeout(this._sendTimeout);
  };
  $.prototype._clearBeaconQueue = function () {
   var r = this._eventQueue.length > this._options.maxBeaconSize ? this._eventQueue.length - this._options.maxBeaconSize : 0,
    e = this._eventQueue.slice(r);
   r > 0 && Object.assign(e[e.length - 1], ve({ mux_view_message: 'event queue truncated' }));
   var t = this._createPayload(e);
   Hr(this._beaconUrl, t, !0, function () {});
  };
  $.prototype._sendBeaconQueue = function () {
   var r = this;
   if (this._postInFlight) {
    this._resendAfterPost = !0;
    return;
   }
   var e = this._eventQueue.slice(0, this._options.maxBeaconSize);
   (this._eventQueue = this._eventQueue.slice(this._options.maxBeaconSize)), (this._postInFlight = !0);
   var t = this._createPayload(e),
    i = A.now();
   Hr(this._beaconUrl, t, !1, function (a, n) {
    n ? ((r._eventQueue = e.concat(r._eventQueue)), (r._failureCount += 1), q.info('Error sending beacon: ' + n)) : (r._failureCount = 0), (r._roundTripTime = A.now() - i), (r._postInFlight = !1), r._resendAfterPost && ((r._resendAfterPost = !1), r._eventQueue.length > 0 && r._sendBeaconQueue());
   });
  };
  $.prototype._getNextBeaconTime = function () {
   if (!this._failureCount) return this._options.baseTimeBetweenBeacons;
   var r = Math.pow(2, this._failureCount - 1);
   return (r = r * Math.random()), (1 + r) * this._options.baseTimeBetweenBeacons;
  };
  $.prototype._startBeaconSending = function () {
   var r = this;
   ie.default.clearTimeout(this._sendTimeout),
    !this.destroyed &&
     (this._sendTimeout = ie.default.setTimeout(function () {
      r._eventQueue.length && r._sendBeaconQueue(), r._startBeaconSending();
     }, this._getNextBeaconTime()));
  };
  $.prototype._createPayload = function (r) {
   var e = this,
    t = { transmission_timestamp: Math.round(A.now()) };
   this._roundTripTime && (t.rtt_ms = Math.round(this._roundTripTime));
   var i,
    a,
    n,
    o = function () {
     (i = JSON.stringify({ metadata: t, events: a || r })), (n = i.length / 1024);
    },
    s = function () {
     return n <= e._options.maxPayloadKBSize;
    };
   return (
    o(),
    s() ||
     (q.info('Payload size is too big (' + n + ' kb). Removing unnecessary events.'),
     (a = r.filter(function (u) {
      return di.indexOf(u.e) === -1;
     })),
     o()),
    s() ||
     (q.info('Payload size still too big (' + n + ' kb). Cropping fields..'),
     a.forEach(function (u) {
      for (var f in u) {
       var g = u[f],
        k = 50 * 1024;
       typeof g == 'string' && g.length > k && (u[f] = g.substring(0, k));
      }
     }),
     o()),
    i
   );
  };
  var ci =
    typeof Mr.default.exitPictureInPicture == 'function'
     ? function (r) {
        return r.length <= ui;
       }
     : function (r) {
        return !1;
       },
   Hr = function (r, e, t, i) {
    if (t && navigator && navigator.sendBeacon && navigator.sendBeacon(r, e)) {
     i();
     return;
    }
    if (ie.default.fetch) {
     ie.default
      .fetch(r, { method: 'POST', body: e, headers: { 'Content-Type': 'text/plain' }, keepalive: ci(e) })
      .then(function (n) {
       return i(null, n.ok ? null : 'Error');
      })
      .catch(function (n) {
       return i(null, n);
      });
     return;
    }
    if (ie.default.XMLHttpRequest) {
     var a = new ie.default.XMLHttpRequest();
     (a.onreadystatechange = function () {
      if (a.readyState === 4) return i(null, a.status !== 200 ? 'error' : void 0);
     }),
      a.open('POST', r),
      a.setRequestHeader('Content-Type', 'text/plain'),
      a.send(e);
     return;
    }
    i();
   },
   Br = $;
  var _i = ['env_key', 'view_id', 'view_sequence_number', 'player_sequence_number', 'beacon_domain', 'player_playhead_time', 'viewer_time', 'mux_api_version', 'event', 'video_id', 'player_instance_id', 'player_error_code', 'player_error_message', 'player_error_context', 'player_error_severity', 'player_error_business_exception'],
   fi = ['adplay', 'adplaying', 'adpause', 'adfirstquartile', 'admidpoint', 'adthirdquartile', 'adended', 'adresponse', 'adrequest'],
   pi = ['ad_id', 'ad_creative_id', 'ad_universal_id'],
   vi = ['viewstart', 'error', 'ended', 'viewend'],
   mi = 10 * 60 * 1e3,
   Ur = (function () {
    'use strict';
    function r(e, t) {
     var i = arguments.length > 2 && arguments[2] !== void 0 ? arguments[2] : {};
     D(this, r);
     var a, n, o, s, u, f, g, k, h, c, v, w;
     l(this, 'mux', void 0), l(this, 'envKey', void 0), l(this, 'options', void 0), l(this, 'eventQueue', void 0), l(this, 'sampleRate', void 0), l(this, 'disableCookies', void 0), l(this, 'respectDoNotTrack', void 0), l(this, 'previousBeaconData', void 0), l(this, 'lastEventTime', void 0), l(this, 'rateLimited', void 0), l(this, 'pageLevelData', void 0), l(this, 'viewerData', void 0), (this.mux = e), (this.envKey = t), (this.options = i), (this.previousBeaconData = null), (this.lastEventTime = 0), (this.rateLimited = !1), (this.eventQueue = new Br(Ke(this.envKey, this.options)));
     var x;
     this.sampleRate = (x = this.options.sampleRate) !== null && x !== void 0 ? x : 1;
     var m;
     this.disableCookies = (m = this.options.disableCookies) !== null && m !== void 0 ? m : !1;
     var p;
     (this.respectDoNotTrack = (p = this.options.respectDoNotTrack) !== null && p !== void 0 ? p : !1), (this.previousBeaconData = null), (this.lastEventTime = 0), (this.rateLimited = !1), (this.pageLevelData = { mux_api_version: this.mux.API_VERSION, mux_embed: this.mux.NAME, mux_embed_version: this.mux.VERSION, viewer_application_name: (a = this.options.platform) === null || a === void 0 ? void 0 : a.name, viewer_application_version: (n = this.options.platform) === null || n === void 0 ? void 0 : n.version, viewer_application_engine: (o = this.options.platform) === null || o === void 0 ? void 0 : o.layout, viewer_device_name: (s = this.options.platform) === null || s === void 0 ? void 0 : s.product, viewer_device_category: '', viewer_device_manufacturer: (u = this.options.platform) === null || u === void 0 ? void 0 : u.manufacturer, viewer_os_family: (g = this.options.platform) === null || g === void 0 || (f = g.os) === null || f === void 0 ? void 0 : f.family, viewer_os_architecture: (h = this.options.platform) === null || h === void 0 || (k = h.os) === null || k === void 0 ? void 0 : k.architecture, viewer_os_version: (v = this.options.platform) === null || v === void 0 || (c = v.os) === null || c === void 0 ? void 0 : c.version, viewer_connection_type: dr(), page_url: Ue.default === null || Ue.default === void 0 || (w = Ue.default.location) === null || w === void 0 ? void 0 : w.href }), (this.viewerData = this.disableCookies ? {} : ir());
    }
    return (
     N(r, [
      {
       key: 'send',
       value: function (t, i) {
        if (!(!t || !(i != null && i.view_id))) {
         if (this.respectDoNotTrack && ce()) return q.info('Not sending `' + t + '` because Do Not Track is enabled');
         if (!i || typeof i != 'object') return q.error('A data object was expected in send() but was not provided');
         var a = this.disableCookies ? {} : nr(),
          n = fe(ue({}, this.pageLevelData, i, a, this.viewerData), { event: t, env_key: this.envKey });
         n.user_id && ((n.viewer_user_id = n.user_id), delete n.user_id);
         var o,
          s = ((o = n.mux_sample_number) !== null && o !== void 0 ? o : 0) >= this.sampleRate,
          u = this._deduplicateBeaconData(t, n),
          f = ve(u);
         if (((this.lastEventTime = this.mux.utils.now()), s)) return q.info('Not sending event due to sample rate restriction', t, n, f);
         if ((this.envKey || q.info('Missing environment key (envKey) - beacons will be dropped if the video source is not a valid mux video URL', t, n, f), !this.rateLimited)) {
          if ((q.info('Sending event', t, n, f), (this.rateLimited = !this.eventQueue.queueEvent(t, f)), this.mux.WINDOW_UNLOADING && t === 'viewend')) this.eventQueue.destroy(!0);
          else if ((this.mux.WINDOW_HIDDEN && t === 'hb' ? this.eventQueue.flushEvents(!0) : vi.indexOf(t) >= 0 && this.eventQueue.flushEvents(), this.rateLimited)) return (n.event = 'eventrateexceeded'), (f = ve(n)), this.eventQueue.queueEvent(n.event, f), q.error('Beaconing disabled due to rate limit.');
         }
        }
       },
      },
      {
       key: 'destroy',
       value: function () {
        this.eventQueue.destroy(!1);
       },
      },
      {
       key: '_deduplicateBeaconData',
       value: function (t, i) {
        var a = this,
         n = {},
         o = i.view_id;
        if (o === '-1' || t === 'viewstart' || t === 'viewend' || !this.previousBeaconData || this.mux.utils.now() - this.lastEventTime >= mi) (n = ue({}, i)), o && (this.previousBeaconData = n), o && t === 'viewend' && (this.previousBeaconData = null);
        else {
         var s = t.indexOf('request') === 0;
         Object.entries(i).forEach(function (u) {
          var f = H(u, 2),
           g = f[0],
           k = f[1];
          a.previousBeaconData && (k !== a.previousBeaconData[g] || _i.indexOf(g) > -1 || a.objectHasChanged(s, g, k, a.previousBeaconData[g]) || a.eventRequiresKey(t, g)) && ((n[g] = k), (a.previousBeaconData[g] = k));
         });
        }
        return n;
       },
      },
      {
       key: 'objectHasChanged',
       value: function (t, i, a, n) {
        return !t || i.indexOf('request_') !== 0 ? !1 : i === 'request_response_headers' || typeof a != 'object' || typeof n != 'object' ? !0 : Object.keys(a || {}).length !== Object.keys(n || {}).length;
       },
      },
      {
       key: 'eventRequiresKey',
       value: function (t, i) {
        return !!((t === 'renditionchange' && i.indexOf('video_source_') === 0) || (pi.includes(i) && fi.includes(t)));
       },
      },
     ]),
     r
    );
   })();
  var hi = function r(e) {
    'use strict';
    D(this, r);
    var t = 0,
     i = 0,
     a = 0,
     n = 0,
     o = 0,
     s = 0,
     u = 0,
     f = function (h, c) {
      var v = c.request_start,
       w = c.request_response_start,
       x = c.request_response_end,
       m = c.request_bytes_loaded;
      n++;
      var p, _;
      if ((w ? ((p = w - (v != null ? v : 0)), (_ = (x != null ? x : 0) - w)) : (_ = (x != null ? x : 0) - (v != null ? v : 0)), _ > 0 && m && m > 0)) {
       var d = (m / _) * 8e3;
       o++, (i += m), (a += _), (e.data.view_min_request_throughput = Math.min(e.data.view_min_request_throughput || 1 / 0, d)), (e.data.view_average_request_throughput = (i / a) * 8e3), (e.data.view_request_count = n), p > 0 && ((t += p), (e.data.view_max_request_latency = Math.max(e.data.view_max_request_latency || 0, p)), (e.data.view_average_request_latency = t / o));
      }
     },
     g = function (h, c) {
      n++, s++, (e.data.view_request_count = n), (e.data.view_request_failed_count = s);
     },
     k = function (h, c) {
      n++, u++, (e.data.view_request_count = n), (e.data.view_request_canceled_count = u);
     };
    e.on('requestcompleted', f), e.on('requestfailed', g), e.on('requestcanceled', k);
   },
   Fr = hi;
  var yi = 60 * 60 * 1e3,
   gi = function r(e) {
    'use strict';
    var t = this;
    D(this, r),
     l(this, '_lastEventTime', void 0),
     e.on('before*', function (i, a) {
      var n = a.viewer_time,
       o = A.now(),
       s = t._lastEventTime;
      if (((t._lastEventTime = o), s && o - s > yi)) {
       var u = Object.keys(e.data).reduce(function (g, k) {
        return k.indexOf('video_') === 0 ? Object.assign(g, l({}, k, e.data[k])) : g;
       }, {});
       e.mux.log.info('Received event after at least an hour inactivity, creating a new view');
       var f = e.playbackHeartbeat._playheadShouldBeProgressing;
       e._resetView(Object.assign({ viewer_time: n }, u)), (e.playbackHeartbeat._playheadShouldBeProgressing = f), e.playbackHeartbeat._playheadShouldBeProgressing && i.type !== 'play' && i.type !== 'adbreakstart' && (e.emit('play', { viewer_time: n }), i.type !== 'playing' && e.emit('playing', { viewer_time: n }));
      }
     });
   },
   Vr = gi;
  var bi = function r(e) {
   'use strict';
   D(this, r);
   var t = function (u) {
     var f = wi(u),
      g = Ti(u);
     if (f != null && !jr(f, n) && o <= g) {
      (n = f), (o = g);
      var k = { video_cdn: f };
      e.emit('cdnchange', k);
     }
    },
    i = null,
    a = null,
    n = null,
    o = 0;
   e.on('viewinit', function () {
    (i = null), (a = null), (n = null), (o = 0);
   }),
    e.on('beforecdnchange', function (s, u) {
     var f = u == null ? void 0 : u.video_cdn;
     f && (typeof u.video_previous_cdn == 'undefined' || u.video_previous_cdn === null) && (jr(f, a) ? (u.video_previous_cdn = i != null ? i : void 0) : ((u.video_previous_cdn = a != null ? a : void 0), (i = a), (a = f)));
    }),
    e.on('requestcompleted', function (s, u) {
     t(u);
    });
  };
  function jr(r, e) {
   return (r == null ? void 0 : r.toLowerCase()) === (e == null ? void 0 : e.toLowerCase());
  }
  function wi(r) {
   var e;
   return r != null && r.request_type && (r.request_type === 'media' || r.request_type === 'video') && !((e = r.request_response_headers) === null || e === void 0) && e['x-cdn'] ? r.request_response_headers['x-cdn'] : r != null && r.video_cdn ? r.video_cdn : null;
  }
  function Ti(r) {
   return r != null && r.request_start ? r.request_start : r != null && r.viewer_time ? r.viewer_time : Date.now();
  }
  var Wr = bi;
  var Ei = ['viewstart', 'ended', 'loadstart', 'pause', 'play', 'playing', 'ratechange', 'waiting', 'adplay', 'adpause', 'adended', 'aderror', 'adplaying', 'adrequest', 'adresponse', 'adbreakstart', 'adbreakend', 'adfirstquartile', 'admidpoint', 'adthirdquartile', 'rebufferstart', 'rebufferend', 'seeked', 'error', 'hb', 'requestcompleted', 'requestfailed', 'requestcanceled', 'renditionchange', 'cdnchange'],
   ki = new Set(['requestcompleted', 'requestfailed', 'requestcanceled']),
   xi = (function (r) {
    'use strict';
    Dt(t, r);
    var e = Ot(t);
    function t(i, a, n) {
     D(this, t);
     var o;
     (o = e.call(this)), l(b(o), 'pageLoadEndTime', void 0), l(b(o), 'pageLoadInitTime', void 0), l(b(o), '_destroyed', void 0), l(b(o), '_heartBeatTimeout', void 0), l(b(o), 'adTracker', void 0), l(b(o), 'dashjs', void 0), l(b(o), 'data', void 0), l(b(o), 'disablePlayheadRebufferTracking', void 0), l(b(o), 'disableRebufferTracking', void 0), l(b(o), 'errorTracker', void 0), l(b(o), 'errorTranslator', void 0), l(b(o), 'emitTranslator', void 0), l(b(o), 'getAdData', void 0), l(b(o), 'getPlayheadTime', void 0), l(b(o), 'getStateData', void 0), l(b(o), 'stateDataTranslator', void 0), l(b(o), 'hlsjs', void 0), l(b(o), 'id', void 0), l(b(o), 'longResumeTracker', void 0), l(b(o), 'minimumRebufferDuration', void 0), l(b(o), 'mux', void 0), l(b(o), 'playbackEventDispatcher', void 0), l(b(o), 'playbackHeartbeat', void 0), l(b(o), 'playbackHeartbeatTime', void 0), l(b(o), 'playheadTime', void 0), l(b(o), 'seekingTracker', void 0), l(b(o), 'sustainedRebufferThreshold', void 0), l(b(o), 'watchTimeTracker', void 0), l(b(o), 'currentFragmentPDT', void 0), l(b(o), 'currentFragmentStart', void 0), (o.pageLoadInitTime = _e.navigationStart()), (o.pageLoadEndTime = _e.domContentLoadedEventEnd());
     var s = {
      debug: !1,
      minimumRebufferDuration: 250,
      sustainedRebufferThreshold: 1e3,
      playbackHeartbeatTime: 25,
      beaconDomain: 'litix.io',
      sampleRate: 1,
      disableCookies: !1,
      respectDoNotTrack: !1,
      disableRebufferTracking: !1,
      disablePlayheadRebufferTracking: !1,
      errorTranslator: function (h) {
       return h;
      },
      emitTranslator: function () {
       for (var h = arguments.length, c = new Array(h), v = 0; v < h; v++) c[v] = arguments[v];
       return c;
      },
      stateDataTranslator: function (h) {
       return h;
      },
     };
     (o.mux = i),
      (o.id = a),
      n != null && n.beaconDomain && o.mux.log.warn('The `beaconDomain` setting has been deprecated in favor of `beaconCollectionDomain`. Please change your integration to use `beaconCollectionDomain` instead of `beaconDomain`.'),
      (n = Object.assign(s, n)),
      (n.data = n.data || {}),
      n.data.property_key && ((n.data.env_key = n.data.property_key), delete n.data.property_key),
      (q.level = n.debug ? Y.DEBUG : Y.WARN),
      (o.getPlayheadTime = n.getPlayheadTime),
      (o.getStateData =
       n.getStateData ||
       function () {
        return {};
       }),
      (o.getAdData = n.getAdData || function () {}),
      (o.minimumRebufferDuration = n.minimumRebufferDuration),
      (o.sustainedRebufferThreshold = n.sustainedRebufferThreshold),
      (o.playbackHeartbeatTime = n.playbackHeartbeatTime),
      (o.disableRebufferTracking = n.disableRebufferTracking),
      o.disableRebufferTracking && o.mux.log.warn('Disabling rebuffer tracking. This should only be used in specific circumstances as a last resort when your player is known to unreliably track rebuffering.'),
      (o.disablePlayheadRebufferTracking = n.disablePlayheadRebufferTracking),
      (o.errorTranslator = n.errorTranslator),
      (o.emitTranslator = n.emitTranslator),
      (o.stateDataTranslator = n.stateDataTranslator),
      (o.playbackEventDispatcher = new Ur(i, n.data.env_key, n)),
      (o.data = { player_instance_id: ee(), mux_sample_rate: n.sampleRate, beacon_domain: n.beaconCollectionDomain || n.beaconDomain }),
      (o.data.view_sequence_number = 1),
      (o.data.player_sequence_number = 1);
     var u = function () {
      typeof this.data.view_start == 'undefined' && ((this.data.view_start = this.mux.utils.now()), this.emit('viewstart'));
     }.bind(b(o));
     if (
      (o.on('viewinit', function (h, c) {
       this._resetVideoData(), this._resetViewData(), this._resetErrorData(), this._updateStateData(), Object.assign(this.data, c), this._initializeViewData(), this.one('play', u), this.one('adbreakstart', u);
      }),
      o.on('videochange', function (h, c) {
       this._resetView(c);
      }),
      o.on('programchange', function (h, c) {
       this.data.player_is_paused && this.mux.log.warn('The `programchange` event is intended to be used when the content changes mid playback without the video source changing, however the video is not currently playing. If the video source is changing please use the videochange event otherwise you will lose startup time information.'), this._resetView(Object.assign(c, { view_program_changed: !0 })), u(), this.emit('play'), this.emit('playing');
      }),
      o.on('fragmentchange', function (h, c) {
       (this.currentFragmentPDT = c.currentFragmentPDT), (this.currentFragmentStart = c.currentFragmentStart);
      }),
      o.on('destroy', o.destroy),
      typeof window != 'undefined' && typeof window.addEventListener == 'function' && typeof window.removeEventListener == 'function')
     ) {
      var f = function () {
       var h = typeof o.data.view_start != 'undefined';
       (o.mux.WINDOW_HIDDEN = document.visibilityState === 'hidden'), h && o.mux.WINDOW_HIDDEN && (o.data.player_is_paused || o.emit('hb'));
      };
      window.addEventListener('visibilitychange', f, !1);
      var g = function (h) {
       h.persisted || o.destroy();
      };
      window.addEventListener('pagehide', g, !1),
       o.on('destroy', function () {
        window.removeEventListener('visibilitychange', f), window.removeEventListener('pagehide', g);
       });
     }
     o.on('playerready', function (h, c) {
      Object.assign(this.data, c);
     }),
      Ei.forEach(function (h) {
       o.on(h, function (c, v) {
        h.indexOf('ad') !== 0 && this._updateStateData(), Object.assign(this.data, v), this._sanitizeData();
       }),
        o.on('after' + h, function () {
         (h !== 'error' || this.errorTracker.viewErrored) && this.send(h);
        });
      }),
      o.on('viewend', function (h, c) {
       Object.assign(o.data, c);
      });
     var k = function (c) {
      var v = this.mux.utils.now();
      this.data.player_init_time && (this.data.player_startup_time = v - this.data.player_init_time), (this.pageLoadInitTime = this.data.page_load_init_time || this.pageLoadInitTime), (this.pageLoadEndTime = this.data.page_load_end_time || this.pageLoadEndTime), !this.mux.PLAYER_TRACKED && this.pageLoadInitTime && ((this.mux.PLAYER_TRACKED = !0), (this.data.player_init_time || this.pageLoadEndTime) && (this.data.page_load_time = Math.min(this.data.player_init_time || 1 / 0, this.pageLoadEndTime || 1 / 0) - this.pageLoadInitTime)), this.send('playerready'), delete this.data.player_startup_time, delete this.data.page_load_time;
     };
     return o.one('playerready', k), (o.longResumeTracker = new Vr(b(o))), (o.errorTracker = new Ft(b(o))), new er(b(o)), (o.seekingTracker = new Yt(b(o))), (o.playheadTime = new Wt(b(o))), (o.playbackHeartbeat = new Ut(b(o))), new Kt(b(o)), (o.watchTimeTracker = new Vt(b(o))), new jt(b(o)), (o.adTracker = new $t(b(o))), new Qt(b(o)), new Jt(b(o)), new zt(b(o)), new Zt(b(o)), new Fr(b(o)), new Wr(b(o)), n.hlsjs && o.addHLSJS(n), n.dashjs && o.addDashJS(n), o.emit('viewinit', n.data), o;
    }
    return (
     N(t, [
      {
       key: 'emit',
       value: function (a, n) {
        var o,
         s = Object.assign({ viewer_time: this.mux.utils.now() }, n),
         u = [a, s];
        if (this.emitTranslator)
         try {
          u = this.emitTranslator(a, s);
         } catch (f) {
          this.mux.log.warn('Exception in emit translator callback.', f);
         }
        u != null && u.length && (o = De(X(t.prototype), 'emit', this)).call.apply(o, [this].concat(j(u)));
       },
      },
      {
       key: 'destroy',
       value: function () {
        this._destroyed || ((this._destroyed = !0), typeof this.data.view_start != 'undefined' && (this.emit('viewend'), this.send('viewend')), this.playbackEventDispatcher.destroy(), this.removeHLSJS(), this.removeDashJS(), window.clearTimeout(this._heartBeatTimeout));
       },
      },
      {
       key: 'send',
       value: function (a) {
        if (this.data.view_id) {
         var n = Object.assign({}, this.data),
          o = ['player_program_time', 'player_manifest_newest_program_time', 'player_live_edge_program_time', 'player_program_time', 'video_holdback', 'video_part_holdback', 'video_target_duration', 'video_part_target_duration'];
         if (
          (n.video_source_is_live === void 0 && (n.player_source_duration === 1 / 0 || n.video_source_duration === 1 / 0 ? (n.video_source_is_live = !0) : (n.player_source_duration > 0 || n.video_source_duration > 0) && (n.video_source_is_live = !1)),
          n.video_source_is_live ||
           o.forEach(function (g) {
            n[g] = void 0;
           }),
          (n.video_source_url = n.video_source_url || n.player_source_url),
          n.video_source_url)
         ) {
          var s = H(re(n.video_source_url), 2),
           u = s[0],
           f = s[1];
          (n.video_source_domain = f), (n.video_source_hostname = u);
         }
         delete n.ad_request_id, this.playbackEventDispatcher.send(a, n), this.data.view_sequence_number++, this.data.player_sequence_number++, ki.has(a) || this._restartHeartBeat(), a === 'viewend' && delete this.data.view_id;
        }
       },
      },
      {
       key: '_resetView',
       value: function (a) {
        this.emit('viewend'), this.send('viewend'), this.emit('viewinit', a);
       },
      },
      {
       key: '_updateStateData',
       value: function () {
        var a,
         n = this.getStateData();
        if (typeof this.stateDataTranslator == 'function')
         try {
          n = this.stateDataTranslator(n);
         } catch (u) {
          this.mux.log.warn('Exception in stateDataTranslator translator callback.', u);
         }
        if (!((a = this.data) === null || a === void 0) && a.video_cdn && n != null && n.video_cdn) {
         var o = n.video_cdn,
          s = Rt(n, ['video_cdn']);
         n = s;
        }
        Object.assign(this.data, n), this.playheadTime._updatePlayheadTime(), this._sanitizeData();
       },
      },
      {
       key: '_sanitizeData',
       value: function () {
        var a = this,
         n = ['player_width', 'player_height', 'video_source_width', 'video_source_height', 'player_playhead_time', 'video_source_bitrate'];
        n.forEach(function (s) {
         var u = parseInt(a.data[s], 10);
         a.data[s] = isNaN(u) ? void 0 : u;
        });
        var o = ['player_source_url', 'video_source_url'];
        o.forEach(function (s) {
         if (a.data[s]) {
          var u = a.data[s].toLowerCase();
          (u.indexOf('data:') === 0 || u.indexOf('blob:') === 0) && (a.data[s] = 'MSE style URL');
         }
        });
       },
      },
      {
       key: '_resetVideoData',
       value: function () {
        var a = this;
        Object.keys(this.data).forEach(function (n) {
         n.indexOf('video_') === 0 && delete a.data[n];
        });
       },
      },
      {
       key: '_resetViewData',
       value: function () {
        var a = this;
        Object.keys(this.data).forEach(function (n) {
         n.indexOf('view_') === 0 && delete a.data[n];
        }),
         (this.data.view_sequence_number = 1);
       },
      },
      {
       key: '_resetErrorData',
       value: function () {
        delete this.data.player_error_code, delete this.data.player_error_message, delete this.data.player_error_context, delete this.data.player_error_severity, delete this.data.player_error_business_exception;
       },
      },
      {
       key: '_initializeViewData',
       value: function () {
        var a = this,
         n = (this.data.view_id = ee()),
         o = function () {
          n === a.data.view_id && O(a.data, 'player_view_count', 1);
         };
        this.data.player_is_paused ? this.one('play', o) : o();
       },
      },
      {
       key: '_restartHeartBeat',
       value: function () {
        var a = this;
        window.clearTimeout(this._heartBeatTimeout),
         (this._heartBeatTimeout = window.setTimeout(function () {
          a.data.player_is_paused || a.emit('hb');
         }, 1e4));
       },
      },
      {
       key: 'addHLSJS',
       value: function (a) {
        if (!a.hlsjs) {
         this.mux.log.warn('You must pass a valid hlsjs instance in order to track it.');
         return;
        }
        if (this.hlsjs) {
         this.mux.log.warn('An instance of HLS.js is already being monitored for this player.');
         return;
        }
        (this.hlsjs = a.hlsjs), It(this.mux, this.id, a.hlsjs, {}, a.Hls || window.Hls);
       },
      },
      {
       key: 'removeHLSJS',
       value: function () {
        this.hlsjs && (Lt(this.hlsjs), (this.hlsjs = void 0));
       },
      },
      {
       key: 'addDashJS',
       value: function (a) {
        if (!a.dashjs) {
         this.mux.log.warn('You must pass a valid dashjs instance in order to track it.');
         return;
        }
        if (this.dashjs) {
         this.mux.log.warn('An instance of Dash.js is already being monitored for this player.');
         return;
        }
        (this.dashjs = a.dashjs), Ct(this.mux, this.id, a.dashjs);
       },
      },
      {
       key: 'removeDashJS',
       value: function () {
        this.dashjs && (Mt(this.dashjs), (this.dashjs = void 0));
       },
      },
     ]),
     t
    );
   })(Bt),
   Gr = xi;
  var he = V(nt());
  function ot() {
   return he.default && !!(he.default.fullscreenElement || he.default.webkitFullscreenElement || he.default.mozFullScreenElement || he.default.msFullscreenElement);
  }
  var Di = ['loadstart', 'pause', 'play', 'playing', 'seeking', 'seeked', 'timeupdate', 'ratechange', 'stalled', 'waiting', 'error', 'ended'],
   Si = { 1: 'MEDIA_ERR_ABORTED', 2: 'MEDIA_ERR_NETWORK', 3: 'MEDIA_ERR_DECODE', 4: 'MEDIA_ERR_SRC_NOT_SUPPORTED' };
  function st(r, e, t) {
   var i = H(se(e), 3),
    a = i[0],
    n = i[1],
    o = i[2],
    s = r.log,
    u = r.utils.getComputedStyle,
    f = r.utils.secondsToMs,
    g = { automaticErrorTracking: !0 };
   if (a) {
    if (o !== 'video' && o !== 'audio') return s.error('The element of `' + n + '` was not a media element.');
   } else return s.error('No element was found with the `' + n + '` query selector.');
   a.mux && (a.mux.destroy(), delete a.mux, s.warn('Already monitoring this video element, replacing existing event listeners'));
   var k = {
    getPlayheadTime: function () {
     return f(a.currentTime);
    },
    getStateData: function () {
     var v,
      w,
      x,
      m = ((v = (w = this).getPlayheadTime) === null || v === void 0 ? void 0 : v.call(w)) || f(a.currentTime),
      p = this.hlsjs && this.hlsjs.url,
      _ = this.dashjs && typeof this.dashjs.getSource == 'function' && this.dashjs.getSource(),
      d = { player_is_paused: a.paused, player_width: parseInt(u(a, 'width')), player_height: parseInt(u(a, 'height')), player_autoplay_on: a.autoplay, player_preload_on: a.preload, player_language_code: a.lang, player_is_fullscreen: ot(), video_poster_url: a.poster, video_source_url: p || _ || a.currentSrc, video_source_duration: f(a.duration), video_source_height: a.videoHeight, video_source_width: a.videoWidth, view_dropped_frame_count: a == null || (x = a.getVideoPlaybackQuality) === null || x === void 0 ? void 0 : x.call(a).droppedVideoFrames };
     if (a.getStartDate && m > 0) {
      var y = a.getStartDate();
      if (y && typeof y.getTime == 'function' && y.getTime()) {
       var T = y.getTime();
       if (((d.player_program_time = T + m), a.seekable.length > 0)) {
        var E = T + a.seekable.end(a.seekable.length - 1);
        d.player_live_edge_program_time = E;
       }
      }
     }
     return d;
    },
   };
   (t = Object.assign(g, t, k)),
    (t.data = Object.assign({ player_software: 'HTML5 Video Element', player_mux_plugin_name: 'VideoElementMonitor', player_mux_plugin_version: r.VERSION }, t.data)),
    (a.mux = a.mux || {}),
    (a.mux.deleted = !1),
    (a.mux.emit = function (c, v) {
     r.emit(n, c, v);
    }),
    (a.mux.updateData = function (c) {
     a.mux.emit('hb', c);
    });
   var h = function () {
    s.error('The monitor for this video element has already been destroyed.');
   };
   (a.mux.destroy = function () {
    Object.keys(a.mux.listeners).forEach(function (c) {
     a.removeEventListener(c, a.mux.listeners[c], !1);
    }),
     delete a.mux.listeners,
     (a.mux.destroy = h),
     (a.mux.swapElement = h),
     (a.mux.emit = h),
     (a.mux.addHLSJS = h),
     (a.mux.addDashJS = h),
     (a.mux.removeHLSJS = h),
     (a.mux.removeDashJS = h),
     (a.mux.updateData = h),
     (a.mux.setEmitTranslator = h),
     (a.mux.setStateDataTranslator = h),
     (a.mux.setGetPlayheadTime = h),
     (a.mux.deleted = !0),
     r.emit(n, 'destroy');
   }),
    (a.mux.swapElement = function (c) {
     var v = H(se(c), 3),
      w = v[0],
      x = v[1],
      m = v[2];
     if (w) {
      if (m !== 'video' && m !== 'audio') return r.log.error('The element of `' + x + '` was not a media element.');
     } else return r.log.error('No element was found with the `' + x + '` query selector.');
     (w.muxId = a.muxId),
      delete a.muxId,
      (w.mux = w.mux || {}),
      (w.mux.listeners = Object.assign({}, a.mux.listeners)),
      delete a.mux.listeners,
      Object.keys(w.mux.listeners).forEach(function (p) {
       a.removeEventListener(p, w.mux.listeners[p], !1), w.addEventListener(p, w.mux.listeners[p], !1);
      }),
      (w.mux.swapElement = a.mux.swapElement),
      (w.mux.destroy = a.mux.destroy),
      delete a.mux,
      (a = w);
    }),
    (a.mux.addHLSJS = function (c) {
     r.addHLSJS(n, c);
    }),
    (a.mux.addDashJS = function (c) {
     r.addDashJS(n, c);
    }),
    (a.mux.removeHLSJS = function () {
     r.removeHLSJS(n);
    }),
    (a.mux.removeDashJS = function () {
     r.removeDashJS(n);
    }),
    (a.mux.setEmitTranslator = function (c) {
     r.setEmitTranslator(n, c);
    }),
    (a.mux.setStateDataTranslator = function (c) {
     r.setStateDataTranslator(n, c);
    }),
    (a.mux.setGetPlayheadTime = function (c) {
     c || (c = t.getPlayheadTime), r.setGetPlayheadTime(n, c);
    }),
    r.init(n, t),
    r.emit(n, 'playerready'),
    a.paused || (r.emit(n, 'play'), a.readyState > 2 && r.emit(n, 'playing')),
    (a.mux.listeners = {}),
    Di.forEach(function (c) {
     (c === 'error' && !t.automaticErrorTracking) ||
      ((a.mux.listeners[c] = function () {
       var v = {};
       if (c === 'error') {
        if (!a.error || a.error.code === 1) return;
        (v.player_error_code = a.error.code), (v.player_error_message = Si[a.error.code] || a.error.message);
       }
       r.emit(n, c, v);
      }),
      a.addEventListener(c, a.mux.listeners[c], !1));
    });
  }
  function ut(r, e, t, i) {
   var a = i;
   if (r && typeof r[e] == 'function')
    try {
     a = r[e].apply(r, t);
    } catch (n) {
     q.info('safeCall error', n);
    }
   return a;
  }
  var ge = V(J()),
   ye;
  ge.default && ge.default.WeakMap && (ye = new WeakMap());
  function dt(r, e) {
   if (!r || !e || !ge.default || typeof ge.default.getComputedStyle != 'function') return '';
   var t;
   return ye && ye.has(r) && (t = ye.get(r)), t || ((t = ge.default.getComputedStyle(r, null)), ye && ye.set(r, t)), t.getPropertyValue(e);
  }
  function lt(r) {
   return Math.floor(r * 1e3);
  }
  var le = { TARGET_DURATION: '#EXT-X-TARGETDURATION', PART_INF: '#EXT-X-PART-INF', SERVER_CONTROL: '#EXT-X-SERVER-CONTROL', INF: '#EXTINF', PROGRAM_DATE_TIME: '#EXT-X-PROGRAM-DATE-TIME', VERSION: '#EXT-X-VERSION', SESSION_DATA: '#EXT-X-SESSION-DATA' },
   Fe = function (e) {
    return (this.buffer = ''), (this.manifest = { segments: [], serverControl: {}, sessionData: {} }), (this.currentUri = {}), this.process(e), this.manifest;
   };
  Fe.prototype.process = function (r) {
   var e;
   for (this.buffer += r, e = this.buffer.indexOf('\n'); e > -1; e = this.buffer.indexOf('\n')) this.processLine(this.buffer.substring(0, e)), (this.buffer = this.buffer.substring(e + 1));
  };
  Fe.prototype.processLine = function (r) {
   var e = r.indexOf(':'),
    t = Oi(r, e),
    i = t[0],
    a = t.length === 2 ? _t(t[1]) : void 0;
   if (i[0] !== '#') (this.currentUri.uri = i), this.manifest.segments.push(this.currentUri), this.manifest.targetDuration && !('duration' in this.currentUri) && (this.currentUri.duration = this.manifest.targetDuration), (this.currentUri = {});
   else
    switch (i) {
     case le.TARGET_DURATION: {
      if (!isFinite(a) || a < 0) return;
      (this.manifest.targetDuration = a), this.setHoldBack();
      break;
     }
     case le.PART_INF: {
      ct(this.manifest, t), this.manifest.partInf.partTarget && (this.manifest.partTargetDuration = this.manifest.partInf.partTarget), this.setHoldBack();
      break;
     }
     case le.SERVER_CONTROL: {
      ct(this.manifest, t), this.setHoldBack();
      break;
     }
     case le.INF: {
      a === 0 ? (this.currentUri.duration = 0.01) : a > 0 && (this.currentUri.duration = a);
      break;
     }
     case le.PROGRAM_DATE_TIME: {
      var n = a,
       o = new Date(n);
      this.manifest.dateTimeString || ((this.manifest.dateTimeString = n), (this.manifest.dateTimeObject = o)), (this.currentUri.dateTimeString = n), (this.currentUri.dateTimeObject = o);
      break;
     }
     case le.VERSION: {
      ct(this.manifest, t);
      break;
     }
     case le.SESSION_DATA: {
      var s = Pi(t[1]),
       u = Ce(s);
      Object.assign(this.manifest.sessionData, u);
     }
    }
  };
  Fe.prototype.setHoldBack = function () {
   var r = this.manifest,
    e = r.serverControl,
    t = r.targetDuration,
    i = r.partTargetDuration;
   if (e) {
    var a = 'holdBack',
     n = 'partHoldBack',
     o = t && t * 3,
     s = i && i * 2;
    t && !e.hasOwnProperty(a) && (e[a] = o), o && e[a] < o && (e[a] = o), i && !e.hasOwnProperty(n) && (e[n] = i * 3), i && e[n] < s && (e[n] = s);
   }
  };
  var ct = function (r, e) {
    var t = Jr(e[0].replace('#EXT-X-', '')),
     i;
    Ai(e[1]) ? ((i = {}), (i = Object.assign(qi(e[1]), i))) : (i = _t(e[1])), (r[t] = i);
   },
   Jr = function (r) {
    return r.toLowerCase().replace(/-(\w)/g, function (e) {
     return e[1].toUpperCase();
    });
   },
   _t = function (r) {
    if (r.toLowerCase() === 'yes' || r.toLowerCase() === 'no') return r.toLowerCase() === 'yes';
    var e = r.indexOf(':') !== -1 ? r : parseFloat(r);
    return isNaN(e) ? r : e;
   },
   Ri = function (r) {
    var e = {},
     t = r.split('=');
    if (t.length > 1) {
     var i = Jr(t[0]);
     e[i] = _t(t[1]);
    }
    return e;
   },
   qi = function (r) {
    for (var e = r.split(','), t = {}, i = 0; e.length > i; i++) {
     var a = e[i],
      n = Ri(a);
     t = Object.assign(n, t);
    }
    return t;
   },
   Ai = function (r) {
    return r.indexOf('=') > -1;
   },
   Oi = function (r, e) {
    return e === -1 ? [r] : [r.substring(0, e), r.substring(e + 1)];
   },
   Pi = function (r) {
    var e = {};
    if (r) {
     var t = r.search(','),
      i = r.slice(0, t),
      a = r.slice(t + 1),
      n = [i, a];
     return (
      n.forEach(function (o, s) {
       for (var u = o.replace(/['"]+/g, '').split('='), f = 0; f < u.length; f++) u[f] === 'DATA-ID' && (e['DATA-ID'] = u[1 - f]), u[f] === 'VALUE' && (e.VALUE = u[1 - f]);
      }),
      { data: e }
     );
    }
   },
   Qr = Fe;
  var Ii = { safeCall: ut, safeIncrement: O, getComputedStyle: dt, secondsToMs: lt, assign: Object.assign, headersStringToObject: pe, cdnHeadersToRequestId: de, extractHostnameAndDomain: re, extractHostname: F, manifestParser: Qr, generateShortID: Oe, generateUUID: ee, now: A.now, findMediaElement: se },
   zr = Ii;
  var Li = { PLAYER_READY: 'playerready', VIEW_INIT: 'viewinit', VIDEO_CHANGE: 'videochange', PLAY: 'play', PAUSE: 'pause', PLAYING: 'playing', TIME_UPDATE: 'timeupdate', SEEKING: 'seeking', SEEKED: 'seeked', REBUFFER_START: 'rebufferstart', REBUFFER_END: 'rebufferend', ERROR: 'error', ENDED: 'ended', RENDITION_CHANGE: 'renditionchange', ORIENTATION_CHANGE: 'orientationchange', AD_REQUEST: 'adrequest', AD_RESPONSE: 'adresponse', AD_BREAK_START: 'adbreakstart', AD_PLAY: 'adplay', AD_PLAYING: 'adplaying', AD_PAUSE: 'adpause', AD_FIRST_QUARTILE: 'adfirstquartile', AD_MID_POINT: 'admidpoint', AD_THIRD_QUARTILE: 'adthirdquartile', AD_ENDED: 'adended', AD_BREAK_END: 'adbreakend', AD_ERROR: 'aderror', REQUEST_COMPLETED: 'requestcompleted', REQUEST_FAILED: 'requestfailed', REQUEST_CANCELLED: 'requestcanceled', HEARTBEAT: 'hb', DESTROY: 'destroy' },
   Kr = Li;
  var Ni = 'mux-embed',
   Ci = '5.11.0',
   Mi = '2.1',
   C = {},
   ne = function (e) {
    var t = arguments;
    typeof e == 'string'
     ? ne.hasOwnProperty(e)
       ? be.default.setTimeout(function () {
          (t = Array.prototype.splice.call(t, 1)), ne[e].apply(null, t);
         }, 0)
       : q.warn('`' + e + '` is an unknown task')
     : typeof e == 'function'
       ? be.default.setTimeout(function () {
          e(ne);
         }, 0)
       : q.warn('`' + e + '` is invalid.');
   },
   Hi = {
    loaded: A.now(),
    NAME: Ni,
    VERSION: Ci,
    API_VERSION: Mi,
    PLAYER_TRACKED: !1,
    monitor: function (e, t) {
     return st(ne, e, t);
    },
    destroyMonitor: function (e) {
     var t = H(se(e), 1),
      i = t[0];
     i && i.mux && typeof i.mux.destroy == 'function' ? i.mux.destroy() : q.error('A video element monitor for `' + e + '` has not been initialized via `mux.monitor`.');
    },
    addHLSJS: function (e, t) {
     var i = Q(e);
     C[i] ? C[i].addHLSJS(t) : q.error('A monitor for `' + i + '` has not been initialized.');
    },
    addDashJS: function (e, t) {
     var i = Q(e);
     C[i] ? C[i].addDashJS(t) : q.error('A monitor for `' + i + '` has not been initialized.');
    },
    removeHLSJS: function (e) {
     var t = Q(e);
     C[t] ? C[t].removeHLSJS() : q.error('A monitor for `' + t + '` has not been initialized.');
    },
    removeDashJS: function (e) {
     var t = Q(e);
     C[t] ? C[t].removeDashJS() : q.error('A monitor for `' + t + '` has not been initialized.');
    },
    init: function (e, t) {
     ce() && t && t.respectDoNotTrack && q.info("The browser's Do Not Track flag is enabled - Mux beaconing is disabled.");
     var i = Q(e);
     C[i] = new Gr(ne, i, t);
    },
    emit: function (e, t, i) {
     var a = Q(e);
     C[a] ? (C[a].emit(t, i), t === 'destroy' && delete C[a]) : q.error('A monitor for `' + a + '` has not been initialized.');
    },
    updateData: function (e, t) {
     var i = Q(e);
     C[i] ? C[i].emit('hb', t) : q.error('A monitor for `' + i + '` has not been initialized.');
    },
    setEmitTranslator: function (e, t) {
     var i = Q(e);
     C[i] ? (C[i].emitTranslator = t) : q.error('A monitor for `' + i + '` has not been initialized.');
    },
    setStateDataTranslator: function (e, t) {
     var i = Q(e);
     C[i] ? (C[i].stateDataTranslator = t) : q.error('A monitor for `' + i + '` has not been initialized.');
    },
    setGetPlayheadTime: function (e, t) {
     var i = Q(e);
     C[i] ? (C[i].getPlayheadTime = t) : q.error('A monitor for `' + i + '` has not been initialized.');
    },
    checkDoNotTrack: ce,
    log: q,
    utils: zr,
    events: Kr,
    WINDOW_HIDDEN: !1,
    WINDOW_UNLOADING: !1,
   };
  Object.assign(ne, Hi);
  typeof be.default != 'undefined' &&
   typeof be.default.addEventListener == 'function' &&
   be.default.addEventListener(
    'pagehide',
    function (r) {
     r.persisted || (ne.WINDOW_UNLOADING = !0);
    },
    !1,
   );
  var Md = ne;
  /*!
   * JavaScript Cookie v2.1.3
   * https://github.com/js-cookie/js-cookie
   *
   * Copyright 2006, 2015 Klaus Hartl & Fagner Brack
   * Released under the MIT license
   */

  // EXTERNAL MODULE: ./node_modules/.pnpm/hls.js@1.6.10/node_modules/hls.js/dist/hls.mjs
  var hls = __webpack_require__(91899); // CONCATENATED MODULE: ./node_modules/.pnpm/@mux+playback-core@0.30.1/node_modules/@mux/playback-core/dist/index.mjs
  var g = hls /* default */.ZP;
  var dist_C = { VIDEO: 'video', THUMBNAIL: 'thumbnail', STORYBOARD: 'storyboard', DRM: 'drm' },
   dist_D = { NOT_AN_ERROR: 0, NETWORK_OFFLINE: 2000002, NETWORK_UNKNOWN_ERROR: 2e6, NETWORK_NO_STATUS: 2000001, NETWORK_INVALID_URL: 24e5, NETWORK_NOT_FOUND: 2404e3, NETWORK_NOT_READY: 2412e3, NETWORK_GENERIC_SERVER_FAIL: 25e5, NETWORK_TOKEN_MISSING: 2403201, NETWORK_TOKEN_MALFORMED: 2412202, NETWORK_TOKEN_EXPIRED: 2403210, NETWORK_TOKEN_AUD_MISSING: 2403221, NETWORK_TOKEN_AUD_MISMATCH: 2403222, NETWORK_TOKEN_SUB_MISMATCH: 2403232, ENCRYPTED_ERROR: 5e6, ENCRYPTED_UNSUPPORTED_KEY_SYSTEM: 5000001, ENCRYPTED_GENERATE_REQUEST_FAILED: 5000002, ENCRYPTED_UPDATE_LICENSE_FAILED: 5000003, ENCRYPTED_UPDATE_SERVER_CERT_FAILED: 5000004, ENCRYPTED_CDM_ERROR: 5000005, ENCRYPTED_OUTPUT_RESTRICTED: 5000006, ENCRYPTED_MISSING_TOKEN: 5000002 },
   dist_V = (e) => (e === dist_C.VIDEO ? 'playback' : e),
   L = class L extends Error {
    constructor(t, r = L.MEDIA_ERR_CUSTOM, n, o) {
     var a;
     super(t), (this.name = 'MediaError'), (this.code = r), (this.context = o), (this.fatal = n != null ? n : r >= L.MEDIA_ERR_NETWORK && r <= L.MEDIA_ERR_ENCRYPTED), this.message || (this.message = (a = L.defaultMessages[this.code]) != null ? a : '');
    }
   };
  (L.MEDIA_ERR_ABORTED = 1), (L.MEDIA_ERR_NETWORK = 2), (L.MEDIA_ERR_DECODE = 3), (L.MEDIA_ERR_SRC_NOT_SUPPORTED = 4), (L.MEDIA_ERR_ENCRYPTED = 5), (L.MEDIA_ERR_CUSTOM = 100), (L.defaultMessages = { 1: 'You aborted the media playback', 2: 'A network error caused the media download to fail.', 3: 'A media error caused playback to be aborted. The media could be corrupt or your browser does not support this format.', 4: 'An unsupported error occurred. The server or network failed, or your browser does not support this format.', 5: 'The media is encrypted and there are no keys to decrypt it.' });
  var f = L;
  var et = (e) => e == null,
   dist_O = (e, t) => (et(t) ? !1 : e in t),
   K = { ANY: 'any', MUTED: 'muted' },
   dist_ = { ON_DEMAND: 'on-demand', LIVE: 'live', UNKNOWN: 'unknown' },
   dist_X = { MSE: 'mse', NATIVE: 'native' },
   S = { HEADER: 'header', QUERY: 'query', NONE: 'none' },
   dist_jt = Object.values(S),
   dist_A = { M3U8: 'application/vnd.apple.mpegurl', MP4: 'video/mp4' },
   W = { HLS: dist_A.M3U8 },
   dist_Jt = Object.keys(W),
   dist_qt = [...Object.values(dist_A), 'hls', 'HLS'],
   dist_Gt = { upTo720p: '720p', upTo1080p: '1080p', upTo1440p: '1440p', upTo2160p: '2160p' },
   dist_Xt = { noLessThan480p: '480p', noLessThan540p: '540p', noLessThan720p: '720p', noLessThan1080p: '1080p', noLessThan1440p: '1440p', noLessThan2160p: '2160p' },
   dist_zt = { DESCENDING: 'desc' };
  var tt = 'en',
   dist_Y = { code: tt };
  var v = (e, t, r, n, o = e) => {
   o.addEventListener(t, r, n),
    e.addEventListener(
     'teardown',
     () => {
      o.removeEventListener(t, r);
     },
     { once: !0 },
    );
  };
  function dist_fe(e, t, r) {
   t && r > t && (r = t);
   for (let n = 0; n < e.length; n++) if (e.start(n) <= r && e.end(n) >= r) return !0;
   return !1;
  }
  var dist_F = (e) => {
    let t = e.indexOf('?');
    if (t < 0) return [e];
    let r = e.slice(0, t),
     n = e.slice(t);
    return [r, n];
   },
   dist_U = (e) => {
    let { type: t } = e;
    if (t) {
     let r = t.toUpperCase();
     return dist_O(r, W) ? W[r] : t;
    }
    return dist_rt(e);
   },
   dist_Q = (e) => (e === 'VOD' ? dist_.ON_DEMAND : dist_.LIVE),
   Z = (e) => (e === 'EVENT' ? Number.POSITIVE_INFINITY : e === 'VOD' ? Number.NaN : 0),
   dist_rt = (e) => {
    let { src: t } = e;
    if (!t) return '';
    let r = '';
    try {
     r = new URL(t).pathname;
    } catch {
     console.error('invalid url');
    }
    let n = r.lastIndexOf('.');
    if (n < 0) return dist_ot(e) ? dist_A.M3U8 : '';
    let a = r.slice(n + 1).toUpperCase();
    return dist_O(a, dist_A) ? dist_A[a] : '';
   },
   dist_nt = 'mux.com',
   dist_ot = ({ src: e, customDomain: t = dist_nt }) => {
    let r;
    try {
     r = new URL(`${e}`);
    } catch {
     return !1;
    }
    let n = r.protocol === 'https:',
     o = r.hostname === `stream.${t}`.toLowerCase(),
     a = r.pathname.split('/'),
     i = a.length === 2,
     c = !(a != null && a[1].includes('.'));
    return n && o && i && c;
   },
   dist_ee = (e) => {
    let t = (e != null ? e : '').split('.')[1];
    if (t)
     try {
      let r = t.replace(/-/g, '+').replace(/_/g, '/'),
       n = decodeURIComponent(
        atob(r)
         .split('')
         .map(function (o) {
          return '%' + ('00' + o.charCodeAt(0).toString(16)).slice(-2);
         })
         .join(''),
       );
      return JSON.parse(n);
     } catch {
      return;
     }
   },
   Te = ({ exp: e }, t = Date.now()) => !e || e * 1e3 < t,
   dist_ye = ({ sub: e }, t) => e !== t,
   me = ({ aud: e }, t) => !e,
   Ee = ({ aud: e }, t) => e !== t,
   dist_ge = 'en';
  function x(e, t = !0) {
   var o, a;
   let r = t && (a = (o = dist_Y) == null ? void 0 : o[e]) != null ? a : e,
    n = t ? dist_Y.code : dist_ge;
   return new z(r, n);
  }
  var z = class {
   constructor(t, r = ((n) => ((n = dist_Y) != null ? n : dist_ge))()) {
    (this.message = t), (this.locale = r);
   }
   format(t) {
    return this.message.replace(/\{(\w+)\}/g, (r, n) => {
     var o;
     return (o = t[n]) != null ? o : '';
    });
   }
   toString() {
    return this.message;
   }
  };
  var at = Object.values(K),
   dist_Me = (e) => typeof e == 'boolean' || (typeof e == 'string' && at.includes(e)),
   xe = (e, t, r) => {
    let { autoplay: n } = e,
     o = !1,
     a = !1,
     i = dist_Me(n) ? n : !!n,
     c = () => {
      o ||
       v(
        t,
        'playing',
        () => {
         o = !0;
        },
        { once: !0 },
       );
     };
    if (
     (c(),
     v(
      t,
      'loadstart',
      () => {
       (o = !1), c(), dist_te(t, i);
      },
      { once: !0 },
     ),
     v(
      t,
      'loadstart',
      () => {
       r || (e.streamType && e.streamType !== dist_.UNKNOWN ? (a = e.streamType === dist_.LIVE) : (a = !Number.isFinite(t.duration))), dist_te(t, i);
      },
      { once: !0 },
     ),
     r &&
      r.once(g.Events.LEVEL_LOADED, (u, s) => {
       var p;
       e.streamType && e.streamType !== dist_.UNKNOWN ? (a = e.streamType === dist_.LIVE) : (a = (p = s.details.live) != null ? p : !1);
      }),
     !i)
    ) {
     let u = () => {
      !a || Number.isFinite(e.startTime) || (r != null && r.liveSyncPosition ? (t.currentTime = r.liveSyncPosition) : Number.isFinite(t.seekable.end(0)) && (t.currentTime = t.seekable.end(0)));
     };
     r &&
      v(
       t,
       'play',
       () => {
        t.preload === 'metadata' ? r.once(g.Events.LEVEL_UPDATED, u) : u();
       },
       { once: !0 },
      );
    }
    return (u) => {
     o || ((i = dist_Me(u) ? u : !!u), dist_te(t, i));
    };
   },
   dist_te = (e, t) => {
    if (!t) return;
    let r = e.muted,
     n = () => (e.muted = r);
    switch (t) {
     case K.ANY:
      e.play().catch(() => {
       (e.muted = !0), e.play().catch(n);
      });
      break;
     case K.MUTED:
      (e.muted = !0), e.play().catch(n);
      break;
     default:
      e.play().catch(() => {});
      break;
    }
   };
  var Re = ({ preload: e, src: t }, r, n) => {
   let o = (p) => {
    p != null && ['', 'none', 'metadata', 'auto'].includes(p) ? r.setAttribute('preload', p) : r.removeAttribute('preload');
   };
   if (!n) return o(e), o;
   let a = !1,
    i = !1,
    c = n.config.maxBufferLength,
    d = n.config.maxBufferSize,
    u = (p) => {
     o(p);
     let l = p != null ? p : r.preload;
     i || l === 'none' || (l === 'metadata' ? ((n.config.maxBufferLength = 1), (n.config.maxBufferSize = 1)) : ((n.config.maxBufferLength = c), (n.config.maxBufferSize = d)), s());
    },
    s = () => {
     !a && t && ((a = !0), n.loadSource(t));
    };
   return (
    v(
     r,
     'play',
     () => {
      (i = !0), (n.config.maxBufferLength = c), (n.config.maxBufferSize = d), s();
     },
     { once: !0 },
    ),
    u(e),
    u
   );
  };
  function dist_De(e, t) {
   var c;
   if (!('videoTracks' in e)) return;
   let r = new WeakMap();
   t.on(g.Events.MANIFEST_PARSED, function (d, u) {
    i();
    let s = e.addVideoTrack('main');
    s.selected = !0;
    for (let [p, l] of u.levels.entries()) {
     let T = s.addRendition(l.url[0], l.width, l.height, l.videoCodec, l.bitrate);
     r.set(l, `${p}`), (T.id = `${p}`);
    }
   }),
    t.on(g.Events.AUDIO_TRACKS_UPDATED, function (d, u) {
     a();
     for (let s of u.audioTracks) {
      let p = s.default ? 'main' : 'alternative',
       l = e.addAudioTrack(p, s.name, s.lang);
      (l.id = `${s.id}`), s.default && (l.enabled = !0);
     }
    }),
    e.audioTracks.addEventListener('change', () => {
     var s;
     let d = +((s = [...e.audioTracks].find((p) => p.enabled)) == null ? void 0 : s.id),
      u = t.audioTracks.map((p) => p.id);
     d != t.audioTrack && u.includes(d) && (t.audioTrack = d);
    }),
    t.on(g.Events.LEVELS_UPDATED, function (d, u) {
     var l;
     let s = e.videoTracks[(l = e.videoTracks.selectedIndex) != null ? l : 0];
     if (!s) return;
     let p = u.levels.map((T) => r.get(T));
     for (let T of e.videoRenditions) T.id && !p.includes(T.id) && s.removeRendition(T);
    });
   let n = (d) => {
    let u = d.target.selectedIndex;
    u != t.nextLevel && (t.nextLevel = u);
   };
   (c = e.videoRenditions) == null || c.addEventListener('change', n);
   let o = () => {
     for (let d of e.videoTracks) e.removeVideoTrack(d);
    },
    a = () => {
     for (let d of e.audioTracks) e.removeAudioTrack(d);
    },
    i = () => {
     o(), a();
    };
   t.once(g.Events.DESTROYING, i);
  }
  var dist_re = (e) => ('time' in e ? e.time : e.startTime);
  function dist_be(e, t) {
   t.on(g.Events.NON_NATIVE_TEXT_TRACKS_FOUND, (o, { tracks: a }) => {
    a.forEach((i) => {
     var s, p;
     let c = (s = i.subtitleTrack) != null ? s : i.closedCaptions,
      d = t.subtitleTracks.findIndex(({ lang: l, name: T, type: m }) => l == (c == null ? void 0 : c.lang) && T === i.label && m.toLowerCase() === i.kind),
      u = ((p = i._id) != null ? p : i.default) ? 'default' : `${i.kind}${d}`;
     dist_ne(e, i.kind, i.label, c == null ? void 0 : c.lang, u, i.default);
    });
   });
   let r = () => {
    if (!t.subtitleTracks.length) return;
    let o = Array.from(e.textTracks).find((c) => c.id && c.mode === 'showing' && ['subtitles', 'captions'].includes(c.kind));
    if (!o) return;
    let a = t.subtitleTracks[t.subtitleTrack],
     i = a ? (a.default ? 'default' : `${t.subtitleTracks[t.subtitleTrack].type.toLowerCase()}${t.subtitleTrack}`) : void 0;
    if (t.subtitleTrack < 0 || (o == null ? void 0 : o.id) !== i) {
     let c = t.subtitleTracks.findIndex(({ lang: d, name: u, type: s, default: p }) => (o.id === 'default' && p) || (d == o.language && u === o.label && s.toLowerCase() === o.kind));
     t.subtitleTrack = c;
    }
    (o == null ? void 0 : o.id) === i &&
     o.cues &&
     Array.from(o.cues).forEach((c) => {
      o.addCue(c);
     });
   };
   e.textTracks.addEventListener('change', r),
    t.on(g.Events.CUES_PARSED, (o, { track: a, cues: i }) => {
     let c = e.textTracks.getTrackById(a);
     if (!c) return;
     let d = c.mode === 'disabled';
     d && (c.mode = 'hidden'),
      i.forEach((u) => {
       var s;
       ((s = c.cues) != null && s.getCueById(u.id)) || c.addCue(u);
      }),
      d && (c.mode = 'disabled');
    }),
    t.once(g.Events.DESTROYING, () => {
     e.textTracks.removeEventListener('change', r),
      e.querySelectorAll('track[data-removeondestroy]').forEach((a) => {
       a.remove();
      });
    });
   let n = () => {
    Array.from(e.textTracks).forEach((o) => {
     var a, i;
     if (!['subtitles', 'caption'].includes(o.kind) && (o.label === 'thumbnails' || o.kind === 'chapters')) {
      if (!((a = o.cues) != null && a.length)) {
       let c = 'track';
       o.kind && (c += `[kind="${o.kind}"]`), o.label && (c += `[label="${o.label}"]`);
       let d = e.querySelector(c),
        u = (i = d == null ? void 0 : d.getAttribute('src')) != null ? i : '';
       d == null || d.removeAttribute('src'),
        setTimeout(() => {
         d == null || d.setAttribute('src', u);
        }, 0);
      }
      o.mode !== 'hidden' && (o.mode = 'hidden');
     }
    });
   };
   t.once(g.Events.MANIFEST_LOADED, n), t.once(g.Events.MEDIA_ATTACHED, n);
  }
  function dist_ne(e, t, r, n, o, a) {
   let i = document.createElement('track');
   return (i.kind = t), (i.label = r), n && (i.srclang = n), o && (i.id = o), a && (i.default = !0), (i.track.mode = ['subtitles', 'captions'].includes(t) ? 'disabled' : 'hidden'), i.setAttribute('data-removeondestroy', ''), e.append(i), i.track;
  }
  function dist_st(e, t) {
   let r = Array.prototype.find.call(e.querySelectorAll('track'), (n) => n.track === t);
   r == null || r.remove();
  }
  function w(e, t, r) {
   var n;
   return (n = Array.from(e.querySelectorAll('track')).find((o) => o.track.label === t && o.track.kind === r)) == null ? void 0 : n.track;
  }
  async function dist_Ce(e, t, r, n) {
   let o = w(e, r, n);
   return (
    o || ((o = dist_ne(e, n, r)), (o.mode = 'hidden'), await new Promise((a) => setTimeout(() => a(void 0), 0))),
    o.mode !== 'hidden' && (o.mode = 'hidden'),
    [...t]
     .sort((a, i) => dist_re(i) - dist_re(a))
     .forEach((a) => {
      var d, u;
      let i = a.value,
       c = dist_re(a);
      if ('endTime' in a && a.endTime != null) o == null || o.addCue(new VTTCue(c, a.endTime, n === 'chapters' ? i : JSON.stringify(i != null ? i : null)));
      else {
       let s = Array.prototype.findIndex.call(o == null ? void 0 : o.cues, (m) => m.startTime >= c),
        p = (d = o == null ? void 0 : o.cues) == null ? void 0 : d[s],
        l = p ? p.startTime : Number.isFinite(e.duration) ? e.duration : Number.MAX_SAFE_INTEGER,
        T = (u = o == null ? void 0 : o.cues) == null ? void 0 : u[s - 1];
       T && (T.endTime = c), o == null || o.addCue(new VTTCue(c, l, n === 'chapters' ? i : JSON.stringify(i != null ? i : null)));
      }
     }),
    e.textTracks.dispatchEvent(new Event('change', { bubbles: !0, composed: !0 })),
    o
   );
  }
  var oe = 'cuepoints',
   dist_ve = Object.freeze({ label: oe });
  async function dist_Pe(e, t, r = dist_ve) {
   return dist_Ce(e, t, r.label, 'metadata');
  }
  var dist_$ = (e) => ({ time: e.startTime, value: JSON.parse(e.text) });
  function it(e, t = { label: oe }) {
   let r = w(e, t.label, 'metadata');
   return r != null && r.cues ? Array.from(r.cues, (n) => dist_$(n)) : [];
  }
  function dist_e(e, t = { label: oe }) {
   var a, i;
   let r = w(e, t.label, 'metadata');
   if (!((a = r == null ? void 0 : r.activeCues) != null && a.length)) return;
   if (r.activeCues.length === 1) return dist_$(r.activeCues[0]);
   let { currentTime: n } = e,
    o = Array.prototype.find.call((i = r.activeCues) != null ? i : [], ({ startTime: c, endTime: d }) => c <= n && d > n);
   return dist_$(o || r.activeCues[0]);
  }
  async function dist_ke(e, t = dist_ve) {
   return new Promise((r) => {
    v(e, 'loadstart', async () => {
     let n = await dist_Pe(e, [], t);
     v(
      e,
      'cuechange',
      () => {
       let o = dist_e(e);
       if (o) {
        let a = new CustomEvent('cuepointchange', { composed: !0, bubbles: !0, detail: o });
        e.dispatchEvent(a);
       }
      },
      {},
      n,
     ),
      r(n);
    });
   });
  }
  var ae = 'chapters',
   dist_he = Object.freeze({ label: ae }),
   dist_B = (e) => ({ startTime: e.startTime, endTime: e.endTime, value: e.text });
  async function dist_Le(e, t, r = dist_he) {
   return dist_Ce(e, t, r.label, 'chapters');
  }
  function dist_ct(e, t = { label: ae }) {
   var n;
   let r = w(e, t.label, 'chapters');
   return (n = r == null ? void 0 : r.cues) != null && n.length ? Array.from(r.cues, (o) => dist_B(o)) : [];
  }
  function dist_Ne(e, t = { label: ae }) {
   var a, i;
   let r = w(e, t.label, 'chapters');
   if (!((a = r == null ? void 0 : r.activeCues) != null && a.length)) return;
   if (r.activeCues.length === 1) return dist_B(r.activeCues[0]);
   let { currentTime: n } = e,
    o = Array.prototype.find.call((i = r.activeCues) != null ? i : [], ({ startTime: c, endTime: d }) => c <= n && d > n);
   return dist_B(o || r.activeCues[0]);
  }
  async function dist_Ae(e, t = dist_he) {
   return new Promise((r) => {
    v(e, 'loadstart', async () => {
     let n = await dist_Le(e, [], t);
     v(
      e,
      'cuechange',
      () => {
       let o = dist_Ne(e);
       if (o) {
        let a = new CustomEvent('chapterchange', { composed: !0, bubbles: !0, detail: o });
        e.dispatchEvent(a);
       }
      },
      {},
      n,
     ),
      r(n);
    });
   });
  }
  function dist_ut(e, t) {
   if (t) {
    let r = t.playingDate;
    if (r != null) return new Date(r.getTime() - e.currentTime * 1e3);
   }
   return typeof e.getStartDate == 'function' ? e.getStartDate() : new Date(NaN);
  }
  function dist_dt(e, t) {
   if (t && t.playingDate) return t.playingDate;
   if (typeof e.getStartDate == 'function') {
    let r = e.getStartDate();
    return new Date(r.getTime() + e.currentTime * 1e3);
   }
   return new Date(NaN);
  }
  var dist_se = { VIDEO: 'v', THUMBNAIL: 't', STORYBOARD: 's', DRM: 'd' },
   dist_lt = (e) => {
    if (e === dist_C.VIDEO) return dist_se.VIDEO;
    if (e === dist_C.DRM) return dist_se.DRM;
   },
   dist_pt = (e, t) => {
    var o, a;
    let r = dist_V(e),
     n = `${r}Token`;
    return (o = t.tokens) != null && o[r] ? ((a = t.tokens) == null ? void 0 : a[r]) : dist_O(n, t) ? t[n] : void 0;
   },
   dist_H = (e, t, r, n, o = !1, a = !((i) => ((i = globalThis.navigator) == null ? void 0 : i.onLine))()) => {
    var M, h;
    if (a) {
     let E = x('Your device appears to be offline', o),
      b = void 0,
      y = f.MEDIA_ERR_NETWORK,
      k = new f(E, y, !1, b);
     return (k.errorCategory = t), (k.muxCode = dist_D.NETWORK_OFFLINE), (k.data = e), k;
    }
    let c = 'status' in e ? e.status : e.code,
     d = Date.now(),
     u = f.MEDIA_ERR_NETWORK;
    if (c === 200) return;
    let s = dist_V(t),
     p = dist_pt(t, r),
     l = dist_lt(t),
     [T] = dist_F((M = r.playbackId) != null ? M : '');
    if (!c || !T) return;
    let m = dist_ee(p);
    if (p && !m) {
     let E = x('The {tokenNamePrefix}-token provided is invalid or malformed.', o).format({ tokenNamePrefix: s }),
      b = x('Compact JWT string: {token}', o).format({ token: p }),
      y = new f(E, u, !0, b);
     return (y.errorCategory = t), (y.muxCode = dist_D.NETWORK_TOKEN_MALFORMED), (y.data = e), y;
    }
    if (c >= 500) {
     let E = new f('', u, n != null ? n : !0);
     return (E.errorCategory = t), (E.muxCode = dist_D.NETWORK_UNKNOWN_ERROR), E;
    }
    if (c === 403)
     if (m) {
      if (Te(m, d)) {
       let E = { timeStyle: 'medium', dateStyle: 'medium' },
        b = x('The video\u2019s secured {tokenNamePrefix}-token has expired.', o).format({ tokenNamePrefix: s }),
        y = x('Expired at: {expiredDate}. Current time: {currentDate}.', o).format({ expiredDate: new Intl.DateTimeFormat('en', E).format((h = m.exp) != null ? h : 0 * 1e3), currentDate: new Intl.DateTimeFormat('en', E).format(d) }),
        k = new f(b, u, !0, y);
       return (k.errorCategory = t), (k.muxCode = dist_D.NETWORK_TOKEN_EXPIRED), (k.data = e), k;
      }
      if (dist_ye(m, T)) {
       let E = x('The video\u2019s playback ID does not match the one encoded in the {tokenNamePrefix}-token.', o).format({ tokenNamePrefix: s }),
        b = x('Specified playback ID: {playbackId} and the playback ID encoded in the {tokenNamePrefix}-token: {tokenPlaybackId}', o).format({ tokenNamePrefix: s, playbackId: T, tokenPlaybackId: m.sub }),
        y = new f(E, u, !0, b);
       return (y.errorCategory = t), (y.muxCode = dist_D.NETWORK_TOKEN_SUB_MISMATCH), (y.data = e), y;
      }
      if (me(m, l)) {
       let E = x('The {tokenNamePrefix}-token is formatted with incorrect information.', o).format({ tokenNamePrefix: s }),
        b = x('The {tokenNamePrefix}-token has no aud value. aud value should be {expectedAud}.', o).format({ tokenNamePrefix: s, expectedAud: l }),
        y = new f(E, u, !0, b);
       return (y.errorCategory = t), (y.muxCode = dist_D.NETWORK_TOKEN_AUD_MISSING), (y.data = e), y;
      }
      if (Ee(m, l)) {
       let E = x('The {tokenNamePrefix}-token is formatted with incorrect information.', o).format({ tokenNamePrefix: s }),
        b = x('The {tokenNamePrefix}-token has an incorrect aud value: {aud}. aud value should be {expectedAud}.', o).format({ tokenNamePrefix: s, expectedAud: l, aud: m.aud }),
        y = new f(E, u, !0, b);
       return (y.errorCategory = t), (y.muxCode = dist_D.NETWORK_TOKEN_AUD_MISMATCH), (y.data = e), y;
      }
     } else {
      let E = x('Authorization error trying to access this {category} URL. If this is a signed URL, you might need to provide a {tokenNamePrefix}-token.', o).format({ tokenNamePrefix: s, category: t }),
       b = x('Specified playback ID: {playbackId}', o).format({ playbackId: T }),
       y = new f(E, u, n != null ? n : !0, b);
      return (y.errorCategory = t), (y.muxCode = dist_D.NETWORK_TOKEN_MISSING), (y.data = e), y;
     }
    if (c === 412) {
     let E = x('This playback-id may belong to a live stream that is not currently active or an asset that is not ready.', o),
      b = x('Specified playback ID: {playbackId}', o).format({ playbackId: T }),
      y = new f(E, u, n != null ? n : !0, b);
     return (y.errorCategory = t), (y.muxCode = dist_D.NETWORK_NOT_READY), (y.streamType = r.streamType === dist_.LIVE ? 'live' : r.streamType === dist_.ON_DEMAND ? 'on-demand' : 'unknown'), (y.data = e), y;
    }
    if (c === 404) {
     let E = x('This URL or playback-id does not exist. You may have used an Asset ID or an ID from a different resource.', o),
      b = x('Specified playback ID: {playbackId}', o).format({ playbackId: T }),
      y = new f(E, u, n != null ? n : !0, b);
     return (y.errorCategory = t), (y.muxCode = dist_D.NETWORK_NOT_FOUND), (y.data = e), y;
    }
    if (c === 400) {
     let E = x('The URL or playback-id was invalid. You may have used an invalid value as a playback-id.'),
      b = x('Specified playback ID: {playbackId}', o).format({ playbackId: T }),
      y = new f(E, u, n != null ? n : !0, b);
     return (y.errorCategory = t), (y.muxCode = dist_D.NETWORK_INVALID_URL), (y.data = e), y;
    }
    let R = new f('', u, n != null ? n : !0);
    return (R.errorCategory = t), (R.muxCode = dist_D.NETWORK_UNKNOWN_ERROR), (R.data = e), R;
   };
  var dist_Ie = g.DefaultConfig.capLevelController,
   dist_j = class j extends dist_Ie {
    constructor(t) {
     super(t);
    }
    get levels() {
     var t;
     return (t = this.hls.levels) != null ? t : [];
    }
    getValidLevels(t) {
     return this.levels.filter((r, n) => this.isLevelAllowed(r) && n <= t);
    }
    getMaxLevel(t) {
     let r = super.getMaxLevel(t),
      n = this.getValidLevels(t);
     if (!n[r]) return r;
     let o = Math.min(n[r].width, n[r].height),
      a = j.minMaxResolution;
     return o >= a ? r : dist_Ie.getMaxLevelByMediaSize(n, a * (16 / 9), a);
    }
   };
  dist_j.minMaxResolution = 720;
  var dist_ie = dist_j,
   dist_Se = dist_ie;
  var dist_J = { FAIRPLAY: 'fairplay', PLAYREADY: 'playready', WIDEVINE: 'widevine' },
   dist_ft = (e) => {
    if (e.includes('fps')) return dist_J.FAIRPLAY;
    if (e.includes('playready')) return dist_J.PLAYREADY;
    if (e.includes('widevine')) return dist_J.WIDEVINE;
   },
   dist_Tt = (e) => {
    let t = e
     .split(
      `
`,
     )
     .find((r, n, o) => n && o[n - 1].startsWith('#EXT-X-STREAM-INF'));
    return fetch(t).then((r) => (r.status !== 200 ? Promise.reject(r) : r.text()));
   },
   yt = (e) => {
    let t = e
     .split(
      `
`,
     )
     .filter((n) => n.startsWith('#EXT-X-SESSION-DATA'));
    if (!t.length) return {};
    let r = {};
    for (let n of t) {
     let o = dist_Et(n),
      a = o['DATA-ID'];
     a && (r[a] = { ...o });
    }
    return { sessionData: r };
   },
   dist_mt = /([A-Z0-9-]+)="?(.*?)"?(?:,|$)/g;
  function dist_Et(e) {
   let t = [...e.matchAll(dist_mt)];
   return Object.fromEntries(t.map(([, r, n]) => [r, n]));
  }
  var dist_gt = (e) => {
    var c, d, u;
    let t = e.split(`
`),
     n = (d = ((c = t.find((s) => s.startsWith('#EXT-X-PLAYLIST-TYPE'))) != null ? c : '').split(':')[1]) == null ? void 0 : d.trim(),
     o = dist_Q(n),
     a = Z(n),
     i;
    if (o === dist_.LIVE) {
     let s = t.find((l) => l.startsWith('#EXT-X-PART-INF'));
     if (!!s) i = +s.split(':')[1].split('=')[1] * 2;
     else {
      let l = t.find((R) => R.startsWith('#EXT-X-TARGETDURATION')),
       T = (u = l == null ? void 0 : l.split(':')) == null ? void 0 : u[1];
      i = +(T != null ? T : 6) * 3;
     }
    }
    return { streamType: o, targetLiveWindow: a, liveEdgeStartOffset: i };
   },
   dist_Mt = async (e, t) => {
    if (t === dist_A.MP4) return { streamType: dist_.ON_DEMAND, targetLiveWindow: Number.NaN, liveEdgeStartOffset: void 0, sessionData: void 0 };
    if (t === dist_A.M3U8) {
     let r = await fetch(e);
     if (!r.ok) return Promise.reject(r);
     let n = await r.text(),
      o = await dist_Tt(n);
     return { ...yt(n), ...dist_gt(o) };
    }
    return console.error(`Media type ${t} is an unrecognized or unsupported type for src ${e}.`), { streamType: void 0, targetLiveWindow: void 0, liveEdgeStartOffset: void 0, sessionData: void 0 };
   },
   dist_xt = async (e, t, r = dist_U({ src: e })) => {
    var d, u, s, p;
    let { streamType: n, targetLiveWindow: o, liveEdgeStartOffset: a, sessionData: i } = await dist_Mt(e, r),
     c = i == null ? void 0 : i['com.apple.hls.chapters'];
    ((c != null && c.URI) || (c != null && c.VALUE.toLocaleLowerCase().startsWith('http'))) && dist_de((d = c.URI) != null ? d : c.VALUE, t), (((u = P.get(t)) != null ? u : {}).liveEdgeStartOffset = a), (((s = P.get(t)) != null ? s : {}).targetLiveWindow = o), t.dispatchEvent(new CustomEvent('targetlivewindowchange', { composed: !0, bubbles: !0 })), (((p = P.get(t)) != null ? p : {}).streamType = n), t.dispatchEvent(new CustomEvent('streamtypechange', { composed: !0, bubbles: !0 }));
   },
   dist_de = async (e, t) => {
    var r, n;
    try {
     let o = await fetch(e);
     if (!o.ok) throw new Error(`Failed to fetch Mux metadata: ${o.status} ${o.statusText}`);
     let a = await o.json(),
      i = {};
     if (!((r = a == null ? void 0 : a[0]) != null && r.metadata)) return;
     for (let d of a[0].metadata) d.key && d.value && (i[d.key] = d.value);
     ((n = P.get(t)) != null ? n : {}).metadata = i;
     let c = new CustomEvent('muxmetadata');
     t.dispatchEvent(c);
    } catch (o) {
     console.error(o);
    }
   },
   dist_Rt = (e) => {
    var i;
    let t = e.type,
     r = dist_Q(t),
     n = Z(t),
     o,
     a = !!((i = e.partList) != null && i.length);
    return r === dist_.LIVE && (o = a ? e.partTarget * 2 : e.targetduration * 3), { streamType: r, targetLiveWindow: n, liveEdgeStartOffset: o, lowLatency: a };
   },
   dist_Dt = (e, t, r) => {
    var c, d, u, s, p, l, T, m;
    let { streamType: n, targetLiveWindow: o, liveEdgeStartOffset: a, lowLatency: i } = dist_Rt(e);
    if (n === dist_.LIVE) {
     i ? ((r.config.backBufferLength = (c = r.userConfig.backBufferLength) != null ? c : 4), (r.config.maxFragLookUpTolerance = (d = r.userConfig.maxFragLookUpTolerance) != null ? d : 0.001), (r.config.abrBandWidthUpFactor = (u = r.userConfig.abrBandWidthUpFactor) != null ? u : r.config.abrBandWidthFactor)) : (r.config.backBufferLength = (s = r.userConfig.backBufferLength) != null ? s : 8);
     let R = Object.freeze({
      get length() {
       return t.seekable.length;
      },
      start(M) {
       return t.seekable.start(M);
      },
      end(M) {
       var h;
       return M > this.length || M < 0 || Number.isFinite(t.duration) ? t.seekable.end(M) : (h = r.liveSyncPosition) != null ? h : t.seekable.end(M);
      },
     });
     ((p = P.get(t)) != null ? p : {}).seekable = R;
    }
    (((l = P.get(t)) != null ? l : {}).liveEdgeStartOffset = a), (((T = P.get(t)) != null ? T : {}).targetLiveWindow = o), t.dispatchEvent(new CustomEvent('targetlivewindowchange', { composed: !0, bubbles: !0 })), (((m = P.get(t)) != null ? m : {}).streamType = n), t.dispatchEvent(new CustomEvent('streamtypechange', { composed: !0, bubbles: !0 }));
   },
   dist_Oe,
   dist_Ue,
   dist_bt = (dist_Ue = (dist_Oe = globalThis == null ? void 0 : globalThis.navigator) == null ? void 0 : dist_Oe.userAgent) != null ? dist_Ue : '',
   dist_He,
   Ve,
   dist_Ke,
   dist_Ct = (dist_Ke = (Ve = (dist_He = globalThis == null ? void 0 : globalThis.navigator) == null ? void 0 : dist_He.userAgentData) == null ? void 0 : Ve.platform) != null ? dist_Ke : '',
   dist_vt = dist_bt.toLowerCase().includes('android') || ['x11', 'android'].some((e) => dist_Ct.toLowerCase().includes(e)),
   P = new WeakMap(),
   I = 'mux.com',
   We,
   dist_Ye,
   dist_Fe = (dist_Ye = (We = g).isSupported) == null ? void 0 : dist_Ye.call(We),
   dist_Pt = dist_vt,
   dist_Wr = () => Md.utils.now(),
   dist_t = Md.utils.generateUUID,
   Yr = ({ playbackId: e, customDomain: t = I, maxResolution: r, minResolution: n, renditionOrder: o, programStartTime: a, programEndTime: i, assetStartTime: c, assetEndTime: d, playbackToken: u, tokens: { playback: s = u } = {}, extraSourceParams: p = {} } = {}) => {
    if (!e) return;
    let [l, T = ''] = dist_F(e),
     m = new URL(`https://stream.${t}/${l}.m3u8${T}`);
    return (
     s || m.searchParams.has('token')
      ? (m.searchParams.forEach((R, M) => {
         M != 'token' && m.searchParams.delete(M);
        }),
        s && m.searchParams.set('token', s))
      : (r && m.searchParams.set('max_resolution', r),
        n && (m.searchParams.set('min_resolution', n), r && +r.slice(0, -1) < +n.slice(0, -1) && console.error('minResolution must be <= maxResolution', 'minResolution', n, 'maxResolution', r)),
        o && m.searchParams.set('rendition_order', o),
        a && m.searchParams.set('program_start_time', `${a}`),
        i && m.searchParams.set('program_end_time', `${i}`),
        c && m.searchParams.set('asset_start_time', `${c}`),
        d && m.searchParams.set('asset_end_time', `${d}`),
        Object.entries(p).forEach(([R, M]) => {
         M != null && m.searchParams.set(R, M);
        })),
     m.toString()
    );
   },
   G = (e) => {
    if (!e) return;
    let [t] = e.split('?');
    return t || void 0;
   },
   dist_$e = (e) => {
    if (!e || !e.startsWith('https://stream.')) return;
    let [t] = new URL(e).pathname.slice(1).split(/\.m3u8|\//);
    return t || void 0;
   },
   dist_kt = (e) => {
    var t, r, n;
    return (t = e == null ? void 0 : e.metadata) != null && t.video_id ? e.metadata.video_id : dist_Xe(e) && (n = (r = G(e.playbackId)) != null ? r : dist_$e(e.src)) != null ? n : e.src;
   },
   dist_ht = (e) => {
    var t;
    return (t = P.get(e)) == null ? void 0 : t.error;
   },
   dist_Fr = (e) => {
    var t;
    return (t = P.get(e)) == null ? void 0 : t.metadata;
   },
   we = (e) => {
    var t, r;
    return (r = (t = P.get(e)) == null ? void 0 : t.streamType) != null ? r : dist_.UNKNOWN;
   },
   $r = (e) => {
    var t, r;
    return (r = (t = P.get(e)) == null ? void 0 : t.targetLiveWindow) != null ? r : Number.NaN;
   },
   Be = (e) => {
    var t, r;
    return (r = (t = P.get(e)) == null ? void 0 : t.seekable) != null ? r : e.seekable;
   },
   dist_Br = (e) => {
    var n;
    let t = (n = P.get(e)) == null ? void 0 : n.liveEdgeStartOffset;
    if (typeof t != 'number') return Number.NaN;
    let r = Be(e);
    return r.length ? r.end(r.length - 1) - t : Number.NaN;
   },
   dist_le = 0.034,
   dist_Lt = (e, t, r = dist_le) => Math.abs(e - t) <= r,
   je = (e, t, r = dist_le) => e > t || dist_Lt(e, t, r),
   dist_Nt = (e, t = dist_le) => e.paused && je(e.currentTime, e.duration, t),
   dist_Je = (e, t) => {
    var u, s, p;
    if (!t || !e.buffered.length) return;
    if (e.readyState > 2) return !1;
    let r = t.currentLevel >= 0 ? ((s = (u = t.levels) == null ? void 0 : u[t.currentLevel]) == null ? void 0 : s.details) : (p = t.levels.find((l) => !!l.details)) == null ? void 0 : p.details;
    if (!r || r.live) return;
    let { fragments: n } = r;
    if (!(n != null && n.length)) return;
    if (e.currentTime < e.duration - (r.targetduration + 0.5)) return !1;
    let o = n[n.length - 1];
    if (e.currentTime <= o.start) return !1;
    let a = o.start + o.duration / 2,
     i = e.buffered.start(e.buffered.length - 1),
     c = e.buffered.end(e.buffered.length - 1);
    return a > i && a < c;
   },
   dist_At = (e, t) => (e.ended || e.loop ? e.ended : t && dist_Je(e, t) ? !0 : dist_Nt(e)),
   dist_jr = (e, t, r) => {
    dist_It(t, r, e);
    let { metadata: n = {} } = e,
     { view_session_id: o = dist_t() } = n,
     a = dist_kt(e);
    (n.view_session_id = o), (n.video_id = a), (e.metadata = n);
    let i = (s) => {
     var p;
     (p = t.mux) == null || p.emit('hb', { view_drm_type: s });
    };
    (e.drmTypeCb = i), P.set(t, { retryCount: 0 });
    let c = dist_St(e, t),
     d = Re(e, t, c);
    e != null && e.muxDataKeepSession && t != null && t.mux && !t.mux.deleted ? c && t.mux.addHLSJS({ hlsjs: c, Hls: c ? g : void 0 }) : dist_Kt(e, t, c), dist_Wt(e, t, c), dist_ke(t), dist_Ae(t);
    let u = xe(e, t, c);
    return { engine: c, setAutoplay: u, setPreload: d };
   },
   dist_It = (e, t, r) => {
    let n = t == null ? void 0 : t.engine;
    e != null && e.mux && !e.mux.deleted && (r != null && r.muxDataKeepSession ? n && e.mux.removeHLSJS() : (e.mux.destroy(), delete e.mux)), n && (n.detachMedia(), n.destroy()), e && (e.hasAttribute('src') && (e.removeAttribute('src'), e.load()), e.removeEventListener('error', dist_Qe), e.removeEventListener('error', dist_ce), e.removeEventListener('durationchange', dist_ze), P.delete(e), e.dispatchEvent(new Event('teardown')));
   };
  function qe(e, t) {
   var u;
   let r = dist_U(e);
   if (!(r === dist_A.M3U8)) return !0;
   let o = !r || ((u = t.canPlayType(r)) != null ? u : !0),
    { preferPlayback: a } = e,
    i = a === dist_X.MSE,
    c = a === dist_X.NATIVE;
   return o && (c || !(dist_Fe && (i || dist_Pt)));
  }
  var dist_St = (e, t) => {
    let { debug: r, streamType: n, startTime: o = -1, metadata: a, preferCmcd: i, _hlsConfig: c = {} } = e,
     u = dist_U(e) === dist_A.M3U8,
     s = qe(e, t);
    if (u && !s && dist_Fe) {
     let p = { backBufferLength: 30, renderTextTracksNatively: !1, liveDurationInfinity: !0, capLevelToPlayerSize: !0, capLevelOnFPSDrop: !0 },
      l = dist_wt(n),
      T = dist_Ot(e),
      m = [S.QUERY, S.HEADER].includes(i) ? { useHeaders: i === S.HEADER, sessionId: a == null ? void 0 : a.view_session_id, contentId: a == null ? void 0 : a.video_id } : void 0,
      R = new g({
       debug: r,
       startPosition: o,
       cmcd: m,
       xhrSetup: (M, h) => {
        var y, k;
        if (i && i !== S.QUERY) return;
        let E = new URL(h);
        if (!E.searchParams.has('CMCD')) return;
        let b = ((k = (y = E.searchParams.get('CMCD')) == null ? void 0 : y.split(',')) != null ? k : []).filter((pe) => pe.startsWith('sid') || pe.startsWith('cid')).join(',');
        E.searchParams.set('CMCD', b), M.open('GET', E);
       },
       capLevelController: dist_Se,
       ...p,
       ...l,
       ...T,
       ...c,
      });
     return (
      R.on(g.Events.MANIFEST_PARSED, async function (M, h) {
       var b, y;
       let E = (b = h.sessionData) == null ? void 0 : b['com.apple.hls.chapters'];
       ((E != null && E.URI) || (E != null && E.VALUE.toLocaleLowerCase().startsWith('http'))) && dist_de((y = E == null ? void 0 : E.URI) != null ? y : E == null ? void 0 : E.VALUE, t);
      }),
      R
     );
    }
   },
   dist_wt = (e) => (e === dist_.LIVE ? { backBufferLength: 8 } : {}),
   dist_Ot = (e) => {
    let { tokens: { drm: t } = {}, playbackId: r, drmTypeCb: n } = e,
     o = G(r);
    return !t || !o
     ? {}
     : {
        emeEnabled: !0,
        drmSystems: { 'com.apple.fps': { licenseUrl: dist_q(e, 'fairplay'), serverCertificateUrl: dist_Ge(e, 'fairplay') }, 'com.widevine.alpha': { licenseUrl: dist_q(e, 'widevine') }, 'com.microsoft.playready': { licenseUrl: dist_q(e, 'playready') } },
        requestMediaKeySystemAccessFunc: (a, i) => (
         a === 'com.widevine.alpha' &&
          (i = [
           ...i.map((c) => {
            var u;
            let d = (u = c.videoCapabilities) == null ? void 0 : u.map((s) => ({ ...s, robustness: 'HW_SECURE_ALL' }));
            return { ...c, videoCapabilities: d };
           }),
           ...i,
          ]),
         navigator.requestMediaKeySystemAccess(a, i).then((c) => {
          let d = dist_ft(a);
          return n == null || n(d), c;
         })
        ),
       };
   },
   dist_Ut = async (e) => {
    let t = await fetch(e);
    return t.status !== 200 ? Promise.reject(t) : await t.arrayBuffer();
   },
   dist_Ht = async (e, t) => {
    let r = await fetch(t, { method: 'POST', headers: { 'Content-type': 'application/octet-stream' }, body: e });
    if (r.status !== 200) return Promise.reject(r);
    let n = await r.arrayBuffer();
    return new Uint8Array(n);
   },
   dist_Vt = (e, t) => {
    v(t, 'encrypted', async (n) => {
     try {
      let o = n.initDataType;
      if (o !== 'skd') {
       console.error(`Received unexpected initialization data type "${o}"`);
       return;
      }
      if (!t.mediaKeys) {
       let u = await navigator
        .requestMediaKeySystemAccess('com.apple.fps', [{ initDataTypes: [o], videoCapabilities: [{ contentType: 'application/vnd.apple.mpegurl', robustness: '' }], distinctiveIdentifier: 'not-allowed', persistentState: 'not-allowed', sessionTypes: ['temporary'] }])
        .then((p) => {
         var l;
         return (l = e.drmTypeCb) == null || l.call(e, dist_J.FAIRPLAY), p;
        })
        .catch(() => {
         let p = x('Cannot play DRM-protected content with current security configuration on this browser. Try playing in another browser.'),
          l = new f(p, f.MEDIA_ERR_ENCRYPTED, !0);
         (l.errorCategory = dist_C.DRM), (l.muxCode = dist_D.ENCRYPTED_UNSUPPORTED_KEY_SYSTEM), dist_N(t, l);
        });
       if (!u) return;
       let s = await u.createMediaKeys();
       try {
        let p = await dist_Ut(dist_Ge(e, 'fairplay')).catch((l) => {
         if (l instanceof Response) {
          let T = dist_H(l, dist_C.DRM, e);
          return console.error('mediaError', T == null ? void 0 : T.message, T == null ? void 0 : T.context), T ? Promise.reject(T) : Promise.reject(new Error('Unexpected error in app cert request'));
         }
         return Promise.reject(l);
        });
        await s.setServerCertificate(p).catch(() => {
         let l = x('Your server certificate failed when attempting to set it. This may be an issue with a no longer valid certificate.'),
          T = new f(l, f.MEDIA_ERR_ENCRYPTED, !0);
         return (T.errorCategory = dist_C.DRM), (T.muxCode = dist_D.ENCRYPTED_UPDATE_SERVER_CERT_FAILED), Promise.reject(T);
        });
       } catch (p) {
        dist_N(t, p);
        return;
       }
       await t.setMediaKeys(s);
      }
      let a = n.initData;
      if (a == null) {
       console.error(`Could not start encrypted playback due to missing initData in ${n.type} event`);
       return;
      }
      let i = t.mediaKeys.createSession();
      i.addEventListener('keystatuseschange', () => {
       i.keyStatuses.forEach((u) => {
        let s;
        if (u === 'internal-error') {
         let p = x('The DRM Content Decryption Module system had an internal failure. Try reloading the page, upading your browser, or playing in another browser.');
         (s = new f(p, f.MEDIA_ERR_ENCRYPTED, !0)), (s.errorCategory = dist_C.DRM), (s.muxCode = dist_D.ENCRYPTED_CDM_ERROR);
        } else if (u === 'output-restricted' || u === 'output-downscaled') {
         let p = x('DRM playback is being attempted in an environment that is not sufficiently secure. User may see black screen.');
         (s = new f(p, f.MEDIA_ERR_ENCRYPTED, !1)), (s.errorCategory = dist_C.DRM), (s.muxCode = dist_D.ENCRYPTED_OUTPUT_RESTRICTED);
        }
        s && dist_N(t, s);
       });
      });
      let c = await Promise.all([
        i.generateRequest(o, a).catch(() => {
         let u = x('Failed to generate a DRM license request. This may be an issue with the player or your protected content.'),
          s = new f(u, f.MEDIA_ERR_ENCRYPTED, !0);
         (s.errorCategory = dist_C.DRM), (s.muxCode = dist_D.ENCRYPTED_GENERATE_REQUEST_FAILED), dist_N(t, s);
        }),
        new Promise((u) => {
         i.addEventListener(
          'message',
          (s) => {
           u(s.message);
          },
          { once: !0 },
         );
        }),
       ]).then(([, u]) => u),
       d = await dist_Ht(c, dist_q(e, 'fairplay')).catch((u) => {
        if (u instanceof Response) {
         let s = dist_H(u, dist_C.DRM, e);
         return console.error('mediaError', s == null ? void 0 : s.message, s == null ? void 0 : s.context), s ? Promise.reject(s) : Promise.reject(new Error('Unexpected error in license key request'));
        }
        return Promise.reject(u);
       });
      await i.update(d).catch(() => {
       let u = x('Failed to update DRM license. This may be an issue with the player or your protected content.'),
        s = new f(u, f.MEDIA_ERR_ENCRYPTED, !0);
       return (s.errorCategory = dist_C.DRM), (s.muxCode = dist_D.ENCRYPTED_UPDATE_LICENSE_FAILED), Promise.reject(s);
      });
     } catch (o) {
      dist_N(t, o);
      return;
     }
    });
   },
   dist_q = ({ playbackId: e, tokens: { drm: t } = {}, customDomain: r = I }, n) => {
    let o = G(e);
    return `https://license.${r.toLocaleLowerCase().endsWith(I) ? r : I}/license/${n}/${o}?token=${t}`;
   },
   dist_Ge = ({ playbackId: e, tokens: { drm: t } = {}, customDomain: r = I }, n) => {
    let o = G(e);
    return `https://license.${r.toLocaleLowerCase().endsWith(I) ? r : I}/appcert/${n}/${o}?token=${t}`;
   },
   dist_Xe = ({ playbackId: e, src: t, customDomain: r }) => {
    if (e) return !0;
    if (typeof t != 'string') return !1;
    let n = window == null ? void 0 : window.location.href,
     o = new URL(t, n).hostname.toLocaleLowerCase();
    return o.includes(I) || (!!r && o.includes(r.toLocaleLowerCase()));
   },
   dist_Kt = (e, t, r) => {
    var d;
    let { envKey: n, disableTracking: o, muxDataSDK: a = Md, muxDataSDKOptions: i = {} } = e,
     c = dist_Xe(e);
    if (!o && (n || c)) {
     let { playerInitTime: u, playerSoftwareName: s, playerSoftwareVersion: p, beaconCollectionDomain: l, debug: T, disableCookies: m } = e,
      R = { ...e.metadata, video_title: ((d = e == null ? void 0 : e.metadata) == null ? void 0 : d.video_title) || void 0 },
      M = (h) => (typeof h.player_error_code == 'string' ? !1 : typeof e.errorTranslator == 'function' ? e.errorTranslator(h) : h);
     a.monitor(t, { debug: T, beaconCollectionDomain: l, hlsjs: r, Hls: r ? g : void 0, automaticErrorTracking: !1, errorTranslator: M, disableCookies: m, ...i, data: { ...(n ? { env_key: n } : {}), player_software_name: s, player_software: s, player_software_version: p, player_init_time: u, ...R } });
    }
   },
   dist_Wt = (e, t, r) => {
    var s, p;
    let n = qe(e, t),
     { src: o, customDomain: a = I } = e,
     i = () => {
      t.ended || !dist_At(t, r) || (dist_Je(t, r) ? (t.currentTime = t.buffered.end(t.buffered.length - 1)) : t.dispatchEvent(new Event('ended')));
     },
     c,
     d,
     u = () => {
      let l = Be(t),
       T,
       m;
      l.length > 0 && ((T = l.start(0)), (m = l.end(0))), (d !== m || c !== T) && t.dispatchEvent(new CustomEvent('seekablechange', { composed: !0 })), (c = T), (d = m);
     };
    if ((v(t, 'durationchange', u), t && n)) {
     let l = dist_U(e);
     if (typeof o == 'string') {
      if (o.endsWith('.mp4') && o.includes(a)) {
       let R = dist_$e(o),
        M = new URL(`https://stream.${a}/${R}/metadata.json`);
       dist_de(M.toString(), t);
      }
      let T = () => {
        if (we(t) !== dist_.LIVE || Number.isFinite(t.duration)) return;
        let R = setInterval(u, 1e3);
        t.addEventListener(
         'teardown',
         () => {
          clearInterval(R);
         },
         { once: !0 },
        ),
         v(t, 'durationchange', () => {
          Number.isFinite(t.duration) && clearInterval(R);
         });
       },
       m = async () =>
        dist_xt(o, t, l)
         .then(T)
         .catch((R) => {
          if (R instanceof Response) {
           let M = dist_H(R, dist_C.VIDEO, e);
           if (M) {
            dist_N(t, M);
            return;
           }
          } else R instanceof Error;
         });
      if (t.preload === 'none') {
       let R = () => {
         m(), t.removeEventListener('loadedmetadata', M);
        },
        M = () => {
         m(), t.removeEventListener('play', R);
        };
       v(t, 'play', R, { once: !0 }), v(t, 'loadedmetadata', M, { once: !0 });
      } else m();
      (s = e.tokens) != null && s.drm
       ? dist_Vt(e, t)
       : v(
          t,
          'encrypted',
          () => {
           let R = x('Attempting to play DRM-protected content without providing a DRM token.'),
            M = new f(R, f.MEDIA_ERR_ENCRYPTED, !0);
           (M.errorCategory = dist_C.DRM), (M.muxCode = dist_D.ENCRYPTED_MISSING_TOKEN), dist_N(t, M);
          },
          { once: !0 },
         ),
       t.setAttribute('src', o),
       e.startTime && ((((p = P.get(t)) != null ? p : {}).startTime = e.startTime), t.addEventListener('durationchange', dist_ze, { once: !0 }));
     } else t.removeAttribute('src');
     t.addEventListener('error', dist_Qe),
      t.addEventListener('error', dist_ce),
      t.addEventListener(
       'emptied',
       () => {
        t.querySelectorAll('track[data-removeondestroy]').forEach((m) => {
         m.remove();
        });
       },
       { once: !0 },
      ),
      v(t, 'pause', i),
      v(t, 'seeked', i),
      v(t, 'play', () => {
       t.ended || (je(t.currentTime, t.duration) && (t.currentTime = t.seekable.length ? t.seekable.start(0) : 0));
      });
    } else
     r && o
      ? (r.once(g.Events.LEVEL_LOADED, (l, T) => {
         dist_Dt(T.details, t, r),
          u(),
          we(t) === dist_.LIVE &&
           !Number.isFinite(t.duration) &&
           (r.on(g.Events.LEVEL_UPDATED, u),
           v(t, 'durationchange', () => {
            Number.isFinite(t.duration) && r.off(g.Events.LEVELS_UPDATED, u);
           }));
        }),
        r.on(g.Events.ERROR, (l, T) => {
         var R, M;
         let m = dist_Yt(T, e);
         if (m.muxCode === dist_D.NETWORK_NOT_READY) {
          let E = (R = P.get(t)) != null ? R : {},
           b = (M = E.retryCount) != null ? M : 0;
          if (b < 6) {
           let y = b === 0 ? 5e3 : 6e4,
            k = new f(`Retrying in ${y / 1e3} seconds...`, m.code, m.fatal);
           Object.assign(k, m),
            dist_N(t, k),
            setTimeout(() => {
             (E.retryCount = b + 1), T.details === 'manifestLoadError' && T.url && r.loadSource(T.url);
            }, y);
           return;
          } else {
           E.retryCount = 0;
           let y = new f('Try again later or <a href="#" onclick="window.location.reload(); return false;" style="color: #4a90e2;">click here to retry</a>', m.code, m.fatal);
           Object.assign(y, m), dist_N(t, y);
           return;
          }
         }
         dist_N(t, m);
        }),
        r.on(g.Events.MANIFEST_LOADED, () => {
         let l = P.get(t);
         l && l.error && ((l.error = null), (l.retryCount = 0), t.dispatchEvent(new Event('emptied')), t.dispatchEvent(new Event('loadstart')));
        }),
        t.addEventListener('error', dist_ce),
        v(t, 'waiting', i),
        dist_De(e, r),
        dist_be(t, r),
        r.attachMedia(t))
      : console.error("It looks like the video you're trying to play will not work on this system! If possible, try upgrading to the newest versions of your browser or software.");
   };
  function dist_ze(e) {
   var n;
   let t = e.target,
    r = (n = P.get(t)) == null ? void 0 : n.startTime;
   if (r && dist_fe(t.seekable, t.duration, r)) {
    let o = t.preload === 'auto';
    o && (t.preload = 'none'), (t.currentTime = r), o && (t.preload = 'auto');
   }
  }
  async function dist_Qe(e) {
   if (!e.isTrusted) return;
   e.stopImmediatePropagation();
   let t = e.target;
   if (!(t != null && t.error)) return;
   let { message: r, code: n } = t.error,
    o = new f(r, n);
   if (t.src && n === f.MEDIA_ERR_SRC_NOT_SUPPORTED && t.readyState === HTMLMediaElement.HAVE_NOTHING) {
    setTimeout(() => {
     var i;
     let a = (i = dist_ht(t)) != null ? i : t.error;
     (a == null ? void 0 : a.code) === f.MEDIA_ERR_SRC_NOT_SUPPORTED && dist_N(t, o);
    }, 500);
    return;
   }
   if (t.src && (n !== f.MEDIA_ERR_DECODE || n !== void 0))
    try {
     let { status: a } = await fetch(t.src);
     o.data = { response: { code: a } };
    } catch {}
   dist_N(t, o);
  }
  function dist_N(e, t) {
   var r;
   t.fatal && ((((r = P.get(e)) != null ? r : {}).error = t), e.dispatchEvent(new CustomEvent('error', { detail: t })));
  }
  function dist_ce(e) {
   var n, o;
   if (!(e instanceof CustomEvent) || !(e.detail instanceof f)) return;
   let t = e.target,
    r = e.detail;
   !r || !r.fatal || ((((n = P.get(t)) != null ? n : {}).error = r), (o = t.mux) == null || o.emit('error', { player_error_code: r.code, player_error_message: r.message, player_error_context: r.context }));
  }
  var dist_Yt = (e, t) => {
   var c, d, u;
   console.error('getErrorFromHlsErrorData()', e);
   let r = { [g.ErrorTypes.NETWORK_ERROR]: f.MEDIA_ERR_NETWORK, [g.ErrorTypes.MEDIA_ERROR]: f.MEDIA_ERR_DECODE, [g.ErrorTypes.KEY_SYSTEM_ERROR]: f.MEDIA_ERR_ENCRYPTED },
    n = (s) => ([g.ErrorDetails.KEY_SYSTEM_LICENSE_REQUEST_FAILED, g.ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED].includes(s.details) ? f.MEDIA_ERR_NETWORK : r[s.type]),
    o = (s) => {
     if (s.type === g.ErrorTypes.KEY_SYSTEM_ERROR) return dist_C.DRM;
     if (s.type === g.ErrorTypes.NETWORK_ERROR) return dist_C.VIDEO;
    },
    a,
    i = n(e);
   if (i === f.MEDIA_ERR_NETWORK && e.response) {
    let s = (c = o(e)) != null ? c : dist_C.VIDEO;
    a = (d = dist_H(e.response, s, t, e.fatal)) != null ? d : new f('', i, e.fatal);
   } else if (i === f.MEDIA_ERR_ENCRYPTED)
    if (e.details === g.ErrorDetails.KEY_SYSTEM_NO_CONFIGURED_LICENSE) {
     let s = x('Attempting to play DRM-protected content without providing a DRM token.');
     (a = new f(s, f.MEDIA_ERR_ENCRYPTED, e.fatal)), (a.errorCategory = dist_C.DRM), (a.muxCode = dist_D.ENCRYPTED_MISSING_TOKEN);
    } else if (e.details === g.ErrorDetails.KEY_SYSTEM_NO_ACCESS) {
     let s = x('Cannot play DRM-protected content with current security configuration on this browser. Try playing in another browser.');
     (a = new f(s, f.MEDIA_ERR_ENCRYPTED, e.fatal)), (a.errorCategory = dist_C.DRM), (a.muxCode = dist_D.ENCRYPTED_UNSUPPORTED_KEY_SYSTEM);
    } else if (e.details === g.ErrorDetails.KEY_SYSTEM_NO_SESSION) {
     let s = x('Failed to generate a DRM license request. This may be an issue with the player or your protected content.');
     (a = new f(s, f.MEDIA_ERR_ENCRYPTED, !0)), (a.errorCategory = dist_C.DRM), (a.muxCode = dist_D.ENCRYPTED_GENERATE_REQUEST_FAILED);
    } else if (e.details === g.ErrorDetails.KEY_SYSTEM_SESSION_UPDATE_FAILED) {
     let s = x('Failed to update DRM license. This may be an issue with the player or your protected content.');
     (a = new f(s, f.MEDIA_ERR_ENCRYPTED, e.fatal)), (a.errorCategory = dist_C.DRM), (a.muxCode = dist_D.ENCRYPTED_UPDATE_LICENSE_FAILED);
    } else if (e.details === g.ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED) {
     let s = x('Your server certificate failed when attempting to set it. This may be an issue with a no longer valid certificate.');
     (a = new f(s, f.MEDIA_ERR_ENCRYPTED, e.fatal)), (a.errorCategory = dist_C.DRM), (a.muxCode = dist_D.ENCRYPTED_UPDATE_SERVER_CERT_FAILED);
    } else if (e.details === g.ErrorDetails.KEY_SYSTEM_STATUS_INTERNAL_ERROR) {
     let s = x('The DRM Content Decryption Module system had an internal failure. Try reloading the page, upading your browser, or playing in another browser.');
     (a = new f(s, f.MEDIA_ERR_ENCRYPTED, e.fatal)), (a.errorCategory = dist_C.DRM), (a.muxCode = dist_D.ENCRYPTED_CDM_ERROR);
    } else if (e.details === g.ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED) {
     let s = x('DRM playback is being attempted in an environment that is not sufficiently secure. User may see black screen.');
     (a = new f(s, f.MEDIA_ERR_ENCRYPTED, !1)), (a.errorCategory = dist_C.DRM), (a.muxCode = dist_D.ENCRYPTED_OUTPUT_RESTRICTED);
    } else (a = new f(e.error.message, f.MEDIA_ERR_ENCRYPTED, e.fatal)), (a.errorCategory = dist_C.DRM), (a.muxCode = dist_D.ENCRYPTED_ERROR);
   else a = new f('', i, e.fatal);
   return (
    a.context ||
     (a.context = `${
      e.url
       ? `url: ${e.url}
`
       : ''
     }${
      e.response && (e.response.code || e.response.text)
       ? `response: ${e.response.code}, ${e.response.text}
`
       : ''
     }${
      e.reason
       ? `failure reason: ${e.reason}
`
       : ''
     }${
      e.level
       ? `level: ${e.level}
`
       : ''
     }${
      e.parent
       ? `parent stream controller: ${e.parent}
`
       : ''
     }${
      e.buffer
       ? `buffer length: ${e.buffer}
`
       : ''
     }${
      e.error
       ? `error: ${e.error}
`
       : ''
     }${
      e.event
       ? `event: ${e.event}
`
       : ''
     }${
      e.err
       ? `error message: ${(u = e.err) == null ? void 0 : u.message}
`
       : ''
     }`),
    (a.data = e),
    a
   );
  };
  //# sourceMappingURL=index.mjs.map

  // EXTERNAL MODULE: ./node_modules/.pnpm/custom-media-element@1.4.5/node_modules/custom-media-element/dist/custom-media-element.js
  var custom_media_element = __webpack_require__(60922); // CONCATENATED MODULE: ./node_modules/.pnpm/@mux+mux-video@0.26.1/node_modules/@mux/mux-video/dist/base.mjs
  var base_C = (s) => {
   throw TypeError(s);
  };
  var base_S = (s, a, t) => a.has(s) || base_C('Cannot ' + t);
  var n = (s, a, t) => (base_S(s, a, 'read from private field'), t ? t.call(s) : a.get(s)),
   base_u = (s, a, t) => (a.has(s) ? base_C('Cannot add the same private member more than once') : a instanceof WeakSet ? a.add(s) : a.set(s, t)),
   o = (s, a, t, i) => (base_S(s, a, 'write to private field'), i ? i.call(s, t) : a.set(s, t), t),
   M = (s, a, t) => (base_S(s, a, 'access private method'), t);
  var base_Y = () => {
    try {
     return '0.26.1';
    } catch {}
    return 'UNKNOWN';
   },
   base_B = base_Y(),
   base_P = () => base_B;
  var k = `
<svg xmlns="http://www.w3.org/2000/svg" xml:space="preserve" part="logo" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2" viewBox="0 0 1600 500"><g fill="#fff"><path d="M994.287 93.486c-17.121 0-31-13.879-31-31 0-17.121 13.879-31 31-31 17.121 0 31 13.879 31 31 0 17.121-13.879 31-31 31m0-93.486c-34.509 0-62.484 27.976-62.484 62.486v187.511c0 68.943-56.09 125.033-125.032 125.033s-125.03-56.09-125.03-125.033V62.486C681.741 27.976 653.765 0 619.256 0s-62.484 27.976-62.484 62.486v187.511C556.772 387.85 668.921 500 806.771 500c137.851 0 250.001-112.15 250.001-250.003V62.486c0-34.51-27.976-62.486-62.485-62.486M1537.51 468.511c-17.121 0-31-13.879-31-31 0-17.121 13.879-31 31-31 17.121 0 31 13.879 31 31 0 17.121-13.879 31-31 31m-275.883-218.509-143.33 143.329c-24.402 24.402-24.402 63.966 0 88.368 24.402 24.402 63.967 24.402 88.369 0l143.33-143.329 143.328 143.329c24.402 24.4 63.967 24.402 88.369 0 24.403-24.402 24.403-63.966.001-88.368l-143.33-143.329.001-.004 143.329-143.329c24.402-24.402 24.402-63.965 0-88.367s-63.967-24.402-88.369 0L1349.996 161.63 1206.667 18.302c-24.402-24.401-63.967-24.402-88.369 0s-24.402 63.965 0 88.367l143.329 143.329v.004ZM437.511 468.521c-17.121 0-31-13.879-31-31 0-17.121 13.879-31 31-31 17.121 0 31 13.879 31 31 0 17.121-13.879 31-31 31M461.426 4.759C438.078-4.913 411.2.432 393.33 18.303L249.999 161.632 106.669 18.303C88.798.432 61.922-4.913 38.573 4.759 15.224 14.43-.001 37.214-.001 62.488v375.026c0 34.51 27.977 62.486 62.487 62.486 34.51 0 62.486-27.976 62.486-62.486V213.341l80.843 80.844c24.404 24.402 63.965 24.402 88.369 0l80.843-80.844v224.173c0 34.51 27.976 62.486 62.486 62.486s62.486-27.976 62.486-62.486V62.488c0-25.274-15.224-48.058-38.573-57.729" style="fill-rule:nonzero"/></g></svg>`;
  var base_e = { BEACON_COLLECTION_DOMAIN: 'beacon-collection-domain', CUSTOM_DOMAIN: 'custom-domain', DEBUG: 'debug', DISABLE_TRACKING: 'disable-tracking', DISABLE_COOKIES: 'disable-cookies', DRM_TOKEN: 'drm-token', PLAYBACK_TOKEN: 'playback-token', ENV_KEY: 'env-key', MAX_RESOLUTION: 'max-resolution', MIN_RESOLUTION: 'min-resolution', RENDITION_ORDER: 'rendition-order', PROGRAM_START_TIME: 'program-start-time', PROGRAM_END_TIME: 'program-end-time', ASSET_START_TIME: 'asset-start-time', ASSET_END_TIME: 'asset-end-time', METADATA_URL: 'metadata-url', PLAYBACK_ID: 'playback-id', PLAYER_SOFTWARE_NAME: 'player-software-name', PLAYER_SOFTWARE_VERSION: 'player-software-version', PLAYER_INIT_TIME: 'player-init-time', PREFER_CMCD: 'prefer-cmcd', PREFER_PLAYBACK: 'prefer-playback', START_TIME: 'start-time', STREAM_TYPE: 'stream-type', TARGET_LIVE_WINDOW: 'target-live-window', LIVE_EDGE_OFFSET: 'live-edge-offset', TYPE: 'type', LOGO: 'logo' },
   base_at = Object.values(base_e),
   base_v = base_P(),
   base_x = 'mux-video',
   base_l,
   base_f,
   c,
   base_A,
   base_b,
   T,
   p,
   _,
   base_O,
   base_g,
   m,
   y,
   base_K = class extends custom_media_element /* CustomVideoElement */.zM {
    constructor() {
     super();
     base_u(this, m);
     base_u(this, base_l);
     base_u(this, base_f);
     base_u(this, c);
     base_u(this, base_A, {});
     base_u(this, base_b, {});
     base_u(this, T);
     base_u(this, p);
     base_u(this, _);
     base_u(this, base_O);
     base_u(this, base_g, '');
     o(this, c, dist_Wr()),
      this.nativeEl.addEventListener('muxmetadata', (t) => {
       var d;
       let i = dist_Fr(this.nativeEl),
        r = (d = this.metadata) != null ? d : {};
       (this.metadata = { ...i, ...r }), (i == null ? void 0 : i['com.mux.video.branding']) === 'mux-free-plan' && (o(this, base_g, 'default'), this.updateLogo());
      });
    }
    static get NAME() {
     return base_x;
    }
    static get VERSION() {
     return base_v;
    }
    static get observedAttributes() {
     var t;
     return [...base_at, ...((t = custom_media_element /* CustomVideoElement */.zM.observedAttributes) != null ? t : [])];
    }
    static getLogoHTML(t) {
     return !t || t === 'false' ? '' : t === 'default' ? k : `<img part="logo" src="${t}" />`;
    }
    static getTemplateHTML(t = {}) {
     var i;
     return `
      ${custom_media_element /* CustomVideoElement */.zM
       .getTemplateHTML(t)}
      <style>
        :host {
          position: relative;
        }
        slot[name="logo"] {
          display: flex;
          justify-content: end;
          position: absolute;
          top: 1rem;
          right: 1rem;
          opacity: 0;
          transition: opacity 0.25s ease-in-out;
          z-index: 1;
        }
        slot[name="logo"]:has([part="logo"]) {
          opacity: 1;
        }
        slot[name="logo"] [part="logo"] {
          width: 5rem;
          pointer-events: none;
          user-select: none;
        }
      </style>
      <slot name="logo">
        ${this.getLogoHTML((i = t[base_e.LOGO]) != null ? i : '')}
      </slot>
    `;
    }
    get preferCmcd() {
     var t;
     return (t = this.getAttribute(base_e.PREFER_CMCD)) != null ? t : void 0;
    }
    set preferCmcd(t) {
     t !== this.preferCmcd && (t ? (dist_jt.includes(t) ? this.setAttribute(base_e.PREFER_CMCD, t) : console.warn(`Invalid value for preferCmcd. Must be one of ${dist_jt.join()}`)) : this.removeAttribute(base_e.PREFER_CMCD));
    }
    get playerInitTime() {
     return this.hasAttribute(base_e.PLAYER_INIT_TIME) ? +this.getAttribute(base_e.PLAYER_INIT_TIME) : n(this, c);
    }
    set playerInitTime(t) {
     t != this.playerInitTime && (t == null ? this.removeAttribute(base_e.PLAYER_INIT_TIME) : this.setAttribute(base_e.PLAYER_INIT_TIME, `${+t}`));
    }
    get playerSoftwareName() {
     var t;
     return (t = n(this, _)) != null ? t : base_x;
    }
    set playerSoftwareName(t) {
     o(this, _, t);
    }
    get playerSoftwareVersion() {
     var t;
     return (t = n(this, p)) != null ? t : base_v;
    }
    set playerSoftwareVersion(t) {
     o(this, p, t);
    }
    get _hls() {
     var t;
     return (t = n(this, base_l)) == null ? void 0 : t.engine;
    }
    get mux() {
     var t;
     return (t = this.nativeEl) == null ? void 0 : t.mux;
    }
    get error() {
     var t;
     return (t = dist_ht(this.nativeEl)) != null ? t : null;
    }
    get errorTranslator() {
     return n(this, base_O);
    }
    set errorTranslator(t) {
     o(this, base_O, t);
    }
    get src() {
     return this.getAttribute('src');
    }
    set src(t) {
     t !== this.src && (t == null ? this.removeAttribute('src') : this.setAttribute('src', t));
    }
    get type() {
     var t;
     return (t = this.getAttribute(base_e.TYPE)) != null ? t : void 0;
    }
    set type(t) {
     t !== this.type && (t ? this.setAttribute(base_e.TYPE, t) : this.removeAttribute(base_e.TYPE));
    }
    get preload() {
     let t = this.getAttribute('preload');
     return t === '' ? 'auto' : ['none', 'metadata', 'auto'].includes(t) ? t : super.preload;
    }
    set preload(t) {
     t != this.getAttribute('preload') && (['', 'none', 'metadata', 'auto'].includes(t) ? this.setAttribute('preload', t) : this.removeAttribute('preload'));
    }
    get debug() {
     return this.getAttribute(base_e.DEBUG) != null;
    }
    set debug(t) {
     t !== this.debug && (t ? this.setAttribute(base_e.DEBUG, '') : this.removeAttribute(base_e.DEBUG));
    }
    get disableTracking() {
     return this.hasAttribute(base_e.DISABLE_TRACKING);
    }
    set disableTracking(t) {
     t !== this.disableTracking && this.toggleAttribute(base_e.DISABLE_TRACKING, !!t);
    }
    get disableCookies() {
     return this.hasAttribute(base_e.DISABLE_COOKIES);
    }
    set disableCookies(t) {
     t !== this.disableCookies && (t ? this.setAttribute(base_e.DISABLE_COOKIES, '') : this.removeAttribute(base_e.DISABLE_COOKIES));
    }
    get startTime() {
     let t = this.getAttribute(base_e.START_TIME);
     if (t == null) return;
     let i = +t;
     return Number.isNaN(i) ? void 0 : i;
    }
    set startTime(t) {
     t !== this.startTime && (t == null ? this.removeAttribute(base_e.START_TIME) : this.setAttribute(base_e.START_TIME, `${t}`));
    }
    get playbackId() {
     var t;
     return this.hasAttribute(base_e.PLAYBACK_ID) ? this.getAttribute(base_e.PLAYBACK_ID) : (t = dist_$e(this.src)) != null ? t : void 0;
    }
    set playbackId(t) {
     t !== this.playbackId && (t ? this.setAttribute(base_e.PLAYBACK_ID, t) : this.removeAttribute(base_e.PLAYBACK_ID));
    }
    get maxResolution() {
     var t;
     return (t = this.getAttribute(base_e.MAX_RESOLUTION)) != null ? t : void 0;
    }
    set maxResolution(t) {
     t !== this.maxResolution && (t ? this.setAttribute(base_e.MAX_RESOLUTION, t) : this.removeAttribute(base_e.MAX_RESOLUTION));
    }
    get minResolution() {
     var t;
     return (t = this.getAttribute(base_e.MIN_RESOLUTION)) != null ? t : void 0;
    }
    set minResolution(t) {
     t !== this.minResolution && (t ? this.setAttribute(base_e.MIN_RESOLUTION, t) : this.removeAttribute(base_e.MIN_RESOLUTION));
    }
    get renditionOrder() {
     var t;
     return (t = this.getAttribute(base_e.RENDITION_ORDER)) != null ? t : void 0;
    }
    set renditionOrder(t) {
     t !== this.renditionOrder && (t ? this.setAttribute(base_e.RENDITION_ORDER, t) : this.removeAttribute(base_e.RENDITION_ORDER));
    }
    get programStartTime() {
     let t = this.getAttribute(base_e.PROGRAM_START_TIME);
     if (t == null) return;
     let i = +t;
     return Number.isNaN(i) ? void 0 : i;
    }
    set programStartTime(t) {
     t == null ? this.removeAttribute(base_e.PROGRAM_START_TIME) : this.setAttribute(base_e.PROGRAM_START_TIME, `${t}`);
    }
    get programEndTime() {
     let t = this.getAttribute(base_e.PROGRAM_END_TIME);
     if (t == null) return;
     let i = +t;
     return Number.isNaN(i) ? void 0 : i;
    }
    set programEndTime(t) {
     t == null ? this.removeAttribute(base_e.PROGRAM_END_TIME) : this.setAttribute(base_e.PROGRAM_END_TIME, `${t}`);
    }
    get assetStartTime() {
     let t = this.getAttribute(base_e.ASSET_START_TIME);
     if (t == null) return;
     let i = +t;
     return Number.isNaN(i) ? void 0 : i;
    }
    set assetStartTime(t) {
     t == null ? this.removeAttribute(base_e.ASSET_START_TIME) : this.setAttribute(base_e.ASSET_START_TIME, `${t}`);
    }
    get assetEndTime() {
     let t = this.getAttribute(base_e.ASSET_END_TIME);
     if (t == null) return;
     let i = +t;
     return Number.isNaN(i) ? void 0 : i;
    }
    set assetEndTime(t) {
     t == null ? this.removeAttribute(base_e.ASSET_END_TIME) : this.setAttribute(base_e.ASSET_END_TIME, `${t}`);
    }
    get customDomain() {
     var t;
     return (t = this.getAttribute(base_e.CUSTOM_DOMAIN)) != null ? t : void 0;
    }
    set customDomain(t) {
     t !== this.customDomain && (t ? this.setAttribute(base_e.CUSTOM_DOMAIN, t) : this.removeAttribute(base_e.CUSTOM_DOMAIN));
    }
    get drmToken() {
     var t;
     return (t = this.getAttribute(base_e.DRM_TOKEN)) != null ? t : void 0;
    }
    set drmToken(t) {
     t !== this.drmToken && (t ? this.setAttribute(base_e.DRM_TOKEN, t) : this.removeAttribute(base_e.DRM_TOKEN));
    }
    get playbackToken() {
     var t, i, r, d;
     if (this.hasAttribute(base_e.PLAYBACK_TOKEN)) return (t = this.getAttribute(base_e.PLAYBACK_TOKEN)) != null ? t : void 0;
     if (this.hasAttribute(base_e.PLAYBACK_ID)) {
      let [, E] = dist_F((i = this.playbackId) != null ? i : '');
      return (r = new URLSearchParams(E).get('token')) != null ? r : void 0;
     }
     if (this.src) return (d = new URLSearchParams(this.src).get('token')) != null ? d : void 0;
    }
    set playbackToken(t) {
     t !== this.playbackToken && (t ? this.setAttribute(base_e.PLAYBACK_TOKEN, t) : this.removeAttribute(base_e.PLAYBACK_TOKEN));
    }
    get tokens() {
     let t = this.getAttribute(base_e.PLAYBACK_TOKEN),
      i = this.getAttribute(base_e.DRM_TOKEN);
     return { ...n(this, base_b), ...(t != null ? { playback: t } : {}), ...(i != null ? { drm: i } : {}) };
    }
    set tokens(t) {
     o(this, base_b, t != null ? t : {});
    }
    get ended() {
     return dist_At(this.nativeEl, this._hls);
    }
    get envKey() {
     var t;
     return (t = this.getAttribute(base_e.ENV_KEY)) != null ? t : void 0;
    }
    set envKey(t) {
     t !== this.envKey && (t ? this.setAttribute(base_e.ENV_KEY, t) : this.removeAttribute(base_e.ENV_KEY));
    }
    get beaconCollectionDomain() {
     var t;
     return (t = this.getAttribute(base_e.BEACON_COLLECTION_DOMAIN)) != null ? t : void 0;
    }
    set beaconCollectionDomain(t) {
     t !== this.beaconCollectionDomain && (t ? this.setAttribute(base_e.BEACON_COLLECTION_DOMAIN, t) : this.removeAttribute(base_e.BEACON_COLLECTION_DOMAIN));
    }
    get streamType() {
     var t;
     return (t = this.getAttribute(base_e.STREAM_TYPE)) != null ? t : we(this.nativeEl);
    }
    set streamType(t) {
     t !== this.streamType && (t ? this.setAttribute(base_e.STREAM_TYPE, t) : this.removeAttribute(base_e.STREAM_TYPE));
    }
    get targetLiveWindow() {
     return this.hasAttribute(base_e.TARGET_LIVE_WINDOW) ? +this.getAttribute(base_e.TARGET_LIVE_WINDOW) : $r(this.nativeEl);
    }
    set targetLiveWindow(t) {
     t != this.targetLiveWindow && (t == null ? this.removeAttribute(base_e.TARGET_LIVE_WINDOW) : this.setAttribute(base_e.TARGET_LIVE_WINDOW, `${+t}`));
    }
    get liveEdgeStart() {
     var t, i;
     if (this.hasAttribute(base_e.LIVE_EDGE_OFFSET)) {
      let { liveEdgeOffset: r } = this,
       d = (t = this.nativeEl.seekable.end(0)) != null ? t : 0,
       E = (i = this.nativeEl.seekable.start(0)) != null ? i : 0;
      return Math.max(E, d - r);
     }
     return dist_Br(this.nativeEl);
    }
    get liveEdgeOffset() {
     if (this.hasAttribute(base_e.LIVE_EDGE_OFFSET)) return +this.getAttribute(base_e.LIVE_EDGE_OFFSET);
    }
    set liveEdgeOffset(t) {
     t != this.liveEdgeOffset && (t == null ? this.removeAttribute(base_e.LIVE_EDGE_OFFSET) : this.setAttribute(base_e.LIVE_EDGE_OFFSET, `${+t}`));
    }
    get seekable() {
     return Be(this.nativeEl);
    }
    async addCuePoints(t) {
     return dist_Pe(this.nativeEl, t);
    }
    get activeCuePoint() {
     return dist_e(this.nativeEl);
    }
    get cuePoints() {
     return it(this.nativeEl);
    }
    async addChapters(t) {
     return dist_Le(this.nativeEl, t);
    }
    get activeChapter() {
     return dist_Ne(this.nativeEl);
    }
    get chapters() {
     return dist_ct(this.nativeEl);
    }
    getStartDate() {
     return dist_ut(this.nativeEl, this._hls);
    }
    get currentPdt() {
     return dist_dt(this.nativeEl, this._hls);
    }
    get preferPlayback() {
     let t = this.getAttribute(base_e.PREFER_PLAYBACK);
     if (t === dist_X.MSE || t === dist_X.NATIVE) return t;
    }
    set preferPlayback(t) {
     t !== this.preferPlayback && (t === dist_X.MSE || t === dist_X.NATIVE ? this.setAttribute(base_e.PREFER_PLAYBACK, t) : this.removeAttribute(base_e.PREFER_PLAYBACK));
    }
    get metadata() {
     return {
      ...this.getAttributeNames()
       .filter((i) => i.startsWith('metadata-') && ![base_e.METADATA_URL].includes(i))
       .reduce((i, r) => {
        let d = this.getAttribute(r);
        return d != null && (i[r.replace(/^metadata-/, '').replace(/-/g, '_')] = d), i;
       }, {}),
      ...n(this, base_A),
     };
    }
    set metadata(t) {
     o(this, base_A, t != null ? t : {}), this.mux && this.mux.emit('hb', n(this, base_A));
    }
    get _hlsConfig() {
     return n(this, T);
    }
    set _hlsConfig(t) {
     o(this, T, t);
    }
    get logo() {
     var t;
     return (t = this.getAttribute(base_e.LOGO)) != null ? t : n(this, base_g);
    }
    set logo(t) {
     t ? this.setAttribute(base_e.LOGO, t) : this.removeAttribute(base_e.LOGO);
    }
    load() {
     o(this, base_l, dist_jr(this, this.nativeEl, n(this, base_l)));
    }
    unload() {
     dist_It(this.nativeEl, n(this, base_l), this), o(this, base_l, void 0);
    }
    attributeChangedCallback(t, i, r) {
     var E, L;
     switch (
      (custom_media_element /* CustomVideoElement */.zM.observedAttributes
       .includes(t) &&
       !['src', 'autoplay', 'preload'].includes(t) &&
       super.attributeChangedCallback(t, i, r),
      t)
     ) {
      case base_e.PLAYER_SOFTWARE_NAME:
       this.playerSoftwareName = r != null ? r : void 0;
       break;
      case base_e.PLAYER_SOFTWARE_VERSION:
       this.playerSoftwareVersion = r != null ? r : void 0;
       break;
      case 'src': {
       let h = !!i,
        N = !!r;
       !h && N ? M(this, m, y).call(this) : h && !N ? this.unload() : h && N && (this.unload(), M(this, m, y).call(this));
       break;
      }
      case 'autoplay':
       if (r === i) break;
       (E = n(this, base_l)) == null || E.setAutoplay(this.autoplay);
       break;
      case 'preload':
       if (r === i) break;
       (L = n(this, base_l)) == null || L.setPreload(r);
       break;
      case base_e.PLAYBACK_ID:
       this.src = Yr(this);
       break;
      case base_e.DEBUG: {
       let h = this.debug;
       this.mux && console.info('Cannot toggle debug mode of mux data after initialization. Make sure you set all metadata to override before setting the src.'), this._hls && (this._hls.config.debug = h);
       break;
      }
      case base_e.METADATA_URL:
       r &&
        fetch(r)
         .then((h) => h.json())
         .then((h) => (this.metadata = h))
         .catch(() => console.error(`Unable to load or parse metadata JSON from metadata-url ${r}!`));
       break;
      case base_e.STREAM_TYPE:
       (r == null || r !== i) && this.dispatchEvent(new CustomEvent('streamtypechange', { composed: !0, bubbles: !0 }));
       break;
      case base_e.TARGET_LIVE_WINDOW:
       (r == null || r !== i) && this.dispatchEvent(new CustomEvent('targetlivewindowchange', { composed: !0, bubbles: !0, detail: this.targetLiveWindow }));
       break;
      case base_e.LOGO:
       (r == null || r !== i) && this.updateLogo();
       break;
     }
    }
    updateLogo() {
     if (!this.shadowRoot) return;
     let t = this.shadowRoot.querySelector('slot[name="logo"]');
     if (!t) return;
     let i = this.constructor.getLogoHTML(n(this, base_g) || this.logo);
     t.innerHTML = i;
    }
    connectedCallback() {
     var t;
     (t = super.connectedCallback) == null || t.call(this), this.nativeEl && this.src && !n(this, base_l) && M(this, m, y).call(this);
    }
    disconnectedCallback() {
     this.unload();
    }
    handleEvent(t) {
     t.target === this.nativeEl && this.dispatchEvent(new CustomEvent(t.type, { composed: !0, detail: t.detail }));
    }
   };
  (base_l = new WeakMap()),
   (base_f = new WeakMap()),
   (c = new WeakMap()),
   (base_A = new WeakMap()),
   (base_b = new WeakMap()),
   (T = new WeakMap()),
   (p = new WeakMap()),
   (_ = new WeakMap()),
   (base_O = new WeakMap()),
   (base_g = new WeakMap()),
   (m = new WeakSet()),
   (y = async function () {
    n(this, base_f) || (await o(this, base_f, Promise.resolve()), o(this, base_f, null), this.load());
   }); // CONCATENATED MODULE: ./node_modules/.pnpm/castable-video@1.1.10/node_modules/castable-video/castable-utils.js
  //# sourceMappingURL=base.mjs.map

  /* global WeakRef */

  const privateProps = new WeakMap();

  class InvalidStateError extends Error {}
  class NotSupportedError extends Error {}
  class NotFoundError extends /* unused pure expression or super */ (null && Error) {}

  const HLS_RESPONSE_HEADERS = ['application/x-mpegURL', 'application/vnd.apple.mpegurl', 'audio/mpegurl'];

  // Fallback to a plain Set if WeakRef is not available.
  const IterableWeakSet = globalThis.WeakRef
   ? class extends Set {
      add(el) {
       super.add(new WeakRef(el));
      }
      forEach(fn) {
       super.forEach((ref) => {
        const value = ref.deref();
        if (value) fn(value);
       });
      }
     }
   : Set;

  function onCastApiAvailable(callback) {
   if (!globalThis.chrome?.cast?.isAvailable) {
    globalThis.__onGCastApiAvailable = () => {
     // The globalThis.__onGCastApiAvailable callback alone is not reliable for
     // the added cast.framework. It's loaded in a separate JS file.
     // https://www.gstatic.com/eureka/clank/101/cast_sender.js
     // https://www.gstatic.com/cast/sdk/libs/sender/1.0/cast_framework.js
     customElements.whenDefined('google-cast-button').then(callback);
    };
   } else if (!globalThis.cast?.framework) {
    customElements.whenDefined('google-cast-button').then(callback);
   } else {
    callback();
   }
  }

  function requiresCastFramework() {
   // todo: exclude for Android>=56 which supports the Remote Playback API natively.
   return globalThis.chrome;
  }

  function loadCastFramework() {
   const sdkUrl = 'https://www.gstatic.com/cv/js/sender/v1/cast_sender.js?loadCastFramework=1';
   if (globalThis.chrome?.cast || document.querySelector(`script[src="${sdkUrl}"]`)) return;

   const script = document.createElement('script');
   script.src = sdkUrl;
   document.head.append(script);
  }

  function castContext() {
   return globalThis.cast?.framework?.CastContext.getInstance();
  }

  function currentSession() {
   return castContext()?.getCurrentSession();
  }

  function currentMedia() {
   return currentSession()?.getSessionObj().media[0];
  }

  function editTracksInfo(request) {
   return new Promise((resolve, reject) => {
    currentMedia().editTracksInfo(request, resolve, reject);
   });
  }

  function getMediaStatus(request) {
   return new Promise((resolve, reject) => {
    currentMedia().getStatus(request, resolve, reject);
   });
  }

  function setCastOptions(options) {
   return castContext().setOptions({
    ...getDefaultCastOptions(),
    ...options,
   });
  }

  function getDefaultCastOptions() {
   return {
    // Set the receiver application ID to your own (created in the
    // Google Cast Developer Console), or optionally
    // use the chrome.cast.media.DEFAULT_MEDIA_RECEIVER_APP_ID
    receiverApplicationId: 'CC1AD845',

    // Auto join policy can be one of the following three:
    // ORIGIN_SCOPED - Auto connect from same appId and page origin
    // TAB_AND_ORIGIN_SCOPED - Auto connect from same appId, page origin, and tab
    // PAGE_SCOPED - No auto connect
    autoJoinPolicy: 'origin_scoped',

    // The following flag enables Cast Connect(requires Chrome 87 or higher)
    // https://developers.googleblog.com/2020/08/introducing-cast-connect-android-tv.html
    androidReceiverCompatible: false,

    language: 'en-US',
    resumeSavedSession: true,
   };
  }

  //Get the segment format given the end of the URL (.m4s, .ts, etc)
  function getFormat(segment) {
   if (!segment) return undefined;

   const regex = /\.([a-zA-Z0-9]+)(?:\?.*)?$/;
   const match = segment.match(regex);
   return match ? match[1] : null;
  }

  function parsePlaylistUrls(playlistContent) {
   const lines = playlistContent.split('\n');
   const urls = [];

   for (let i = 0; i < lines.length; i++) {
    const line = lines[i].trim();

    // Locate available video playlists and get the next line which is the URI (https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis-17#section-4.4.6.2)
    if (line.startsWith('#EXT-X-STREAM-INF')) {
     const nextLine = lines[i + 1] ? lines[i + 1].trim() : '';
     if (nextLine && !nextLine.startsWith('#')) {
      urls.push(nextLine);
     }
    }
   }

   return urls;
  }

  function parseSegment(playlistContent) {
   const lines = playlistContent.split('\n');

   const url = lines.find((line) => !line.trim().startsWith('#') && line.trim() !== '');

   return url;
  }

  async function isHls(url) {
   try {
    const response = await fetch(url, { method: 'HEAD' });
    const contentType = response.headers.get('Content-Type');

    return HLS_RESPONSE_HEADERS.some((header) => contentType === header);
   } catch (err) {
    console.error('Error while trying to get the Content-Type of the manifest', err);
    return false;
   }
  }

  async function getPlaylistSegmentFormat(url) {
   try {
    const mainManifestContent = await (await fetch(url)).text();
    let availableChunksContent = mainManifestContent;

    const playlists = parsePlaylistUrls(mainManifestContent);
    if (playlists.length > 0) {
     const chosenPlaylistUrl = new URL(playlists[0], url).toString();
     availableChunksContent = await (await fetch(chosenPlaylistUrl)).text();
    }

    const segment = parseSegment(availableChunksContent);
    const format = getFormat(segment);
    return format;
   } catch (err) {
    console.error('Error while trying to parse the manifest playlist', err);
    return undefined;
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/castable-video@1.1.10/node_modules/castable-video/castable-remote-playback.js
  /* global chrome, cast */

  const remoteInstances = new IterableWeakSet();
  const castElementRef = new WeakSet();

  let cf;

  onCastApiAvailable(() => {
   if (!globalThis.chrome?.cast?.isAvailable) {
    // Useful to see in verbose logs if this shows undefined or false.
    console.debug('chrome.cast.isAvailable', globalThis.chrome?.cast?.isAvailable);
    return;
   }

   if (!cf) {
    cf = cast.framework;

    castContext().addEventListener(cf.CastContextEventType.CAST_STATE_CHANGED, (e) => {
     remoteInstances.forEach((r) => privateProps.get(r).onCastStateChanged?.(e));
    });

    castContext().addEventListener(cf.CastContextEventType.SESSION_STATE_CHANGED, (e) => {
     remoteInstances.forEach((r) => privateProps.get(r).onSessionStateChanged?.(e));
    });

    remoteInstances.forEach((r) => privateProps.get(r).init?.());
   }
  });

  let remotePlaybackCallbackIdCount = 0;

  /**
   * Remote Playback shim for the Google cast SDK.
   * https://w3c.github.io/remote-playback/
   */
  class RemotePlayback extends EventTarget {
   #media;
   #isInit;
   #remotePlayer;
   #remoteListeners;
   #state = 'disconnected';
   #available = false;
   #callbacks = new Set();
   #callbackIds = new WeakMap();

   constructor(media) {
    super();

    this.#media = media;

    remoteInstances.add(this);
    privateProps.set(this, {
     init: () => this.#init(),
     onCastStateChanged: () => this.#onCastStateChanged(),
     onSessionStateChanged: () => this.#onSessionStateChanged(),
     getCastPlayer: () => this.#castPlayer,
    });

    this.#init();
   }

   get #castPlayer() {
    if (castElementRef.has(this.#media)) return this.#remotePlayer;
    return undefined;
   }

   /**
    * https://developer.mozilla.org/en-US/docs/Web/API/RemotePlayback/state
    * @return {'disconnected'|'connecting'|'connected'}
    */
   get state() {
    return this.#state;
   }

   async watchAvailability(callback) {
    if (this.#media.disableRemotePlayback) {
     throw new InvalidStateError('disableRemotePlayback attribute is present.');
    }

    this.#callbackIds.set(callback, ++remotePlaybackCallbackIdCount);
    this.#callbacks.add(callback);

    // https://w3c.github.io/remote-playback/#getting-the-remote-playback-devices-availability-information
    queueMicrotask(() => callback(this.#hasDevicesAvailable()));

    return remotePlaybackCallbackIdCount;
   }

   async cancelWatchAvailability(callback) {
    if (this.#media.disableRemotePlayback) {
     throw new InvalidStateError('disableRemotePlayback attribute is present.');
    }

    if (callback) {
     this.#callbacks.delete(callback);
    } else {
     this.#callbacks.clear();
    }
   }

   async prompt() {
    if (this.#media.disableRemotePlayback) {
     throw new InvalidStateError('disableRemotePlayback attribute is present.');
    }

    if (!globalThis.chrome?.cast?.isAvailable) {
     throw new NotSupportedError('The RemotePlayback API is disabled on this platform.');
    }

    const willDisconnect = castElementRef.has(this.#media);
    castElementRef.add(this.#media);

    setCastOptions(this.#media.castOptions);

    Object.entries(this.#remoteListeners).forEach(([event, listener]) => {
     this.#remotePlayer.controller.addEventListener(event, listener);
    });

    try {
     // Open browser cast menu.
     await castContext().requestSession();
    } catch (err) {
     // If there will be no disconnect, reset some state here.
     if (!willDisconnect) {
      castElementRef.delete(this.#media);
     }

     // Don't throw an error if disconnecting or cancelling.
     if (err === 'cancel') {
      return;
     }

     throw new Error(err);
    }

    privateProps.get(this.#media)?.loadOnPrompt?.();
   }

   #disconnect() {
    if (!castElementRef.has(this.#media)) return;

    Object.entries(this.#remoteListeners).forEach(([event, listener]) => {
     this.#remotePlayer.controller.removeEventListener(event, listener);
    });

    castElementRef.delete(this.#media);

    // isMuted is not in savedPlayerState. should we sync this back to local?
    this.#media.muted = this.#remotePlayer.isMuted;
    this.#media.currentTime = this.#remotePlayer.savedPlayerState.currentTime;
    if (this.#remotePlayer.savedPlayerState.isPaused === false) {
     this.#media.play();
    }
   }

   #hasDevicesAvailable() {
    // Cast state: NO_DEVICES_AVAILABLE, NOT_CONNECTED, CONNECTING, CONNECTED
    // https://developers.google.com/cast/docs/reference/web_sender/cast.framework#.CastState
    const castState = castContext()?.getCastState();
    return castState && castState !== 'NO_DEVICES_AVAILABLE';
   }

   #onCastStateChanged() {
    // Cast state: NO_DEVICES_AVAILABLE, NOT_CONNECTED, CONNECTING, CONNECTED
    // https://developers.google.com/cast/docs/reference/web_sender/cast.framework#.CastState
    const castState = castContext().getCastState();

    if (castElementRef.has(this.#media)) {
     if (castState === 'CONNECTING') {
      this.#state = 'connecting';
      this.dispatchEvent(new Event('connecting'));
     }
    }

    if (!this.#available && castState?.includes('CONNECT')) {
     this.#available = true;
     for (let callback of this.#callbacks) callback(true);
    } else if (this.#available && (!castState || castState === 'NO_DEVICES_AVAILABLE')) {
     this.#available = false;
     for (let callback of this.#callbacks) callback(false);
    }
   }

   async #onSessionStateChanged() {
    // Session states: NO_SESSION, SESSION_STARTING, SESSION_STARTED, SESSION_START_FAILED,
    //                 SESSION_ENDING, SESSION_ENDED, SESSION_RESUMED
    // https://developers.google.com/cast/docs/reference/web_sender/cast.framework#.SessionState

    const { SESSION_RESUMED } = cf.SessionState;
    if (castContext().getSessionState() === SESSION_RESUMED) {
     /**
      * Figure out if this was the video that started the resumed session.
      * @TODO make this more specific than just checking against the video src!! (WL)
      *
      * If this video element can get the same unique id on each browser refresh
      * it would be possible to pass this unique id w/ `LoadRequest.customData`
      * and verify against currentMedia().customData below.
      */
     if (this.#media.castSrc === currentMedia()?.media.contentId) {
      castElementRef.add(this.#media);

      Object.entries(this.#remoteListeners).forEach(([event, listener]) => {
       this.#remotePlayer.controller.addEventListener(event, listener);
      });

      /**
       * There is cast framework resume session bug when you refresh the page a few
       * times the this.#remotePlayer.currentTime will not be in sync with the receiver :(
       * The below status request syncs it back up.
       */
      try {
       await getMediaStatus(new chrome.cast.media.GetStatusRequest());
      } catch (error) {
       console.error(error);
      }

      // Dispatch the play, playing events manually to sync remote playing state.
      this.#remoteListeners[cf.RemotePlayerEventType.IS_PAUSED_CHANGED]();
      this.#remoteListeners[cf.RemotePlayerEventType.PLAYER_STATE_CHANGED]();
     }
    }
   }

   #init() {
    if (!cf || this.#isInit) return;
    this.#isInit = true;

    setCastOptions(this.#media.castOptions);

    /**
     * @TODO add listeners for addtrack, removetrack (WL)
     * This only has an impact on <track> with a `src` because these have to be
     * loaded manually in the load() method. This will require a new load() call
     * for each added/removed track w/ src.
     */
    this.#media.textTracks.addEventListener('change', () => this.#updateRemoteTextTrack());

    this.#onCastStateChanged();

    this.#remotePlayer = new cf.RemotePlayer();
    new cf.RemotePlayerController(this.#remotePlayer);

    this.#remoteListeners = {
     [cf.RemotePlayerEventType.IS_CONNECTED_CHANGED]: ({ value }) => {
      if (value === true) {
       this.#state = 'connected';
       this.dispatchEvent(new Event('connect'));
      } else {
       this.#disconnect();
       this.#state = 'disconnected';
       this.dispatchEvent(new Event('disconnect'));
      }
     },
     [cf.RemotePlayerEventType.DURATION_CHANGED]: () => {
      this.#media.dispatchEvent(new Event('durationchange'));
     },
     [cf.RemotePlayerEventType.VOLUME_LEVEL_CHANGED]: () => {
      this.#media.dispatchEvent(new Event('volumechange'));
     },
     [cf.RemotePlayerEventType.IS_MUTED_CHANGED]: () => {
      this.#media.dispatchEvent(new Event('volumechange'));
     },
     [cf.RemotePlayerEventType.CURRENT_TIME_CHANGED]: () => {
      if (!this.#castPlayer?.isMediaLoaded) return;
      this.#media.dispatchEvent(new Event('timeupdate'));
     },
     [cf.RemotePlayerEventType.VIDEO_INFO_CHANGED]: () => {
      this.#media.dispatchEvent(new Event('resize'));
     },
     [cf.RemotePlayerEventType.IS_PAUSED_CHANGED]: () => {
      this.#media.dispatchEvent(new Event(this.paused ? 'pause' : 'play'));
     },
     [cf.RemotePlayerEventType.PLAYER_STATE_CHANGED]: () => {
      // Player states: IDLE, PLAYING, PAUSED, BUFFERING
      // https://developers.google.com/cast/docs/reference/web_sender/chrome.cast.media#.PlayerState

      // pause event is handled above.
      if (this.#castPlayer?.playerState === chrome.cast.media.PlayerState.PAUSED) {
       return;
      }

      this.#media.dispatchEvent(
       new Event(
        {
         [chrome.cast.media.PlayerState.PLAYING]: 'playing',
         [chrome.cast.media.PlayerState.BUFFERING]: 'waiting',
         [chrome.cast.media.PlayerState.IDLE]: 'emptied',
        }[this.#castPlayer?.playerState],
       ),
      );
     },
     [cf.RemotePlayerEventType.IS_MEDIA_LOADED_CHANGED]: async () => {
      if (!this.#castPlayer?.isMediaLoaded) return;

      // mediaInfo is not immediately available due to a bug? wait one tick
      await Promise.resolve();
      this.#onRemoteMediaLoaded();
     },
    };
   }

   #onRemoteMediaLoaded() {
    this.#updateRemoteTextTrack();
   }

   async #updateRemoteTextTrack() {
    if (!this.#castPlayer) return;

    // Get the tracks w/ trackId's that have been loaded; manually or via a playlist like a M3U8 or MPD.
    const remoteTracks = this.#remotePlayer.mediaInfo?.tracks ?? [];
    const remoteSubtitles = remoteTracks.filter(({ type }) => type === chrome.cast.media.TrackType.TEXT);

    const localSubtitles = [...this.#media.textTracks].filter(({ kind }) => kind === 'subtitles' || kind === 'captions');

    // Create a new array from the local subs w/ the trackId's from the remote subs.
    const subtitles = remoteSubtitles
     .map(({ language, name, trackId }) => {
      // Find the corresponding local text track and assign the trackId.
      const { mode } = localSubtitles.find((local) => local.language === language && local.label === name) ?? {};
      if (mode) return { mode, trackId };
      return false;
     })
     .filter(Boolean);

    const hiddenSubtitles = subtitles.filter(({ mode }) => mode !== 'showing');
    const hiddenTrackIds = hiddenSubtitles.map(({ trackId }) => trackId);
    const showingSubtitle = subtitles.find(({ mode }) => mode === 'showing');

    // Note this could also include audio or video tracks, diff against local state.
    const activeTrackIds = currentSession()?.getSessionObj().media[0]?.activeTrackIds ?? [];
    let requestTrackIds = activeTrackIds;

    if (activeTrackIds.length) {
     // Filter out all local hidden subtitle trackId's.
     requestTrackIds = requestTrackIds.filter((id) => !hiddenTrackIds.includes(id));
    }

    if (showingSubtitle?.trackId) {
     requestTrackIds = [...requestTrackIds, showingSubtitle.trackId];
    }

    // Remove duplicate ids.
    requestTrackIds = [...new Set(requestTrackIds)];

    const arrayEquals = (a, b) => a.length === b.length && a.every((a) => b.includes(a));
    if (!arrayEquals(activeTrackIds, requestTrackIds)) {
     try {
      const request = new chrome.cast.media.EditTracksInfoRequest(requestTrackIds);
      await editTracksInfo(request);
     } catch (error) {
      console.error(error);
     }
    }
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/castable-video@1.1.10/node_modules/castable-video/castable-mixin.js

  /* global chrome */

  /**
   * CastableMediaMixin
   *
   * This mixin function provides a way to compose multiple classes.
   * @see https://justinfagnani.com/2015/12/21/real-mixins-with-javascript-classes/
   *
   * @param  {HTMLMediaElement} superclass - HTMLMediaElement or an extended class of it.
   * @return {CastableMedia}
   */
  const CastableMediaMixin = (superclass) =>
   class CastableMedia extends superclass {
    static observedAttributes = [...(superclass.observedAttributes ?? []), 'cast-src', 'cast-content-type', 'cast-stream-type', 'cast-receiver'];

    #localState = { paused: false };
    #castOptions = getDefaultCastOptions();
    #castCustomData;
    #remote;

    get remote() {
     if (this.#remote) return this.#remote;

     if (requiresCastFramework()) {
      // No need to load the Cast framework if it's disabled.
      if (!this.disableRemotePlayback) {
       loadCastFramework();
      }

      privateProps.set(this, {
       loadOnPrompt: () => this.#loadOnPrompt(),
      });

      return (this.#remote = new RemotePlayback(this));
     }

     return super.remote;
    }

    get #castPlayer() {
     return privateProps.get(this.remote)?.getCastPlayer?.();
    }

    attributeChangedCallback(attrName, oldValue, newValue) {
     super.attributeChangedCallback(attrName, oldValue, newValue);

     if (attrName === 'cast-receiver' && newValue) {
      this.#castOptions.receiverApplicationId = newValue;
      return;
     }

     if (!this.#castPlayer) return;

     switch (attrName) {
      case 'cast-stream-type':
      case 'cast-src':
       this.load();
       break;
     }
    }

    async #loadOnPrompt() {
     // Pause locally when the session is created.
     this.#localState.paused = super.paused;
     super.pause();

     // Sync over the muted state but not volume, 100% is different on TV's :P
     this.muted = super.muted;

     try {
      await this.load();
     } catch (err) {
      console.error(err);
     }
    }

    async load() {
     if (!this.#castPlayer) return super.load();

     const mediaInfo = new chrome.cast.media.MediaInfo(this.castSrc, this.castContentType);
     mediaInfo.customData = this.castCustomData;

     // Manually add text tracks with a `src` attribute.
     // M3U8's load text tracks in the receiver, handle these in the media loaded event.
     const subtitles = [...this.querySelectorAll('track')].filter(({ kind, src }) => src && (kind === 'subtitles' || kind === 'captions'));

     const activeTrackIds = [];
     let textTrackIdCount = 0;

     if (subtitles.length) {
      mediaInfo.tracks = subtitles.map((trackEl) => {
       const trackId = ++textTrackIdCount;
       // only activate 1 subtitle text track.
       if (activeTrackIds.length === 0 && trackEl.track.mode === 'showing') {
        activeTrackIds.push(trackId);
       }

       const track = new chrome.cast.media.Track(trackId, chrome.cast.media.TrackType.TEXT);
       track.trackContentId = trackEl.src;
       track.trackContentType = 'text/vtt';
       track.subtype = trackEl.kind === 'captions' ? chrome.cast.media.TextTrackType.CAPTIONS : chrome.cast.media.TextTrackType.SUBTITLES;
       track.name = trackEl.label;
       track.language = trackEl.srclang;
       return track;
      });
     }

     if (this.castStreamType === 'live') {
      mediaInfo.streamType = chrome.cast.media.StreamType.LIVE;
     } else {
      mediaInfo.streamType = chrome.cast.media.StreamType.BUFFERED;
     }

     mediaInfo.metadata = new chrome.cast.media.GenericMediaMetadata();
     mediaInfo.metadata.title = this.title;
     mediaInfo.metadata.images = [{ url: this.poster }];

     if (isHls(this.castSrc)) {
      const segmentFormat = await getPlaylistSegmentFormat(this.castSrc);
      const isFragmentedMP4 = segmentFormat?.includes('m4s') || segmentFormat?.includes('mp4');
      if (isFragmentedMP4) {
       mediaInfo.hlsSegmentFormat = chrome.cast.media.HlsSegmentFormat.FMP4;
       mediaInfo.hlsVideoSegmentFormat = chrome.cast.media.HlsVideoSegmentFormat.FMP4;
      }
     }

     const request = new chrome.cast.media.LoadRequest(mediaInfo);
     request.currentTime = super.currentTime ?? 0;
     request.autoplay = !this.#localState.paused;
     request.activeTrackIds = activeTrackIds;

     await currentSession()?.loadMedia(request);

     this.dispatchEvent(new Event('volumechange'));
    }

    play() {
     if (this.#castPlayer) {
      if (this.#castPlayer.isPaused) {
       this.#castPlayer.controller?.playOrPause();
      }
      return;
     }
     return super.play();
    }

    pause() {
     if (this.#castPlayer) {
      if (!this.#castPlayer.isPaused) {
       this.#castPlayer.controller?.playOrPause();
      }
      return;
     }
     super.pause();
    }

    /**
     * @see https://developers.google.com/cast/docs/reference/web_sender/cast.framework.CastOptions
     * @readonly
     *
     * @typedef {Object} CastOptions
     * @property {string} [receiverApplicationId='CC1AD845'] - The app id of the cast receiver.
     * @property {string} [autoJoinPolicy='origin_scoped'] - The auto join policy.
     * @property {string} [language='en-US'] - The language to use for the cast receiver.
     * @property {boolean} [androidReceiverCompatible=false] - Whether to use the Cast Connect.
     * @property {boolean} [resumeSavedSession=true] - Whether to resume the last session.
     *
     * @return {CastOptions}
     */
    get castOptions() {
     return this.#castOptions;
    }

    get castReceiver() {
     return this.getAttribute('cast-receiver') ?? undefined;
    }

    set castReceiver(val) {
     if (this.castReceiver == val) return;
     this.setAttribute('cast-receiver', `${val}`);
    }

    // Allow the cast source url to be different than <video src>, could be a blob.
    get castSrc() {
     // Try the first <source src> for usage with even more native markup.
     return this.getAttribute('cast-src') ?? this.querySelector('source')?.src ?? this.currentSrc;
    }

    set castSrc(val) {
     if (this.castSrc == val) return;
     this.setAttribute('cast-src', `${val}`);
    }

    get castContentType() {
     return this.getAttribute('cast-content-type') ?? undefined;
    }

    set castContentType(val) {
     this.setAttribute('cast-content-type', `${val}`);
    }

    get castStreamType() {
     // NOTE: Per https://github.com/video-dev/media-ui-extensions/issues/3 `streamType` may yield `"unknown"`
     return this.getAttribute('cast-stream-type') ?? this.streamType ?? undefined;
    }

    set castStreamType(val) {
     this.setAttribute('cast-stream-type', `${val}`);
    }

    get castCustomData() {
     return this.#castCustomData;
    }

    set castCustomData(val) {
     const valType = typeof val;
     if (!['object', 'undefined'].includes(valType)) {
      console.error(`castCustomData must be nullish or an object but value was of type ${valType}`);
      return;
     }

     this.#castCustomData = val;
    }

    get readyState() {
     if (this.#castPlayer) {
      switch (this.#castPlayer.playerState) {
       case chrome.cast.media.PlayerState.IDLE:
        return 0;
       case chrome.cast.media.PlayerState.BUFFERING:
        return 2;
       default:
        return 3;
      }
     }
     return super.readyState;
    }

    get paused() {
     if (this.#castPlayer) return this.#castPlayer.isPaused;
     return super.paused;
    }

    get muted() {
     if (this.#castPlayer) return this.#castPlayer?.isMuted;
     return super.muted;
    }

    set muted(val) {
     if (this.#castPlayer) {
      if ((val && !this.#castPlayer.isMuted) || (!val && this.#castPlayer.isMuted)) {
       this.#castPlayer.controller?.muteOrUnmute();
      }
      return;
     }
     super.muted = val;
    }

    get volume() {
     if (this.#castPlayer) return this.#castPlayer?.volumeLevel ?? 1;
     return super.volume;
    }

    set volume(val) {
     if (this.#castPlayer) {
      this.#castPlayer.volumeLevel = +val;
      this.#castPlayer.controller?.setVolumeLevel();
      return;
     }
     super.volume = val;
    }

    get duration() {
     // castPlayer duration returns `0` when no media is loaded.
     if (this.#castPlayer && this.#castPlayer?.isMediaLoaded) {
      return this.#castPlayer?.duration ?? NaN;
     }
     return super.duration;
    }

    get currentTime() {
     if (this.#castPlayer && this.#castPlayer?.isMediaLoaded) {
      return this.#castPlayer?.currentTime ?? 0;
     }
     return super.currentTime;
    }

    set currentTime(val) {
     if (this.#castPlayer) {
      this.#castPlayer.currentTime = val;
      this.#castPlayer.controller?.seek();
      return;
     }
     super.currentTime = val;
    }
   };

  const CastableVideoMixin = /* unused pure expression or super */ null && CastableMediaMixin;

  // EXTERNAL MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/index.js + 12 modules
  var dist = __webpack_require__(47273); // CONCATENATED MODULE: ./node_modules/.pnpm/@mux+mux-video@0.26.1/node_modules/@mux/mux-video/dist/index.mjs
  var dist_f = (e) => {
   throw TypeError(e);
  };
  var dist_g = (e, o, t) => o.has(e) || dist_f('Cannot ' + t);
  var dist_u = (e, o, t) => (dist_g(e, o, 'read from private field'), t ? t.call(e) : o.get(e)),
   dist_m = (e, o, t) => (o.has(e) ? dist_f('Cannot add the same private member more than once') : o instanceof WeakSet ? o.add(e) : o.set(e, t)),
   d = (e, o, t, l) => (dist_g(e, o, 'write to private field'), l ? l.call(e, t) : o.set(e, t), t);
  var s = class {
   addEventListener() {}
   removeEventListener() {}
   dispatchEvent(o) {
    return !0;
   }
  };
  if (typeof DocumentFragment == 'undefined') {
   class e extends s {}
   globalThis.DocumentFragment = e;
  }
  var dist_n = class extends s {},
   dist_p = class extends s {},
   dist_x = {
    get(e) {},
    define(e, o, t) {},
    getName(e) {
     return null;
    },
    upgrade(e) {},
    whenDefined(e) {
     return Promise.resolve(dist_n);
    },
   },
   a,
   h = class {
    constructor(o, t = {}) {
     dist_m(this, a);
     d(this, a, t == null ? void 0 : t.detail);
    }
    get detail() {
     return dist_u(this, a);
    }
    initCustomEvent() {}
   };
  a = new WeakMap();
  function mux_video_dist_C(e, o) {
   return new dist_n();
  }
  var dist_y = { document: { createElement: mux_video_dist_C }, DocumentFragment, customElements: dist_x, CustomEvent: h, EventTarget: s, HTMLElement: dist_n, HTMLVideoElement: dist_p },
   dist_b = typeof window == 'undefined' || typeof globalThis.customElements == 'undefined',
   dist_c = dist_b ? dist_y : globalThis,
   dist_k = dist_b ? dist_y.document : globalThis.document;
  var r,
   i = class extends CastableMediaMixin((0, dist /* MediaTracksMixin */.lK)(base_K)) {
    constructor() {
     super(...arguments);
     dist_m(this, r);
    }
    get autoplay() {
     let t = this.getAttribute('autoplay');
     return t === null ? !1 : t === '' ? !0 : t;
    }
    set autoplay(t) {
     let l = this.autoplay;
     t !== l && (t ? this.setAttribute('autoplay', typeof t == 'string' ? t : '') : this.removeAttribute('autoplay'));
    }
    get muxCastCustomData() {
     return { mux: { playbackId: this.playbackId, minResolution: this.minResolution, maxResolution: this.maxResolution, renditionOrder: this.renditionOrder, customDomain: this.customDomain, tokens: { drm: this.drmToken }, envKey: this.envKey, metadata: this.metadata, disableCookies: this.disableCookies, disableTracking: this.disableTracking, beaconCollectionDomain: this.beaconCollectionDomain, startTime: this.startTime, preferCmcd: this.preferCmcd } };
    }
    get castCustomData() {
     var t;
     return (t = dist_u(this, r)) != null ? t : this.muxCastCustomData;
    }
    set castCustomData(t) {
     d(this, r, t);
    }
   };
  r = new WeakMap();
  dist_c.customElements.get('mux-video') || (dist_c.customElements.define('mux-video', i), (dist_c.MuxVideoElement = i));
  var mux_video_dist_F = /* unused pure expression or super */ null && i; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/constants.js
  //# sourceMappingURL=index.mjs.map

  const MediaUIEvents = {
   MEDIA_PLAY_REQUEST: 'mediaplayrequest',
   MEDIA_PAUSE_REQUEST: 'mediapauserequest',
   MEDIA_MUTE_REQUEST: 'mediamuterequest',
   MEDIA_UNMUTE_REQUEST: 'mediaunmuterequest',
   MEDIA_VOLUME_REQUEST: 'mediavolumerequest',
   MEDIA_SEEK_REQUEST: 'mediaseekrequest',
   MEDIA_AIRPLAY_REQUEST: 'mediaairplayrequest',
   MEDIA_ENTER_FULLSCREEN_REQUEST: 'mediaenterfullscreenrequest',
   MEDIA_EXIT_FULLSCREEN_REQUEST: 'mediaexitfullscreenrequest',
   MEDIA_PREVIEW_REQUEST: 'mediapreviewrequest',
   MEDIA_ENTER_PIP_REQUEST: 'mediaenterpiprequest',
   MEDIA_EXIT_PIP_REQUEST: 'mediaexitpiprequest',
   MEDIA_ENTER_CAST_REQUEST: 'mediaentercastrequest',
   MEDIA_EXIT_CAST_REQUEST: 'mediaexitcastrequest',
   MEDIA_SHOW_TEXT_TRACKS_REQUEST: 'mediashowtexttracksrequest',
   MEDIA_HIDE_TEXT_TRACKS_REQUEST: 'mediahidetexttracksrequest',
   MEDIA_SHOW_SUBTITLES_REQUEST: 'mediashowsubtitlesrequest',
   MEDIA_DISABLE_SUBTITLES_REQUEST: 'mediadisablesubtitlesrequest',
   MEDIA_TOGGLE_SUBTITLES_REQUEST: 'mediatogglesubtitlesrequest',
   MEDIA_PLAYBACK_RATE_REQUEST: 'mediaplaybackraterequest',
   MEDIA_RENDITION_REQUEST: 'mediarenditionrequest',
   MEDIA_AUDIO_TRACK_REQUEST: 'mediaaudiotrackrequest',
   MEDIA_SEEK_TO_LIVE_REQUEST: 'mediaseektoliverequest',
   REGISTER_MEDIA_STATE_RECEIVER: 'registermediastatereceiver',
   UNREGISTER_MEDIA_STATE_RECEIVER: 'unregistermediastatereceiver',
  };
  const MediaStateReceiverAttributes = {
   MEDIA_CHROME_ATTRIBUTES: 'mediachromeattributes',
   MEDIA_CONTROLLER: 'mediacontroller',
  };
  const MediaUIProps = {
   MEDIA_AIRPLAY_UNAVAILABLE: 'mediaAirplayUnavailable',
   MEDIA_AUDIO_TRACK_ENABLED: 'mediaAudioTrackEnabled',
   MEDIA_AUDIO_TRACK_LIST: 'mediaAudioTrackList',
   MEDIA_AUDIO_TRACK_UNAVAILABLE: 'mediaAudioTrackUnavailable',
   MEDIA_BUFFERED: 'mediaBuffered',
   MEDIA_CAST_UNAVAILABLE: 'mediaCastUnavailable',
   MEDIA_CHAPTERS_CUES: 'mediaChaptersCues',
   MEDIA_CURRENT_TIME: 'mediaCurrentTime',
   MEDIA_DURATION: 'mediaDuration',
   MEDIA_ENDED: 'mediaEnded',
   MEDIA_ERROR: 'mediaError',
   MEDIA_ERROR_CODE: 'mediaErrorCode',
   MEDIA_ERROR_MESSAGE: 'mediaErrorMessage',
   MEDIA_FULLSCREEN_UNAVAILABLE: 'mediaFullscreenUnavailable',
   MEDIA_HAS_PLAYED: 'mediaHasPlayed',
   MEDIA_HEIGHT: 'mediaHeight',
   MEDIA_IS_AIRPLAYING: 'mediaIsAirplaying',
   MEDIA_IS_CASTING: 'mediaIsCasting',
   MEDIA_IS_FULLSCREEN: 'mediaIsFullscreen',
   MEDIA_IS_PIP: 'mediaIsPip',
   MEDIA_LOADING: 'mediaLoading',
   MEDIA_MUTED: 'mediaMuted',
   MEDIA_PAUSED: 'mediaPaused',
   MEDIA_PIP_UNAVAILABLE: 'mediaPipUnavailable',
   MEDIA_PLAYBACK_RATE: 'mediaPlaybackRate',
   MEDIA_PREVIEW_CHAPTER: 'mediaPreviewChapter',
   MEDIA_PREVIEW_COORDS: 'mediaPreviewCoords',
   MEDIA_PREVIEW_IMAGE: 'mediaPreviewImage',
   MEDIA_PREVIEW_TIME: 'mediaPreviewTime',
   MEDIA_RENDITION_LIST: 'mediaRenditionList',
   MEDIA_RENDITION_SELECTED: 'mediaRenditionSelected',
   MEDIA_RENDITION_UNAVAILABLE: 'mediaRenditionUnavailable',
   MEDIA_SEEKABLE: 'mediaSeekable',
   MEDIA_STREAM_TYPE: 'mediaStreamType',
   MEDIA_SUBTITLES_LIST: 'mediaSubtitlesList',
   MEDIA_SUBTITLES_SHOWING: 'mediaSubtitlesShowing',
   MEDIA_TARGET_LIVE_WINDOW: 'mediaTargetLiveWindow',
   MEDIA_TIME_IS_LIVE: 'mediaTimeIsLive',
   MEDIA_VOLUME: 'mediaVolume',
   MEDIA_VOLUME_LEVEL: 'mediaVolumeLevel',
   MEDIA_VOLUME_UNAVAILABLE: 'mediaVolumeUnavailable',
   MEDIA_WIDTH: 'mediaWidth',
  };
  const MediaUIPropsEntries = Object.entries(MediaUIProps);
  const MediaUIAttributes = MediaUIPropsEntries.reduce((dictObj, [key, propName]) => {
   dictObj[key] = propName.toLowerCase();
   return dictObj;
  }, {});
  const AdditionalStateChangeEvents = {
   USER_INACTIVE_CHANGE: 'userinactivechange',
   BREAKPOINTS_CHANGE: 'breakpointchange',
   BREAKPOINTS_COMPUTED: 'breakpointscomputed',
  };
  const MediaStateChangeEvents = MediaUIPropsEntries.reduce(
   (dictObj, [key, propName]) => {
    dictObj[key] = propName.toLowerCase();
    return dictObj;
   },
   { ...AdditionalStateChangeEvents },
  );
  const StateChangeEventToAttributeMap = Object.entries(MediaStateChangeEvents).reduce(
   (mapObj, [key, eventType]) => {
    const attrName = MediaUIAttributes[key];
    if (attrName) {
     mapObj[eventType] = attrName;
    }
    return mapObj;
   },
   { userinactivechange: 'userinactive' },
  );
  const AttributeToStateChangeEventMap = Object.entries(MediaUIAttributes).reduce(
   (mapObj, [key, attrName]) => {
    const evtType = MediaStateChangeEvents[key];
    if (evtType) {
     mapObj[attrName] = evtType;
    }
    return mapObj;
   },
   { userinactive: 'userinactivechange' },
  );
  const TextTrackKinds = {
   SUBTITLES: 'subtitles',
   CAPTIONS: 'captions',
   DESCRIPTIONS: 'descriptions',
   CHAPTERS: 'chapters',
   METADATA: 'metadata',
  };
  const TextTrackModes = {
   DISABLED: 'disabled',
   HIDDEN: 'hidden',
   SHOWING: 'showing',
  };
  const ReadyStates = {
   HAVE_NOTHING: 0,
   HAVE_METADATA: 1,
   HAVE_CURRENT_DATA: 2,
   HAVE_FUTURE_DATA: 3,
   HAVE_ENOUGH_DATA: 4,
  };
  const PointerTypes = {
   MOUSE: 'mouse',
   PEN: 'pen',
   TOUCH: 'touch',
  };
  const AvailabilityStates = {
   UNAVAILABLE: 'unavailable',
   UNSUPPORTED: 'unsupported',
  };
  const StreamTypes = {
   LIVE: 'live',
   ON_DEMAND: 'on-demand',
   UNKNOWN: 'unknown',
  };
  const VolumeLevels = {
   HIGH: 'high',
   MEDIUM: 'medium',
   LOW: 'low',
   OFF: 'off',
  };
  const WebkitPresentationModes = {
   INLINE: 'inline',
   FULLSCREEN: 'fullscreen',
   PICTURE_IN_PICTURE: 'picture-in-picture',
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/utils.js

  function stringifyRenditionList(renditions) {
   return renditions == null ? void 0 : renditions.map(stringifyRendition).join(' ');
  }
  function parseRenditionList(renditions) {
   return renditions == null ? void 0 : renditions.split(/\s+/).map(parseRendition);
  }
  function stringifyRendition(rendition) {
   if (rendition) {
    const { id, width, height } = rendition;
    return [id, width, height].filter((a) => a != null).join(':');
   }
  }
  function parseRendition(rendition) {
   if (rendition) {
    const [id, width, height] = rendition.split(':');
    return { id, width: +width, height: +height };
   }
  }
  function stringifyAudioTrackList(audioTracks) {
   return audioTracks == null ? void 0 : audioTracks.map(stringifyAudioTrack).join(' ');
  }
  function parseAudioTrackList(audioTracks) {
   return audioTracks == null ? void 0 : audioTracks.split(/\s+/).map(parseAudioTrack);
  }
  function stringifyAudioTrack(audioTrack) {
   if (audioTrack) {
    const { id, kind, language, label } = audioTrack;
    return [id, kind, language, label].filter((a) => a != null).join(':');
   }
  }
  function parseAudioTrack(audioTrack) {
   if (audioTrack) {
    const [id, kind, language, label] = audioTrack.split(':');
    return {
     id,
     kind,
     language,
     label,
    };
   }
  }
  function dashedToCamel(word) {
   return word
    .split('-')
    .map(function (x, i) {
     return (i ? x[0].toUpperCase() : x[0].toLowerCase()) + x.slice(1).toLowerCase();
    })
    .join('');
  }
  function constToCamel(word, upperFirst = false) {
   return word
    .split('_')
    .map(function (x, i) {
     return (i || upperFirst ? x[0].toUpperCase() : x[0].toLowerCase()) + x.slice(1).toLowerCase();
    })
    .join('');
  }
  function camelCase(name) {
   return name.replace(/[-_]([a-z])/g, ($0, $1) => $1.toUpperCase());
  }
  function isValidNumber(x) {
   return typeof x === 'number' && !Number.isNaN(x) && Number.isFinite(x);
  }
  function isNumericString(str) {
   if (typeof str != 'string') return false;
   return !isNaN(str) && !isNaN(parseFloat(str));
  }
  const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));
  const capitalize = (str) => str && str[0].toUpperCase() + str.slice(1); // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/time.js

  const UnitLabels = [
   {
    singular: 'hour',
    plural: 'hours',
   },
   {
    singular: 'minute',
    plural: 'minutes',
   },
   {
    singular: 'second',
    plural: 'seconds',
   },
  ];
  const toTimeUnitPhrase = (timeUnitValue, unitIndex) => {
   const unitLabel = timeUnitValue === 1 ? UnitLabels[unitIndex].singular : UnitLabels[unitIndex].plural;
   return `${timeUnitValue} ${unitLabel}`;
  };
  const formatAsTimePhrase = (seconds) => {
   if (!isValidNumber(seconds)) return '';
   const positiveSeconds = Math.abs(seconds);
   const negative = positiveSeconds !== seconds;
   const secondsDateTime = new Date(0, 0, 0, 0, 0, positiveSeconds, 0);
   const timeParts = [secondsDateTime.getHours(), secondsDateTime.getMinutes(), secondsDateTime.getSeconds()];
   const timeString = timeParts
    .map((timeUnitValue, index) => timeUnitValue && toTimeUnitPhrase(timeUnitValue, index))
    .filter((x) => x)
    .join(', ');
   const negativeSuffix = negative ? ' remaining' : '';
   return `${timeString}${negativeSuffix}`;
  };
  function formatTime(seconds, guide) {
   let negative = false;
   if (seconds < 0) {
    negative = true;
    seconds = 0 - seconds;
   }
   seconds = seconds < 0 ? 0 : seconds;
   let s = Math.floor(seconds % 60);
   let m = Math.floor((seconds / 60) % 60);
   let h = Math.floor(seconds / 3600);
   const gm = Math.floor((guide / 60) % 60);
   const gh = Math.floor(guide / 3600);
   if (isNaN(seconds) || seconds === Infinity) {
    h = m = s = '0';
   }
   h = h > 0 || gh > 0 ? h + ':' : '';
   m = ((h || gm >= 10) && m < 10 ? '0' + m : m) + ':';
   s = s < 10 ? '0' + s : s;
   return (negative ? '-' : '') + h + m + s;
  }
  const emptyTimeRanges = Object.freeze({
   length: 0,
   start(index) {
    const unsignedIdx = index >>> 0;
    if (unsignedIdx >= this.length) {
     throw new DOMException(`Failed to execute 'start' on 'TimeRanges': The index provided (${unsignedIdx}) is greater than or equal to the maximum bound (${this.length}).`);
    }
    return 0;
   },
   end(index) {
    const unsignedIdx = index >>> 0;
    if (unsignedIdx >= this.length) {
     throw new DOMException(`Failed to execute 'end' on 'TimeRanges': The index provided (${unsignedIdx}) is greater than or equal to the maximum bound (${this.length}).`);
    }
    return 0;
   },
  });
  function serializeTimeRanges(timeRanges = emptyTimeRanges) {
   return Array.from(timeRanges)
    .map((_, i) => [Number(timeRanges.start(i).toFixed(3)), Number(timeRanges.end(i).toFixed(3))].join(':'))
    .join(' ');
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/lang/en.js

  const En = {
   'Start airplay': 'Start airplay',
   'Stop airplay': 'Stop airplay',
   Audio: 'Audio',
   Captions: 'Captions',
   'Enable captions': 'Enable captions',
   'Disable captions': 'Disable captions',
   'Start casting': 'Start casting',
   'Stop casting': 'Stop casting',
   'Enter fullscreen mode': 'Enter fullscreen mode',
   'Exit fullscreen mode': 'Exit fullscreen mode',
   Mute: 'Mute',
   Unmute: 'Unmute',
   'Enter picture in picture mode': 'Enter picture in picture mode',
   'Exit picture in picture mode': 'Exit picture in picture mode',
   Play: 'Play',
   Pause: 'Pause',
   'Playback rate': 'Playback rate',
   'Playback rate {playbackRate}': 'Playback rate {playbackRate}',
   Quality: 'Quality',
   'Seek backward': 'Seek backward',
   'Seek forward': 'Seek forward',
   Settings: 'Settings',
   Auto: 'Auto',
   'audio player': 'audio player',
   'video player': 'video player',
   volume: 'volume',
   seek: 'seek',
   'closed captions': 'closed captions',
   'current playback rate': 'current playback rate',
   'playback time': 'playback time',
   'media loading': 'media loading',
   settings: 'settings',
   'audio tracks': 'audio tracks',
   quality: 'quality',
   play: 'play',
   pause: 'pause',
   mute: 'mute',
   unmute: 'unmute',
   live: 'live',
   Off: 'Off',
   'start airplay': 'start airplay',
   'stop airplay': 'stop airplay',
   'start casting': 'start casting',
   'stop casting': 'stop casting',
   'enter fullscreen mode': 'enter fullscreen mode',
   'exit fullscreen mode': 'exit fullscreen mode',
   'enter picture in picture mode': 'enter picture in picture mode',
   'exit picture in picture mode': 'exit picture in picture mode',
   'seek to live': 'seek to live',
   'playing live': 'playing live',
   'seek back {seekOffset} seconds': 'seek back {seekOffset} seconds',
   'seek forward {seekOffset} seconds': 'seek forward {seekOffset} seconds',
   'Network Error': 'Network Error',
   'Decode Error': 'Decode Error',
   'Source Not Supported': 'Source Not Supported',
   'Encryption Error': 'Encryption Error',
   'A network error caused the media download to fail.': 'A network error caused the media download to fail.',
   'A media error caused playback to be aborted. The media could be corrupt or your browser does not support this format.': 'A media error caused playback to be aborted. The media could be corrupt or your browser does not support this format.',
   'An unsupported error occurred. The server or network failed, or your browser does not support this format.': 'An unsupported error occurred. The server or network failed, or your browser does not support this format.',
   'The media is encrypted and there are no keys to decrypt it.': 'The media is encrypted and there are no keys to decrypt it.',
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/i18n.js

  var i18n_a;

  const translations = {
   en: En,
  };
  let currentLang = ((i18n_a = globalThis.navigator) == null ? void 0 : i18n_a.language) || 'en';
  const setLanguage = (langCode) => {
   currentLang = langCode;
  };
  const addTranslation = (lang, languageDictionary) => {
   translations[lang] = languageDictionary;
  };
  const resolveTranslation = (key) => {
   var _a2, _b, _c;
   const [base] = currentLang.split('-');
   return ((_a2 = translations[currentLang]) == null ? void 0 : _a2[key]) || ((_b = translations[base]) == null ? void 0 : _b[key]) || ((_c = translations.en) == null ? void 0 : _c[key]) || key;
  };
  const t = (key, vars = {}) => resolveTranslation(key).replace(/\{(\w+)\}/g, (_, v) => (v in vars ? String(vars[v]) : `{${v}}`)); // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/server-safe-globals.js

  class server_safe_globals_EventTarget {
   addEventListener() {}
   removeEventListener() {}
   dispatchEvent() {
    return true;
   }
  }
  class Node extends server_safe_globals_EventTarget {}
  class server_safe_globals_Element extends Node {
   constructor() {
    super(...arguments);
    this.role = null;
   }
  }
  class ResizeObserver {
   observe() {}
   unobserve() {}
   disconnect() {}
  }
  const documentShim = {
   createElement: function () {
    return new globalThisShim.HTMLElement();
   },
   createElementNS: function () {
    return new globalThisShim.HTMLElement();
   },
   addEventListener() {},
   removeEventListener() {},
   dispatchEvent(_event) {
    return false;
   },
  };
  const globalThisShim = {
   ResizeObserver,
   document: documentShim,
   Node,
   Element: server_safe_globals_Element,
   HTMLElement: class HTMLElement extends server_safe_globals_Element {
    constructor() {
     super(...arguments);
     this.innerHTML = '';
    }
    get content() {
     return new globalThisShim.DocumentFragment();
    }
   },
   DocumentFragment: class DocumentFragment extends server_safe_globals_EventTarget {},
   customElements: {
    get: function () {},
    define: function () {},
    whenDefined: function () {},
   },
   localStorage: {
    getItem(_key) {
     return null;
    },
    setItem(_key, _value) {},
    removeItem(_key) {},
   },
   CustomEvent: function CustomEvent() {},
   getComputedStyle: function () {},
   navigator: {
    languages: [],
    get userAgent() {
     return '';
    },
   },
   matchMedia(media) {
    return {
     matches: false,
     media,
    };
   },
   DOMParser: class DOMParser {
    parseFromString(string, _contentType) {
     return {
      body: {
       textContent: string,
      },
     };
    }
   },
  };
  const isServer = typeof window === 'undefined' || typeof window.customElements === 'undefined';
  const isShimmed = Object.keys(globalThisShim).every((key) => key in globalThis);
  const GlobalThis = isServer && !isShimmed ? globalThisShim : globalThis;
  const server_safe_globals_Document = isServer && !isShimmed ? documentShim : globalThis.document; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/resize-observer.js

  const callbacksMap = /* @__PURE__ */ new WeakMap();
  const getCallbacks = (element) => {
   let callbacks = callbacksMap.get(element);
   if (!callbacks) callbacksMap.set(element, (callbacks = /* @__PURE__ */ new Set()));
   return callbacks;
  };
  const observer = new GlobalThis.ResizeObserver((entries) => {
   for (const entry of entries) {
    for (const callback of getCallbacks(entry.target)) {
     callback(entry);
    }
   }
  });
  function observeResize(element, callback) {
   getCallbacks(element).add(callback);
   observer.observe(element);
  }
  function unobserveResize(element, callback) {
   const callbacks = getCallbacks(element);
   callbacks.delete(callback);
   if (!callbacks.size) {
    observer.unobserve(element);
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/element-utils.js

  function namedNodeMapToObject(namedNodeMap) {
   const obj = {};
   for (const attr of namedNodeMap) {
    obj[attr.name] = attr.value;
   }
   return obj;
  }
  function getMediaController(host) {
   var _a;
   return (_a = getAttributeMediaController(host)) != null ? _a : closestComposedNode(host, 'media-controller');
  }
  function getAttributeMediaController(host) {
   var _a;
   const { MEDIA_CONTROLLER } = MediaStateReceiverAttributes;
   const mediaControllerId = host.getAttribute(MEDIA_CONTROLLER);
   if (mediaControllerId) {
    return (_a = getDocumentOrShadowRoot(host)) == null ? void 0 : _a.getElementById(mediaControllerId);
   }
  }
  const updateIconText = (svg, value, selector = '.value') => {
   const node = svg.querySelector(selector);
   if (!node) return;
   node.textContent = value;
  };
  const getAllSlotted = (el, name) => {
   const slotSelector = `slot[name="${name}"]`;
   const slot = el.shadowRoot.querySelector(slotSelector);
   if (!slot) return [];
   return slot.children;
  };
  const getSlotted = (el, name) => getAllSlotted(el, name)[0];
  const containsComposedNode = (rootNode, childNode) => {
   if (!rootNode || !childNode) return false;
   if (rootNode == null ? void 0 : rootNode.contains(childNode)) return true;
   return containsComposedNode(rootNode, childNode.getRootNode().host);
  };
  const closestComposedNode = (childNode, selector) => {
   if (!childNode) return null;
   const closest = childNode.closest(selector);
   if (closest) return closest;
   return closestComposedNode(childNode.getRootNode().host, selector);
  };
  function getActiveElement(root = document) {
   var _a;
   const activeEl = root == null ? void 0 : root.activeElement;
   if (!activeEl) return null;
   return (_a = getActiveElement(activeEl.shadowRoot)) != null ? _a : activeEl;
  }
  function getDocumentOrShadowRoot(node) {
   var _a;
   const rootNode = (_a = node == null ? void 0 : node.getRootNode) == null ? void 0 : _a.call(node);
   if (rootNode instanceof ShadowRoot || rootNode instanceof Document) {
    return rootNode;
   }
   return null;
  }
  function isElementVisible(element, { depth = 3, checkOpacity = true, checkVisibilityCSS = true } = {}) {
   if (element.checkVisibility) {
    return element.checkVisibility({
     checkOpacity,
     checkVisibilityCSS,
    });
   }
   let el = element;
   while (el && depth > 0) {
    const style = getComputedStyle(el);
    if ((checkOpacity && style.opacity === '0') || (checkVisibilityCSS && style.visibility === 'hidden') || style.display === 'none') {
     return false;
    }
    el = el.parentElement;
    depth--;
   }
   return true;
  }
  function getPointProgressOnLine(x, y, p1, p2) {
   const dx = p2.x - p1.x;
   const dy = p2.y - p1.y;
   const lengthSquared = dx * dx + dy * dy;
   if (lengthSquared === 0) return 0;
   const projection = ((x - p1.x) * dx + (y - p1.y) * dy) / lengthSquared;
   return Math.max(0, Math.min(1, projection));
  }
  function distance(p1, p2) {
   return Math.sqrt(Math.pow(p2.x - p1.x, 2) + Math.pow(p2.y - p1.y, 2));
  }
  function getOrInsertCSSRule(styleParent, selectorText) {
   const cssRule = getCSSRule(styleParent, (st) => st === selectorText);
   if (cssRule) return cssRule;
   return insertCSSRule(styleParent, selectorText);
  }
  function getCSSRule(styleParent, predicate) {
   var _a, _b;
   let style;
   for (style of (_a = styleParent.querySelectorAll('style:not([media])')) != null ? _a : []) {
    let cssRules;
    try {
     cssRules = (_b = style.sheet) == null ? void 0 : _b.cssRules;
    } catch {
     continue;
    }
    for (const rule of cssRules != null ? cssRules : []) {
     if (predicate(rule.selectorText)) return rule;
    }
   }
  }
  function insertCSSRule(styleParent, selectorText) {
   var _a, _b;
   const styles = (_a = styleParent.querySelectorAll('style:not([media])')) != null ? _a : [];
   const style = styles == null ? void 0 : styles[styles.length - 1];
   if (!(style == null ? void 0 : style.sheet)) {
    console.warn('Media Chrome: No style sheet found on style tag of', styleParent);
    return {
     // @ts-ignore
     style: {
      setProperty: () => {},
      removeProperty: () => '',
      getPropertyValue: () => '',
     },
    };
   }
   style == null ? void 0 : style.sheet.insertRule(`${selectorText}{}`, style.sheet.cssRules.length);
   return (
    /** @type {CSSStyleRule} */
    (_b = style.sheet.cssRules) == null ? void 0 : _b[style.sheet.cssRules.length - 1]
   );
  }
  function getNumericAttr(el, attrName, defaultValue = Number.NaN) {
   const attrVal = el.getAttribute(attrName);
   return attrVal != null ? +attrVal : defaultValue;
  }
  function setNumericAttr(el, attrName, value) {
   const nextNumericValue = +value;
   if (value == null || Number.isNaN(nextNumericValue)) {
    if (el.hasAttribute(attrName)) {
     el.removeAttribute(attrName);
    }
    return;
   }
   if (getNumericAttr(el, attrName, void 0) === nextNumericValue) return;
   el.setAttribute(attrName, `${nextNumericValue}`);
  }
  function getBooleanAttr(el, attrName) {
   return el.hasAttribute(attrName);
  }
  function setBooleanAttr(el, attrName, value) {
   if (value == null) {
    if (el.hasAttribute(attrName)) {
     el.removeAttribute(attrName);
    }
    return;
   }
   if (getBooleanAttr(el, attrName) == value) return;
   el.toggleAttribute(attrName, value);
  }
  function getStringAttr(el, attrName, defaultValue = null) {
   var _a;
   return (_a = el.getAttribute(attrName)) != null ? _a : defaultValue;
  }
  function setStringAttr(el, attrName, value) {
   if (value == null) {
    if (el.hasAttribute(attrName)) {
     el.removeAttribute(attrName);
    }
    return;
   }
   const nextValue = `${value}`;
   if (getStringAttr(el, attrName, void 0) === nextValue) return;
   el.setAttribute(attrName, nextValue);
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-gesture-receiver.js

  var __accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var __privateGet = (obj, member, getter) => {
   __accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var __privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var __privateSet = (obj, member, value, setter) => {
   __accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var _mediaController;

  function getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        display: var(--media-control-display, var(--media-gesture-receiver-display, inline-block));
        box-sizing: border-box;
      }
    </style>
  `
   );
  }
  class MediaGestureReceiver extends GlobalThis.HTMLElement {
   constructor() {
    super();
    __privateAdd(this, _mediaController, void 0);
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
   }
   // NOTE: Currently "baking in" actions + attrs until we come up with
   // a more robust architecture (CJP)
   static get observedAttributes() {
    return [MediaStateReceiverAttributes.MEDIA_CONTROLLER, MediaUIAttributes.MEDIA_PAUSED];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d, _e;
    if (attrName === MediaStateReceiverAttributes.MEDIA_CONTROLLER) {
     if (oldValue) {
      (_b = (_a = __privateGet(this, _mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
      __privateSet(this, _mediaController, null);
     }
     if (newValue && this.isConnected) {
      __privateSet(this, _mediaController, (_c = this.getRootNode()) == null ? void 0 : _c.getElementById(newValue));
      (_e = (_d = __privateGet(this, _mediaController)) == null ? void 0 : _d.associateElement) == null ? void 0 : _e.call(_d, this);
     }
    }
   }
   connectedCallback() {
    var _a, _b, _c, _d;
    this.tabIndex = -1;
    this.setAttribute('aria-hidden', 'true');
    __privateSet(this, _mediaController, getMediaControllerEl(this));
    if (this.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER)) {
     (_b = (_a = __privateGet(this, _mediaController)) == null ? void 0 : _a.associateElement) == null ? void 0 : _b.call(_a, this);
    }
    (_c = __privateGet(this, _mediaController)) == null ? void 0 : _c.addEventListener('pointerdown', this);
    (_d = __privateGet(this, _mediaController)) == null ? void 0 : _d.addEventListener('click', this);
   }
   disconnectedCallback() {
    var _a, _b, _c, _d;
    if (this.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER)) {
     (_b = (_a = __privateGet(this, _mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
    }
    (_c = __privateGet(this, _mediaController)) == null ? void 0 : _c.removeEventListener('pointerdown', this);
    (_d = __privateGet(this, _mediaController)) == null ? void 0 : _d.removeEventListener('click', this);
    __privateSet(this, _mediaController, null);
   }
   handleEvent(event) {
    var _a;
    const composedTarget = (_a = event.composedPath()) == null ? void 0 : _a[0];
    const allowList = ['video', 'media-controller'];
    if (!allowList.includes(composedTarget == null ? void 0 : composedTarget.localName)) return;
    if (event.type === 'pointerdown') {
     this._pointerType = event.pointerType;
    } else if (event.type === 'click') {
     const { clientX, clientY } = event;
     const { left, top, width, height } = this.getBoundingClientRect();
     const x = clientX - left;
     const y = clientY - top;
     if (
      x < 0 ||
      y < 0 ||
      x > width ||
      y > height || // In case this element has no dimensions (or display: none) return.
      (width === 0 && height === 0)
     ) {
      return;
     }
     const { pointerType = this._pointerType } = event;
     this._pointerType = void 0;
     if (pointerType === PointerTypes.TOUCH) {
      this.handleTap(event);
      return;
     } else if (pointerType === PointerTypes.MOUSE) {
      this.handleMouseClick(event);
      return;
     }
    }
   }
   /**
    * @type {boolean} Is the media paused
    */
   get mediaPaused() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED);
   }
   set mediaPaused(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED, value);
   }
   // NOTE: Currently "baking in" actions + attrs until we come up with
   // a more robust architecture (CJP)
   /**
    * @abstract
    * @argument {Event} e
    */
   handleTap(e) {}
   // eslint-disable-line
   // eslint-disable-next-line
   handleMouseClick(e) {
    const eventName = this.mediaPaused ? MediaUIEvents.MEDIA_PLAY_REQUEST : MediaUIEvents.MEDIA_PAUSE_REQUEST;
    this.dispatchEvent(new GlobalThis.CustomEvent(eventName, { composed: true, bubbles: true }));
   }
  }
  _mediaController = new WeakMap();
  MediaGestureReceiver.shadowRootOptions = { mode: 'open' };
  MediaGestureReceiver.getTemplateHTML = getTemplateHTML;
  function getMediaControllerEl(controlEl) {
   var _a;
   const mediaControllerId = controlEl.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER);
   if (mediaControllerId) {
    return (_a = controlEl.getRootNode()) == null ? void 0 : _a.getElementById(mediaControllerId);
   }
   return closestComposedNode(controlEl, 'media-controller');
  }
  if (!GlobalThis.customElements.get('media-gesture-receiver')) {
   GlobalThis.customElements.define('media-gesture-receiver', MediaGestureReceiver);
  }
  var media_gesture_receiver_default = MediaGestureReceiver; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-container.js

  var media_container_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_container_privateGet = (obj, member, getter) => {
   media_container_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_container_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_container_privateSet = (obj, member, value, setter) => {
   media_container_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var __privateMethod = (obj, member, method) => {
   media_container_accessCheck(obj, member, 'access private method');
   return method;
  };
  var _pointerDownTimeStamp, _currentMedia, _inactiveTimeout, _autohide, _mutationObserver, _handleMutation, handleMutation_fn, _isResizePending, _handleResize, _handlePointerMove, handlePointerMove_fn, _handlePointerUp, handlePointerUp_fn, _setInactive, setInactive_fn, _setActive, setActive_fn, _scheduleInactive, scheduleInactive_fn;

  const Attributes = {
   AUDIO: 'audio',
   AUTOHIDE: 'autohide',
   BREAKPOINTS: 'breakpoints',
   GESTURES_DISABLED: 'gesturesdisabled',
   KEYBOARD_CONTROL: 'keyboardcontrol',
   NO_AUTOHIDE: 'noautohide',
   USER_INACTIVE: 'userinactive',
   AUTOHIDE_OVER_CONTROLS: 'autohideovercontrols',
  };
  function media_container_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      ${
       /*
        * outline on media is turned off because it is allowed to get focus to faciliate hotkeys.
        * However, on keyboard interactions, the focus outline is shown,
        * which is particularly noticeable when going fullscreen via hotkeys.
        */
       ''
      }
      :host([${MediaUIAttributes.MEDIA_IS_FULLSCREEN}]) ::slotted([slot=media]) {
        outline: none;
      }

      :host {
        box-sizing: border-box;
        position: relative;
        display: inline-block;
        line-height: 0;
        background-color: var(--media-background-color, #000);
      }

      :host(:not([${Attributes.AUDIO}])) [part~=layer]:not([part~=media-layer]) {
        position: absolute;
        top: 0;
        left: 0;
        bottom: 0;
        right: 0;
        display: flex;
        flex-flow: column nowrap;
        align-items: start;
        pointer-events: none;
        background: none;
      }

      slot[name=media] {
        display: var(--media-slot-display, contents);
      }

      ${
       /*
        * when in audio mode, hide the slotted media element by default
        */
       ''
      }
      :host([${Attributes.AUDIO}]) slot[name=media] {
        display: var(--media-slot-display, none);
      }

      ${
       /*
        * when in audio mode, hide the gesture-layer which causes media-controller to be taller than the control bar
        */
       ''
      }
      :host([${Attributes.AUDIO}]) [part~=layer][part~=gesture-layer] {
        height: 0;
        display: block;
      }

      ${
       /*
        * if gestures are disabled, don't accept pointer-events
        */
       ''
      }
      :host(:not([${Attributes.AUDIO}])[${Attributes.GESTURES_DISABLED}]) ::slotted([slot=gestures-chrome]),
          :host(:not([${Attributes.AUDIO}])[${Attributes.GESTURES_DISABLED}]) media-gesture-receiver[slot=gestures-chrome] {
        display: none;
      }

      ${
       /*
        * any slotted element that isn't a poster or media slot should be pointer-events auto
        * we'll want to add here any slotted elements that shouldn't get pointer-events by default when slotted
        */
       ''
      }
      ::slotted(:not([slot=media]):not([slot=poster]):not(media-loading-indicator):not([role=dialog]):not([hidden])) {
        pointer-events: auto;
      }

      :host(:not([${Attributes.AUDIO}])) *[part~=layer][part~=centered-layer] {
        align-items: center;
        justify-content: center;
      }

      :host(:not([${Attributes.AUDIO}])) ::slotted(media-gesture-receiver[slot=gestures-chrome]),
      :host(:not([${Attributes.AUDIO}])) media-gesture-receiver[slot=gestures-chrome] {
        align-self: stretch;
        flex-grow: 1;
      }

      slot[name=middle-chrome] {
        display: inline;
        flex-grow: 1;
        pointer-events: none;
        background: none;
      }

      ${/* Position the media and poster elements to fill the container */ ''}
      ::slotted([slot=media]),
      ::slotted([slot=poster]) {
        width: 100%;
        height: 100%;
      }

      ${/* Video specific styles */ ''}
      :host(:not([${Attributes.AUDIO}])) .spacer {
        flex-grow: 1;
      }

      ${/* Safari needs this to actually make the element fill the window */ ''}
      :host(:-webkit-full-screen) {
        ${/* Needs to use !important otherwise easy to break */ ''}
        width: 100% !important;
        height: 100% !important;
      }

      ${/* Only add these if auto hide is not disabled */ ''}
      ::slotted(:not([slot=media]):not([slot=poster]):not([${Attributes.NO_AUTOHIDE}]):not([hidden]):not([role=dialog])) {
        opacity: 1;
        transition: var(--media-control-transition-in, opacity 0.25s);
      }

      ${/* Hide controls when inactive, not paused, not audio and auto hide not disabled */ ''}
      :host([${Attributes.USER_INACTIVE}]:not([${MediaUIAttributes.MEDIA_PAUSED}]):not([${MediaUIAttributes.MEDIA_IS_AIRPLAYING}]):not([${MediaUIAttributes.MEDIA_IS_CASTING}]):not([${Attributes.AUDIO}])) ::slotted(:not([slot=media]):not([slot=poster]):not([${Attributes.NO_AUTOHIDE}]):not([role=dialog])) {
        opacity: 0;
        transition: var(--media-control-transition-out, opacity 1s);
      }

      :host([${Attributes.USER_INACTIVE}]:not([${Attributes.NO_AUTOHIDE}]):not([${MediaUIAttributes.MEDIA_PAUSED}]):not([${MediaUIAttributes.MEDIA_IS_CASTING}]):not([${Attributes.AUDIO}])) ::slotted([slot=media]) {
        cursor: none;
      }

      :host([${Attributes.USER_INACTIVE}][${Attributes.AUTOHIDE_OVER_CONTROLS}]:not([${Attributes.NO_AUTOHIDE}]):not([${MediaUIAttributes.MEDIA_PAUSED}]):not([${MediaUIAttributes.MEDIA_IS_CASTING}]):not([${Attributes.AUDIO}])) * {
        --media-cursor: none;
        cursor: none;
      }


      ::slotted(media-control-bar)  {
        align-self: stretch;
      }

      ${/* ::slotted([slot=poster]) doesn't work for slot fallback content so hide parent slot instead */ ''}
      :host(:not([${Attributes.AUDIO}])[${MediaUIAttributes.MEDIA_HAS_PLAYED}]) slot[name=poster] {
        display: none;
      }

      ::slotted([role=dialog]) {
        width: 100%;
        height: 100%;
        align-self: center;
      }

      ::slotted([role=menu]) {
        align-self: end;
      }
    </style>

    <slot name="media" part="layer media-layer"></slot>
    <slot name="poster" part="layer poster-layer"></slot>
    <slot name="gestures-chrome" part="layer gesture-layer">
      <media-gesture-receiver slot="gestures-chrome">
        <template shadowrootmode="${media_gesture_receiver_default.shadowRootOptions.mode}">
          ${media_gesture_receiver_default.getTemplateHTML({})}
        </template>
      </media-gesture-receiver>
    </slot>
    <span part="layer vertical-layer">
      <slot name="top-chrome" part="top chrome"></slot>
      <slot name="middle-chrome" part="middle chrome"></slot>
      <slot name="centered-chrome" part="layer centered-layer center centered chrome"></slot>
      ${/* default, effectively "bottom-chrome" */ ''}
      <slot part="bottom chrome"></slot>
    </span>
    <slot name="dialog" part="layer dialog-layer"></slot>
  `
   );
  }
  const MEDIA_UI_ATTRIBUTE_NAMES = Object.values(MediaUIAttributes);
  const defaultBreakpoints = 'sm:384 md:576 lg:768 xl:960';
  function resizeCallback(entry) {
   setBreakpoints(entry.target, entry.contentRect.width);
  }
  function setBreakpoints(container, width) {
   var _a;
   if (!container.isConnected) return;
   const breakpoints = (_a = container.getAttribute(Attributes.BREAKPOINTS)) != null ? _a : defaultBreakpoints;
   const ranges = createBreakpointMap(breakpoints);
   const activeBreakpoints = getBreakpoints(ranges, width);
   let changed = false;
   Object.keys(ranges).forEach((name) => {
    if (activeBreakpoints.includes(name)) {
     if (!container.hasAttribute(`breakpoint${name}`)) {
      container.setAttribute(`breakpoint${name}`, '');
      changed = true;
     }
     return;
    }
    if (container.hasAttribute(`breakpoint${name}`)) {
     container.removeAttribute(`breakpoint${name}`);
     changed = true;
    }
   });
   if (changed) {
    const evt = new CustomEvent(MediaStateChangeEvents.BREAKPOINTS_CHANGE, {
     detail: activeBreakpoints,
    });
    container.dispatchEvent(evt);
   }
   if (!container.breakpointsComputed) {
    container.breakpointsComputed = true;
    container.dispatchEvent(
     new CustomEvent(MediaStateChangeEvents.BREAKPOINTS_COMPUTED, {
      bubbles: true,
      composed: true,
     }),
    );
   }
  }
  function createBreakpointMap(breakpoints) {
   const pairs = breakpoints.split(/\s+/);
   return Object.fromEntries(pairs.map((pair) => pair.split(':')));
  }
  function getBreakpoints(breakpoints, width) {
   return Object.keys(breakpoints).filter((name) => {
    return width >= parseInt(breakpoints[name]);
   });
  }
  class MediaContainer extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_container_privateAdd(this, _handleMutation);
    media_container_privateAdd(this, _handlePointerMove);
    media_container_privateAdd(this, _handlePointerUp);
    media_container_privateAdd(this, _setInactive);
    media_container_privateAdd(this, _setActive);
    media_container_privateAdd(this, _scheduleInactive);
    media_container_privateAdd(this, _pointerDownTimeStamp, 0);
    media_container_privateAdd(this, _currentMedia, null);
    media_container_privateAdd(this, _inactiveTimeout, null);
    media_container_privateAdd(this, _autohide, void 0);
    this.breakpointsComputed = false;
    media_container_privateAdd(this, _mutationObserver, new MutationObserver(__privateMethod(this, _handleMutation, handleMutation_fn).bind(this)));
    media_container_privateAdd(this, _isResizePending, false);
    media_container_privateAdd(this, _handleResize, (entry) => {
     if (media_container_privateGet(this, _isResizePending)) return;
     setTimeout(() => {
      resizeCallback(entry);
      media_container_privateSet(this, _isResizePending, false);
     }, 0);
     media_container_privateSet(this, _isResizePending, true);
    });
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     const html = this.constructor.getTemplateHTML(attrs);
     this.shadowRoot.setHTMLUnsafe ? this.shadowRoot.setHTMLUnsafe(html) : (this.shadowRoot.innerHTML = html);
    }
    const chainedSlot = this.querySelector(':scope > slot[slot=media]');
    if (chainedSlot) {
     chainedSlot.addEventListener('slotchange', () => {
      const slotEls = chainedSlot.assignedElements({ flatten: true });
      if (!slotEls.length) {
       if (media_container_privateGet(this, _currentMedia)) {
        this.mediaUnsetCallback(media_container_privateGet(this, _currentMedia));
       }
       return;
      }
      this.handleMediaUpdated(this.media);
     });
    }
   }
   static get observedAttributes() {
    return [Attributes.AUTOHIDE, Attributes.GESTURES_DISABLED].concat(MEDIA_UI_ATTRIBUTE_NAMES).filter((name) => ![MediaUIAttributes.MEDIA_RENDITION_LIST, MediaUIAttributes.MEDIA_AUDIO_TRACK_LIST, MediaUIAttributes.MEDIA_CHAPTERS_CUES, MediaUIAttributes.MEDIA_WIDTH, MediaUIAttributes.MEDIA_HEIGHT, MediaUIAttributes.MEDIA_ERROR, MediaUIAttributes.MEDIA_ERROR_MESSAGE].includes(name));
   }
   // Could share this code with media-chrome-html-element instead
   attributeChangedCallback(attrName, _oldValue, newValue) {
    if (attrName.toLowerCase() == Attributes.AUTOHIDE) {
     this.autohide = newValue;
    }
   }
   // First direct child with slot=media, or null
   get media() {
    let media = this.querySelector(':scope > [slot=media]');
    if ((media == null ? void 0 : media.nodeName) == 'SLOT') media = media.assignedElements({ flatten: true })[0];
    return media;
   }
   async handleMediaUpdated(media) {
    if (!media) return;
    media_container_privateSet(this, _currentMedia, media);
    if (media.localName.includes('-')) {
     await GlobalThis.customElements.whenDefined(media.localName);
    }
    this.mediaSetCallback(media);
   }
   connectedCallback() {
    var _a;
    media_container_privateGet(this, _mutationObserver).observe(this, { childList: true, subtree: true });
    observeResize(this, media_container_privateGet(this, _handleResize));
    const isAudioChrome = this.getAttribute(Attributes.AUDIO) != null;
    const label = isAudioChrome ? t('audio player') : t('video player');
    this.setAttribute('role', 'region');
    this.setAttribute('aria-label', label);
    this.handleMediaUpdated(this.media);
    this.setAttribute(Attributes.USER_INACTIVE, '');
    setBreakpoints(this, this.getBoundingClientRect().width);
    this.addEventListener('pointerdown', this);
    this.addEventListener('pointermove', this);
    this.addEventListener('pointerup', this);
    this.addEventListener('mouseleave', this);
    this.addEventListener('keyup', this);
    (_a = GlobalThis.window) == null ? void 0 : _a.addEventListener('mouseup', this);
   }
   disconnectedCallback() {
    var _a;
    media_container_privateGet(this, _mutationObserver).disconnect();
    unobserveResize(this, media_container_privateGet(this, _handleResize));
    if (this.media) {
     this.mediaUnsetCallback(this.media);
    }
    (_a = GlobalThis.window) == null ? void 0 : _a.removeEventListener('mouseup', this);
   }
   /**
    * @abstract
    */
   mediaSetCallback(_media) {}
   mediaUnsetCallback(_media) {
    media_container_privateSet(this, _currentMedia, null);
   }
   handleEvent(event) {
    switch (event.type) {
     case 'pointerdown':
      media_container_privateSet(this, _pointerDownTimeStamp, event.timeStamp);
      break;
     case 'pointermove':
      __privateMethod(this, _handlePointerMove, handlePointerMove_fn).call(this, event);
      break;
     case 'pointerup':
      __privateMethod(this, _handlePointerUp, handlePointerUp_fn).call(this, event);
      break;
     case 'mouseleave':
      __privateMethod(this, _setInactive, setInactive_fn).call(this);
      break;
     case 'mouseup':
      this.removeAttribute(Attributes.KEYBOARD_CONTROL);
      break;
     case 'keyup':
      __privateMethod(this, _scheduleInactive, scheduleInactive_fn).call(this);
      this.setAttribute(Attributes.KEYBOARD_CONTROL, '');
      break;
    }
   }
   set autohide(seconds) {
    const parsedSeconds = Number(seconds);
    media_container_privateSet(this, _autohide, isNaN(parsedSeconds) ? 0 : parsedSeconds);
   }
   get autohide() {
    return (media_container_privateGet(this, _autohide) === void 0 ? 2 : media_container_privateGet(this, _autohide)).toString();
   }
   get breakpoints() {
    return getStringAttr(this, Attributes.BREAKPOINTS);
   }
   set breakpoints(value) {
    setStringAttr(this, Attributes.BREAKPOINTS, value);
   }
   get audio() {
    return getBooleanAttr(this, Attributes.AUDIO);
   }
   set audio(value) {
    setBooleanAttr(this, Attributes.AUDIO, value);
   }
   get gesturesDisabled() {
    return getBooleanAttr(this, Attributes.GESTURES_DISABLED);
   }
   set gesturesDisabled(value) {
    setBooleanAttr(this, Attributes.GESTURES_DISABLED, value);
   }
   get keyboardControl() {
    return getBooleanAttr(this, Attributes.KEYBOARD_CONTROL);
   }
   set keyboardControl(value) {
    setBooleanAttr(this, Attributes.KEYBOARD_CONTROL, value);
   }
   get noAutohide() {
    return getBooleanAttr(this, Attributes.NO_AUTOHIDE);
   }
   set noAutohide(value) {
    setBooleanAttr(this, Attributes.NO_AUTOHIDE, value);
   }
   get autohideOverControls() {
    return getBooleanAttr(this, Attributes.AUTOHIDE_OVER_CONTROLS);
   }
   set autohideOverControls(value) {
    setBooleanAttr(this, Attributes.AUTOHIDE_OVER_CONTROLS, value);
   }
   get userInteractive() {
    return getBooleanAttr(this, Attributes.USER_INACTIVE);
   }
   set userInteractive(value) {
    setBooleanAttr(this, Attributes.USER_INACTIVE, value);
   }
  }
  _pointerDownTimeStamp = new WeakMap();
  _currentMedia = new WeakMap();
  _inactiveTimeout = new WeakMap();
  _autohide = new WeakMap();
  _mutationObserver = new WeakMap();
  _handleMutation = new WeakSet();
  handleMutation_fn = function (mutationsList) {
   const media = this.media;
   for (const mutation of mutationsList) {
    if (mutation.type !== 'childList') continue;
    const removedNodes = mutation.removedNodes;
    for (const node of removedNodes) {
     if (node.slot != 'media' || mutation.target != this) continue;
     let previousSibling = mutation.previousSibling && mutation.previousSibling.previousElementSibling;
     if (!previousSibling || !media) {
      this.mediaUnsetCallback(node);
     } else {
      let wasFirst = previousSibling.slot !== 'media';
      while ((previousSibling = previousSibling.previousSibling) !== null) {
       if (previousSibling.slot == 'media') wasFirst = false;
      }
      if (wasFirst) this.mediaUnsetCallback(node);
     }
    }
    if (media) {
     for (const node of mutation.addedNodes) {
      if (node === media) this.handleMediaUpdated(media);
     }
    }
   }
  };
  _isResizePending = new WeakMap();
  _handleResize = new WeakMap();
  _handlePointerMove = new WeakSet();
  handlePointerMove_fn = function (event) {
   if (event.pointerType !== 'mouse') {
    const MAX_TAP_DURATION = 250;
    if (event.timeStamp - media_container_privateGet(this, _pointerDownTimeStamp) < MAX_TAP_DURATION) return;
   }
   __privateMethod(this, _setActive, setActive_fn).call(this);
   clearTimeout(media_container_privateGet(this, _inactiveTimeout));
   const autohideOverControls = this.hasAttribute(Attributes.AUTOHIDE_OVER_CONTROLS);
   if ([this, this.media].includes(event.target) || autohideOverControls) {
    __privateMethod(this, _scheduleInactive, scheduleInactive_fn).call(this);
   }
  };
  _handlePointerUp = new WeakSet();
  handlePointerUp_fn = function (event) {
   if (event.pointerType === 'touch') {
    const controlsVisible = !this.hasAttribute(Attributes.USER_INACTIVE);
    if ([this, this.media].includes(event.target) && controlsVisible) {
     __privateMethod(this, _setInactive, setInactive_fn).call(this);
    } else {
     __privateMethod(this, _scheduleInactive, scheduleInactive_fn).call(this);
    }
   } else if (event.composedPath().some((el) => ['media-play-button', 'media-fullscreen-button'].includes(el == null ? void 0 : el.localName))) {
    __privateMethod(this, _scheduleInactive, scheduleInactive_fn).call(this);
   }
  };
  _setInactive = new WeakSet();
  setInactive_fn = function () {
   if (media_container_privateGet(this, _autohide) < 0) return;
   if (this.hasAttribute(Attributes.USER_INACTIVE)) return;
   this.setAttribute(Attributes.USER_INACTIVE, '');
   const evt = new GlobalThis.CustomEvent(MediaStateChangeEvents.USER_INACTIVE_CHANGE, { composed: true, bubbles: true, detail: true });
   this.dispatchEvent(evt);
  };
  _setActive = new WeakSet();
  setActive_fn = function () {
   if (!this.hasAttribute(Attributes.USER_INACTIVE)) return;
   this.removeAttribute(Attributes.USER_INACTIVE);
   const evt = new GlobalThis.CustomEvent(MediaStateChangeEvents.USER_INACTIVE_CHANGE, { composed: true, bubbles: true, detail: false });
   this.dispatchEvent(evt);
  };
  _scheduleInactive = new WeakSet();
  scheduleInactive_fn = function () {
   __privateMethod(this, _setActive, setActive_fn).call(this);
   clearTimeout(media_container_privateGet(this, _inactiveTimeout));
   const autohide = parseInt(this.autohide);
   if (autohide < 0) return;
   media_container_privateSet(
    this,
    _inactiveTimeout,
    setTimeout(() => {
     __privateMethod(this, _setInactive, setInactive_fn).call(this);
    }, autohide * 1e3),
   );
  };
  MediaContainer.shadowRootOptions = { mode: 'open' };
  MediaContainer.getTemplateHTML = media_container_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-container')) {
   GlobalThis.customElements.define('media-container', MediaContainer);
  }
  var media_container_default = /* unused pure expression or super */ null && MediaContainer; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/attribute-token-list.js

  var attribute_token_list_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var attribute_token_list_privateGet = (obj, member, getter) => {
   attribute_token_list_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var attribute_token_list_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var attribute_token_list_privateSet = (obj, member, value, setter) => {
   attribute_token_list_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var _el, _attr, _defaultSet, _tokenSet, _tokens, tokens_get;
  class AttributeTokenList {
   constructor(el, attr, { defaultValue } = { defaultValue: void 0 }) {
    attribute_token_list_privateAdd(this, _tokens);
    attribute_token_list_privateAdd(this, _el, void 0);
    attribute_token_list_privateAdd(this, _attr, void 0);
    attribute_token_list_privateAdd(this, _defaultSet, void 0);
    attribute_token_list_privateAdd(this, _tokenSet, /* @__PURE__ */ new Set());
    attribute_token_list_privateSet(this, _el, el);
    attribute_token_list_privateSet(this, _attr, attr);
    attribute_token_list_privateSet(this, _defaultSet, new Set(defaultValue));
   }
   [Symbol.iterator]() {
    return attribute_token_list_privateGet(this, _tokens, tokens_get).values();
   }
   get length() {
    return attribute_token_list_privateGet(this, _tokens, tokens_get).size;
   }
   get value() {
    var _a;
    return (_a = [...attribute_token_list_privateGet(this, _tokens, tokens_get)].join(' ')) != null ? _a : '';
   }
   set value(val) {
    var _a;
    if (val === this.value) return;
    attribute_token_list_privateSet(this, _tokenSet, /* @__PURE__ */ new Set());
    this.add(...((_a = val == null ? void 0 : val.split(' ')) != null ? _a : []));
   }
   toString() {
    return this.value;
   }
   item(index) {
    return [...attribute_token_list_privateGet(this, _tokens, tokens_get)][index];
   }
   values() {
    return attribute_token_list_privateGet(this, _tokens, tokens_get).values();
   }
   forEach(callback, thisArg) {
    attribute_token_list_privateGet(this, _tokens, tokens_get).forEach(callback, thisArg);
   }
   add(...tokens) {
    var _a, _b;
    tokens.forEach((t) => attribute_token_list_privateGet(this, _tokenSet).add(t));
    if (this.value === '' && !((_a = attribute_token_list_privateGet(this, _el)) == null ? void 0 : _a.hasAttribute(`${attribute_token_list_privateGet(this, _attr)}`))) {
     return;
    }
    (_b = attribute_token_list_privateGet(this, _el)) == null ? void 0 : _b.setAttribute(`${attribute_token_list_privateGet(this, _attr)}`, `${this.value}`);
   }
   remove(...tokens) {
    var _a;
    tokens.forEach((t) => attribute_token_list_privateGet(this, _tokenSet).delete(t));
    (_a = attribute_token_list_privateGet(this, _el)) == null ? void 0 : _a.setAttribute(`${attribute_token_list_privateGet(this, _attr)}`, `${this.value}`);
   }
   contains(token) {
    return attribute_token_list_privateGet(this, _tokens, tokens_get).has(token);
   }
   toggle(token, force) {
    if (typeof force !== 'undefined') {
     if (force) {
      this.add(token);
      return true;
     } else {
      this.remove(token);
      return false;
     }
    }
    if (this.contains(token)) {
     this.remove(token);
     return false;
    }
    this.add(token);
    return true;
   }
   replace(oldToken, newToken) {
    this.remove(oldToken);
    this.add(newToken);
    return oldToken === newToken;
   }
  }
  _el = new WeakMap();
  _attr = new WeakMap();
  _defaultSet = new WeakMap();
  _tokenSet = new WeakMap();
  _tokens = new WeakSet();
  tokens_get = function () {
   return attribute_token_list_privateGet(this, _tokenSet).size ? attribute_token_list_privateGet(this, _tokenSet) : attribute_token_list_privateGet(this, _defaultSet);
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/captions.js

  const splitTextTracksStr = (textTracksStr = '') => textTracksStr.split(/\s+/);
  const parseTextTrackStr = (textTrackStr = '') => {
   const [kind, language, encodedLabel] = textTrackStr.split(':');
   const label = encodedLabel ? decodeURIComponent(encodedLabel) : void 0;
   return {
    kind: kind === 'cc' ? TextTrackKinds.CAPTIONS : TextTrackKinds.SUBTITLES,
    language,
    label,
   };
  };
  const parseTextTracksStr = (textTracksStr = '', textTrackLikeObj = {}) => {
   return splitTextTracksStr(textTracksStr).map((textTrackStr) => {
    const textTrackObj = parseTextTrackStr(textTrackStr);
    return {
     ...textTrackLikeObj,
     ...textTrackObj,
    };
   });
  };
  const parseTracks = (trackOrTracks) => {
   if (!trackOrTracks) return [];
   if (Array.isArray(trackOrTracks)) {
    return trackOrTracks.map((trackObjOrStr) => {
     if (typeof trackObjOrStr === 'string') {
      return parseTextTrackStr(trackObjOrStr);
     }
     return trackObjOrStr;
    });
   }
   if (typeof trackOrTracks === 'string') {
    return parseTextTracksStr(trackOrTracks);
   }
   return [trackOrTracks];
  };
  const formatTextTrackObj = ({ kind, label, language } = { kind: 'subtitles' }) => {
   if (!label) return language;
   return `${kind === 'captions' ? 'cc' : 'sb'}:${language}:${encodeURIComponent(label)}`;
  };
  const stringifyTextTrackList = (textTracks = []) => {
   return Array.prototype.map.call(textTracks, formatTextTrackObj).join(' ');
  };
  const isMatchingPropOf = (key, value) => (obj) => obj[key] === value;
  const textTrackObjAsPred = (filterObj) => {
   const preds = Object.entries(filterObj).map(([key, value]) => {
    return isMatchingPropOf(key, value);
   });
   return (textTrack) => preds.every((pred) => pred(textTrack));
  };
  const updateTracksModeTo = (mode, tracks = [], tracksToUpdate = []) => {
   const preds = parseTracks(tracksToUpdate).map(textTrackObjAsPred);
   const isTrackToUpdate = (textTrack) => {
    return preds.some((pred) => pred(textTrack));
   };
   Array.from(tracks)
    .filter(isTrackToUpdate)
    .forEach((textTrack) => {
     textTrack.mode = mode;
    });
  };
  const getTextTracksList = (media, filterPredOrObj = () => true) => {
   if (!(media == null ? void 0 : media.textTracks)) return [];
   const filterPred = typeof filterPredOrObj === 'function' ? filterPredOrObj : textTrackObjAsPred(filterPredOrObj);
   return Array.from(media.textTracks).filter(filterPred);
  };
  const areSubsOn = (el) => {
   var _a;
   const showingSubtitles = !!((_a = el.mediaSubtitlesShowing) == null ? void 0 : _a.length) || el.hasAttribute(MediaUIAttributes.MEDIA_SUBTITLES_SHOWING);
   return showingSubtitles;
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/fullscreen-api.js

  const enterFullscreen = (stateOwners) => {
   var _a;
   const { media, fullscreenElement } = stateOwners;
   try {
    const enterFullscreenKey = fullscreenElement && 'requestFullscreen' in fullscreenElement ? 'requestFullscreen' : fullscreenElement && 'webkitRequestFullScreen' in fullscreenElement ? 'webkitRequestFullScreen' : void 0;
    if (enterFullscreenKey) {
     const maybePromise = (_a = fullscreenElement[enterFullscreenKey]) == null ? void 0 : _a.call(fullscreenElement);
     if (maybePromise instanceof Promise) {
      return maybePromise.catch(() => {});
     }
    } else if (media == null ? void 0 : media.webkitEnterFullscreen) {
     media.webkitEnterFullscreen();
    } else if (media == null ? void 0 : media.requestFullscreen) {
     media.requestFullscreen();
    }
   } catch (e) {
    console.error(e);
   }
  };
  const exitFullscreenKey = 'exitFullscreen' in server_safe_globals_Document ? 'exitFullscreen' : 'webkitExitFullscreen' in server_safe_globals_Document ? 'webkitExitFullscreen' : 'webkitCancelFullScreen' in server_safe_globals_Document ? 'webkitCancelFullScreen' : void 0;
  const exitFullscreen = (stateOwners) => {
   var _a;
   const { documentElement } = stateOwners;
   if (exitFullscreenKey) {
    const maybePromise = (_a = documentElement == null ? void 0 : documentElement[exitFullscreenKey]) == null ? void 0 : _a.call(documentElement);
    if (maybePromise instanceof Promise) {
     return maybePromise.catch(() => {});
    }
   }
  };
  const fullscreenElementKey = 'fullscreenElement' in server_safe_globals_Document ? 'fullscreenElement' : 'webkitFullscreenElement' in server_safe_globals_Document ? 'webkitFullscreenElement' : void 0;
  const getFullscreenElement = (stateOwners) => {
   const { documentElement, media } = stateOwners;
   const docFullscreenElement = documentElement == null ? void 0 : documentElement[fullscreenElementKey];
   if (!docFullscreenElement && 'webkitDisplayingFullscreen' in media && 'webkitPresentationMode' in media && media.webkitDisplayingFullscreen && media.webkitPresentationMode === WebkitPresentationModes.FULLSCREEN) {
    return media;
   }
   return docFullscreenElement;
  };
  const isFullscreen = (stateOwners) => {
   var _a;
   const { media, documentElement, fullscreenElement = media } = stateOwners;
   if (!media || !documentElement) return false;
   const currentFullscreenElement = getFullscreenElement(stateOwners);
   if (!currentFullscreenElement) return false;
   if (currentFullscreenElement === fullscreenElement || currentFullscreenElement === media) {
    return true;
   }
   if (currentFullscreenElement.localName.includes('-')) {
    let currentRoot = currentFullscreenElement.shadowRoot;
    if (!(fullscreenElementKey in currentRoot)) {
     return containsComposedNode(
      currentFullscreenElement,
      /** @TODO clean up type assumptions (e.g. Node) (CJP) */
      // @ts-ignore
      fullscreenElement,
     );
    }
    while (currentRoot == null ? void 0 : currentRoot[fullscreenElementKey]) {
     if (currentRoot[fullscreenElementKey] === fullscreenElement) return true;
     currentRoot = (_a = currentRoot[fullscreenElementKey]) == null ? void 0 : _a.shadowRoot;
    }
   }
   return false;
  };
  const fullscreenEnabledKey = 'fullscreenEnabled' in server_safe_globals_Document ? 'fullscreenEnabled' : 'webkitFullscreenEnabled' in server_safe_globals_Document ? 'webkitFullscreenEnabled' : void 0;
  const isFullscreenEnabled = (stateOwners) => {
   const { documentElement, media } = stateOwners;
   return !!(documentElement == null ? void 0 : documentElement[fullscreenEnabledKey]) || (media && 'webkitSupportsFullscreen' in media);
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/platform-tests.js

  let testMediaEl;
  const getTestMediaEl = () => {
   var _a, _b;
   if (testMediaEl) return testMediaEl;
   testMediaEl = (_b = (_a = server_safe_globals_Document) == null ? void 0 : _a.createElement) == null ? void 0 : _b.call(_a, 'video');
   return testMediaEl;
  };
  const hasVolumeSupportAsync = async (mediaEl = getTestMediaEl()) => {
   if (!mediaEl) return false;
   const prevVolume = mediaEl.volume;
   mediaEl.volume = prevVolume / 2 + 0.1;
   const abortController = new AbortController();
   const volumeSupported = await Promise.race([dispatchedVolumeChange(mediaEl, abortController.signal), volumeChanged(mediaEl, prevVolume)]);
   abortController.abort();
   return volumeSupported;
  };
  const dispatchedVolumeChange = (mediaEl, signal) => {
   return new Promise((resolve) => {
    mediaEl.addEventListener('volumechange', () => resolve(true), { signal });
   });
  };
  const volumeChanged = async (mediaEl, prevVolume) => {
   for (let i = 0; i < 10; i++) {
    if (mediaEl.volume === prevVolume) return false;
    await delay(10);
   }
   return mediaEl.volume !== prevVolume;
  };
  const isSafari = /.*Version\/.*Safari\/.*/.test(GlobalThis.navigator.userAgent);
  const hasPipSupport = (mediaEl = getTestMediaEl()) => {
   if (GlobalThis.matchMedia('(display-mode: standalone)').matches && isSafari) return false;
   return typeof (mediaEl == null ? void 0 : mediaEl.requestPictureInPicture) === 'function';
  };
  const hasFullscreenSupport = (mediaEl = getTestMediaEl()) => {
   return isFullscreenEnabled({ documentElement: server_safe_globals_Document, media: mediaEl });
  };
  const fullscreenSupported = hasFullscreenSupport();
  const pipSupported = hasPipSupport();
  const airplaySupported = !!GlobalThis.WebKitPlaybackTargetAvailabilityEvent;
  const castSupported = !!GlobalThis.chrome; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-store/util.js

  const getSubtitleTracks = (stateOwners) => {
   return getTextTracksList(stateOwners.media, (textTrack) => {
    return [TextTrackKinds.SUBTITLES, TextTrackKinds.CAPTIONS].includes(textTrack.kind);
   }).sort((a, b) => (a.kind >= b.kind ? 1 : -1));
  };
  const getShowingSubtitleTracks = (stateOwners) => {
   return getTextTracksList(stateOwners.media, (textTrack) => {
    return textTrack.mode === TextTrackModes.SHOWING && [TextTrackKinds.SUBTITLES, TextTrackKinds.CAPTIONS].includes(textTrack.kind);
   });
  };
  const toggleSubtitleTracks = (stateOwners, force) => {
   const tracks = getSubtitleTracks(stateOwners);
   const showingSubitleTracks = getShowingSubtitleTracks(stateOwners);
   const subtitlesShowing = !!showingSubitleTracks.length;
   if (!tracks.length) return;
   if (force === false || (subtitlesShowing && force !== true)) {
    updateTracksModeTo(TextTrackModes.DISABLED, tracks, showingSubitleTracks);
   } else if (force === true || (!subtitlesShowing && force !== false)) {
    let subTrack = tracks[0];
    const { options } = stateOwners;
    if (!(options == null ? void 0 : options.noSubtitlesLangPref)) {
     const subtitlesPref = globalThis.localStorage.getItem('media-chrome-pref-subtitles-lang');
     const userLangPrefs = subtitlesPref ? [subtitlesPref, ...globalThis.navigator.languages] : globalThis.navigator.languages;
     const preferredAvailableSubs = tracks
      .filter((textTrack) => {
       return userLangPrefs.some((lang) => textTrack.language.toLowerCase().startsWith(lang.split('-')[0]));
      })
      .sort((textTrackA, textTrackB) => {
       const idxA = userLangPrefs.findIndex((lang) => textTrackA.language.toLowerCase().startsWith(lang.split('-')[0]));
       const idxB = userLangPrefs.findIndex((lang) => textTrackB.language.toLowerCase().startsWith(lang.split('-')[0]));
       return idxA - idxB;
      });
     if (preferredAvailableSubs[0]) {
      subTrack = preferredAvailableSubs[0];
     }
    }
    const { language, label, kind } = subTrack;
    updateTracksModeTo(TextTrackModes.DISABLED, tracks, showingSubitleTracks);
    updateTracksModeTo(TextTrackModes.SHOWING, tracks, [{ language, label, kind }]);
   }
  };
  const areValuesEq = (x, y) => {
   if (x === y) return true;
   if (x == null || y == null) return false;
   if (typeof x !== typeof y) return false;
   if (typeof x === 'number' && Number.isNaN(x) && Number.isNaN(y)) return true;
   if (typeof x !== 'object') return false;
   if (Array.isArray(x)) return areArraysEq(x, y);
   return Object.entries(x).every(
    // NOTE: Checking key in y to disambiguate between between missing keys and keys whose value are undefined (CJP)
    ([key, value]) => key in y && areValuesEq(value, y[key]),
   );
  };
  const areArraysEq = (xs, ys) => {
   const xIsArray = Array.isArray(xs);
   const yIsArray = Array.isArray(ys);
   if (xIsArray !== yIsArray) return false;
   if (!(xIsArray || yIsArray)) return true;
   if (xs.length !== ys.length) return false;
   return xs.every((x, i) => areValuesEq(x, ys[i]));
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-store/state-mediator.js

  const StreamTypeValues = Object.values(StreamTypes);
  let volumeSupported;
  const volumeSupportPromise = hasVolumeSupportAsync().then((supported) => {
   volumeSupported = supported;
   return volumeSupported;
  });
  const prepareStateOwners = async (...stateOwners) => {
   await Promise.all(
    stateOwners
     .filter((x) => x)
     .map(async (stateOwner) => {
      if (!('localName' in stateOwner && stateOwner instanceof GlobalThis.HTMLElement)) {
       return;
      }
      const name = stateOwner.localName;
      if (!name.includes('-')) return;
      const classDef = GlobalThis.customElements.get(name);
      if (classDef && stateOwner instanceof classDef) return;
      await GlobalThis.customElements.whenDefined(name);
      GlobalThis.customElements.upgrade(stateOwner);
     }),
   );
  };
  const domParser = new GlobalThis.DOMParser();
  const parseHtmlToText = (text) => (text ? domParser.parseFromString(text, 'text/html').body.textContent || text : text);
  const state_mediator_stateMediator = {
   mediaError: {
    get(stateOwners, event) {
     const { media } = stateOwners;
     if ((event == null ? void 0 : event.type) === 'playing') return;
     return media == null ? void 0 : media.error;
    },
    mediaEvents: ['emptied', 'error', 'playing'],
   },
   mediaErrorCode: {
    get(stateOwners, event) {
     var _a;
     const { media } = stateOwners;
     if ((event == null ? void 0 : event.type) === 'playing') return;
     return (_a = media == null ? void 0 : media.error) == null ? void 0 : _a.code;
    },
    mediaEvents: ['emptied', 'error', 'playing'],
   },
   mediaErrorMessage: {
    get(stateOwners, event) {
     var _a, _b;
     const { media } = stateOwners;
     if ((event == null ? void 0 : event.type) === 'playing') return;
     return (_b = (_a = media == null ? void 0 : media.error) == null ? void 0 : _a.message) != null ? _b : '';
    },
    mediaEvents: ['emptied', 'error', 'playing'],
   },
   mediaWidth: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return (_a = media == null ? void 0 : media.videoWidth) != null ? _a : 0;
    },
    mediaEvents: ['resize'],
   },
   mediaHeight: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return (_a = media == null ? void 0 : media.videoHeight) != null ? _a : 0;
    },
    mediaEvents: ['resize'],
   },
   mediaPaused: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return (_a = media == null ? void 0 : media.paused) != null ? _a : true;
    },
    set(value, stateOwners) {
     var _a;
     const { media } = stateOwners;
     if (!media) return;
     if (value) {
      media.pause();
     } else {
      (_a = media.play()) == null ? void 0 : _a.catch(() => {});
     }
    },
    mediaEvents: ['play', 'playing', 'pause', 'emptied'],
   },
   mediaHasPlayed: {
    // We want to let the user know that the media started playing at any point (`media-has-played`).
    // Since these propagators are all called when boostrapping state, let's verify this is
    // a real playing event by checking that 1) there's media and 2) it isn't currently paused.
    get(stateOwners, event) {
     const { media } = stateOwners;
     if (!media) return false;
     if (!event) return !media.paused;
     return event.type === 'playing';
    },
    mediaEvents: ['playing', 'emptied'],
   },
   mediaEnded: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return (_a = media == null ? void 0 : media.ended) != null ? _a : false;
    },
    mediaEvents: ['seeked', 'ended', 'emptied'],
   },
   mediaPlaybackRate: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return (_a = media == null ? void 0 : media.playbackRate) != null ? _a : 1;
    },
    set(value, stateOwners) {
     const { media } = stateOwners;
     if (!media) return;
     if (!Number.isFinite(+value)) return;
     media.playbackRate = +value;
    },
    mediaEvents: ['ratechange', 'loadstart'],
   },
   mediaMuted: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return (_a = media == null ? void 0 : media.muted) != null ? _a : false;
    },
    set(value, stateOwners) {
     const { media } = stateOwners;
     if (!media) return;
     try {
      GlobalThis.localStorage.setItem('media-chrome-pref-muted', value ? 'true' : 'false');
     } catch (e) {
      console.debug('Error setting muted pref', e);
     }
     media.muted = value;
    },
    mediaEvents: ['volumechange'],
    stateOwnersUpdateHandlers: [
     (handler, stateOwners) => {
      const {
       options: { noMutedPref },
      } = stateOwners;
      const { media } = stateOwners;
      if (!media || media.muted || noMutedPref) return;
      try {
       const mutedPref = GlobalThis.localStorage.getItem('media-chrome-pref-muted') === 'true';
       state_mediator_stateMediator.mediaMuted.set(mutedPref, stateOwners);
       handler(mutedPref);
      } catch (e) {
       console.debug('Error getting muted pref', e);
      }
     },
    ],
   },
   mediaVolume: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return (_a = media == null ? void 0 : media.volume) != null ? _a : 1;
    },
    set(value, stateOwners) {
     const { media } = stateOwners;
     if (!media) return;
     try {
      if (value == null) {
       GlobalThis.localStorage.removeItem('media-chrome-pref-volume');
      } else {
       GlobalThis.localStorage.setItem('media-chrome-pref-volume', value.toString());
      }
     } catch (e) {
      console.debug('Error setting volume pref', e);
     }
     if (!Number.isFinite(+value)) return;
     media.volume = +value;
    },
    mediaEvents: ['volumechange'],
    stateOwnersUpdateHandlers: [
     (handler, stateOwners) => {
      const {
       options: { noVolumePref },
      } = stateOwners;
      if (noVolumePref) return;
      try {
       const { media } = stateOwners;
       if (!media) return;
       const volumePref = GlobalThis.localStorage.getItem('media-chrome-pref-volume');
       if (volumePref == null) return;
       state_mediator_stateMediator.mediaVolume.set(+volumePref, stateOwners);
       handler(+volumePref);
      } catch (e) {
       console.debug('Error getting volume pref', e);
      }
     },
    ],
   },
   // NOTE: Keeping this roughly equivalent to prior impl to reduce number of changes,
   // however we may want to model "derived" state differently from "primary" state
   // (in this case, derived === mediaVolumeLevel, primary === mediaMuted, mediaVolume) (CJP)
   mediaVolumeLevel: {
    get(stateOwners) {
     const { media } = stateOwners;
     if (typeof (media == null ? void 0 : media.volume) == 'undefined') return 'high';
     if (media.muted || media.volume === 0) return 'off';
     if (media.volume < 0.5) return 'low';
     if (media.volume < 0.75) return 'medium';
     return 'high';
    },
    mediaEvents: ['volumechange'],
   },
   mediaCurrentTime: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return (_a = media == null ? void 0 : media.currentTime) != null ? _a : 0;
    },
    set(value, stateOwners) {
     const { media } = stateOwners;
     if (!media || !isValidNumber(value)) return;
     media.currentTime = value;
    },
    mediaEvents: ['timeupdate', 'loadedmetadata'],
   },
   mediaDuration: {
    get(stateOwners) {
     const { media, options: { defaultDuration } = {} } = stateOwners;
     if (defaultDuration && (!media || !media.duration || Number.isNaN(media.duration) || !Number.isFinite(media.duration))) {
      return defaultDuration;
     }
     return Number.isFinite(media == null ? void 0 : media.duration) ? media.duration : Number.NaN;
    },
    mediaEvents: ['durationchange', 'loadedmetadata', 'emptied'],
   },
   mediaLoading: {
    get(stateOwners) {
     const { media } = stateOwners;
     return (media == null ? void 0 : media.readyState) < 3;
    },
    mediaEvents: ['waiting', 'playing', 'emptied'],
   },
   mediaSeekable: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     if (!((_a = media == null ? void 0 : media.seekable) == null ? void 0 : _a.length)) return void 0;
     const start = media.seekable.start(0);
     const end = media.seekable.end(media.seekable.length - 1);
     if (!start && !end) return void 0;
     return [Number(start.toFixed(3)), Number(end.toFixed(3))];
    },
    mediaEvents: ['loadedmetadata', 'emptied', 'progress', 'seekablechange'],
   },
   mediaBuffered: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     const timeRanges = (_a = media == null ? void 0 : media.buffered) != null ? _a : [];
     return Array.from(timeRanges).map((_, i) => [Number(timeRanges.start(i).toFixed(3)), Number(timeRanges.end(i).toFixed(3))]);
    },
    mediaEvents: ['progress', 'emptied'],
   },
   mediaStreamType: {
    get(stateOwners) {
     const { media, options: { defaultStreamType } = {} } = stateOwners;
     const usedDefaultStreamType = [StreamTypes.LIVE, StreamTypes.ON_DEMAND].includes(defaultStreamType) ? defaultStreamType : void 0;
     if (!media) return usedDefaultStreamType;
     const { streamType } = media;
     if (StreamTypeValues.includes(streamType)) {
      if (streamType === StreamTypes.UNKNOWN) {
       return usedDefaultStreamType;
      }
      return streamType;
     }
     const duration = media.duration;
     if (duration === Infinity) {
      return StreamTypes.LIVE;
     } else if (Number.isFinite(duration)) {
      return StreamTypes.ON_DEMAND;
     }
     return usedDefaultStreamType;
    },
    mediaEvents: ['emptied', 'durationchange', 'loadedmetadata', 'streamtypechange'],
   },
   mediaTargetLiveWindow: {
    get(stateOwners) {
     const { media } = stateOwners;
     if (!media) return Number.NaN;
     const { targetLiveWindow } = media;
     const streamType = state_mediator_stateMediator.mediaStreamType.get(stateOwners);
     if ((targetLiveWindow == null || Number.isNaN(targetLiveWindow)) && streamType === StreamTypes.LIVE) {
      return 0;
     }
     return targetLiveWindow;
    },
    mediaEvents: ['emptied', 'durationchange', 'loadedmetadata', 'streamtypechange', 'targetlivewindowchange'],
   },
   mediaTimeIsLive: {
    get(stateOwners) {
     const {
      media,
      // Default to 10 seconds
      options: { liveEdgeOffset = 10 } = {},
     } = stateOwners;
     if (!media) return false;
     if (typeof media.liveEdgeStart === 'number') {
      if (Number.isNaN(media.liveEdgeStart)) return false;
      return media.currentTime >= media.liveEdgeStart;
     }
     const live = state_mediator_stateMediator.mediaStreamType.get(stateOwners) === StreamTypes.LIVE;
     if (!live) return false;
     const seekable = media.seekable;
     if (!seekable) return true;
     if (!seekable.length) return false;
     const liveEdgeStart = seekable.end(seekable.length - 1) - liveEdgeOffset;
     return media.currentTime >= liveEdgeStart;
    },
    mediaEvents: ['playing', 'timeupdate', 'progress', 'waiting', 'emptied'],
   },
   // Text Tracks modeling
   mediaSubtitlesList: {
    get(stateOwners) {
     return getSubtitleTracks(stateOwners).map(({ kind, label, language }) => ({ kind, label, language }));
    },
    mediaEvents: ['loadstart'],
    textTracksEvents: ['addtrack', 'removetrack'],
   },
   mediaSubtitlesShowing: {
    get(stateOwners) {
     return getShowingSubtitleTracks(stateOwners).map(({ kind, label, language }) => ({ kind, label, language }));
    },
    mediaEvents: ['loadstart'],
    textTracksEvents: ['addtrack', 'removetrack', 'change'],
    stateOwnersUpdateHandlers: [
     (_handler, stateOwners) => {
      var _a, _b;
      const { media, options } = stateOwners;
      if (!media) return;
      const updateDefaultSubtitlesCallback = (event) => {
       var _a2;
       if (!options.defaultSubtitles) return;
       const nonSubsEvent =
        event &&
        ![TextTrackKinds.CAPTIONS, TextTrackKinds.SUBTITLES].includes(
         // @ts-ignore
         (_a2 = event == null ? void 0 : event.track) == null ? void 0 : _a2.kind,
        );
       if (nonSubsEvent) return;
       toggleSubtitleTracks(stateOwners, true);
      };
      media.addEventListener('loadstart', updateDefaultSubtitlesCallback);
      (_a = media.textTracks) == null ? void 0 : _a.addEventListener('addtrack', updateDefaultSubtitlesCallback);
      (_b = media.textTracks) == null ? void 0 : _b.addEventListener('removetrack', updateDefaultSubtitlesCallback);
      return () => {
       var _a2, _b2;
       media.removeEventListener('loadstart', updateDefaultSubtitlesCallback);
       (_a2 = media.textTracks) == null ? void 0 : _a2.removeEventListener('addtrack', updateDefaultSubtitlesCallback);
       (_b2 = media.textTracks) == null ? void 0 : _b2.removeEventListener('removetrack', updateDefaultSubtitlesCallback);
      };
     },
    ],
   },
   mediaChaptersCues: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     if (!media) return [];
     const [chaptersTrack] = getTextTracksList(media, {
      kind: TextTrackKinds.CHAPTERS,
     });
     return Array.from((_a = chaptersTrack == null ? void 0 : chaptersTrack.cues) != null ? _a : []).map(({ text, startTime, endTime }) => ({
      text: parseHtmlToText(text),
      startTime,
      endTime,
     }));
    },
    mediaEvents: ['loadstart', 'loadedmetadata'],
    textTracksEvents: ['addtrack', 'removetrack', 'change'],
    stateOwnersUpdateHandlers: [
     (handler, stateOwners) => {
      var _a;
      const { media } = stateOwners;
      if (!media) return;
      const chaptersTrack = media.querySelector('track[kind="chapters"][default][src]');
      const shadowChaptersTrack = (_a = media.shadowRoot) == null ? void 0 : _a.querySelector(':is(video,audio) > track[kind="chapters"][default][src]');
      chaptersTrack == null ? void 0 : chaptersTrack.addEventListener('load', handler);
      shadowChaptersTrack == null ? void 0 : shadowChaptersTrack.addEventListener('load', handler);
      return () => {
       chaptersTrack == null ? void 0 : chaptersTrack.removeEventListener('load', handler);
       shadowChaptersTrack == null ? void 0 : shadowChaptersTrack.removeEventListener('load', handler);
      };
     },
    ],
   },
   // Modeling state tied to root node
   mediaIsPip: {
    get(stateOwners) {
     var _a, _b;
     const { media, documentElement } = stateOwners;
     if (!media || !documentElement) return false;
     if (!documentElement.pictureInPictureElement) return false;
     if (documentElement.pictureInPictureElement === media) return true;
     if (documentElement.pictureInPictureElement instanceof HTMLMediaElement) {
      if (!((_a = media.localName) == null ? void 0 : _a.includes('-'))) return false;
      return containsComposedNode(media, documentElement.pictureInPictureElement);
     }
     if (documentElement.pictureInPictureElement.localName.includes('-')) {
      let currentRoot = documentElement.pictureInPictureElement.shadowRoot;
      while (currentRoot == null ? void 0 : currentRoot.pictureInPictureElement) {
       if (currentRoot.pictureInPictureElement === media) return true;
       currentRoot = (_b = currentRoot.pictureInPictureElement) == null ? void 0 : _b.shadowRoot;
      }
     }
     return false;
    },
    set(value, stateOwners) {
     const { media } = stateOwners;
     if (!media) return;
     if (value) {
      if (!server_safe_globals_Document.pictureInPictureEnabled) {
       console.warn('MediaChrome: Picture-in-picture is not enabled');
       return;
      }
      if (!media.requestPictureInPicture) {
       console.warn('MediaChrome: The current media does not support picture-in-picture');
       return;
      }
      const warnNotReady = () => {
       console.warn('MediaChrome: The media is not ready for picture-in-picture. It must have a readyState > 0.');
      };
      media.requestPictureInPicture().catch((err) => {
       if (err.code === 11) {
        if (!media.src) {
         console.warn('MediaChrome: The media is not ready for picture-in-picture. It must have a src set.');
         return;
        }
        if (media.readyState === 0 && media.preload === 'none') {
         const cleanup = () => {
          media.removeEventListener('loadedmetadata', tryPip);
          media.preload = 'none';
         };
         const tryPip = () => {
          media.requestPictureInPicture().catch(warnNotReady);
          cleanup();
         };
         media.addEventListener('loadedmetadata', tryPip);
         media.preload = 'metadata';
         setTimeout(() => {
          if (media.readyState === 0) warnNotReady();
          cleanup();
         }, 1e3);
        } else {
         throw err;
        }
       } else {
        throw err;
       }
      });
     } else if (server_safe_globals_Document.pictureInPictureElement) {
      server_safe_globals_Document.exitPictureInPicture();
     }
    },
    mediaEvents: ['enterpictureinpicture', 'leavepictureinpicture'],
   },
   mediaRenditionList: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return [...((_a = media == null ? void 0 : media.videoRenditions) != null ? _a : [])].map((videoRendition) => ({
      ...videoRendition,
     }));
    },
    mediaEvents: ['emptied', 'loadstart'],
    videoRenditionsEvents: ['addrendition', 'removerendition'],
   },
   /** @TODO Model this as a derived value? (CJP) */
   mediaRenditionSelected: {
    get(stateOwners) {
     var _a, _b, _c;
     const { media } = stateOwners;
     return (_c = (_b = media == null ? void 0 : media.videoRenditions) == null ? void 0 : _b[(_a = media.videoRenditions) == null ? void 0 : _a.selectedIndex]) == null ? void 0 : _c.id;
    },
    set(value, stateOwners) {
     const { media } = stateOwners;
     if (!(media == null ? void 0 : media.videoRenditions)) {
      console.warn('MediaController: Rendition selection not supported by this media.');
      return;
     }
     const renditionId = value;
     const index = Array.prototype.findIndex.call(media.videoRenditions, (r) => r.id == renditionId);
     if (media.videoRenditions.selectedIndex != index) {
      media.videoRenditions.selectedIndex = index;
     }
    },
    mediaEvents: ['emptied'],
    videoRenditionsEvents: ['addrendition', 'removerendition', 'change'],
   },
   mediaAudioTrackList: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     return [...((_a = media == null ? void 0 : media.audioTracks) != null ? _a : [])];
    },
    mediaEvents: ['emptied', 'loadstart'],
    audioTracksEvents: ['addtrack', 'removetrack'],
   },
   mediaAudioTrackEnabled: {
    get(stateOwners) {
     var _a, _b;
     const { media } = stateOwners;
     return (_b = [...((_a = media == null ? void 0 : media.audioTracks) != null ? _a : [])].find((audioTrack) => audioTrack.enabled)) == null ? void 0 : _b.id;
    },
    set(value, stateOwners) {
     const { media } = stateOwners;
     if (!(media == null ? void 0 : media.audioTracks)) {
      console.warn('MediaChrome: Audio track selection not supported by this media.');
      return;
     }
     const audioTrackId = value;
     for (const track of media.audioTracks) {
      track.enabled = audioTrackId == track.id;
     }
    },
    mediaEvents: ['emptied'],
    audioTracksEvents: ['addtrack', 'removetrack', 'change'],
   },
   mediaIsFullscreen: {
    get(stateOwners) {
     return isFullscreen(stateOwners);
    },
    set(value, stateOwners) {
     if (!value) {
      exitFullscreen(stateOwners);
     } else {
      enterFullscreen(stateOwners);
     }
    },
    // older Safari version may require webkit-specific events
    rootEvents: ['fullscreenchange', 'webkitfullscreenchange'],
    // iOS requires webkit-specific events on the video.
    mediaEvents: ['webkitbeginfullscreen', 'webkitendfullscreen', 'webkitpresentationmodechanged'],
   },
   mediaIsCasting: {
    // Note this relies on a customized castable-video element.
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     if (!(media == null ? void 0 : media.remote) || ((_a = media.remote) == null ? void 0 : _a.state) === 'disconnected') return false;
     return !!media.remote.state;
    },
    set(value, stateOwners) {
     var _a, _b;
     const { media } = stateOwners;
     if (!media) return;
     if (value && ((_a = media.remote) == null ? void 0 : _a.state) !== 'disconnected') return;
     if (!value && ((_b = media.remote) == null ? void 0 : _b.state) !== 'connected') return;
     if (typeof media.remote.prompt !== 'function') {
      console.warn('MediaChrome: Casting is not supported in this environment');
      return;
     }
     media.remote.prompt().catch(() => {});
    },
    remoteEvents: ['connect', 'connecting', 'disconnect'],
   },
   // NOTE: Newly added state for tracking airplaying
   mediaIsAirplaying: {
    // NOTE: Cannot know if airplaying since Safari doesn't fully support HTMLMediaElement::remote yet (e.g. remote::state) (CJP)
    get() {
     return false;
    },
    set(_value, stateOwners) {
     const { media } = stateOwners;
     if (!media) return;
     if (!(media.webkitShowPlaybackTargetPicker && GlobalThis.WebKitPlaybackTargetAvailabilityEvent)) {
      console.error('MediaChrome: received a request to select AirPlay but AirPlay is not supported in this environment');
      return;
     }
     media.webkitShowPlaybackTargetPicker();
    },
    mediaEvents: ['webkitcurrentplaybacktargetiswirelesschanged'],
   },
   mediaFullscreenUnavailable: {
    get(stateOwners) {
     const { media } = stateOwners;
     if (!fullscreenSupported || !hasFullscreenSupport(media)) return AvailabilityStates.UNSUPPORTED;
     return void 0;
    },
   },
   mediaPipUnavailable: {
    get(stateOwners) {
     const { media } = stateOwners;
     if (!pipSupported || !hasPipSupport(media)) return AvailabilityStates.UNSUPPORTED;
    },
   },
   mediaVolumeUnavailable: {
    get(stateOwners) {
     const { media } = stateOwners;
     if (volumeSupported === false || (media == null ? void 0 : media.volume) == void 0) {
      return AvailabilityStates.UNSUPPORTED;
     }
     return void 0;
    },
    // NOTE: Slightly different impl here. Added generic support for
    // "stateOwnersUpdateHandlers" since the original impl had to hack around
    // race conditions. (CJP)
    stateOwnersUpdateHandlers: [
     (handler) => {
      if (volumeSupported == null) {
       volumeSupportPromise.then((supported) => handler(supported ? void 0 : AvailabilityStates.UNSUPPORTED));
      }
     },
    ],
   },
   mediaCastUnavailable: {
    // @ts-ignore
    get(stateOwners, { availability = 'not-available' } = {}) {
     var _a;
     const { media } = stateOwners;
     if (!castSupported || !((_a = media == null ? void 0 : media.remote) == null ? void 0 : _a.state)) {
      return AvailabilityStates.UNSUPPORTED;
     }
     if (availability == null || availability === 'available') return void 0;
     return AvailabilityStates.UNAVAILABLE;
    },
    stateOwnersUpdateHandlers: [
     (handler, stateOwners) => {
      var _a;
      const { media } = stateOwners;
      if (!media) return;
      const remotePlaybackDisabled = media.disableRemotePlayback || media.hasAttribute('disableremoteplayback');
      if (!remotePlaybackDisabled) {
       (_a = media == null ? void 0 : media.remote) == null
        ? void 0
        : _a
           .watchAvailability((availabilityBool) => {
            const availability = availabilityBool ? 'available' : 'not-available';
            handler({ availability });
           })
           .catch((error) => {
            if (error.name === 'NotSupportedError') {
             handler({ availability: null });
            } else {
             handler({ availability: 'not-available' });
            }
           });
      }
      return () => {
       var _a2;
       (_a2 = media == null ? void 0 : media.remote) == null ? void 0 : _a2.cancelWatchAvailability().catch(() => {});
      };
     },
    ],
   },
   mediaAirplayUnavailable: {
    get(_stateOwners, event) {
     if (!airplaySupported) return AvailabilityStates.UNSUPPORTED;
     if ((event == null ? void 0 : event.availability) === 'not-available') {
      return AvailabilityStates.UNAVAILABLE;
     }
     return void 0;
    },
    // NOTE: Keeping this event, as it's still the documented way of monitoring
    // for AirPlay availability from Apple.
    // See: https://developer.apple.com/documentation/webkitjs/adding_an_airplay_button_to_your_safari_media_controls#2940021 (CJP)
    mediaEvents: ['webkitplaybacktargetavailabilitychanged'],
    stateOwnersUpdateHandlers: [
     (handler, stateOwners) => {
      var _a;
      const { media } = stateOwners;
      if (!media) return;
      const remotePlaybackDisabled = media.disableRemotePlayback || media.hasAttribute('disableremoteplayback');
      if (!remotePlaybackDisabled) {
       (_a = media == null ? void 0 : media.remote) == null
        ? void 0
        : _a
           .watchAvailability((availabilityBool) => {
            const availability = availabilityBool ? 'available' : 'not-available';
            handler({ availability });
           })
           .catch((error) => {
            if (error.name === 'NotSupportedError') {
             handler({ availability: null });
            } else {
             handler({ availability: 'not-available' });
            }
           });
      }
      return () => {
       var _a2;
       (_a2 = media == null ? void 0 : media.remote) == null ? void 0 : _a2.cancelWatchAvailability().catch(() => {});
      };
     },
    ],
   },
   mediaRenditionUnavailable: {
    get(stateOwners) {
     var _a;
     const { media } = stateOwners;
     if (!(media == null ? void 0 : media.videoRenditions)) {
      return AvailabilityStates.UNSUPPORTED;
     }
     if (!((_a = media.videoRenditions) == null ? void 0 : _a.length)) {
      return AvailabilityStates.UNAVAILABLE;
     }
     return void 0;
    },
    mediaEvents: ['emptied', 'loadstart'],
    videoRenditionsEvents: ['addrendition', 'removerendition'],
   },
   mediaAudioTrackUnavailable: {
    get(stateOwners) {
     var _a, _b;
     const { media } = stateOwners;
     if (!(media == null ? void 0 : media.audioTracks)) {
      return AvailabilityStates.UNSUPPORTED;
     }
     if (((_b = (_a = media.audioTracks) == null ? void 0 : _a.length) != null ? _b : 0) <= 1) {
      return AvailabilityStates.UNAVAILABLE;
     }
     return void 0;
    },
    mediaEvents: ['emptied', 'loadstart'],
    audioTracksEvents: ['addtrack', 'removetrack'],
   },
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-store/request-map.js

  const request_map_requestMap = {
   /**
    * @TODO Consider adding state to `StateMediator` for e.g. `mediaThumbnailCues` and use that for derived state here (CJP)
    */
   [MediaUIEvents.MEDIA_PREVIEW_REQUEST](stateMediator, stateOwners, { detail }) {
    var _a, _b, _c;
    const { media } = stateOwners;
    const mediaPreviewTime = detail != null ? detail : void 0;
    let mediaPreviewImage = void 0;
    let mediaPreviewCoords = void 0;
    if (media && mediaPreviewTime != null) {
     const [track] = getTextTracksList(media, {
      kind: TextTrackKinds.METADATA,
      label: 'thumbnails',
     });
     const cue = Array.prototype.find.call((_a = track == null ? void 0 : track.cues) != null ? _a : [], (c, i, cs) => {
      if (i === 0) return c.endTime > mediaPreviewTime;
      if (i === cs.length - 1) return c.startTime <= mediaPreviewTime;
      return c.startTime <= mediaPreviewTime && c.endTime > mediaPreviewTime;
     });
     if (cue) {
      const base = !/'^(?:[a-z]+:)?\/\//i.test(cue.text) ? ((_b = media == null ? void 0 : media.querySelector('track[label="thumbnails"]')) == null ? void 0 : _b.src) : void 0;
      const url = new URL(cue.text, base);
      const previewCoordsStr = new URLSearchParams(url.hash).get('#xywh');
      mediaPreviewCoords = previewCoordsStr.split(',').map((numStr) => +numStr);
      mediaPreviewImage = url.href;
     }
    }
    const mediaDuration = stateMediator.mediaDuration.get(stateOwners);
    const mediaChaptersCues = stateMediator.mediaChaptersCues.get(stateOwners);
    let mediaPreviewChapter =
     (_c = mediaChaptersCues.find((c, i, cs) => {
      if (i === cs.length - 1 && mediaDuration === c.endTime) {
       return c.startTime <= mediaPreviewTime && c.endTime >= mediaPreviewTime;
      }
      return c.startTime <= mediaPreviewTime && c.endTime > mediaPreviewTime;
     })) == null
      ? void 0
      : _c.text;
    if (detail != null && mediaPreviewChapter == null) {
     mediaPreviewChapter = '';
    }
    return {
     mediaPreviewTime,
     mediaPreviewImage,
     mediaPreviewCoords,
     mediaPreviewChapter,
    };
   },
   [MediaUIEvents.MEDIA_PAUSE_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaPaused';
    const value = true;
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_PLAY_REQUEST](stateMediator, stateOwners) {
    var _a, _b, _c, _d;
    const key = 'mediaPaused';
    const value = false;
    const isLive = stateMediator.mediaStreamType.get(stateOwners) === StreamTypes.LIVE;
    const canAutoSeekToLive = !((_a = stateOwners.options) == null ? void 0 : _a.noAutoSeekToLive);
    const isDVR = stateMediator.mediaTargetLiveWindow.get(stateOwners) > 0;
    if (isLive && canAutoSeekToLive && !isDVR) {
     const seekableEnd = (_b = stateMediator.mediaSeekable.get(stateOwners)) == null ? void 0 : _b[1];
     if (seekableEnd) {
      const seekToLiveOffset = (_d = (_c = stateOwners.options) == null ? void 0 : _c.seekToLiveOffset) != null ? _d : 0;
      const liveEdgeTime = seekableEnd - seekToLiveOffset;
      stateMediator.mediaCurrentTime.set(liveEdgeTime, stateOwners);
     }
    }
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_PLAYBACK_RATE_REQUEST](stateMediator, stateOwners, { detail }) {
    const key = 'mediaPlaybackRate';
    const value = detail;
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_MUTE_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaMuted';
    const value = true;
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_UNMUTE_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaMuted';
    const value = false;
    if (!stateMediator.mediaVolume.get(stateOwners)) {
     stateMediator.mediaVolume.set(0.25, stateOwners);
    }
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_VOLUME_REQUEST](stateMediator, stateOwners, { detail }) {
    const key = 'mediaVolume';
    const value = detail;
    if (value && stateMediator.mediaMuted.get(stateOwners)) {
     stateMediator.mediaMuted.set(false, stateOwners);
    }
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_SEEK_REQUEST](stateMediator, stateOwners, { detail }) {
    const key = 'mediaCurrentTime';
    const value = detail;
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_SEEK_TO_LIVE_REQUEST](stateMediator, stateOwners) {
    var _a, _b, _c;
    const key = 'mediaCurrentTime';
    const seekableEnd = (_a = stateMediator.mediaSeekable.get(stateOwners)) == null ? void 0 : _a[1];
    if (Number.isNaN(Number(seekableEnd))) return;
    const seekToLiveOffset = (_c = (_b = stateOwners.options) == null ? void 0 : _b.seekToLiveOffset) != null ? _c : 0;
    const value = seekableEnd - seekToLiveOffset;
    stateMediator[key].set(value, stateOwners);
   },
   // Text Tracks state change requests
   [MediaUIEvents.MEDIA_SHOW_SUBTITLES_REQUEST](_stateMediator, stateOwners, { detail }) {
    var _a;
    const { options } = stateOwners;
    const tracks = getSubtitleTracks(stateOwners);
    const tracksToUpdate = parseTracks(detail);
    const preferredLanguage = (_a = tracksToUpdate[0]) == null ? void 0 : _a.language;
    if (preferredLanguage && !options.noSubtitlesLangPref) {
     GlobalThis.localStorage.setItem('media-chrome-pref-subtitles-lang', preferredLanguage);
    }
    updateTracksModeTo(TextTrackModes.SHOWING, tracks, tracksToUpdate);
   },
   [MediaUIEvents.MEDIA_DISABLE_SUBTITLES_REQUEST](_stateMediator, stateOwners, { detail }) {
    const tracks = getSubtitleTracks(stateOwners);
    const tracksToUpdate = detail != null ? detail : [];
    updateTracksModeTo(TextTrackModes.DISABLED, tracks, tracksToUpdate);
   },
   [MediaUIEvents.MEDIA_TOGGLE_SUBTITLES_REQUEST](_stateMediator, stateOwners, { detail }) {
    toggleSubtitleTracks(stateOwners, detail);
   },
   // Renditions/Tracks state change requests
   [MediaUIEvents.MEDIA_RENDITION_REQUEST](stateMediator, stateOwners, { detail }) {
    const key = 'mediaRenditionSelected';
    const value = detail;
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_AUDIO_TRACK_REQUEST](stateMediator, stateOwners, { detail }) {
    const key = 'mediaAudioTrackEnabled';
    const value = detail;
    stateMediator[key].set(value, stateOwners);
   },
   // State change requests dependent on root node
   [MediaUIEvents.MEDIA_ENTER_PIP_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaIsPip';
    const value = true;
    if (stateMediator.mediaIsFullscreen.get(stateOwners)) {
     stateMediator.mediaIsFullscreen.set(false, stateOwners);
    }
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_EXIT_PIP_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaIsPip';
    const value = false;
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_ENTER_FULLSCREEN_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaIsFullscreen';
    const value = true;
    if (stateMediator.mediaIsPip.get(stateOwners)) {
     stateMediator.mediaIsPip.set(false, stateOwners);
    }
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_EXIT_FULLSCREEN_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaIsFullscreen';
    const value = false;
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_ENTER_CAST_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaIsCasting';
    const value = true;
    if (stateMediator.mediaIsFullscreen.get(stateOwners)) {
     stateMediator.mediaIsFullscreen.set(false, stateOwners);
    }
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_EXIT_CAST_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaIsCasting';
    const value = false;
    stateMediator[key].set(value, stateOwners);
   },
   [MediaUIEvents.MEDIA_AIRPLAY_REQUEST](stateMediator, stateOwners) {
    const key = 'mediaIsAirplaying';
    const value = true;
    stateMediator[key].set(value, stateOwners);
   },
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-store/media-store.js

  const createMediaStore = ({ media, fullscreenElement, documentElement, stateMediator = state_mediator_stateMediator, requestMap = request_map_requestMap, options = {}, monitorStateOwnersOnlyWithSubscriptions = true }) => {
   const callbacks = [];
   const stateOwners = {
    // Spreading options here since folks should not rely on holding onto references
    // for any app-level logic wrt options.
    options: { ...options },
   };
   let state = Object.freeze({
    mediaPreviewTime: void 0,
    mediaPreviewImage: void 0,
    mediaPreviewCoords: void 0,
    mediaPreviewChapter: void 0,
   });
   const updateState = (nextStateDelta) => {
    if (nextStateDelta == void 0) return;
    if (areValuesEq(nextStateDelta, state)) {
     return;
    }
    state = Object.freeze({
     ...state,
     ...nextStateDelta,
    });
    callbacks.forEach((cb) => cb(state));
   };
   const updateStateFromFacade = () => {
    const nextState = Object.entries(stateMediator).reduce((nextState2, [stateName, { get }]) => {
     nextState2[stateName] = get(stateOwners);
     return nextState2;
    }, {});
    updateState(nextState);
   };
   const stateUpdateHandlers = {};
   let nextStateOwners = void 0;
   const updateStateOwners = async (nextStateOwnersDelta, nextSubscriberCount) => {
    var _a, _b, _c, _d, _e, _f, _g, _h, _i, _j, _k, _l, _m, _n, _o, _p;
    const pendingUpdate = !!nextStateOwners;
    nextStateOwners = {
     ...stateOwners,
     ...(nextStateOwners != null ? nextStateOwners : {}),
     ...nextStateOwnersDelta,
    };
    if (pendingUpdate) return;
    await prepareStateOwners(...Object.values(nextStateOwnersDelta));
    const shouldTeardownFromSubscriberCount = callbacks.length > 0 && nextSubscriberCount === 0 && monitorStateOwnersOnlyWithSubscriptions;
    const mediaChanged = stateOwners.media !== nextStateOwners.media;
    const textTracksChanged = ((_a = stateOwners.media) == null ? void 0 : _a.textTracks) !== ((_b = nextStateOwners.media) == null ? void 0 : _b.textTracks);
    const videoRenditionsChanged = ((_c = stateOwners.media) == null ? void 0 : _c.videoRenditions) !== ((_d = nextStateOwners.media) == null ? void 0 : _d.videoRenditions);
    const audioTracksChanged = ((_e = stateOwners.media) == null ? void 0 : _e.audioTracks) !== ((_f = nextStateOwners.media) == null ? void 0 : _f.audioTracks);
    const remoteChanged = ((_g = stateOwners.media) == null ? void 0 : _g.remote) !== ((_h = nextStateOwners.media) == null ? void 0 : _h.remote);
    const rootNodeChanged = stateOwners.documentElement !== nextStateOwners.documentElement;
    const teardownMedia = !!stateOwners.media && (mediaChanged || shouldTeardownFromSubscriberCount);
    const teardownTextTracks = !!((_i = stateOwners.media) == null ? void 0 : _i.textTracks) && (textTracksChanged || shouldTeardownFromSubscriberCount);
    const teardownVideoRenditions = !!((_j = stateOwners.media) == null ? void 0 : _j.videoRenditions) && (videoRenditionsChanged || shouldTeardownFromSubscriberCount);
    const teardownAudioTracks = !!((_k = stateOwners.media) == null ? void 0 : _k.audioTracks) && (audioTracksChanged || shouldTeardownFromSubscriberCount);
    const teardownRemote = !!((_l = stateOwners.media) == null ? void 0 : _l.remote) && (remoteChanged || shouldTeardownFromSubscriberCount);
    const teardownRootNode = !!stateOwners.documentElement && (rootNodeChanged || shouldTeardownFromSubscriberCount);
    const teardownSomething = teardownMedia || teardownTextTracks || teardownVideoRenditions || teardownAudioTracks || teardownRemote || teardownRootNode;
    const shouldSetupFromSubscriberCount = callbacks.length === 0 && nextSubscriberCount === 1 && monitorStateOwnersOnlyWithSubscriptions;
    const setupMedia = !!nextStateOwners.media && (mediaChanged || shouldSetupFromSubscriberCount);
    const setupTextTracks = !!((_m = nextStateOwners.media) == null ? void 0 : _m.textTracks) && (textTracksChanged || shouldSetupFromSubscriberCount);
    const setupVideoRenditions = !!((_n = nextStateOwners.media) == null ? void 0 : _n.videoRenditions) && (videoRenditionsChanged || shouldSetupFromSubscriberCount);
    const setupAudioTracks = !!((_o = nextStateOwners.media) == null ? void 0 : _o.audioTracks) && (audioTracksChanged || shouldSetupFromSubscriberCount);
    const setupRemote = !!((_p = nextStateOwners.media) == null ? void 0 : _p.remote) && (remoteChanged || shouldSetupFromSubscriberCount);
    const setupRootNode = !!nextStateOwners.documentElement && (rootNodeChanged || shouldSetupFromSubscriberCount);
    const setupSomething = setupMedia || setupTextTracks || setupVideoRenditions || setupAudioTracks || setupRemote || setupRootNode;
    const somethingToDo = teardownSomething || setupSomething;
    if (!somethingToDo) {
     Object.entries(nextStateOwners).forEach(([stateOwnerName, stateOwner]) => {
      stateOwners[stateOwnerName] = stateOwner;
     });
     updateStateFromFacade();
     nextStateOwners = void 0;
     return;
    }
    Object.entries(stateMediator).forEach(([stateName, { get, mediaEvents = [], textTracksEvents = [], videoRenditionsEvents = [], audioTracksEvents = [], remoteEvents = [], rootEvents = [], stateOwnersUpdateHandlers = [] }]) => {
     if (!stateUpdateHandlers[stateName]) {
      stateUpdateHandlers[stateName] = {};
     }
     const handler = (event) => {
      const nextValue = get(stateOwners, event);
      updateState({ [stateName]: nextValue });
     };
     let prevHandler;
     prevHandler = stateUpdateHandlers[stateName].mediaEvents;
     mediaEvents.forEach((eventType) => {
      if (prevHandler && teardownMedia) {
       stateOwners.media.removeEventListener(eventType, prevHandler);
       stateUpdateHandlers[stateName].mediaEvents = void 0;
      }
      if (setupMedia) {
       nextStateOwners.media.addEventListener(eventType, handler);
       stateUpdateHandlers[stateName].mediaEvents = handler;
      }
     });
     prevHandler = stateUpdateHandlers[stateName].textTracksEvents;
     textTracksEvents.forEach((eventType) => {
      var _a2, _b2;
      if (prevHandler && teardownTextTracks) {
       (_a2 = stateOwners.media.textTracks) == null ? void 0 : _a2.removeEventListener(eventType, prevHandler);
       stateUpdateHandlers[stateName].textTracksEvents = void 0;
      }
      if (setupTextTracks) {
       (_b2 = nextStateOwners.media.textTracks) == null ? void 0 : _b2.addEventListener(eventType, handler);
       stateUpdateHandlers[stateName].textTracksEvents = handler;
      }
     });
     prevHandler = stateUpdateHandlers[stateName].videoRenditionsEvents;
     videoRenditionsEvents.forEach((eventType) => {
      var _a2, _b2;
      if (prevHandler && teardownVideoRenditions) {
       (_a2 = stateOwners.media.videoRenditions) == null ? void 0 : _a2.removeEventListener(eventType, prevHandler);
       stateUpdateHandlers[stateName].videoRenditionsEvents = void 0;
      }
      if (setupVideoRenditions) {
       (_b2 = nextStateOwners.media.videoRenditions) == null ? void 0 : _b2.addEventListener(eventType, handler);
       stateUpdateHandlers[stateName].videoRenditionsEvents = handler;
      }
     });
     prevHandler = stateUpdateHandlers[stateName].audioTracksEvents;
     audioTracksEvents.forEach((eventType) => {
      var _a2, _b2;
      if (prevHandler && teardownAudioTracks) {
       (_a2 = stateOwners.media.audioTracks) == null ? void 0 : _a2.removeEventListener(eventType, prevHandler);
       stateUpdateHandlers[stateName].audioTracksEvents = void 0;
      }
      if (setupAudioTracks) {
       (_b2 = nextStateOwners.media.audioTracks) == null ? void 0 : _b2.addEventListener(eventType, handler);
       stateUpdateHandlers[stateName].audioTracksEvents = handler;
      }
     });
     prevHandler = stateUpdateHandlers[stateName].remoteEvents;
     remoteEvents.forEach((eventType) => {
      var _a2, _b2;
      if (prevHandler && teardownRemote) {
       (_a2 = stateOwners.media.remote) == null ? void 0 : _a2.removeEventListener(eventType, prevHandler);
       stateUpdateHandlers[stateName].remoteEvents = void 0;
      }
      if (setupRemote) {
       (_b2 = nextStateOwners.media.remote) == null ? void 0 : _b2.addEventListener(eventType, handler);
       stateUpdateHandlers[stateName].remoteEvents = handler;
      }
     });
     prevHandler = stateUpdateHandlers[stateName].rootEvents;
     rootEvents.forEach((eventType) => {
      if (prevHandler && teardownRootNode) {
       stateOwners.documentElement.removeEventListener(eventType, prevHandler);
       stateUpdateHandlers[stateName].rootEvents = void 0;
      }
      if (setupRootNode) {
       nextStateOwners.documentElement.addEventListener(eventType, handler);
       stateUpdateHandlers[stateName].rootEvents = handler;
      }
     });
     const prevHandlerTeardown = stateUpdateHandlers[stateName].stateOwnersUpdateHandlers;
     stateOwnersUpdateHandlers.forEach((fn) => {
      if (prevHandlerTeardown && teardownSomething) {
       prevHandlerTeardown();
      }
      if (setupSomething) {
       stateUpdateHandlers[stateName].stateOwnersUpdateHandlers = fn(handler, nextStateOwners);
      }
     });
    });
    Object.entries(nextStateOwners).forEach(([stateOwnerName, stateOwner]) => {
     stateOwners[stateOwnerName] = stateOwner;
    });
    updateStateFromFacade();
    nextStateOwners = void 0;
   };
   updateStateOwners({ media, fullscreenElement, documentElement, options });
   return {
    // note that none of these cases directly interact with the media element, root node, full screen element, etc.
    // note these "actions" could just be the events if we wanted, especially if we normalize on "detail" for
    // any payload-relevant values
    // This is roughly equivalent to our used to be in our state requests dictionary object, though much of the
    // "heavy lifting" is now moved into the facade `set()`
    dispatch(action) {
     const { type, detail } = action;
     if (requestMap[type] && state.mediaErrorCode == null) {
      updateState(requestMap[type](stateMediator, stateOwners, action));
      return;
     }
     if (type === 'mediaelementchangerequest') {
      updateStateOwners({ media: detail });
     } else if (type === 'fullscreenelementchangerequest') {
      updateStateOwners({ fullscreenElement: detail });
     } else if (type === 'documentelementchangerequest') {
      updateStateOwners({ documentElement: detail });
     } else if (type === 'optionschangerequest') {
      Object.entries(detail != null ? detail : {}).forEach(([optionName, optionValue]) => {
       stateOwners.options[optionName] = optionValue;
      });
     }
    },
    getState() {
     return state;
    },
    subscribe(callback) {
     updateStateOwners({}, callbacks.length + 1);
     callbacks.push(callback);
     callback(state);
     return () => {
      const idx = callbacks.indexOf(callback);
      if (idx >= 0) {
       updateStateOwners({}, callbacks.length - 1);
       callbacks.splice(idx, 1);
      }
     };
    },
   };
  };
  var media_store_default = /* unused pure expression or super */ null && createMediaStore; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-controller.js

  var media_controller_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_controller_privateGet = (obj, member, getter) => {
   media_controller_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_controller_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_controller_privateSet = (obj, member, value, setter) => {
   media_controller_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_controller_privateMethod = (obj, member, method) => {
   media_controller_accessCheck(obj, member, 'access private method');
   return method;
  };
  var _hotKeys, _fullscreenElement, _mediaStore, _mediaStateCallback, _mediaStoreUnsubscribe, _mediaStateEventHandler, _setupDefaultStore, setupDefaultStore_fn, _keyUpHandler, keyUpHandler_fn, _keyDownHandler, keyDownHandler_fn;

  const ButtonPressedKeys = ['ArrowLeft', 'ArrowRight', 'Enter', ' ', 'f', 'm', 'k', 'c'];
  const DEFAULT_SEEK_OFFSET = 10;
  const media_controller_Attributes = {
   DEFAULT_SUBTITLES: 'defaultsubtitles',
   DEFAULT_STREAM_TYPE: 'defaultstreamtype',
   DEFAULT_DURATION: 'defaultduration',
   FULLSCREEN_ELEMENT: 'fullscreenelement',
   HOTKEYS: 'hotkeys',
   KEYS_USED: 'keysused',
   LIVE_EDGE_OFFSET: 'liveedgeoffset',
   SEEK_TO_LIVE_OFFSET: 'seektoliveoffset',
   NO_AUTO_SEEK_TO_LIVE: 'noautoseektolive',
   NO_HOTKEYS: 'nohotkeys',
   NO_VOLUME_PREF: 'novolumepref',
   NO_SUBTITLES_LANG_PREF: 'nosubtitleslangpref',
   NO_DEFAULT_STORE: 'nodefaultstore',
   KEYBOARD_FORWARD_SEEK_OFFSET: 'keyboardforwardseekoffset',
   KEYBOARD_BACKWARD_SEEK_OFFSET: 'keyboardbackwardseekoffset',
   LANG: 'lang',
  };
  class MediaController extends MediaContainer {
   constructor() {
    super();
    media_controller_privateAdd(this, _setupDefaultStore);
    media_controller_privateAdd(this, _keyUpHandler);
    media_controller_privateAdd(this, _keyDownHandler);
    this.mediaStateReceivers = [];
    this.associatedElementSubscriptions = /* @__PURE__ */ new Map();
    media_controller_privateAdd(this, _hotKeys, new AttributeTokenList(this, media_controller_Attributes.HOTKEYS));
    media_controller_privateAdd(this, _fullscreenElement, void 0);
    media_controller_privateAdd(this, _mediaStore, void 0);
    media_controller_privateAdd(this, _mediaStateCallback, void 0);
    media_controller_privateAdd(this, _mediaStoreUnsubscribe, void 0);
    media_controller_privateAdd(this, _mediaStateEventHandler, (event) => {
     var _a;
     (_a = media_controller_privateGet(this, _mediaStore)) == null ? void 0 : _a.dispatch(event);
    });
    this.associateElement(this);
    let prevState = {};
    media_controller_privateSet(this, _mediaStateCallback, (nextState) => {
     Object.entries(nextState).forEach(([stateName, stateValue]) => {
      if (stateName in prevState && prevState[stateName] === stateValue) return;
      this.propagateMediaState(stateName, stateValue);
      const attrName = stateName.toLowerCase();
      const evt = new GlobalThis.CustomEvent(AttributeToStateChangeEventMap[attrName], { composed: true, detail: stateValue });
      this.dispatchEvent(evt);
     });
     prevState = nextState;
    });
    this.enableHotkeys();
   }
   static get observedAttributes() {
    return super.observedAttributes.concat(media_controller_Attributes.NO_HOTKEYS, media_controller_Attributes.HOTKEYS, media_controller_Attributes.DEFAULT_STREAM_TYPE, media_controller_Attributes.DEFAULT_SUBTITLES, media_controller_Attributes.DEFAULT_DURATION, media_controller_Attributes.LANG);
   }
   get mediaStore() {
    return media_controller_privateGet(this, _mediaStore);
   }
   set mediaStore(value) {
    var _a, _b;
    if (media_controller_privateGet(this, _mediaStore)) {
     (_a = media_controller_privateGet(this, _mediaStoreUnsubscribe)) == null ? void 0 : _a.call(this);
     media_controller_privateSet(this, _mediaStoreUnsubscribe, void 0);
    }
    media_controller_privateSet(this, _mediaStore, value);
    if (!media_controller_privateGet(this, _mediaStore) && !this.hasAttribute(media_controller_Attributes.NO_DEFAULT_STORE)) {
     media_controller_privateMethod(this, _setupDefaultStore, setupDefaultStore_fn).call(this);
     return;
    }
    media_controller_privateSet(this, _mediaStoreUnsubscribe, (_b = media_controller_privateGet(this, _mediaStore)) == null ? void 0 : _b.subscribe(media_controller_privateGet(this, _mediaStateCallback)));
   }
   get fullscreenElement() {
    var _a;
    return (_a = media_controller_privateGet(this, _fullscreenElement)) != null ? _a : this;
   }
   set fullscreenElement(element) {
    var _a;
    if (this.hasAttribute(media_controller_Attributes.FULLSCREEN_ELEMENT)) {
     this.removeAttribute(media_controller_Attributes.FULLSCREEN_ELEMENT);
    }
    media_controller_privateSet(this, _fullscreenElement, element);
    (_a = media_controller_privateGet(this, _mediaStore)) == null
     ? void 0
     : _a.dispatch({
        type: 'fullscreenelementchangerequest',
        detail: this.fullscreenElement,
       });
   }
   get defaultSubtitles() {
    return getBooleanAttr(this, media_controller_Attributes.DEFAULT_SUBTITLES);
   }
   set defaultSubtitles(value) {
    setBooleanAttr(this, media_controller_Attributes.DEFAULT_SUBTITLES, value);
   }
   get defaultStreamType() {
    return getStringAttr(this, media_controller_Attributes.DEFAULT_STREAM_TYPE);
   }
   set defaultStreamType(value) {
    setStringAttr(this, media_controller_Attributes.DEFAULT_STREAM_TYPE, value);
   }
   get defaultDuration() {
    return getNumericAttr(this, media_controller_Attributes.DEFAULT_DURATION);
   }
   set defaultDuration(value) {
    setNumericAttr(this, media_controller_Attributes.DEFAULT_DURATION, value);
   }
   get noHotkeys() {
    return getBooleanAttr(this, media_controller_Attributes.NO_HOTKEYS);
   }
   set noHotkeys(value) {
    setBooleanAttr(this, media_controller_Attributes.NO_HOTKEYS, value);
   }
   get keysUsed() {
    return getStringAttr(this, media_controller_Attributes.KEYS_USED);
   }
   set keysUsed(value) {
    setStringAttr(this, media_controller_Attributes.KEYS_USED, value);
   }
   get liveEdgeOffset() {
    return getNumericAttr(this, media_controller_Attributes.LIVE_EDGE_OFFSET);
   }
   set liveEdgeOffset(value) {
    setNumericAttr(this, media_controller_Attributes.LIVE_EDGE_OFFSET, value);
   }
   get noAutoSeekToLive() {
    return getBooleanAttr(this, media_controller_Attributes.NO_AUTO_SEEK_TO_LIVE);
   }
   set noAutoSeekToLive(value) {
    setBooleanAttr(this, media_controller_Attributes.NO_AUTO_SEEK_TO_LIVE, value);
   }
   get noVolumePref() {
    return getBooleanAttr(this, media_controller_Attributes.NO_VOLUME_PREF);
   }
   set noVolumePref(value) {
    setBooleanAttr(this, media_controller_Attributes.NO_VOLUME_PREF, value);
   }
   get noSubtitlesLangPref() {
    return getBooleanAttr(this, media_controller_Attributes.NO_SUBTITLES_LANG_PREF);
   }
   set noSubtitlesLangPref(value) {
    setBooleanAttr(this, media_controller_Attributes.NO_SUBTITLES_LANG_PREF, value);
   }
   get noDefaultStore() {
    return getBooleanAttr(this, media_controller_Attributes.NO_DEFAULT_STORE);
   }
   set noDefaultStore(value) {
    setBooleanAttr(this, media_controller_Attributes.NO_DEFAULT_STORE, value);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d, _e, _f, _g, _h;
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === media_controller_Attributes.NO_HOTKEYS) {
     if (newValue !== oldValue && newValue === '') {
      if (this.hasAttribute(media_controller_Attributes.HOTKEYS)) {
       console.warn('Media Chrome: Both `hotkeys` and `nohotkeys` have been set. All hotkeys will be disabled.');
      }
      this.disableHotkeys();
     } else if (newValue !== oldValue && newValue === null) {
      this.enableHotkeys();
     }
    } else if (attrName === media_controller_Attributes.HOTKEYS) {
     media_controller_privateGet(this, _hotKeys).value = newValue;
    } else if (attrName === media_controller_Attributes.DEFAULT_SUBTITLES && newValue !== oldValue) {
     (_a = media_controller_privateGet(this, _mediaStore)) == null
      ? void 0
      : _a.dispatch({
         type: 'optionschangerequest',
         detail: {
          defaultSubtitles: this.hasAttribute(media_controller_Attributes.DEFAULT_SUBTITLES),
         },
        });
    } else if (attrName === media_controller_Attributes.DEFAULT_STREAM_TYPE) {
     (_c = media_controller_privateGet(this, _mediaStore)) == null
      ? void 0
      : _c.dispatch({
         type: 'optionschangerequest',
         detail: {
          defaultStreamType: (_b = this.getAttribute(media_controller_Attributes.DEFAULT_STREAM_TYPE)) != null ? _b : void 0,
         },
        });
    } else if (attrName === media_controller_Attributes.LIVE_EDGE_OFFSET) {
     (_d = media_controller_privateGet(this, _mediaStore)) == null
      ? void 0
      : _d.dispatch({
         type: 'optionschangerequest',
         detail: {
          liveEdgeOffset: this.hasAttribute(media_controller_Attributes.LIVE_EDGE_OFFSET) ? +this.getAttribute(media_controller_Attributes.LIVE_EDGE_OFFSET) : void 0,
          seekToLiveOffset: !this.hasAttribute(media_controller_Attributes.SEEK_TO_LIVE_OFFSET) ? +this.getAttribute(media_controller_Attributes.LIVE_EDGE_OFFSET) : void 0,
         },
        });
    } else if (attrName === media_controller_Attributes.SEEK_TO_LIVE_OFFSET) {
     (_e = media_controller_privateGet(this, _mediaStore)) == null
      ? void 0
      : _e.dispatch({
         type: 'optionschangerequest',
         detail: {
          seekToLiveOffset: this.hasAttribute(media_controller_Attributes.SEEK_TO_LIVE_OFFSET) ? +this.getAttribute(media_controller_Attributes.SEEK_TO_LIVE_OFFSET) : void 0,
         },
        });
    } else if (attrName === media_controller_Attributes.NO_AUTO_SEEK_TO_LIVE) {
     (_f = media_controller_privateGet(this, _mediaStore)) == null
      ? void 0
      : _f.dispatch({
         type: 'optionschangerequest',
         detail: {
          noAutoSeekToLive: this.hasAttribute(media_controller_Attributes.NO_AUTO_SEEK_TO_LIVE),
         },
        });
    } else if (attrName === media_controller_Attributes.FULLSCREEN_ELEMENT) {
     const el = newValue ? ((_g = this.getRootNode()) == null ? void 0 : _g.getElementById(newValue)) : void 0;
     media_controller_privateSet(this, _fullscreenElement, el);
     (_h = media_controller_privateGet(this, _mediaStore)) == null
      ? void 0
      : _h.dispatch({
         type: 'fullscreenelementchangerequest',
         detail: this.fullscreenElement,
        });
    } else if (attrName === media_controller_Attributes.LANG && newValue !== oldValue) {
     setLanguage(newValue);
    }
   }
   connectedCallback() {
    var _a, _b;
    if (!media_controller_privateGet(this, _mediaStore) && !this.hasAttribute(media_controller_Attributes.NO_DEFAULT_STORE)) {
     media_controller_privateMethod(this, _setupDefaultStore, setupDefaultStore_fn).call(this);
    }
    (_a = media_controller_privateGet(this, _mediaStore)) == null
     ? void 0
     : _a.dispatch({
        type: 'documentelementchangerequest',
        detail: server_safe_globals_Document,
       });
    super.connectedCallback();
    if (media_controller_privateGet(this, _mediaStore) && !media_controller_privateGet(this, _mediaStoreUnsubscribe)) {
     media_controller_privateSet(this, _mediaStoreUnsubscribe, (_b = media_controller_privateGet(this, _mediaStore)) == null ? void 0 : _b.subscribe(media_controller_privateGet(this, _mediaStateCallback)));
    }
    this.enableHotkeys();
   }
   disconnectedCallback() {
    var _a, _b, _c, _d;
    (_a = super.disconnectedCallback) == null ? void 0 : _a.call(this);
    if (media_controller_privateGet(this, _mediaStore)) {
     (_b = media_controller_privateGet(this, _mediaStore)) == null
      ? void 0
      : _b.dispatch({
         type: 'documentelementchangerequest',
         detail: void 0,
        });
     (_c = media_controller_privateGet(this, _mediaStore)) == null
      ? void 0
      : _c.dispatch({
         type: MediaUIEvents.MEDIA_TOGGLE_SUBTITLES_REQUEST,
         detail: false,
        });
    }
    if (media_controller_privateGet(this, _mediaStoreUnsubscribe)) {
     (_d = media_controller_privateGet(this, _mediaStoreUnsubscribe)) == null ? void 0 : _d.call(this);
     media_controller_privateSet(this, _mediaStoreUnsubscribe, void 0);
    }
   }
   /**
    * @override
    * @param {HTMLMediaElement} media
    */
   mediaSetCallback(media) {
    var _a;
    super.mediaSetCallback(media);
    (_a = media_controller_privateGet(this, _mediaStore)) == null
     ? void 0
     : _a.dispatch({
        type: 'mediaelementchangerequest',
        detail: media,
       });
    if (!media.hasAttribute('tabindex')) {
     media.tabIndex = -1;
    }
   }
   /**
    * @override
    * @param {HTMLMediaElement} media
    */
   mediaUnsetCallback(media) {
    var _a;
    super.mediaUnsetCallback(media);
    (_a = media_controller_privateGet(this, _mediaStore)) == null
     ? void 0
     : _a.dispatch({
        type: 'mediaelementchangerequest',
        detail: void 0,
       });
   }
   propagateMediaState(stateName, state) {
    propagateMediaState(this.mediaStateReceivers, stateName, state);
   }
   associateElement(element) {
    if (!element) return;
    const { associatedElementSubscriptions } = this;
    if (associatedElementSubscriptions.has(element)) return;
    const registerMediaStateReceiver = this.registerMediaStateReceiver.bind(this);
    const unregisterMediaStateReceiver = this.unregisterMediaStateReceiver.bind(this);
    const unsubscribe = monitorForMediaStateReceivers(element, registerMediaStateReceiver, unregisterMediaStateReceiver);
    Object.values(MediaUIEvents).forEach((eventName) => {
     element.addEventListener(eventName, media_controller_privateGet(this, _mediaStateEventHandler));
    });
    associatedElementSubscriptions.set(element, unsubscribe);
   }
   unassociateElement(element) {
    if (!element) return;
    const { associatedElementSubscriptions } = this;
    if (!associatedElementSubscriptions.has(element)) return;
    const unsubscribe = associatedElementSubscriptions.get(element);
    unsubscribe();
    associatedElementSubscriptions.delete(element);
    Object.values(MediaUIEvents).forEach((eventName) => {
     element.removeEventListener(eventName, media_controller_privateGet(this, _mediaStateEventHandler));
    });
   }
   registerMediaStateReceiver(el) {
    if (!el) return;
    const els = this.mediaStateReceivers;
    const index = els.indexOf(el);
    if (index > -1) return;
    els.push(el);
    if (media_controller_privateGet(this, _mediaStore)) {
     Object.entries(media_controller_privateGet(this, _mediaStore).getState()).forEach(([stateName, stateValue]) => {
      propagateMediaState([el], stateName, stateValue);
     });
    }
   }
   unregisterMediaStateReceiver(el) {
    const els = this.mediaStateReceivers;
    const index = els.indexOf(el);
    if (index < 0) return;
    els.splice(index, 1);
   }
   enableHotkeys() {
    this.addEventListener('keydown', media_controller_privateMethod(this, _keyDownHandler, keyDownHandler_fn));
   }
   disableHotkeys() {
    this.removeEventListener('keydown', media_controller_privateMethod(this, _keyDownHandler, keyDownHandler_fn));
    this.removeEventListener('keyup', media_controller_privateMethod(this, _keyUpHandler, keyUpHandler_fn));
   }
   get hotkeys() {
    return getStringAttr(this, media_controller_Attributes.HOTKEYS);
   }
   set hotkeys(value) {
    setStringAttr(this, media_controller_Attributes.HOTKEYS, value);
   }
   keyboardShortcutHandler(e) {
    var _a, _b, _c, _d, _e;
    const target = e.target;
    const keysUsed = ((_c = (_b = (_a = target.getAttribute(media_controller_Attributes.KEYS_USED)) == null ? void 0 : _a.split(' ')) != null ? _b : target == null ? void 0 : target.keysUsed) != null ? _c : []).map((key) => (key === 'Space' ? ' ' : key)).filter(Boolean);
    if (keysUsed.includes(e.key)) {
     return;
    }
    let eventName, detail, evt;
    if (media_controller_privateGet(this, _hotKeys).contains(`no${e.key.toLowerCase()}`)) return;
    if (e.key === ' ' && media_controller_privateGet(this, _hotKeys).contains(`nospace`)) return;
    switch (e.key) {
     case ' ':
     case 'k':
      eventName = media_controller_privateGet(this, _mediaStore).getState().mediaPaused ? MediaUIEvents.MEDIA_PLAY_REQUEST : MediaUIEvents.MEDIA_PAUSE_REQUEST;
      this.dispatchEvent(
       new GlobalThis.CustomEvent(eventName, {
        composed: true,
        bubbles: true,
       }),
      );
      break;
     case 'm':
      eventName = this.mediaStore.getState().mediaVolumeLevel === 'off' ? MediaUIEvents.MEDIA_UNMUTE_REQUEST : MediaUIEvents.MEDIA_MUTE_REQUEST;
      this.dispatchEvent(
       new GlobalThis.CustomEvent(eventName, {
        composed: true,
        bubbles: true,
       }),
      );
      break;
     case 'f':
      eventName = this.mediaStore.getState().mediaIsFullscreen ? MediaUIEvents.MEDIA_EXIT_FULLSCREEN_REQUEST : MediaUIEvents.MEDIA_ENTER_FULLSCREEN_REQUEST;
      this.dispatchEvent(
       new GlobalThis.CustomEvent(eventName, {
        composed: true,
        bubbles: true,
       }),
      );
      break;
     case 'c':
      this.dispatchEvent(new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_TOGGLE_SUBTITLES_REQUEST, { composed: true, bubbles: true }));
      break;
     case 'ArrowLeft': {
      const offsetValue = this.hasAttribute(media_controller_Attributes.KEYBOARD_BACKWARD_SEEK_OFFSET) ? +this.getAttribute(media_controller_Attributes.KEYBOARD_BACKWARD_SEEK_OFFSET) : DEFAULT_SEEK_OFFSET;
      detail = Math.max(((_d = this.mediaStore.getState().mediaCurrentTime) != null ? _d : 0) - offsetValue, 0);
      evt = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_SEEK_REQUEST, {
       composed: true,
       bubbles: true,
       detail,
      });
      this.dispatchEvent(evt);
      break;
     }
     case 'ArrowRight': {
      const offsetValue = this.hasAttribute(media_controller_Attributes.KEYBOARD_FORWARD_SEEK_OFFSET) ? +this.getAttribute(media_controller_Attributes.KEYBOARD_FORWARD_SEEK_OFFSET) : DEFAULT_SEEK_OFFSET;
      detail = Math.max(((_e = this.mediaStore.getState().mediaCurrentTime) != null ? _e : 0) + offsetValue, 0);
      evt = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_SEEK_REQUEST, {
       composed: true,
       bubbles: true,
       detail,
      });
      this.dispatchEvent(evt);
      break;
     }
     default:
      break;
    }
   }
  }
  _hotKeys = new WeakMap();
  _fullscreenElement = new WeakMap();
  _mediaStore = new WeakMap();
  _mediaStateCallback = new WeakMap();
  _mediaStoreUnsubscribe = new WeakMap();
  _mediaStateEventHandler = new WeakMap();
  _setupDefaultStore = new WeakSet();
  setupDefaultStore_fn = function () {
   var _a;
   this.mediaStore = createMediaStore({
    media: this.media,
    fullscreenElement: this.fullscreenElement,
    options: {
     defaultSubtitles: this.hasAttribute(media_controller_Attributes.DEFAULT_SUBTITLES),
     defaultDuration: this.hasAttribute(media_controller_Attributes.DEFAULT_DURATION) ? +this.getAttribute(media_controller_Attributes.DEFAULT_DURATION) : void 0,
     defaultStreamType:
      /** @type {import('./media-store/state-mediator.js').StreamTypeValue} */
      (_a = this.getAttribute(media_controller_Attributes.DEFAULT_STREAM_TYPE)) != null ? _a : void 0,
     liveEdgeOffset: this.hasAttribute(media_controller_Attributes.LIVE_EDGE_OFFSET) ? +this.getAttribute(media_controller_Attributes.LIVE_EDGE_OFFSET) : void 0,
     seekToLiveOffset: this.hasAttribute(media_controller_Attributes.SEEK_TO_LIVE_OFFSET) ? +this.getAttribute(media_controller_Attributes.SEEK_TO_LIVE_OFFSET) : this.hasAttribute(media_controller_Attributes.LIVE_EDGE_OFFSET) ? +this.getAttribute(media_controller_Attributes.LIVE_EDGE_OFFSET) : void 0,
     noAutoSeekToLive: this.hasAttribute(media_controller_Attributes.NO_AUTO_SEEK_TO_LIVE),
     // NOTE: This wasn't updated if it was changed later. Should it be? (CJP)
     noVolumePref: this.hasAttribute(media_controller_Attributes.NO_VOLUME_PREF),
     noSubtitlesLangPref: this.hasAttribute(media_controller_Attributes.NO_SUBTITLES_LANG_PREF),
    },
   });
  };
  _keyUpHandler = new WeakSet();
  keyUpHandler_fn = function (e) {
   const { key } = e;
   if (!ButtonPressedKeys.includes(key)) {
    this.removeEventListener('keyup', media_controller_privateMethod(this, _keyUpHandler, keyUpHandler_fn));
    return;
   }
   this.keyboardShortcutHandler(e);
  };
  _keyDownHandler = new WeakSet();
  keyDownHandler_fn = function (e) {
   const { metaKey, altKey, key } = e;
   if (metaKey || altKey || !ButtonPressedKeys.includes(key)) {
    this.removeEventListener('keyup', media_controller_privateMethod(this, _keyUpHandler, keyUpHandler_fn));
    return;
   }
   if ([' ', 'ArrowLeft', 'ArrowRight'].includes(key) && !(media_controller_privateGet(this, _hotKeys).contains(`no${key.toLowerCase()}`) || (key === ' ' && media_controller_privateGet(this, _hotKeys).contains('nospace')))) {
    e.preventDefault();
   }
   this.addEventListener('keyup', media_controller_privateMethod(this, _keyUpHandler, keyUpHandler_fn), { once: true });
  };
  const media_controller_MEDIA_UI_ATTRIBUTE_NAMES = Object.values(MediaUIAttributes);
  const MEDIA_UI_PROP_NAMES = Object.values(MediaUIProps);
  const getMediaUIAttributesFrom = (child) => {
   var _a, _b, _c, _d;
   let { observedAttributes } = child.constructor;
   if (!observedAttributes && ((_a = child.nodeName) == null ? void 0 : _a.includes('-'))) {
    GlobalThis.customElements.upgrade(child);
    ({ observedAttributes } = child.constructor);
   }
   const mediaChromeAttributesList = (_d = (_c = (_b = child == null ? void 0 : child.getAttribute) == null ? void 0 : _b.call(child, MediaStateReceiverAttributes.MEDIA_CHROME_ATTRIBUTES)) == null ? void 0 : _c.split) == null ? void 0 : _d.call(_c, /\s+/);
   if (!Array.isArray(observedAttributes || mediaChromeAttributesList)) return [];
   return (observedAttributes || mediaChromeAttributesList).filter((attrName) => media_controller_MEDIA_UI_ATTRIBUTE_NAMES.includes(attrName));
  };
  const hasMediaUIProps = (mediaStateReceiverCandidate) => {
   var _a, _b;
   if (((_a = mediaStateReceiverCandidate.nodeName) == null ? void 0 : _a.includes('-')) && !!GlobalThis.customElements.get((_b = mediaStateReceiverCandidate.nodeName) == null ? void 0 : _b.toLowerCase()) && !(mediaStateReceiverCandidate instanceof GlobalThis.customElements.get(mediaStateReceiverCandidate.nodeName.toLowerCase()))) {
    GlobalThis.customElements.upgrade(mediaStateReceiverCandidate);
   }
   return MEDIA_UI_PROP_NAMES.some((propName) => propName in mediaStateReceiverCandidate);
  };
  const isMediaStateReceiver = (child) => {
   return hasMediaUIProps(child) || !!getMediaUIAttributesFrom(child).length;
  };
  const serializeTuple = (tuple) => {
   var _a;
   return (_a = tuple == null ? void 0 : tuple.join) == null ? void 0 : _a.call(tuple, ':');
  };
  const CustomAttrSerializer = {
   [MediaUIAttributes.MEDIA_SUBTITLES_LIST]: stringifyTextTrackList,
   [MediaUIAttributes.MEDIA_SUBTITLES_SHOWING]: stringifyTextTrackList,
   [MediaUIAttributes.MEDIA_SEEKABLE]: serializeTuple,
   [MediaUIAttributes.MEDIA_BUFFERED]: (tuples) => (tuples == null ? void 0 : tuples.map(serializeTuple).join(' ')),
   [MediaUIAttributes.MEDIA_PREVIEW_COORDS]: (coords) => (coords == null ? void 0 : coords.join(' ')),
   [MediaUIAttributes.MEDIA_RENDITION_LIST]: stringifyRenditionList,
   [MediaUIAttributes.MEDIA_AUDIO_TRACK_LIST]: stringifyAudioTrackList,
  };
  const setAttr = async (child, attrName, attrValue) => {
   var _a, _b;
   if (!child.isConnected) {
    await delay(0);
   }
   if (typeof attrValue === 'boolean' || attrValue == null) {
    return setBooleanAttr(child, attrName, attrValue);
   }
   if (typeof attrValue === 'number') {
    return setNumericAttr(child, attrName, attrValue);
   }
   if (typeof attrValue === 'string') {
    return setStringAttr(child, attrName, attrValue);
   }
   if (Array.isArray(attrValue) && !attrValue.length) {
    return child.removeAttribute(attrName);
   }
   const val = (_b = (_a = CustomAttrSerializer[attrName]) == null ? void 0 : _a.call(CustomAttrSerializer, attrValue)) != null ? _b : attrValue;
   return child.setAttribute(attrName, val);
  };
  const isMediaSlotElementDescendant = (el) => {
   var _a;
   return !!((_a = el.closest) == null ? void 0 : _a.call(el, '*[slot="media"]'));
  };
  const traverseForMediaStateReceivers = (rootNode, mediaStateReceiverCallback) => {
   if (isMediaSlotElementDescendant(rootNode)) {
    return;
   }
   const traverseForMediaStateReceiversSync = (rootNode2, mediaStateReceiverCallback2) => {
    var _a, _b;
    if (isMediaStateReceiver(rootNode2)) {
     mediaStateReceiverCallback2(rootNode2);
    }
    const { children = [] } = rootNode2 != null ? rootNode2 : {};
    const shadowChildren = (_b = (_a = rootNode2 == null ? void 0 : rootNode2.shadowRoot) == null ? void 0 : _a.children) != null ? _b : [];
    const allChildren = [...children, ...shadowChildren];
    allChildren.forEach((child) => traverseForMediaStateReceivers(child, mediaStateReceiverCallback2));
   };
   const name = rootNode == null ? void 0 : rootNode.nodeName.toLowerCase();
   if (name.includes('-') && !isMediaStateReceiver(rootNode)) {
    GlobalThis.customElements.whenDefined(name).then(() => {
     traverseForMediaStateReceiversSync(rootNode, mediaStateReceiverCallback);
    });
    return;
   }
   traverseForMediaStateReceiversSync(rootNode, mediaStateReceiverCallback);
  };
  const propagateMediaState = (els, stateName, val) => {
   els.forEach((el) => {
    if (stateName in el) {
     el[stateName] = val;
     return;
    }
    const relevantAttrs = getMediaUIAttributesFrom(el);
    const attrName = stateName.toLowerCase();
    if (!relevantAttrs.includes(attrName)) return;
    setAttr(el, attrName, val);
   });
  };
  const monitorForMediaStateReceivers = (rootNode, registerMediaStateReceiver, unregisterMediaStateReceiver) => {
   traverseForMediaStateReceivers(rootNode, registerMediaStateReceiver);
   const registerMediaStateReceiverHandler = (evt) => {
    var _a;
    const el = (_a = evt == null ? void 0 : evt.composedPath()[0]) != null ? _a : evt.target;
    registerMediaStateReceiver(el);
   };
   const unregisterMediaStateReceiverHandler = (evt) => {
    var _a;
    const el = (_a = evt == null ? void 0 : evt.composedPath()[0]) != null ? _a : evt.target;
    unregisterMediaStateReceiver(el);
   };
   rootNode.addEventListener(MediaUIEvents.REGISTER_MEDIA_STATE_RECEIVER, registerMediaStateReceiverHandler);
   rootNode.addEventListener(MediaUIEvents.UNREGISTER_MEDIA_STATE_RECEIVER, unregisterMediaStateReceiverHandler);
   const mutationCallback = (mutationsList) => {
    mutationsList.forEach((mutationRecord) => {
     const { addedNodes = [], removedNodes = [], type, target, attributeName } = mutationRecord;
     if (type === 'childList') {
      Array.prototype.forEach.call(addedNodes, (node) => traverseForMediaStateReceivers(node, registerMediaStateReceiver));
      Array.prototype.forEach.call(removedNodes, (node) => traverseForMediaStateReceivers(node, unregisterMediaStateReceiver));
     } else if (type === 'attributes' && attributeName === MediaStateReceiverAttributes.MEDIA_CHROME_ATTRIBUTES) {
      if (isMediaStateReceiver(target)) {
       registerMediaStateReceiver(target);
      } else {
       unregisterMediaStateReceiver(target);
      }
     }
    });
   };
   let prevSlotted = [];
   const slotChangeHandler = (event) => {
    const slotEl = event.target;
    if (slotEl.name === 'media') return;
    prevSlotted.forEach((node) => traverseForMediaStateReceivers(node, unregisterMediaStateReceiver));
    prevSlotted = [...slotEl.assignedElements({ flatten: true })];
    prevSlotted.forEach((node) => traverseForMediaStateReceivers(node, registerMediaStateReceiver));
   };
   rootNode.addEventListener('slotchange', slotChangeHandler);
   const observer = new MutationObserver(mutationCallback);
   observer.observe(rootNode, {
    childList: true,
    attributes: true,
    subtree: true,
   });
   const unsubscribe = () => {
    traverseForMediaStateReceivers(rootNode, unregisterMediaStateReceiver);
    rootNode.removeEventListener('slotchange', slotChangeHandler);
    observer.disconnect();
    rootNode.removeEventListener(MediaUIEvents.REGISTER_MEDIA_STATE_RECEIVER, registerMediaStateReceiverHandler);
    rootNode.removeEventListener(MediaUIEvents.UNREGISTER_MEDIA_STATE_RECEIVER, unregisterMediaStateReceiverHandler);
   };
   return unsubscribe;
  };
  if (!GlobalThis.customElements.get('media-controller')) {
   GlobalThis.customElements.define('media-controller', MediaController);
  }
  var media_controller_default = MediaController; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-tooltip.js

  const media_tooltip_Attributes = {
   PLACEMENT: 'placement',
   BOUNDS: 'bounds',
  };
  function media_tooltip_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        --_tooltip-background-color: var(--media-tooltip-background-color, var(--media-secondary-color, rgba(20, 20, 30, .7)));
        --_tooltip-background: var(--media-tooltip-background, var(--_tooltip-background-color));
        --_tooltip-arrow-half-width: calc(var(--media-tooltip-arrow-width, 12px) / 2);
        --_tooltip-arrow-height: var(--media-tooltip-arrow-height, 5px);
        --_tooltip-arrow-background: var(--media-tooltip-arrow-color, var(--_tooltip-background-color));
        position: relative;
        pointer-events: none;
        display: var(--media-tooltip-display, inline-flex);
        justify-content: center;
        align-items: center;
        box-sizing: border-box;
        z-index: var(--media-tooltip-z-index, 1);
        background: var(--_tooltip-background);
        color: var(--media-text-color, var(--media-primary-color, rgb(238 238 238)));
        font: var(--media-font,
          var(--media-font-weight, 400)
          var(--media-font-size, 13px) /
          var(--media-text-content-height, var(--media-control-height, 18px))
          var(--media-font-family, helvetica neue, segoe ui, roboto, arial, sans-serif));
        padding: var(--media-tooltip-padding, .35em .7em);
        border: var(--media-tooltip-border, none);
        border-radius: var(--media-tooltip-border-radius, 5px);
        filter: var(--media-tooltip-filter, drop-shadow(0 0 4px rgba(0, 0, 0, .2)));
        white-space: var(--media-tooltip-white-space, nowrap);
      }

      :host([hidden]) {
        display: none;
      }

      img, svg {
        display: inline-block;
      }

      #arrow {
        position: absolute;
        width: 0px;
        height: 0px;
        border-style: solid;
        display: var(--media-tooltip-arrow-display, block);
      }

      :host(:not([placement])),
      :host([placement="top"]) {
        position: absolute;
        bottom: calc(100% + var(--media-tooltip-distance, 12px));
        left: 50%;
        transform: translate(calc(-50% - var(--media-tooltip-offset-x, 0px)), 0);
      }
      :host(:not([placement])) #arrow,
      :host([placement="top"]) #arrow {
        top: 100%;
        left: 50%;
        border-width: var(--_tooltip-arrow-height) var(--_tooltip-arrow-half-width) 0 var(--_tooltip-arrow-half-width);
        border-color: var(--_tooltip-arrow-background) transparent transparent transparent;
        transform: translate(calc(-50% + var(--media-tooltip-offset-x, 0px)), 0);
      }

      :host([placement="right"]) {
        position: absolute;
        left: calc(100% + var(--media-tooltip-distance, 12px));
        top: 50%;
        transform: translate(0, -50%);
      }
      :host([placement="right"]) #arrow {
        top: 50%;
        right: 100%;
        border-width: var(--_tooltip-arrow-half-width) var(--_tooltip-arrow-height) var(--_tooltip-arrow-half-width) 0;
        border-color: transparent var(--_tooltip-arrow-background) transparent transparent;
        transform: translate(0, -50%);
      }

      :host([placement="bottom"]) {
        position: absolute;
        top: calc(100% + var(--media-tooltip-distance, 12px));
        left: 50%;
        transform: translate(calc(-50% - var(--media-tooltip-offset-x, 0px)), 0);
      }
      :host([placement="bottom"]) #arrow {
        bottom: 100%;
        left: 50%;
        border-width: 0 var(--_tooltip-arrow-half-width) var(--_tooltip-arrow-height) var(--_tooltip-arrow-half-width);
        border-color: transparent transparent var(--_tooltip-arrow-background) transparent;
        transform: translate(calc(-50% + var(--media-tooltip-offset-x, 0px)), 0);
      }

      :host([placement="left"]) {
        position: absolute;
        right: calc(100% + var(--media-tooltip-distance, 12px));
        top: 50%;
        transform: translate(0, -50%);
      }
      :host([placement="left"]) #arrow {
        top: 50%;
        left: 100%;
        border-width: var(--_tooltip-arrow-half-width) 0 var(--_tooltip-arrow-half-width) var(--_tooltip-arrow-height);
        border-color: transparent transparent transparent var(--_tooltip-arrow-background);
        transform: translate(0, -50%);
      }
      
      :host([placement="none"]) #arrow {
        display: none;
      }
    </style>
    <slot></slot>
    <div id="arrow"></div>
  `
   );
  }
  class MediaTooltip extends GlobalThis.HTMLElement {
   constructor() {
    super();
    // Adjusts tooltip position relative to the closest specified container
    // such that it doesn't spill out of the left or right sides. Only applies
    // to 'top' and 'bottom' placed tooltips.
    this.updateXOffset = () => {
     var _a;
     if (!isElementVisible(this, { checkOpacity: false, checkVisibilityCSS: false })) return;
     const placement = this.placement;
     if (placement === 'left' || placement === 'right') {
      this.style.removeProperty('--media-tooltip-offset-x');
      return;
     }
     const tooltipStyle = getComputedStyle(this);
     const containingEl = (_a = closestComposedNode(this, '#' + this.bounds)) != null ? _a : getMediaController(this);
     if (!containingEl) return;
     const { x: containerX, width: containerWidth } = containingEl.getBoundingClientRect();
     const { x: tooltipX, width: tooltipWidth } = this.getBoundingClientRect();
     const tooltipRight = tooltipX + tooltipWidth;
     const containerRight = containerX + containerWidth;
     const offsetXVal = tooltipStyle.getPropertyValue('--media-tooltip-offset-x');
     const currOffsetX = offsetXVal ? parseFloat(offsetXVal.replace('px', '')) : 0;
     const marginVal = tooltipStyle.getPropertyValue('--media-tooltip-container-margin');
     const currMargin = marginVal ? parseFloat(marginVal.replace('px', '')) : 0;
     const leftDiff = tooltipX - containerX + currOffsetX - currMargin;
     const rightDiff = tooltipRight - containerRight + currOffsetX + currMargin;
     if (leftDiff < 0) {
      this.style.setProperty('--media-tooltip-offset-x', `${leftDiff}px`);
      return;
     }
     if (rightDiff > 0) {
      this.style.setProperty('--media-tooltip-offset-x', `${rightDiff}px`);
      return;
     }
     this.style.removeProperty('--media-tooltip-offset-x');
    };
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
    this.arrowEl = this.shadowRoot.querySelector('#arrow');
    if (Object.prototype.hasOwnProperty.call(this, 'placement')) {
     const placement = this.placement;
     delete this.placement;
     this.placement = placement;
    }
   }
   static get observedAttributes() {
    return [media_tooltip_Attributes.PLACEMENT, media_tooltip_Attributes.BOUNDS];
   }
   /**
    * Get or set tooltip placement
    */
   get placement() {
    return getStringAttr(this, media_tooltip_Attributes.PLACEMENT);
   }
   set placement(value) {
    setStringAttr(this, media_tooltip_Attributes.PLACEMENT, value);
   }
   /**
    * Get or set tooltip container ID selector that will constrain the tooltips
    * horizontal position.
    */
   get bounds() {
    return getStringAttr(this, media_tooltip_Attributes.BOUNDS);
   }
   set bounds(value) {
    setStringAttr(this, media_tooltip_Attributes.BOUNDS, value);
   }
  }
  MediaTooltip.shadowRootOptions = { mode: 'open' };
  MediaTooltip.getTemplateHTML = media_tooltip_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-tooltip')) {
   GlobalThis.customElements.define('media-tooltip', MediaTooltip);
  }
  var media_tooltip_default = MediaTooltip; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-chrome-button.js

  var media_chrome_button_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_chrome_button_privateGet = (obj, member, getter) => {
   media_chrome_button_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_chrome_button_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_chrome_button_privateSet = (obj, member, value, setter) => {
   media_chrome_button_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_chrome_button_privateMethod = (obj, member, method) => {
   media_chrome_button_accessCheck(obj, member, 'access private method');
   return method;
  };
  var media_chrome_button_mediaController, _clickListener, _positionTooltip, _keyupListener, _keydownListener, _setupTooltip, setupTooltip_fn;

  const media_chrome_button_Attributes = {
   TOOLTIP_PLACEMENT: 'tooltipplacement',
   DISABLED: 'disabled',
   NO_TOOLTIP: 'notooltip',
  };
  function media_chrome_button_getTemplateHTML(_attrs, _props = {}) {
   return (
    /*html*/
    `
    <style>
      :host {
        position: relative;
        font: var(--media-font,
          var(--media-font-weight, bold)
          var(--media-font-size, 14px) /
          var(--media-text-content-height, var(--media-control-height, 24px))
          var(--media-font-family, helvetica neue, segoe ui, roboto, arial, sans-serif));
        color: var(--media-text-color, var(--media-primary-color, rgb(238 238 238)));
        background: var(--media-control-background, var(--media-secondary-color, rgb(20 20 30 / .7)));
        padding: var(--media-button-padding, var(--media-control-padding, 10px));
        justify-content: var(--media-button-justify-content, center);
        display: inline-flex;
        align-items: center;
        vertical-align: middle;
        box-sizing: border-box;
        transition: background .15s linear;
        pointer-events: auto;
        cursor: var(--media-cursor, pointer);
        -webkit-tap-highlight-color: transparent;
      }

      ${
       /*
      Only show outline when keyboard focusing.
      https://drafts.csswg.org/selectors-4/#the-focus-visible-pseudo
    */
       ''
      }
      :host(:focus-visible) {
        box-shadow: inset 0 0 0 2px rgb(27 127 204 / .9);
        outline: 0;
      }
      ${
       /*
        * hide default focus ring, particularly when using mouse
        */
       ''
      }
      :host(:where(:focus)) {
        box-shadow: none;
        outline: 0;
      }

      :host(:hover) {
        background: var(--media-control-hover-background, rgba(50 50 70 / .7));
      }

      svg, img, ::slotted(svg), ::slotted(img) {
        width: var(--media-button-icon-width);
        height: var(--media-button-icon-height, var(--media-control-height, 24px));
        transform: var(--media-button-icon-transform);
        transition: var(--media-button-icon-transition);
        fill: var(--media-icon-color, var(--media-primary-color, rgb(238 238 238)));
        vertical-align: middle;
        max-width: 100%;
        max-height: 100%;
        min-width: 100%;
      }

      media-tooltip {
        ${/** Make sure unpositioned tooltip doesn't cause page overflow (scroll). */ ''}
        max-width: 0;
        overflow-x: clip;
        opacity: 0;
        transition: opacity .3s, max-width 0s 9s;
      }

      :host(:hover) media-tooltip,
      :host(:focus-visible) media-tooltip {
        max-width: 100vw;
        opacity: 1;
        transition: opacity .3s;
      }

      :host([notooltip]) slot[name="tooltip"] {
        display: none;
      }
    </style>

    ${this.getSlotTemplateHTML(_attrs, _props)}

    <slot name="tooltip">
      <media-tooltip part="tooltip" aria-hidden="true">
        <template shadowrootmode="${media_tooltip_default.shadowRootOptions.mode}">
          ${media_tooltip_default.getTemplateHTML({})}
        </template>
        <slot name="tooltip-content">
          ${this.getTooltipContentHTML(_attrs)}
        </slot>
      </media-tooltip>
    </slot>
  `
   );
  }
  function getSlotTemplateHTML(_attrs, _props) {
   return (
    /*html*/
    `
    <slot></slot>
  `
   );
  }
  function getTooltipContentHTML() {
   return '';
  }
  class MediaChromeButton extends GlobalThis.HTMLElement {
   constructor() {
    super();
    // Called when we know the tooltip is ready / defined
    media_chrome_button_privateAdd(this, _setupTooltip);
    media_chrome_button_privateAdd(this, media_chrome_button_mediaController, void 0);
    this.preventClick = false;
    this.tooltipEl = null;
    media_chrome_button_privateAdd(this, _clickListener, (e) => {
     if (!this.preventClick) {
      this.handleClick(e);
     }
     setTimeout(media_chrome_button_privateGet(this, _positionTooltip), 0);
    });
    media_chrome_button_privateAdd(this, _positionTooltip, () => {
     var _a, _b;
     (_b = (_a = this.tooltipEl) == null ? void 0 : _a.updateXOffset) == null ? void 0 : _b.call(_a);
    });
    // NOTE: There are definitely some "false positive" cases with multi-key pressing,
    // but this should be good enough for most use cases.
    media_chrome_button_privateAdd(this, _keyupListener, (e) => {
     const { key } = e;
     if (!this.keysUsed.includes(key)) {
      this.removeEventListener('keyup', media_chrome_button_privateGet(this, _keyupListener));
      return;
     }
     if (!this.preventClick) {
      this.handleClick(e);
     }
    });
    media_chrome_button_privateAdd(this, _keydownListener, (e) => {
     const { metaKey, altKey, key } = e;
     if (metaKey || altKey || !this.keysUsed.includes(key)) {
      this.removeEventListener('keyup', media_chrome_button_privateGet(this, _keyupListener));
      return;
     }
     this.addEventListener('keyup', media_chrome_button_privateGet(this, _keyupListener), { once: true });
    });
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     const html = this.constructor.getTemplateHTML(attrs);
     this.shadowRoot.setHTMLUnsafe ? this.shadowRoot.setHTMLUnsafe(html) : (this.shadowRoot.innerHTML = html);
    }
    this.tooltipEl = this.shadowRoot.querySelector('media-tooltip');
   }
   static get observedAttributes() {
    return ['disabled', media_chrome_button_Attributes.TOOLTIP_PLACEMENT, MediaStateReceiverAttributes.MEDIA_CONTROLLER];
   }
   enable() {
    this.addEventListener('click', media_chrome_button_privateGet(this, _clickListener));
    this.addEventListener('keydown', media_chrome_button_privateGet(this, _keydownListener));
    this.tabIndex = 0;
   }
   disable() {
    this.removeEventListener('click', media_chrome_button_privateGet(this, _clickListener));
    this.removeEventListener('keydown', media_chrome_button_privateGet(this, _keydownListener));
    this.removeEventListener('keyup', media_chrome_button_privateGet(this, _keyupListener));
    this.tabIndex = -1;
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d, _e;
    if (attrName === MediaStateReceiverAttributes.MEDIA_CONTROLLER) {
     if (oldValue) {
      (_b = (_a = media_chrome_button_privateGet(this, media_chrome_button_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
      media_chrome_button_privateSet(this, media_chrome_button_mediaController, null);
     }
     if (newValue && this.isConnected) {
      media_chrome_button_privateSet(this, media_chrome_button_mediaController, (_c = this.getRootNode()) == null ? void 0 : _c.getElementById(newValue));
      (_e = (_d = media_chrome_button_privateGet(this, media_chrome_button_mediaController)) == null ? void 0 : _d.associateElement) == null ? void 0 : _e.call(_d, this);
     }
    } else if (attrName === 'disabled' && newValue !== oldValue) {
     if (newValue == null) {
      this.enable();
     } else {
      this.disable();
     }
    } else if (attrName === media_chrome_button_Attributes.TOOLTIP_PLACEMENT && this.tooltipEl && newValue !== oldValue) {
     this.tooltipEl.placement = newValue;
    }
    media_chrome_button_privateGet(this, _positionTooltip).call(this);
   }
   connectedCallback() {
    var _a, _b, _c;
    const { style } = getOrInsertCSSRule(this.shadowRoot, ':host');
    style.setProperty('display', `var(--media-control-display, var(--${this.localName}-display, inline-flex))`);
    if (!this.hasAttribute('disabled')) {
     this.enable();
    } else {
     this.disable();
    }
    this.setAttribute('role', 'button');
    const mediaControllerId = this.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER);
    if (mediaControllerId) {
     media_chrome_button_privateSet(
      this,
      media_chrome_button_mediaController,
      // @ts-ignore
      (_a = this.getRootNode()) == null ? void 0 : _a.getElementById(mediaControllerId),
     );
     (_c = (_b = media_chrome_button_privateGet(this, media_chrome_button_mediaController)) == null ? void 0 : _b.associateElement) == null ? void 0 : _c.call(_b, this);
    }
    GlobalThis.customElements.whenDefined('media-tooltip').then(() => media_chrome_button_privateMethod(this, _setupTooltip, setupTooltip_fn).call(this));
   }
   disconnectedCallback() {
    var _a, _b;
    this.disable();
    (_b = (_a = media_chrome_button_privateGet(this, media_chrome_button_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
    media_chrome_button_privateSet(this, media_chrome_button_mediaController, null);
    this.removeEventListener('mouseenter', media_chrome_button_privateGet(this, _positionTooltip));
    this.removeEventListener('focus', media_chrome_button_privateGet(this, _positionTooltip));
    this.removeEventListener('click', media_chrome_button_privateGet(this, _clickListener));
   }
   get keysUsed() {
    return ['Enter', ' '];
   }
   /**
    * Get or set tooltip placement
    */
   get tooltipPlacement() {
    return getStringAttr(this, media_chrome_button_Attributes.TOOLTIP_PLACEMENT);
   }
   set tooltipPlacement(value) {
    setStringAttr(this, media_chrome_button_Attributes.TOOLTIP_PLACEMENT, value);
   }
   get mediaController() {
    return getStringAttr(this, MediaStateReceiverAttributes.MEDIA_CONTROLLER);
   }
   set mediaController(value) {
    setStringAttr(this, MediaStateReceiverAttributes.MEDIA_CONTROLLER, value);
   }
   get disabled() {
    return getBooleanAttr(this, media_chrome_button_Attributes.DISABLED);
   }
   set disabled(value) {
    setBooleanAttr(this, media_chrome_button_Attributes.DISABLED, value);
   }
   get noTooltip() {
    return getBooleanAttr(this, media_chrome_button_Attributes.NO_TOOLTIP);
   }
   set noTooltip(value) {
    setBooleanAttr(this, media_chrome_button_Attributes.NO_TOOLTIP, value);
   }
   /**
    * @abstract
    * @argument {Event} e
    */
   handleClick(e) {}
   // eslint-disable-line
  }
  media_chrome_button_mediaController = new WeakMap();
  _clickListener = new WeakMap();
  _positionTooltip = new WeakMap();
  _keyupListener = new WeakMap();
  _keydownListener = new WeakMap();
  _setupTooltip = new WeakSet();
  setupTooltip_fn = function () {
   this.addEventListener('mouseenter', media_chrome_button_privateGet(this, _positionTooltip));
   this.addEventListener('focus', media_chrome_button_privateGet(this, _positionTooltip));
   this.addEventListener('click', media_chrome_button_privateGet(this, _clickListener));
   const initialPlacement = this.tooltipPlacement;
   if (initialPlacement && this.tooltipEl) {
    this.tooltipEl.placement = initialPlacement;
   }
  };
  MediaChromeButton.shadowRootOptions = { mode: 'open' };
  MediaChromeButton.getTemplateHTML = media_chrome_button_getTemplateHTML;
  MediaChromeButton.getSlotTemplateHTML = getSlotTemplateHTML;
  MediaChromeButton.getTooltipContentHTML = getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-chrome-button')) {
   GlobalThis.customElements.define('media-chrome-button', MediaChromeButton);
  }
  var media_chrome_button_default = /* unused pure expression or super */ null && MediaChromeButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-airplay-button.js

  const airplayIcon = `<svg aria-hidden="true" viewBox="0 0 26 24">
  <path d="M22.13 3H3.87a.87.87 0 0 0-.87.87v13.26a.87.87 0 0 0 .87.87h3.4L9 16H5V5h16v11h-4l1.72 2h3.4a.87.87 0 0 0 .87-.87V3.87a.87.87 0 0 0-.86-.87Zm-8.75 11.44a.5.5 0 0 0-.76 0l-4.91 5.73a.5.5 0 0 0 .38.83h9.82a.501.501 0 0 0 .38-.83l-4.91-5.73Z"/>
</svg>
`;
  function media_airplay_button_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host([${MediaUIAttributes.MEDIA_IS_AIRPLAYING}]) slot[name=icon] slot:not([name=exit]) {
        display: none !important;
      }

      ${/* Double negative, but safer if display doesn't equal 'block' */ ''}
      :host(:not([${MediaUIAttributes.MEDIA_IS_AIRPLAYING}])) slot[name=icon] slot:not([name=enter]) {
        display: none !important;
      }

      :host([${MediaUIAttributes.MEDIA_IS_AIRPLAYING}]) slot[name=tooltip-enter],
      :host(:not([${MediaUIAttributes.MEDIA_IS_AIRPLAYING}])) slot[name=tooltip-exit] {
        display: none;
      }
    </style>

    <slot name="icon">
      <slot name="enter">${airplayIcon}</slot>
      <slot name="exit">${airplayIcon}</slot>
    </slot>
  `
   );
  }
  function media_airplay_button_getTooltipContentHTML() {
   return (
    /*html*/
    `
    <slot name="tooltip-enter">${t('start airplay')}</slot>
    <slot name="tooltip-exit">${t('stop airplay')}</slot>
  `
   );
  }
  const updateAriaLabel = (el) => {
   const label = el.mediaIsAirplaying ? t('stop airplay') : t('start airplay');
   el.setAttribute('aria-label', label);
  };
  class MediaAirplayButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_IS_AIRPLAYING, MediaUIAttributes.MEDIA_AIRPLAY_UNAVAILABLE];
   }
   connectedCallback() {
    super.connectedCallback();
    updateAriaLabel(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_IS_AIRPLAYING) {
     updateAriaLabel(this);
    }
   }
   /**
    * Are we currently airplaying
    */
   get mediaIsAirplaying() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_IS_AIRPLAYING);
   }
   set mediaIsAirplaying(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_IS_AIRPLAYING, value);
   }
   /**
    * Airplay unavailability state
    */
   get mediaAirplayUnavailable() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_AIRPLAY_UNAVAILABLE);
   }
   set mediaAirplayUnavailable(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_AIRPLAY_UNAVAILABLE, value);
   }
   handleClick() {
    const evt = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_AIRPLAY_REQUEST, {
     composed: true,
     bubbles: true,
    });
    this.dispatchEvent(evt);
   }
  }
  MediaAirplayButton.getSlotTemplateHTML = media_airplay_button_getSlotTemplateHTML;
  MediaAirplayButton.getTooltipContentHTML = media_airplay_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-airplay-button')) {
   GlobalThis.customElements.define('media-airplay-button', MediaAirplayButton);
  }
  var media_airplay_button_default = /* unused pure expression or super */ null && MediaAirplayButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-captions-button.js

  const ccIconOn = `<svg aria-hidden="true" viewBox="0 0 26 24">
  <path d="M22.83 5.68a2.58 2.58 0 0 0-2.3-2.5c-3.62-.24-11.44-.24-15.06 0a2.58 2.58 0 0 0-2.3 2.5c-.23 4.21-.23 8.43 0 12.64a2.58 2.58 0 0 0 2.3 2.5c3.62.24 11.44.24 15.06 0a2.58 2.58 0 0 0 2.3-2.5c.23-4.21.23-8.43 0-12.64Zm-11.39 9.45a3.07 3.07 0 0 1-1.91.57 3.06 3.06 0 0 1-2.34-1 3.75 3.75 0 0 1-.92-2.67 3.92 3.92 0 0 1 .92-2.77 3.18 3.18 0 0 1 2.43-1 2.94 2.94 0 0 1 2.13.78c.364.359.62.813.74 1.31l-1.43.35a1.49 1.49 0 0 0-1.51-1.17 1.61 1.61 0 0 0-1.29.58 2.79 2.79 0 0 0-.5 1.89 3 3 0 0 0 .49 1.93 1.61 1.61 0 0 0 1.27.58 1.48 1.48 0 0 0 1-.37 2.1 2.1 0 0 0 .59-1.14l1.4.44a3.23 3.23 0 0 1-1.07 1.69Zm7.22 0a3.07 3.07 0 0 1-1.91.57 3.06 3.06 0 0 1-2.34-1 3.75 3.75 0 0 1-.92-2.67 3.88 3.88 0 0 1 .93-2.77 3.14 3.14 0 0 1 2.42-1 3 3 0 0 1 2.16.82 2.8 2.8 0 0 1 .73 1.31l-1.43.35a1.49 1.49 0 0 0-1.51-1.21 1.61 1.61 0 0 0-1.29.58A2.79 2.79 0 0 0 15 12a3 3 0 0 0 .49 1.93 1.61 1.61 0 0 0 1.27.58 1.44 1.44 0 0 0 1-.37 2.1 2.1 0 0 0 .6-1.15l1.4.44a3.17 3.17 0 0 1-1.1 1.7Z"/>
</svg>`;
  const ccIconOff = `<svg aria-hidden="true" viewBox="0 0 26 24">
  <path d="M17.73 14.09a1.4 1.4 0 0 1-1 .37 1.579 1.579 0 0 1-1.27-.58A3 3 0 0 1 15 12a2.8 2.8 0 0 1 .5-1.85 1.63 1.63 0 0 1 1.29-.57 1.47 1.47 0 0 1 1.51 1.2l1.43-.34A2.89 2.89 0 0 0 19 9.07a3 3 0 0 0-2.14-.78 3.14 3.14 0 0 0-2.42 1 3.91 3.91 0 0 0-.93 2.78 3.74 3.74 0 0 0 .92 2.66 3.07 3.07 0 0 0 2.34 1 3.07 3.07 0 0 0 1.91-.57 3.17 3.17 0 0 0 1.07-1.74l-1.4-.45c-.083.43-.3.822-.62 1.12Zm-7.22 0a1.43 1.43 0 0 1-1 .37 1.58 1.58 0 0 1-1.27-.58A3 3 0 0 1 7.76 12a2.8 2.8 0 0 1 .5-1.85 1.63 1.63 0 0 1 1.29-.57 1.47 1.47 0 0 1 1.51 1.2l1.43-.34a2.81 2.81 0 0 0-.74-1.32 2.94 2.94 0 0 0-2.13-.78 3.18 3.18 0 0 0-2.43 1 4 4 0 0 0-.92 2.78 3.74 3.74 0 0 0 .92 2.66 3.07 3.07 0 0 0 2.34 1 3.07 3.07 0 0 0 1.91-.57 3.23 3.23 0 0 0 1.07-1.74l-1.4-.45a2.06 2.06 0 0 1-.6 1.07Zm12.32-8.41a2.59 2.59 0 0 0-2.3-2.51C18.72 3.05 15.86 3 13 3c-2.86 0-5.72.05-7.53.17a2.59 2.59 0 0 0-2.3 2.51c-.23 4.207-.23 8.423 0 12.63a2.57 2.57 0 0 0 2.3 2.5c1.81.13 4.67.19 7.53.19 2.86 0 5.72-.06 7.53-.19a2.57 2.57 0 0 0 2.3-2.5c.23-4.207.23-8.423 0-12.63Zm-1.49 12.53a1.11 1.11 0 0 1-.91 1.11c-1.67.11-4.45.18-7.43.18-2.98 0-5.76-.07-7.43-.18a1.11 1.11 0 0 1-.91-1.11c-.21-4.14-.21-8.29 0-12.43a1.11 1.11 0 0 1 .91-1.11C7.24 4.56 10 4.49 13 4.49s5.76.07 7.43.18a1.11 1.11 0 0 1 .91 1.11c.21 4.14.21 8.29 0 12.43Z"/>
</svg>`;
  function media_captions_button_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host([aria-checked="true"]) slot[name=off] {
        display: none !important;
      }

      ${/* Double negative, but safer if display doesn't equal 'block' */ ''}
      :host(:not([aria-checked="true"])) slot[name=on] {
        display: none !important;
      }

      :host([aria-checked="true"]) slot[name=tooltip-enable],
      :host(:not([aria-checked="true"])) slot[name=tooltip-disable] {
        display: none;
      }
    </style>

    <slot name="icon">
      <slot name="on">${ccIconOn}</slot>
      <slot name="off">${ccIconOff}</slot>
    </slot>
  `
   );
  }
  function media_captions_button_getTooltipContentHTML() {
   return (
    /*html*/
    `
    <slot name="tooltip-enable">${t('Enable captions')}</slot>
    <slot name="tooltip-disable">${t('Disable captions')}</slot>
  `
   );
  }
  const updateAriaChecked = (el) => {
   el.setAttribute('aria-checked', areSubsOn(el).toString());
  };
  class MediaCaptionsButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_SUBTITLES_LIST, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING];
   }
   connectedCallback() {
    super.connectedCallback();
    this.setAttribute('role', 'switch');
    this.setAttribute('aria-label', t('closed captions'));
    updateAriaChecked(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_SUBTITLES_SHOWING) {
     updateAriaChecked(this);
    }
   }
   /**
    * An array of TextTrack-like objects.
    * Objects must have the properties: kind, language, and label.
    */
   get mediaSubtitlesList() {
    return getSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_LIST);
   }
   set mediaSubtitlesList(list) {
    setSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_LIST, list);
   }
   /**
    * An array of TextTrack-like objects.
    * Objects must have the properties: kind, language, and label.
    */
   get mediaSubtitlesShowing() {
    return getSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING);
   }
   set mediaSubtitlesShowing(list) {
    setSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING, list);
   }
   handleClick() {
    this.dispatchEvent(
     new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_TOGGLE_SUBTITLES_REQUEST, {
      composed: true,
      bubbles: true,
     }),
    );
   }
  }
  MediaCaptionsButton.getSlotTemplateHTML = media_captions_button_getSlotTemplateHTML;
  MediaCaptionsButton.getTooltipContentHTML = media_captions_button_getTooltipContentHTML;
  const getSubtitlesListAttr = (el, attrName) => {
   const attrVal = el.getAttribute(attrName);
   return attrVal ? parseTextTracksStr(attrVal) : [];
  };
  const setSubtitlesListAttr = (el, attrName, list) => {
   if (!(list == null ? void 0 : list.length)) {
    el.removeAttribute(attrName);
    return;
   }
   const newValStr = stringifyTextTrackList(list);
   const oldVal = el.getAttribute(attrName);
   if (oldVal === newValStr) return;
   el.setAttribute(attrName, newValStr);
  };
  if (!GlobalThis.customElements.get('media-captions-button')) {
   GlobalThis.customElements.define('media-captions-button', MediaCaptionsButton);
  }
  var media_captions_button_default = /* unused pure expression or super */ null && MediaCaptionsButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-cast-button.js

  const enterIcon = `<svg aria-hidden="true" viewBox="0 0 24 24"><g><path class="cast_caf_icon_arch0" d="M1,18 L1,21 L4,21 C4,19.3 2.66,18 1,18 L1,18 Z"/><path class="cast_caf_icon_arch1" d="M1,14 L1,16 C3.76,16 6,18.2 6,21 L8,21 C8,17.13 4.87,14 1,14 L1,14 Z"/><path class="cast_caf_icon_arch2" d="M1,10 L1,12 C5.97,12 10,16.0 10,21 L12,21 C12,14.92 7.07,10 1,10 L1,10 Z"/><path class="cast_caf_icon_box" d="M21,3 L3,3 C1.9,3 1,3.9 1,5 L1,8 L3,8 L3,5 L21,5 L21,19 L14,19 L14,21 L21,21 C22.1,21 23,20.1 23,19 L23,5 C23,3.9 22.1,3 21,3 L21,3 Z"/></g></svg>`;
  const exitIcon = `<svg aria-hidden="true" viewBox="0 0 24 24"><g><path class="cast_caf_icon_arch0" d="M1,18 L1,21 L4,21 C4,19.3 2.66,18 1,18 L1,18 Z"/><path class="cast_caf_icon_arch1" d="M1,14 L1,16 C3.76,16 6,18.2 6,21 L8,21 C8,17.13 4.87,14 1,14 L1,14 Z"/><path class="cast_caf_icon_arch2" d="M1,10 L1,12 C5.97,12 10,16.0 10,21 L12,21 C12,14.92 7.07,10 1,10 L1,10 Z"/><path class="cast_caf_icon_box" d="M21,3 L3,3 C1.9,3 1,3.9 1,5 L1,8 L3,8 L3,5 L21,5 L21,19 L14,19 L14,21 L21,21 C22.1,21 23,20.1 23,19 L23,5 C23,3.9 22.1,3 21,3 L21,3 Z"/><path class="cast_caf_icon_boxfill" d="M5,7 L5,8.63 C8,8.6 13.37,14 13.37,17 L19,17 L19,7 Z"/></g></svg>`;
  function media_cast_button_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host([${MediaUIAttributes.MEDIA_IS_CASTING}]) slot[name=icon] slot:not([name=exit]) {
        display: none !important;
      }

      ${/* Double negative, but safer if display doesn't equal 'block' */ ''}
      :host(:not([${MediaUIAttributes.MEDIA_IS_CASTING}])) slot[name=icon] slot:not([name=enter]) {
        display: none !important;
      }

      :host([${MediaUIAttributes.MEDIA_IS_CASTING}]) slot[name=tooltip-enter],
      :host(:not([${MediaUIAttributes.MEDIA_IS_CASTING}])) slot[name=tooltip-exit] {
        display: none;
      }
    </style>

    <slot name="icon">
      <slot name="enter">${enterIcon}</slot>
      <slot name="exit">${exitIcon}</slot>
    </slot>
  `
   );
  }
  function media_cast_button_getTooltipContentHTML() {
   return (
    /*html*/
    `
    <slot name="tooltip-enter">${t('Start casting')}</slot>
    <slot name="tooltip-exit">${t('Stop casting')}</slot>
  `
   );
  }
  const media_cast_button_updateAriaLabel = (el) => {
   const label = el.mediaIsCasting ? t('stop casting') : t('start casting');
   el.setAttribute('aria-label', label);
  };
  class MediaCastButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_IS_CASTING, MediaUIAttributes.MEDIA_CAST_UNAVAILABLE];
   }
   connectedCallback() {
    super.connectedCallback();
    media_cast_button_updateAriaLabel(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_IS_CASTING) {
     media_cast_button_updateAriaLabel(this);
    }
   }
   /**
    * @type {boolean} Are we currently casting
    */
   get mediaIsCasting() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_IS_CASTING);
   }
   set mediaIsCasting(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_IS_CASTING, value);
   }
   /**
    * @type {string | undefined} Cast unavailability state
    */
   get mediaCastUnavailable() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_CAST_UNAVAILABLE);
   }
   set mediaCastUnavailable(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_CAST_UNAVAILABLE, value);
   }
   handleClick() {
    const eventName = this.mediaIsCasting ? MediaUIEvents.MEDIA_EXIT_CAST_REQUEST : MediaUIEvents.MEDIA_ENTER_CAST_REQUEST;
    this.dispatchEvent(new GlobalThis.CustomEvent(eventName, { composed: true, bubbles: true }));
   }
  }
  MediaCastButton.getSlotTemplateHTML = media_cast_button_getSlotTemplateHTML;
  MediaCastButton.getTooltipContentHTML = media_cast_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-cast-button')) {
   GlobalThis.customElements.define('media-cast-button', MediaCastButton);
  }
  var media_cast_button_default = /* unused pure expression or super */ null && MediaCastButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-chrome-dialog.js

  var media_chrome_dialog_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_chrome_dialog_privateGet = (obj, member, getter) => {
   media_chrome_dialog_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_chrome_dialog_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_chrome_dialog_privateSet = (obj, member, value, setter) => {
   media_chrome_dialog_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_chrome_dialog_privateMethod = (obj, member, method) => {
   media_chrome_dialog_accessCheck(obj, member, 'access private method');
   return method;
  };
  var _isInit, _previouslyFocused, _invokerElement, _init, init_fn, _handleOpen, handleOpen_fn, _handleClosed, handleClosed_fn, _handleInvoke, handleInvoke_fn, _handleFocusOut, handleFocusOut_fn, _handleKeyDown, handleKeyDown_fn;

  function media_chrome_dialog_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        font: var(--media-font,
          var(--media-font-weight, normal)
          var(--media-font-size, 14px) /
          var(--media-text-content-height, var(--media-control-height, 24px))
          var(--media-font-family, helvetica neue, segoe ui, roboto, arial, sans-serif));
        color: var(--media-text-color, var(--media-primary-color, rgb(238 238 238)));
        display: var(--media-dialog-display, inline-flex);
        justify-content: center;
        align-items: center;
        ${/** The hide transition is defined below after a short delay. */ ''}
        transition-behavior: allow-discrete;
        visibility: hidden;
        opacity: 0;
        transform: translateY(2px) scale(.99);
        pointer-events: none;
      }

      :host([open]) {
        transition: display .2s, visibility 0s, opacity .2s ease-out, transform .15s ease-out;
        visibility: visible;
        opacity: 1;
        transform: translateY(0) scale(1);
        pointer-events: auto;
      }

      #content {
        display: flex;
        position: relative;
        box-sizing: border-box;
        width: min(320px, 100%);
        word-wrap: break-word;
        max-height: 100%;
        overflow: auto;
        text-align: center;
        line-height: 1.4;
      }
    </style>
    ${this.getSlotTemplateHTML(_attrs)}
  `
   );
  }
  function media_chrome_dialog_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <slot id="content"></slot>
  `
   );
  }
  const media_chrome_dialog_Attributes = {
   OPEN: 'open',
   ANCHOR: 'anchor',
  };
  class MediaChromeDialog extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_chrome_dialog_privateAdd(this, _init);
    media_chrome_dialog_privateAdd(this, _handleOpen);
    media_chrome_dialog_privateAdd(this, _handleClosed);
    media_chrome_dialog_privateAdd(this, _handleInvoke);
    media_chrome_dialog_privateAdd(this, _handleFocusOut);
    media_chrome_dialog_privateAdd(this, _handleKeyDown);
    media_chrome_dialog_privateAdd(this, _isInit, false);
    media_chrome_dialog_privateAdd(this, _previouslyFocused, null);
    media_chrome_dialog_privateAdd(this, _invokerElement, null);
    this.addEventListener('invoke', this);
    this.addEventListener('focusout', this);
    this.addEventListener('keydown', this);
   }
   static get observedAttributes() {
    return [media_chrome_dialog_Attributes.OPEN, media_chrome_dialog_Attributes.ANCHOR];
   }
   get open() {
    return getBooleanAttr(this, media_chrome_dialog_Attributes.OPEN);
   }
   set open(value) {
    setBooleanAttr(this, media_chrome_dialog_Attributes.OPEN, value);
   }
   handleEvent(event) {
    switch (event.type) {
     case 'invoke':
      media_chrome_dialog_privateMethod(this, _handleInvoke, handleInvoke_fn).call(this, event);
      break;
     case 'focusout':
      media_chrome_dialog_privateMethod(this, _handleFocusOut, handleFocusOut_fn).call(this, event);
      break;
     case 'keydown':
      media_chrome_dialog_privateMethod(this, _handleKeyDown, handleKeyDown_fn).call(this, event);
      break;
    }
   }
   connectedCallback() {
    media_chrome_dialog_privateMethod(this, _init, init_fn).call(this);
    if (!this.role) {
     this.role = 'dialog';
    }
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    media_chrome_dialog_privateMethod(this, _init, init_fn).call(this);
    if (attrName === media_chrome_dialog_Attributes.OPEN && newValue !== oldValue) {
     if (this.open) {
      media_chrome_dialog_privateMethod(this, _handleOpen, handleOpen_fn).call(this);
     } else {
      media_chrome_dialog_privateMethod(this, _handleClosed, handleClosed_fn).call(this);
     }
    }
   }
   focus() {
    media_chrome_dialog_privateSet(this, _previouslyFocused, getActiveElement());
    const focusCancelled = !this.dispatchEvent(new Event('focus', { composed: true, cancelable: true }));
    const focusInCancelled = !this.dispatchEvent(new Event('focusin', { composed: true, bubbles: true, cancelable: true }));
    if (focusCancelled || focusInCancelled) return;
    const focusable = this.querySelector('[autofocus], [tabindex]:not([tabindex="-1"]), [role="menu"]');
    focusable == null ? void 0 : focusable.focus();
   }
   get keysUsed() {
    return ['Escape', 'Tab'];
   }
  }
  _isInit = new WeakMap();
  _previouslyFocused = new WeakMap();
  _invokerElement = new WeakMap();
  _init = new WeakSet();
  init_fn = function () {
   if (media_chrome_dialog_privateGet(this, _isInit)) return;
   media_chrome_dialog_privateSet(this, _isInit, true);
   if (!this.shadowRoot) {
    this.attachShadow(this.constructor.shadowRootOptions);
    const attrs = namedNodeMapToObject(this.attributes);
    this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    queueMicrotask(() => {
     const { style } = getOrInsertCSSRule(this.shadowRoot, ':host');
     style.setProperty('transition', `display .15s, visibility .15s, opacity .15s ease-in, transform .15s ease-in`);
    });
   }
  };
  _handleOpen = new WeakSet();
  handleOpen_fn = function () {
   var _a;
   (_a = media_chrome_dialog_privateGet(this, _invokerElement)) == null ? void 0 : _a.setAttribute('aria-expanded', 'true');
   this.dispatchEvent(new Event('open', { composed: true, bubbles: true }));
   this.addEventListener('transitionend', () => this.focus(), { once: true });
  };
  _handleClosed = new WeakSet();
  handleClosed_fn = function () {
   var _a;
   (_a = media_chrome_dialog_privateGet(this, _invokerElement)) == null ? void 0 : _a.setAttribute('aria-expanded', 'false');
   this.dispatchEvent(new Event('close', { composed: true, bubbles: true }));
  };
  _handleInvoke = new WeakSet();
  handleInvoke_fn = function (event) {
   media_chrome_dialog_privateSet(this, _invokerElement, event.relatedTarget);
   if (!containsComposedNode(this, event.relatedTarget)) {
    this.open = !this.open;
   }
  };
  _handleFocusOut = new WeakSet();
  handleFocusOut_fn = function (event) {
   var _a;
   if (!containsComposedNode(this, event.relatedTarget)) {
    (_a = media_chrome_dialog_privateGet(this, _previouslyFocused)) == null ? void 0 : _a.focus();
    if (media_chrome_dialog_privateGet(this, _invokerElement) && media_chrome_dialog_privateGet(this, _invokerElement) !== event.relatedTarget && this.open) {
     this.open = false;
    }
   }
  };
  _handleKeyDown = new WeakSet();
  handleKeyDown_fn = function (event) {
   var _a, _b, _c, _d, _e;
   const { key, ctrlKey, altKey, metaKey } = event;
   if (ctrlKey || altKey || metaKey) {
    return;
   }
   if (!this.keysUsed.includes(key)) {
    return;
   }
   event.preventDefault();
   event.stopPropagation();
   if (key === 'Tab') {
    if (event.shiftKey) {
     (_b = (_a = this.previousElementSibling) == null ? void 0 : _a.focus) == null ? void 0 : _b.call(_a);
    } else {
     (_d = (_c = this.nextElementSibling) == null ? void 0 : _c.focus) == null ? void 0 : _d.call(_c);
    }
    this.blur();
   } else if (key === 'Escape') {
    (_e = media_chrome_dialog_privateGet(this, _previouslyFocused)) == null ? void 0 : _e.focus();
    this.open = false;
   }
  };
  MediaChromeDialog.shadowRootOptions = { mode: 'open' };
  MediaChromeDialog.getTemplateHTML = media_chrome_dialog_getTemplateHTML;
  MediaChromeDialog.getSlotTemplateHTML = media_chrome_dialog_getSlotTemplateHTML;
  if (!GlobalThis.customElements.get('media-chrome-dialog')) {
   GlobalThis.customElements.define('media-chrome-dialog', MediaChromeDialog);
  }
  var media_chrome_dialog_default = /* unused pure expression or super */ null && MediaChromeDialog; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-chrome-range.js

  var media_chrome_range_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_chrome_range_privateGet = (obj, member, getter) => {
   media_chrome_range_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_chrome_range_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_chrome_range_privateSet = (obj, member, value, setter) => {
   media_chrome_range_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_chrome_range_privateMethod = (obj, member, method) => {
   media_chrome_range_accessCheck(obj, member, 'access private method');
   return method;
  };
  var media_chrome_range_mediaController, _isInputTarget, _startpoint, _endpoint, _cssRules, _segments, _onFocusIn, _onFocusOut, _updateComputedStyles, _updateActiveSegment, updateActiveSegment_fn, _enableUserEvents, enableUserEvents_fn, _disableUserEvents, disableUserEvents_fn, _handlePointerDown, handlePointerDown_fn, _handlePointerEnter, handlePointerEnter_fn, media_chrome_range_handlePointerUp, media_chrome_range_handlePointerUp_fn, _handlePointerLeave, handlePointerLeave_fn, media_chrome_range_handlePointerMove, media_chrome_range_handlePointerMove_fn;

  function media_chrome_range_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        --_focus-box-shadow: var(--media-focus-box-shadow, inset 0 0 0 2px rgb(27 127 204 / .9));
        --_media-range-padding: var(--media-range-padding, var(--media-control-padding, 10px));

        box-shadow: var(--_focus-visible-box-shadow, none);
        background: var(--media-control-background, var(--media-secondary-color, rgb(20 20 30 / .7)));
        height: calc(var(--media-control-height, 24px) + 2 * var(--_media-range-padding));
        display: inline-flex;
        align-items: center;
        ${/* Don't horizontal align w/ justify-content! #container can go negative on the x-axis w/ small width. */ ''}
        vertical-align: middle;
        box-sizing: border-box;
        position: relative;
        width: 100px;
        transition: background .15s linear;
        cursor: var(--media-cursor, pointer);
        pointer-events: auto;
        touch-action: none; ${/* Prevent scrolling when dragging on mobile. */ ''}
      }

      ${/* Reset before `outline` on track could be set by a CSS var */ ''}
      input[type=range]:focus {
        outline: 0;
      }
      input[type=range]:focus::-webkit-slider-runnable-track {
        outline: 0;
      }

      :host(:hover) {
        background: var(--media-control-hover-background, rgb(50 50 70 / .7));
      }

      #leftgap {
        padding-left: var(--media-range-padding-left, var(--_media-range-padding));
      }

      #rightgap {
        padding-right: var(--media-range-padding-right, var(--_media-range-padding));
      }

      #startpoint,
      #endpoint {
        position: absolute;
      }

      #endpoint {
        right: 0;
      }

      #container {
        ${/* Not using the CSS `padding` prop makes it easier for slide open volume ranges so the width can be zero. */ ''}
        width: var(--media-range-track-width, 100%);
        transform: translate(var(--media-range-track-translate-x, 0px), var(--media-range-track-translate-y, 0px));
        position: relative;
        height: 100%;
        display: flex;
        align-items: center;
        min-width: 40px;
      }

      #range {
        ${/* The input range acts as a hover and hit zone for input events. */ ''}
        display: var(--media-time-range-hover-display, block);
        bottom: var(--media-time-range-hover-bottom, -7px);
        height: var(--media-time-range-hover-height, max(100% + 7px, 25px));
        width: 100%;
        position: absolute;
        cursor: var(--media-cursor, pointer);

        -webkit-appearance: none; ${/* Hides the slider so that custom slider can be made */ ''}
        -webkit-tap-highlight-color: transparent;
        background: transparent; ${/* Otherwise white in Chrome */ ''}
        margin: 0;
        z-index: 1;
      }

      @media (hover: hover) {
        #range {
          bottom: var(--media-time-range-hover-bottom, -5px);
          height: var(--media-time-range-hover-height, max(100% + 5px, 20px));
        }
      }

      ${/* Special styling for WebKit/Blink */ ''}
      ${/* Make thumb width/height small so it has no effect on range click position. */ ''}
      #range::-webkit-slider-thumb {
        -webkit-appearance: none;
        background: transparent;
        width: .1px;
        height: .1px;
      }

      ${/* The thumb is not positioned relative to the track in Firefox */ ''}
      #range::-moz-range-thumb {
        background: transparent;
        border: transparent;
        width: .1px;
        height: .1px;
      }

      #appearance {
        height: var(--media-range-track-height, 4px);
        display: flex;
        flex-direction: column;
        justify-content: center;
        width: 100%;
        position: absolute;
        ${/* Required for Safari to stop glitching track height on hover */ ''}
        will-change: transform;
      }

      #track {
        background: var(--media-range-track-background, rgb(255 255 255 / .2));
        border-radius: var(--media-range-track-border-radius, 1px);
        border: var(--media-range-track-border, none);
        outline: var(--media-range-track-outline);
        outline-offset: var(--media-range-track-outline-offset);
        backdrop-filter: var(--media-range-track-backdrop-filter);
        -webkit-backdrop-filter: var(--media-range-track-backdrop-filter);
        box-shadow: var(--media-range-track-box-shadow, none);
        position: absolute;
        width: 100%;
        height: 100%;
        overflow: hidden;
      }

      #progress,
      #pointer {
        position: absolute;
        height: 100%;
        will-change: width;
      }

      #progress {
        background: var(--media-range-bar-color, var(--media-primary-color, rgb(238 238 238)));
        transition: var(--media-range-track-transition);
      }

      #pointer {
        background: var(--media-range-track-pointer-background);
        border-right: var(--media-range-track-pointer-border-right);
        transition: visibility .25s, opacity .25s;
        visibility: hidden;
        opacity: 0;
      }

      @media (hover: hover) {
        :host(:hover) #pointer {
          transition: visibility .5s, opacity .5s;
          visibility: visible;
          opacity: 1;
        }
      }

      #thumb,
      ::slotted([slot=thumb]) {
        width: var(--media-range-thumb-width, 10px);
        height: var(--media-range-thumb-height, 10px);
        transition: var(--media-range-thumb-transition);
        transform: var(--media-range-thumb-transform, none);
        opacity: var(--media-range-thumb-opacity, 1);
        translate: -50%;
        position: absolute;
        left: 0;
        cursor: var(--media-cursor, pointer);
      }

      #thumb {
        border-radius: var(--media-range-thumb-border-radius, 10px);
        background: var(--media-range-thumb-background, var(--media-primary-color, rgb(238 238 238)));
        box-shadow: var(--media-range-thumb-box-shadow, 1px 1px 1px transparent);
        border: var(--media-range-thumb-border, none);
      }

      :host([disabled]) #thumb {
        background-color: #777;
      }

      .segments #appearance {
        height: var(--media-range-segment-hover-height, 7px);
      }

      #track {
        clip-path: url(#segments-clipping);
      }

      #segments {
        --segments-gap: var(--media-range-segments-gap, 2px);
        position: absolute;
        width: 100%;
        height: 100%;
      }

      #segments-clipping {
        transform: translateX(calc(var(--segments-gap) / 2));
      }

      #segments-clipping:empty {
        display: none;
      }

      #segments-clipping rect {
        height: var(--media-range-track-height, 4px);
        y: calc((var(--media-range-segment-hover-height, 7px) - var(--media-range-track-height, 4px)) / 2);
        transition: var(--media-range-segment-transition, transform .1s ease-in-out);
        transform: var(--media-range-segment-transform, scaleY(1));
        transform-origin: center;
      }
    </style>
    <div id="leftgap"></div>
    <div id="container">
      <div id="startpoint"></div>
      <div id="endpoint"></div>
      <div id="appearance">
        <div id="track" part="track">
          <div id="pointer"></div>
          <div id="progress" part="progress"></div>
        </div>
        <slot name="thumb">
          <div id="thumb" part="thumb"></div>
        </slot>
        <svg id="segments"><clipPath id="segments-clipping"></clipPath></svg>
      </div>
      <input id="range" type="range" min="0" max="1" step="any" value="0">
    </div>
    <div id="rightgap"></div>
  `
   );
  }
  class MediaChromeRange extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_chrome_range_privateAdd(this, _updateActiveSegment);
    media_chrome_range_privateAdd(this, _enableUserEvents);
    media_chrome_range_privateAdd(this, _disableUserEvents);
    media_chrome_range_privateAdd(this, _handlePointerDown);
    media_chrome_range_privateAdd(this, _handlePointerEnter);
    media_chrome_range_privateAdd(this, media_chrome_range_handlePointerUp);
    media_chrome_range_privateAdd(this, _handlePointerLeave);
    media_chrome_range_privateAdd(this, media_chrome_range_handlePointerMove);
    media_chrome_range_privateAdd(this, media_chrome_range_mediaController, void 0);
    media_chrome_range_privateAdd(this, _isInputTarget, void 0);
    media_chrome_range_privateAdd(this, _startpoint, void 0);
    media_chrome_range_privateAdd(this, _endpoint, void 0);
    media_chrome_range_privateAdd(this, _cssRules, {});
    media_chrome_range_privateAdd(this, _segments, []);
    media_chrome_range_privateAdd(this, _onFocusIn, () => {
     if (this.range.matches(':focus-visible')) {
      const { style } = getOrInsertCSSRule(this.shadowRoot, ':host');
      style.setProperty('--_focus-visible-box-shadow', 'var(--_focus-box-shadow)');
     }
    });
    media_chrome_range_privateAdd(this, _onFocusOut, () => {
     const { style } = getOrInsertCSSRule(this.shadowRoot, ':host');
     style.removeProperty('--_focus-visible-box-shadow');
    });
    media_chrome_range_privateAdd(this, _updateComputedStyles, () => {
     const clipping = this.shadowRoot.querySelector('#segments-clipping');
     if (clipping) clipping.parentNode.append(clipping);
    });
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     const html = this.constructor.getTemplateHTML(attrs);
     this.shadowRoot.setHTMLUnsafe ? this.shadowRoot.setHTMLUnsafe(html) : (this.shadowRoot.innerHTML = html);
    }
    this.container = this.shadowRoot.querySelector('#container');
    media_chrome_range_privateSet(this, _startpoint, this.shadowRoot.querySelector('#startpoint'));
    media_chrome_range_privateSet(this, _endpoint, this.shadowRoot.querySelector('#endpoint'));
    this.range = this.shadowRoot.querySelector('#range');
    this.appearance = this.shadowRoot.querySelector('#appearance');
   }
   static get observedAttributes() {
    return ['disabled', 'aria-disabled', MediaStateReceiverAttributes.MEDIA_CONTROLLER];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d, _e;
    if (attrName === MediaStateReceiverAttributes.MEDIA_CONTROLLER) {
     if (oldValue) {
      (_b = (_a = media_chrome_range_privateGet(this, media_chrome_range_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
      media_chrome_range_privateSet(this, media_chrome_range_mediaController, null);
     }
     if (newValue && this.isConnected) {
      media_chrome_range_privateSet(this, media_chrome_range_mediaController, (_c = this.getRootNode()) == null ? void 0 : _c.getElementById(newValue));
      (_e = (_d = media_chrome_range_privateGet(this, media_chrome_range_mediaController)) == null ? void 0 : _d.associateElement) == null ? void 0 : _e.call(_d, this);
     }
    } else if (attrName === 'disabled' || (attrName === 'aria-disabled' && oldValue !== newValue)) {
     if (newValue == null) {
      this.range.removeAttribute(attrName);
      media_chrome_range_privateMethod(this, _enableUserEvents, enableUserEvents_fn).call(this);
     } else {
      this.range.setAttribute(attrName, newValue);
      media_chrome_range_privateMethod(this, _disableUserEvents, disableUserEvents_fn).call(this);
     }
    }
   }
   connectedCallback() {
    var _a, _b, _c;
    const { style } = getOrInsertCSSRule(this.shadowRoot, ':host');
    style.setProperty('display', `var(--media-control-display, var(--${this.localName}-display, inline-flex))`);
    media_chrome_range_privateGet(this, _cssRules).pointer = getOrInsertCSSRule(this.shadowRoot, '#pointer');
    media_chrome_range_privateGet(this, _cssRules).progress = getOrInsertCSSRule(this.shadowRoot, '#progress');
    media_chrome_range_privateGet(this, _cssRules).thumb = getOrInsertCSSRule(this.shadowRoot, '#thumb, ::slotted([slot="thumb"])');
    media_chrome_range_privateGet(this, _cssRules).activeSegment = getOrInsertCSSRule(this.shadowRoot, '#segments-clipping rect:nth-child(0)');
    const mediaControllerId = this.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER);
    if (mediaControllerId) {
     media_chrome_range_privateSet(this, media_chrome_range_mediaController, (_a = this.getRootNode()) == null ? void 0 : _a.getElementById(mediaControllerId));
     (_c = (_b = media_chrome_range_privateGet(this, media_chrome_range_mediaController)) == null ? void 0 : _b.associateElement) == null ? void 0 : _c.call(_b, this);
    }
    this.updateBar();
    this.shadowRoot.addEventListener('focusin', media_chrome_range_privateGet(this, _onFocusIn));
    this.shadowRoot.addEventListener('focusout', media_chrome_range_privateGet(this, _onFocusOut));
    media_chrome_range_privateMethod(this, _enableUserEvents, enableUserEvents_fn).call(this);
    observeResize(this.container, media_chrome_range_privateGet(this, _updateComputedStyles));
   }
   disconnectedCallback() {
    var _a, _b;
    media_chrome_range_privateMethod(this, _disableUserEvents, disableUserEvents_fn).call(this);
    (_b = (_a = media_chrome_range_privateGet(this, media_chrome_range_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
    media_chrome_range_privateSet(this, media_chrome_range_mediaController, null);
    this.shadowRoot.removeEventListener('focusin', media_chrome_range_privateGet(this, _onFocusIn));
    this.shadowRoot.removeEventListener('focusout', media_chrome_range_privateGet(this, _onFocusOut));
    unobserveResize(this.container, media_chrome_range_privateGet(this, _updateComputedStyles));
   }
   updatePointerBar(evt) {
    var _a;
    (_a = media_chrome_range_privateGet(this, _cssRules).pointer) == null ? void 0 : _a.style.setProperty('width', `${this.getPointerRatio(evt) * 100}%`);
   }
   updateBar() {
    var _a, _b;
    const rangePercent = this.range.valueAsNumber * 100;
    (_a = media_chrome_range_privateGet(this, _cssRules).progress) == null ? void 0 : _a.style.setProperty('width', `${rangePercent}%`);
    (_b = media_chrome_range_privateGet(this, _cssRules).thumb) == null ? void 0 : _b.style.setProperty('left', `${rangePercent}%`);
   }
   updateSegments(segments) {
    const clipping = this.shadowRoot.querySelector('#segments-clipping');
    clipping.textContent = '';
    this.container.classList.toggle('segments', !!(segments == null ? void 0 : segments.length));
    if (!(segments == null ? void 0 : segments.length)) return;
    const normalized = [.../* @__PURE__ */ new Set([+this.range.min, ...segments.flatMap((s) => [s.start, s.end]), +this.range.max])];
    media_chrome_range_privateSet(this, _segments, [...normalized]);
    const lastMarker = normalized.pop();
    for (const [i, marker] of normalized.entries()) {
     const [isFirst, isLast] = [i === 0, i === normalized.length - 1];
     const x = isFirst ? 'calc(var(--segments-gap) / -1)' : `${marker * 100}%`;
     const x2 = isLast ? lastMarker : normalized[i + 1];
     const width = `calc(${(x2 - marker) * 100}%${isFirst || isLast ? '' : ` - var(--segments-gap)`})`;
     const segmentEl = server_safe_globals_Document.createElementNS('http://www.w3.org/2000/svg', 'rect');
     const cssRule = getOrInsertCSSRule(this.shadowRoot, `#segments-clipping rect:nth-child(${i + 1})`);
     cssRule.style.setProperty('x', x);
     cssRule.style.setProperty('width', width);
     clipping.append(segmentEl);
    }
   }
   getPointerRatio(evt) {
    return getPointProgressOnLine(evt.clientX, evt.clientY, media_chrome_range_privateGet(this, _startpoint).getBoundingClientRect(), media_chrome_range_privateGet(this, _endpoint).getBoundingClientRect());
   }
   get dragging() {
    return this.hasAttribute('dragging');
   }
   handleEvent(evt) {
    switch (evt.type) {
     case 'pointermove':
      media_chrome_range_privateMethod(this, media_chrome_range_handlePointerMove, media_chrome_range_handlePointerMove_fn).call(this, evt);
      break;
     case 'input':
      this.updateBar();
      break;
     case 'pointerenter':
      media_chrome_range_privateMethod(this, _handlePointerEnter, handlePointerEnter_fn).call(this, evt);
      break;
     case 'pointerdown':
      media_chrome_range_privateMethod(this, _handlePointerDown, handlePointerDown_fn).call(this, evt);
      break;
     case 'pointerup':
      media_chrome_range_privateMethod(this, media_chrome_range_handlePointerUp, media_chrome_range_handlePointerUp_fn).call(this);
      break;
     case 'pointerleave':
      media_chrome_range_privateMethod(this, _handlePointerLeave, handlePointerLeave_fn).call(this);
      break;
    }
   }
   get keysUsed() {
    return ['ArrowUp', 'ArrowRight', 'ArrowDown', 'ArrowLeft'];
   }
  }
  media_chrome_range_mediaController = new WeakMap();
  _isInputTarget = new WeakMap();
  _startpoint = new WeakMap();
  _endpoint = new WeakMap();
  _cssRules = new WeakMap();
  _segments = new WeakMap();
  _onFocusIn = new WeakMap();
  _onFocusOut = new WeakMap();
  _updateComputedStyles = new WeakMap();
  _updateActiveSegment = new WeakSet();
  updateActiveSegment_fn = function (evt) {
   const rule = media_chrome_range_privateGet(this, _cssRules).activeSegment;
   if (!rule) return;
   const pointerRatio = this.getPointerRatio(evt);
   const segmentIndex = media_chrome_range_privateGet(this, _segments).findIndex((start, i, arr) => {
    const end = arr[i + 1];
    return end != null && pointerRatio >= start && pointerRatio <= end;
   });
   const selectorText = `#segments-clipping rect:nth-child(${segmentIndex + 1})`;
   if (rule.selectorText != selectorText || !rule.style.transform) {
    rule.selectorText = selectorText;
    rule.style.setProperty('transform', 'var(--media-range-segment-hover-transform, scaleY(2))');
   }
  };
  _enableUserEvents = new WeakSet();
  enableUserEvents_fn = function () {
   if (this.hasAttribute('disabled')) return;
   this.addEventListener('input', this);
   this.addEventListener('pointerdown', this);
   this.addEventListener('pointerenter', this);
  };
  _disableUserEvents = new WeakSet();
  disableUserEvents_fn = function () {
   var _a, _b;
   this.removeEventListener('input', this);
   this.removeEventListener('pointerdown', this);
   this.removeEventListener('pointerenter', this);
   (_a = GlobalThis.window) == null ? void 0 : _a.removeEventListener('pointerup', this);
   (_b = GlobalThis.window) == null ? void 0 : _b.removeEventListener('pointermove', this);
  };
  _handlePointerDown = new WeakSet();
  handlePointerDown_fn = function (evt) {
   var _a;
   media_chrome_range_privateSet(this, _isInputTarget, evt.composedPath().includes(this.range));
   (_a = GlobalThis.window) == null ? void 0 : _a.addEventListener('pointerup', this);
  };
  _handlePointerEnter = new WeakSet();
  handlePointerEnter_fn = function (evt) {
   var _a;
   if (evt.pointerType !== 'mouse') media_chrome_range_privateMethod(this, _handlePointerDown, handlePointerDown_fn).call(this, evt);
   this.addEventListener('pointerleave', this);
   (_a = GlobalThis.window) == null ? void 0 : _a.addEventListener('pointermove', this);
  };
  media_chrome_range_handlePointerUp = new WeakSet();
  media_chrome_range_handlePointerUp_fn = function () {
   var _a;
   (_a = GlobalThis.window) == null ? void 0 : _a.removeEventListener('pointerup', this);
   this.toggleAttribute('dragging', false);
   this.range.disabled = this.hasAttribute('disabled');
  };
  _handlePointerLeave = new WeakSet();
  handlePointerLeave_fn = function () {
   var _a, _b;
   this.removeEventListener('pointerleave', this);
   (_a = GlobalThis.window) == null ? void 0 : _a.removeEventListener('pointermove', this);
   this.toggleAttribute('dragging', false);
   this.range.disabled = this.hasAttribute('disabled');
   (_b = media_chrome_range_privateGet(this, _cssRules).activeSegment) == null ? void 0 : _b.style.removeProperty('transform');
  };
  media_chrome_range_handlePointerMove = new WeakSet();
  media_chrome_range_handlePointerMove_fn = function (evt) {
   this.toggleAttribute('dragging', evt.buttons === 1 || evt.pointerType !== 'mouse');
   this.updatePointerBar(evt);
   media_chrome_range_privateMethod(this, _updateActiveSegment, updateActiveSegment_fn).call(this, evt);
   if (this.dragging && (evt.pointerType !== 'mouse' || !media_chrome_range_privateGet(this, _isInputTarget))) {
    this.range.disabled = true;
    this.range.valueAsNumber = this.getPointerRatio(evt);
    this.range.dispatchEvent(new Event('input', { bubbles: true, composed: true }));
   }
  };
  MediaChromeRange.shadowRootOptions = { mode: 'open' };
  MediaChromeRange.getTemplateHTML = media_chrome_range_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-chrome-range')) {
   GlobalThis.customElements.define('media-chrome-range', MediaChromeRange);
  }
  var media_chrome_range_default = /* unused pure expression or super */ null && MediaChromeRange; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-control-bar.js

  var media_control_bar_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_control_bar_privateGet = (obj, member, getter) => {
   media_control_bar_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_control_bar_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_control_bar_privateSet = (obj, member, value, setter) => {
   media_control_bar_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_control_bar_mediaController;

  function media_control_bar_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        ${/* Need position to display above video for some reason */ ''}
        box-sizing: border-box;
        display: var(--media-control-display, var(--media-control-bar-display, inline-flex));
        color: var(--media-text-color, var(--media-primary-color, rgb(238 238 238)));
        --media-loading-indicator-icon-height: 44px;
      }

      ::slotted(media-time-range),
      ::slotted(media-volume-range) {
        min-height: 100%;
      }

      ::slotted(media-time-range),
      ::slotted(media-clip-selector) {
        flex-grow: 1;
      }

      ::slotted([role="menu"]) {
        position: absolute;
      }
    </style>

    <slot></slot>
  `
   );
  }
  class MediaControlBar extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_control_bar_privateAdd(this, media_control_bar_mediaController, void 0);
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
   }
   static get observedAttributes() {
    return [MediaStateReceiverAttributes.MEDIA_CONTROLLER];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d, _e;
    if (attrName === MediaStateReceiverAttributes.MEDIA_CONTROLLER) {
     if (oldValue) {
      (_b = (_a = media_control_bar_privateGet(this, media_control_bar_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
      media_control_bar_privateSet(this, media_control_bar_mediaController, null);
     }
     if (newValue && this.isConnected) {
      media_control_bar_privateSet(this, media_control_bar_mediaController, (_c = this.getRootNode()) == null ? void 0 : _c.getElementById(newValue));
      (_e = (_d = media_control_bar_privateGet(this, media_control_bar_mediaController)) == null ? void 0 : _d.associateElement) == null ? void 0 : _e.call(_d, this);
     }
    }
   }
   connectedCallback() {
    var _a, _b, _c;
    const mediaControllerId = this.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER);
    if (mediaControllerId) {
     media_control_bar_privateSet(this, media_control_bar_mediaController, (_a = this.getRootNode()) == null ? void 0 : _a.getElementById(mediaControllerId));
     (_c = (_b = media_control_bar_privateGet(this, media_control_bar_mediaController)) == null ? void 0 : _b.associateElement) == null ? void 0 : _c.call(_b, this);
    }
   }
   disconnectedCallback() {
    var _a, _b;
    (_b = (_a = media_control_bar_privateGet(this, media_control_bar_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
    media_control_bar_privateSet(this, media_control_bar_mediaController, null);
   }
  }
  media_control_bar_mediaController = new WeakMap();
  MediaControlBar.shadowRootOptions = { mode: 'open' };
  MediaControlBar.getTemplateHTML = media_control_bar_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-control-bar')) {
   GlobalThis.customElements.define('media-control-bar', MediaControlBar);
  }
  var media_control_bar_default = /* unused pure expression or super */ null && MediaControlBar; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-text-display.js

  var media_text_display_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_text_display_privateGet = (obj, member, getter) => {
   media_text_display_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_text_display_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_text_display_privateSet = (obj, member, value, setter) => {
   media_text_display_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_text_display_mediaController;

  function media_text_display_getTemplateHTML(_attrs, _props = {}) {
   return (
    /*html*/
    `
    <style>
      :host {
        font: var(--media-font,
          var(--media-font-weight, normal)
          var(--media-font-size, 14px) /
          var(--media-text-content-height, var(--media-control-height, 24px))
          var(--media-font-family, helvetica neue, segoe ui, roboto, arial, sans-serif));
        color: var(--media-text-color, var(--media-primary-color, rgb(238 238 238)));
        background: var(--media-text-background, var(--media-control-background, var(--media-secondary-color, rgb(20 20 30 / .7))));
        padding: var(--media-control-padding, 10px);
        display: inline-flex;
        justify-content: center;
        align-items: center;
        vertical-align: middle;
        box-sizing: border-box;
        text-align: center;
        pointer-events: auto;
      }

      ${
       /*
      Only show outline when keyboard focusing.
      https://drafts.csswg.org/selectors-4/#the-focus-visible-pseudo
    */
       ''
      }
      :host(:focus-visible) {
        box-shadow: inset 0 0 0 2px rgb(27 127 204 / .9);
        outline: 0;
      }

      ${
       /*
        * hide default focus ring, particularly when using mouse
        */
       ''
      }
      :host(:where(:focus)) {
        box-shadow: none;
        outline: 0;
      }
    </style>

    ${this.getSlotTemplateHTML(_attrs, _props)}
  `
   );
  }
  function media_text_display_getSlotTemplateHTML(_attrs, _props) {
   return (
    /*html*/
    `
    <slot></slot>
  `
   );
  }
  class MediaTextDisplay extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_text_display_privateAdd(this, media_text_display_mediaController, void 0);
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
   }
   static get observedAttributes() {
    return [MediaStateReceiverAttributes.MEDIA_CONTROLLER];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d, _e;
    if (attrName === MediaStateReceiverAttributes.MEDIA_CONTROLLER) {
     if (oldValue) {
      (_b = (_a = media_text_display_privateGet(this, media_text_display_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
      media_text_display_privateSet(this, media_text_display_mediaController, null);
     }
     if (newValue && this.isConnected) {
      media_text_display_privateSet(this, media_text_display_mediaController, (_c = this.getRootNode()) == null ? void 0 : _c.getElementById(newValue));
      (_e = (_d = media_text_display_privateGet(this, media_text_display_mediaController)) == null ? void 0 : _d.associateElement) == null ? void 0 : _e.call(_d, this);
     }
    }
   }
   connectedCallback() {
    var _a, _b, _c;
    const { style } = getOrInsertCSSRule(this.shadowRoot, ':host');
    style.setProperty('display', `var(--media-control-display, var(--${this.localName}-display, inline-flex))`);
    const mediaControllerId = this.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER);
    if (mediaControllerId) {
     media_text_display_privateSet(this, media_text_display_mediaController, (_a = this.getRootNode()) == null ? void 0 : _a.getElementById(mediaControllerId));
     (_c = (_b = media_text_display_privateGet(this, media_text_display_mediaController)) == null ? void 0 : _b.associateElement) == null ? void 0 : _c.call(_b, this);
    }
   }
   disconnectedCallback() {
    var _a, _b;
    (_b = (_a = media_text_display_privateGet(this, media_text_display_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
    media_text_display_privateSet(this, media_text_display_mediaController, null);
   }
  }
  media_text_display_mediaController = new WeakMap();
  MediaTextDisplay.shadowRootOptions = { mode: 'open' };
  MediaTextDisplay.getTemplateHTML = media_text_display_getTemplateHTML;
  MediaTextDisplay.getSlotTemplateHTML = media_text_display_getSlotTemplateHTML;
  if (!GlobalThis.customElements.get('media-text-display')) {
   GlobalThis.customElements.define('media-text-display', MediaTextDisplay);
  }
  var media_text_display_default = /* unused pure expression or super */ null && MediaTextDisplay; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-duration-display.js

  var media_duration_display_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_duration_display_privateGet = (obj, member, getter) => {
   media_duration_display_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_duration_display_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_duration_display_privateSet = (obj, member, value, setter) => {
   media_duration_display_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var _slot;

  function media_duration_display_getSlotTemplateHTML(_attrs, props) {
   return (
    /*html*/
    `
    <slot>${formatTime(props.mediaDuration)}</slot>
  `
   );
  }
  class MediaDurationDisplay extends MediaTextDisplay {
   constructor() {
    var _a;
    super();
    media_duration_display_privateAdd(this, _slot, void 0);
    media_duration_display_privateSet(this, _slot, this.shadowRoot.querySelector('slot'));
    media_duration_display_privateGet(this, _slot).textContent = formatTime((_a = this.mediaDuration) != null ? _a : 0);
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_DURATION];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    if (attrName === MediaUIAttributes.MEDIA_DURATION) {
     media_duration_display_privateGet(this, _slot).textContent = formatTime(+newValue);
    }
    super.attributeChangedCallback(attrName, oldValue, newValue);
   }
   /**
    * @type {number | undefined} In seconds
    */
   get mediaDuration() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_DURATION);
   }
   set mediaDuration(time) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_DURATION, time);
   }
  }
  _slot = new WeakMap();
  MediaDurationDisplay.getSlotTemplateHTML = media_duration_display_getSlotTemplateHTML;
  if (!GlobalThis.customElements.get('media-duration-display')) {
   GlobalThis.customElements.define('media-duration-display', MediaDurationDisplay);
  }
  var media_duration_display_default = /* unused pure expression or super */ null && MediaDurationDisplay; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/labels/labels.js

  const defaultErrorTitles = {
   2: t('Network Error'),
   3: t('Decode Error'),
   4: t('Source Not Supported'),
   5: t('Encryption Error'),
  };
  const defaultErrorMessages = {
   2: t('A network error caused the media download to fail.'),
   3: t('A media error caused playback to be aborted. The media could be corrupt or your browser does not support this format.'),
   4: t('An unsupported error occurred. The server or network failed, or your browser does not support this format.'),
   5: t('The media is encrypted and there are no keys to decrypt it.'),
  };
  const formatError = (error) => {
   var _a, _b;
   if (error.code === 1) return null;
   return {
    title: (_a = defaultErrorTitles[error.code]) != null ? _a : `Error ${error.code}`,
    message: (_b = defaultErrorMessages[error.code]) != null ? _b : error.message,
   };
  }; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-error-dialog.js

  var media_error_dialog_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_error_dialog_privateGet = (obj, member, getter) => {
   media_error_dialog_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_error_dialog_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_error_dialog_privateSet = (obj, member, value, setter) => {
   media_error_dialog_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var _mediaError;

  function media_error_dialog_getSlotTemplateHTML(attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        background: rgb(20 20 30 / .8);
      }

      #content {
        display: block;
        padding: 1.2em 1.5em;
      }

      h3,
      p {
        margin-block: 0 .3em;
      }
    </style>
    <slot name="error-${attrs.mediaerrorcode}" id="content">
      ${formatErrorMessage({ code: +attrs.mediaerrorcode, message: attrs.mediaerrormessage })}
    </slot>
  `
   );
  }
  function shouldOpenErrorDialog(error) {
   return error.code && formatError(error) !== null;
  }
  function formatErrorMessage(error) {
   var _a;
   const { title, message } = (_a = formatError(error)) != null ? _a : {};
   let html = '';
   if (title) html += `<slot name="error-${error.code}-title"><h3>${title}</h3></slot>`;
   if (message) html += `<slot name="error-${error.code}-message"><p>${message}</p></slot>`;
   return html;
  }
  const observedAttributes = [MediaUIAttributes.MEDIA_ERROR_CODE, MediaUIAttributes.MEDIA_ERROR_MESSAGE];
  class MediaErrorDialog extends MediaChromeDialog {
   constructor() {
    super(...arguments);
    media_error_dialog_privateAdd(this, _mediaError, null);
   }
   static get observedAttributes() {
    return [...super.observedAttributes, ...observedAttributes];
   }
   formatErrorMessage(error) {
    return this.constructor.formatErrorMessage(error);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a;
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (!observedAttributes.includes(attrName)) return;
    const mediaError =
     (_a = this.mediaError) != null
      ? _a
      : {
         code: this.mediaErrorCode,
         message: this.mediaErrorMessage,
        };
    this.open = shouldOpenErrorDialog(mediaError);
    if (this.open) {
     this.shadowRoot.querySelector('slot').name = `error-${this.mediaErrorCode}`;
     this.shadowRoot.querySelector('#content').innerHTML = this.formatErrorMessage(mediaError);
    }
   }
   get mediaError() {
    return media_error_dialog_privateGet(this, _mediaError);
   }
   set mediaError(value) {
    media_error_dialog_privateSet(this, _mediaError, value);
   }
   get mediaErrorCode() {
    return getNumericAttr(this, 'mediaerrorcode');
   }
   set mediaErrorCode(value) {
    setNumericAttr(this, 'mediaerrorcode', value);
   }
   get mediaErrorMessage() {
    return getStringAttr(this, 'mediaerrormessage');
   }
   set mediaErrorMessage(value) {
    setStringAttr(this, 'mediaerrormessage', value);
   }
  }
  _mediaError = new WeakMap();
  MediaErrorDialog.getSlotTemplateHTML = media_error_dialog_getSlotTemplateHTML;
  MediaErrorDialog.formatErrorMessage = formatErrorMessage;
  if (!GlobalThis.customElements.get('media-error-dialog')) {
   GlobalThis.customElements.define('media-error-dialog', MediaErrorDialog);
  }
  var media_error_dialog_default = MediaErrorDialog; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-fullscreen-button.js

  const enterFullscreenIcon = `<svg aria-hidden="true" viewBox="0 0 26 24">
  <path d="M16 3v2.5h3.5V9H22V3h-6ZM4 9h2.5V5.5H10V3H4v6Zm15.5 9.5H16V21h6v-6h-2.5v3.5ZM6.5 15H4v6h6v-2.5H6.5V15Z"/>
</svg>`;
  const exitFullscreenIcon = `<svg aria-hidden="true" viewBox="0 0 26 24">
  <path d="M18.5 6.5V3H16v6h6V6.5h-3.5ZM16 21h2.5v-3.5H22V15h-6v6ZM4 17.5h3.5V21H10v-6H4v2.5Zm3.5-11H4V9h6V3H7.5v3.5Z"/>
</svg>`;
  function media_fullscreen_button_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host([${MediaUIAttributes.MEDIA_IS_FULLSCREEN}]) slot[name=icon] slot:not([name=exit]) {
        display: none !important;
      }

      ${/* Double negative, but safer if display doesn't equal 'block' */ ''}
      :host(:not([${MediaUIAttributes.MEDIA_IS_FULLSCREEN}])) slot[name=icon] slot:not([name=enter]) {
        display: none !important;
      }

      :host([${MediaUIAttributes.MEDIA_IS_FULLSCREEN}]) slot[name=tooltip-enter],
      :host(:not([${MediaUIAttributes.MEDIA_IS_FULLSCREEN}])) slot[name=tooltip-exit] {
        display: none;
      }
    </style>

    <slot name="icon">
      <slot name="enter">${enterFullscreenIcon}</slot>
      <slot name="exit">${exitFullscreenIcon}</slot>
    </slot>
  `
   );
  }
  function media_fullscreen_button_getTooltipContentHTML() {
   return (
    /*html*/
    `
    <slot name="tooltip-enter">${t('Enter fullscreen mode')}</slot>
    <slot name="tooltip-exit">${t('Exit fullscreen mode')}</slot>
  `
   );
  }
  const media_fullscreen_button_updateAriaLabel = (el) => {
   const label = el.mediaIsFullscreen ? t('exit fullscreen mode') : t('enter fullscreen mode');
   el.setAttribute('aria-label', label);
  };
  class MediaFullscreenButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_IS_FULLSCREEN, MediaUIAttributes.MEDIA_FULLSCREEN_UNAVAILABLE];
   }
   connectedCallback() {
    super.connectedCallback();
    media_fullscreen_button_updateAriaLabel(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_IS_FULLSCREEN) {
     media_fullscreen_button_updateAriaLabel(this);
    }
   }
   /**
    * @type {string | undefined} Fullscreen unavailability state
    */
   get mediaFullscreenUnavailable() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_FULLSCREEN_UNAVAILABLE);
   }
   set mediaFullscreenUnavailable(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_FULLSCREEN_UNAVAILABLE, value);
   }
   /**
    * @type {boolean} Whether fullscreen is available
    */
   get mediaIsFullscreen() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_IS_FULLSCREEN);
   }
   set mediaIsFullscreen(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_IS_FULLSCREEN, value);
   }
   handleClick() {
    const eventName = this.mediaIsFullscreen ? MediaUIEvents.MEDIA_EXIT_FULLSCREEN_REQUEST : MediaUIEvents.MEDIA_ENTER_FULLSCREEN_REQUEST;
    this.dispatchEvent(new GlobalThis.CustomEvent(eventName, { composed: true, bubbles: true }));
   }
  }
  MediaFullscreenButton.getSlotTemplateHTML = media_fullscreen_button_getSlotTemplateHTML;
  MediaFullscreenButton.getTooltipContentHTML = media_fullscreen_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-fullscreen-button')) {
   GlobalThis.customElements.define('media-fullscreen-button', MediaFullscreenButton);
  }
  var media_fullscreen_button_default = /* unused pure expression or super */ null && MediaFullscreenButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-live-button.js

  const { MEDIA_TIME_IS_LIVE, MEDIA_PAUSED } = MediaUIAttributes;
  const { MEDIA_SEEK_TO_LIVE_REQUEST, MEDIA_PLAY_REQUEST } = MediaUIEvents;
  const indicatorSVG = '<svg viewBox="0 0 6 12"><circle cx="3" cy="6" r="2"></circle></svg>';
  function media_live_button_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host { --media-tooltip-display: none; }
      
      slot[name=indicator] > *,
      :host ::slotted([slot=indicator]) {
        ${/* Override styles for icon-only buttons */ ''}
        min-width: auto;
        fill: var(--media-live-button-icon-color, rgb(140, 140, 140));
        color: var(--media-live-button-icon-color, rgb(140, 140, 140));
      }

      :host([${MEDIA_TIME_IS_LIVE}]:not([${MEDIA_PAUSED}])) slot[name=indicator] > *,
      :host([${MEDIA_TIME_IS_LIVE}]:not([${MEDIA_PAUSED}])) ::slotted([slot=indicator]) {
        fill: var(--media-live-button-indicator-color, rgb(255, 0, 0));
        color: var(--media-live-button-indicator-color, rgb(255, 0, 0));
      }

      :host([${MEDIA_TIME_IS_LIVE}]:not([${MEDIA_PAUSED}])) {
        cursor: var(--media-cursor, not-allowed);
      }

      slot[name=text]{
        text-transform: uppercase;
      }

    </style>

    <slot name="indicator">${indicatorSVG}</slot>
    ${
     /*
      A new line between spacer and text creates inconsistent spacing
      between slotted items and default slots.
    */
     ''
    }
    <slot name="spacer">&nbsp;</slot><slot name="text">${t('live')}</slot>
  `
   );
  }
  const updateAriaAttributes = (el) => {
   const isPausedOrNotLive = el.mediaPaused || !el.mediaTimeIsLive;
   const label = isPausedOrNotLive ? t('seek to live') : t('playing live');
   el.setAttribute('aria-label', label);
   isPausedOrNotLive ? el.removeAttribute('aria-disabled') : el.setAttribute('aria-disabled', 'true');
  };
  class MediaLiveButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MEDIA_TIME_IS_LIVE, MEDIA_PAUSED];
   }
   connectedCallback() {
    super.connectedCallback();
    updateAriaAttributes(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    updateAriaAttributes(this);
   }
   /**
    * @type {boolean} Is the media paused
    */
   get mediaPaused() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED);
   }
   set mediaPaused(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED, value);
   }
   /**
    * @type {boolean} Is the media playback currently live
    */
   get mediaTimeIsLive() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_TIME_IS_LIVE);
   }
   set mediaTimeIsLive(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_TIME_IS_LIVE, value);
   }
   handleClick() {
    if (!this.mediaPaused && this.mediaTimeIsLive) return;
    this.dispatchEvent(
     new GlobalThis.CustomEvent(MEDIA_SEEK_TO_LIVE_REQUEST, {
      composed: true,
      bubbles: true,
     }),
    );
    if (this.hasAttribute(MEDIA_PAUSED)) {
     this.dispatchEvent(
      new GlobalThis.CustomEvent(MEDIA_PLAY_REQUEST, {
       composed: true,
       bubbles: true,
      }),
     );
    }
   }
  }
  MediaLiveButton.getSlotTemplateHTML = media_live_button_getSlotTemplateHTML;
  if (!GlobalThis.customElements.get('media-live-button')) {
   GlobalThis.customElements.define('media-live-button', MediaLiveButton);
  }
  var media_live_button_default = /* unused pure expression or super */ null && MediaLiveButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-loading-indicator.js

  var media_loading_indicator_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_loading_indicator_privateGet = (obj, member, getter) => {
   media_loading_indicator_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_loading_indicator_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_loading_indicator_privateSet = (obj, member, value, setter) => {
   media_loading_indicator_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_loading_indicator_mediaController, _delay;

  const media_loading_indicator_Attributes = {
   LOADING_DELAY: 'loadingdelay',
   NO_AUTOHIDE: 'noautohide',
  };
  const DEFAULT_LOADING_DELAY = 500;
  const loadingIndicatorIcon = `
<svg aria-hidden="true" viewBox="0 0 100 100">
  <path d="M73,50c0-12.7-10.3-23-23-23S27,37.3,27,50 M30.9,50c0-10.5,8.5-19.1,19.1-19.1S69.1,39.5,69.1,50">
    <animateTransform
       attributeName="transform"
       attributeType="XML"
       type="rotate"
       dur="1s"
       from="0 50 50"
       to="360 50 50"
       repeatCount="indefinite" />
  </path>
</svg>
`;
  function media_loading_indicator_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        display: var(--media-control-display, var(--media-loading-indicator-display, inline-block));
        vertical-align: middle;
        box-sizing: border-box;
        --_loading-indicator-delay: var(--media-loading-indicator-transition-delay, ${DEFAULT_LOADING_DELAY}ms);
      }

      #status {
        color: rgba(0,0,0,0);
        width: 0px;
        height: 0px;
      }

      :host slot[name=icon] > *,
      :host ::slotted([slot=icon]) {
        opacity: var(--media-loading-indicator-opacity, 0);
        transition: opacity 0.15s;
      }

      :host([${MediaUIAttributes.MEDIA_LOADING}]:not([${MediaUIAttributes.MEDIA_PAUSED}])) slot[name=icon] > *,
      :host([${MediaUIAttributes.MEDIA_LOADING}]:not([${MediaUIAttributes.MEDIA_PAUSED}])) ::slotted([slot=icon]) {
        opacity: var(--media-loading-indicator-opacity, 1);
        transition: opacity 0.15s var(--_loading-indicator-delay);
      }

      :host #status {
        visibility: var(--media-loading-indicator-opacity, hidden);
        transition: visibility 0.15s;
      }

      :host([${MediaUIAttributes.MEDIA_LOADING}]:not([${MediaUIAttributes.MEDIA_PAUSED}])) #status {
        visibility: var(--media-loading-indicator-opacity, visible);
        transition: visibility 0.15s var(--_loading-indicator-delay);
      }

      svg, img, ::slotted(svg), ::slotted(img) {
        width: var(--media-loading-indicator-icon-width);
        height: var(--media-loading-indicator-icon-height, 100px);
        fill: var(--media-icon-color, var(--media-primary-color, rgb(238 238 238)));
        vertical-align: middle;
      }
    </style>

    <slot name="icon">${loadingIndicatorIcon}</slot>
    <div id="status" role="status" aria-live="polite">${t('media loading')}</div>
  `
   );
  }
  class MediaLoadingIndicator extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_loading_indicator_privateAdd(this, media_loading_indicator_mediaController, void 0);
    media_loading_indicator_privateAdd(this, _delay, DEFAULT_LOADING_DELAY);
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
   }
   static get observedAttributes() {
    return [MediaStateReceiverAttributes.MEDIA_CONTROLLER, MediaUIAttributes.MEDIA_PAUSED, MediaUIAttributes.MEDIA_LOADING, media_loading_indicator_Attributes.LOADING_DELAY];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d, _e;
    if (attrName === media_loading_indicator_Attributes.LOADING_DELAY && oldValue !== newValue) {
     this.loadingDelay = Number(newValue);
    } else if (attrName === MediaStateReceiverAttributes.MEDIA_CONTROLLER) {
     if (oldValue) {
      (_b = (_a = media_loading_indicator_privateGet(this, media_loading_indicator_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
      media_loading_indicator_privateSet(this, media_loading_indicator_mediaController, null);
     }
     if (newValue && this.isConnected) {
      media_loading_indicator_privateSet(this, media_loading_indicator_mediaController, (_c = this.getRootNode()) == null ? void 0 : _c.getElementById(newValue));
      (_e = (_d = media_loading_indicator_privateGet(this, media_loading_indicator_mediaController)) == null ? void 0 : _d.associateElement) == null ? void 0 : _e.call(_d, this);
     }
    }
   }
   connectedCallback() {
    var _a, _b, _c;
    const mediaControllerId = this.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER);
    if (mediaControllerId) {
     media_loading_indicator_privateSet(this, media_loading_indicator_mediaController, (_a = this.getRootNode()) == null ? void 0 : _a.getElementById(mediaControllerId));
     (_c = (_b = media_loading_indicator_privateGet(this, media_loading_indicator_mediaController)) == null ? void 0 : _b.associateElement) == null ? void 0 : _c.call(_b, this);
    }
   }
   disconnectedCallback() {
    var _a, _b;
    (_b = (_a = media_loading_indicator_privateGet(this, media_loading_indicator_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
    media_loading_indicator_privateSet(this, media_loading_indicator_mediaController, null);
   }
   /**
    * Delay in ms
    */
   get loadingDelay() {
    return media_loading_indicator_privateGet(this, _delay);
   }
   set loadingDelay(delay) {
    media_loading_indicator_privateSet(this, _delay, delay);
    const { style } = getOrInsertCSSRule(this.shadowRoot, ':host');
    style.setProperty('--_loading-indicator-delay', `var(--media-loading-indicator-transition-delay, ${delay}ms)`);
   }
   /**
    * Is the media paused
    */
   get mediaPaused() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED);
   }
   set mediaPaused(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED, value);
   }
   /**
    * Is the media loading
    */
   get mediaLoading() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_LOADING);
   }
   set mediaLoading(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_LOADING, value);
   }
   get mediaController() {
    return getStringAttr(this, MediaStateReceiverAttributes.MEDIA_CONTROLLER);
   }
   set mediaController(value) {
    setStringAttr(this, MediaStateReceiverAttributes.MEDIA_CONTROLLER, value);
   }
   get noAutohide() {
    return getBooleanAttr(this, media_loading_indicator_Attributes.NO_AUTOHIDE);
   }
   set noAutohide(value) {
    setBooleanAttr(this, media_loading_indicator_Attributes.NO_AUTOHIDE, value);
   }
  }
  media_loading_indicator_mediaController = new WeakMap();
  _delay = new WeakMap();
  MediaLoadingIndicator.shadowRootOptions = { mode: 'open' };
  MediaLoadingIndicator.getTemplateHTML = media_loading_indicator_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-loading-indicator')) {
   GlobalThis.customElements.define('media-loading-indicator', MediaLoadingIndicator);
  }
  var media_loading_indicator_default = /* unused pure expression or super */ null && MediaLoadingIndicator; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-mute-button.js

  const offIcon = `<svg aria-hidden="true" viewBox="0 0 24 24">
  <path d="M16.5 12A4.5 4.5 0 0 0 14 8v2.18l2.45 2.45a4.22 4.22 0 0 0 .05-.63Zm2.5 0a6.84 6.84 0 0 1-.54 2.64L20 16.15A8.8 8.8 0 0 0 21 12a9 9 0 0 0-7-8.77v2.06A7 7 0 0 1 19 12ZM4.27 3 3 4.27 7.73 9H3v6h4l5 5v-6.73l4.25 4.25A6.92 6.92 0 0 1 14 18.7v2.06A9 9 0 0 0 17.69 19l2 2.05L21 19.73l-9-9L4.27 3ZM12 4 9.91 6.09 12 8.18V4Z"/>
</svg>`;
  const lowIcon = `<svg aria-hidden="true" viewBox="0 0 24 24">
  <path d="M3 9v6h4l5 5V4L7 9H3Zm13.5 3A4.5 4.5 0 0 0 14 8v8a4.47 4.47 0 0 0 2.5-4Z"/>
</svg>`;
  const highIcon = `<svg aria-hidden="true" viewBox="0 0 24 24">
  <path d="M3 9v6h4l5 5V4L7 9H3Zm13.5 3A4.5 4.5 0 0 0 14 8v8a4.47 4.47 0 0 0 2.5-4ZM14 3.23v2.06a7 7 0 0 1 0 13.42v2.06a9 9 0 0 0 0-17.54Z"/>
</svg>`;
  function media_mute_button_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host(:not([${MediaUIAttributes.MEDIA_VOLUME_LEVEL}])) slot[name=icon] slot:not([name=high]),
      :host([${MediaUIAttributes.MEDIA_VOLUME_LEVEL}=high]) slot[name=icon] slot:not([name=high]) {
        display: none !important;
      }

      :host([${MediaUIAttributes.MEDIA_VOLUME_LEVEL}=off]) slot[name=icon] slot:not([name=off]) {
        display: none !important;
      }

      :host([${MediaUIAttributes.MEDIA_VOLUME_LEVEL}=low]) slot[name=icon] slot:not([name=low]) {
        display: none !important;
      }

      :host([${MediaUIAttributes.MEDIA_VOLUME_LEVEL}=medium]) slot[name=icon] slot:not([name=medium]) {
        display: none !important;
      }

      :host(:not([${MediaUIAttributes.MEDIA_VOLUME_LEVEL}=off])) slot[name=tooltip-unmute],
      :host([${MediaUIAttributes.MEDIA_VOLUME_LEVEL}=off]) slot[name=tooltip-mute] {
        display: none;
      }
    </style>

    <slot name="icon">
      <slot name="off">${offIcon}</slot>
      <slot name="low">${lowIcon}</slot>
      <slot name="medium">${lowIcon}</slot>
      <slot name="high">${highIcon}</slot>
    </slot>
  `
   );
  }
  function media_mute_button_getTooltipContentHTML() {
   return (
    /*html*/
    `
    <slot name="tooltip-mute">${t('Mute')}</slot>
    <slot name="tooltip-unmute">${t('Unmute')}</slot>
  `
   );
  }
  const media_mute_button_updateAriaLabel = (el) => {
   const muted = el.mediaVolumeLevel === 'off';
   const label = muted ? t('unmute') : t('mute');
   el.setAttribute('aria-label', label);
  };
  class MediaMuteButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_VOLUME_LEVEL];
   }
   connectedCallback() {
    super.connectedCallback();
    media_mute_button_updateAriaLabel(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_VOLUME_LEVEL) {
     media_mute_button_updateAriaLabel(this);
    }
   }
   /**
    * @type {string | undefined}
    */
   get mediaVolumeLevel() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_VOLUME_LEVEL);
   }
   set mediaVolumeLevel(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_VOLUME_LEVEL, value);
   }
   handleClick() {
    const eventName = this.mediaVolumeLevel === 'off' ? MediaUIEvents.MEDIA_UNMUTE_REQUEST : MediaUIEvents.MEDIA_MUTE_REQUEST;
    this.dispatchEvent(new GlobalThis.CustomEvent(eventName, { composed: true, bubbles: true }));
   }
  }
  MediaMuteButton.getSlotTemplateHTML = media_mute_button_getSlotTemplateHTML;
  MediaMuteButton.getTooltipContentHTML = media_mute_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-mute-button')) {
   GlobalThis.customElements.define('media-mute-button', MediaMuteButton);
  }
  var media_mute_button_default = /* unused pure expression or super */ null && MediaMuteButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-pip-button.js

  const pipIcon = `<svg aria-hidden="true" viewBox="0 0 28 24">
  <path d="M24 3H4a1 1 0 0 0-1 1v16a1 1 0 0 0 1 1h20a1 1 0 0 0 1-1V4a1 1 0 0 0-1-1Zm-1 16H5V5h18v14Zm-3-8h-7v5h7v-5Z"/>
</svg>`;
  function media_pip_button_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host([${MediaUIAttributes.MEDIA_IS_PIP}]) slot[name=icon] slot:not([name=exit]) {
        display: none !important;
      }

      :host(:not([${MediaUIAttributes.MEDIA_IS_PIP}])) slot[name=icon] slot:not([name=enter]) {
        display: none !important;
      }

      :host([${MediaUIAttributes.MEDIA_IS_PIP}]) slot[name=tooltip-enter],
      :host(:not([${MediaUIAttributes.MEDIA_IS_PIP}])) slot[name=tooltip-exit] {
        display: none;
      }
    </style>

    <slot name="icon">
      <slot name="enter">${pipIcon}</slot>
      <slot name="exit">${pipIcon}</slot>
    </slot>
  `
   );
  }
  function media_pip_button_getTooltipContentHTML() {
   return (
    /*html*/
    `
    <slot name="tooltip-enter">${t('Enter picture in picture mode')}</slot>
    <slot name="tooltip-exit">${t('Exit picture in picture mode')}</slot>
  `
   );
  }
  const media_pip_button_updateAriaLabel = (el) => {
   const label = el.mediaIsPip ? t('exit picture in picture mode') : t('enter picture in picture mode');
   el.setAttribute('aria-label', label);
  };
  class MediaPipButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_IS_PIP, MediaUIAttributes.MEDIA_PIP_UNAVAILABLE];
   }
   connectedCallback() {
    super.connectedCallback();
    media_pip_button_updateAriaLabel(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_IS_PIP) {
     media_pip_button_updateAriaLabel(this);
    }
   }
   /**
    * @type {string | undefined} Pip unavailability state
    */
   get mediaPipUnavailable() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_PIP_UNAVAILABLE);
   }
   set mediaPipUnavailable(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_PIP_UNAVAILABLE, value);
   }
   /**
    * @type {boolean} Is the media currently playing picture-in-picture
    */
   get mediaIsPip() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_IS_PIP);
   }
   set mediaIsPip(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_IS_PIP, value);
   }
   handleClick() {
    const eventName = this.mediaIsPip ? MediaUIEvents.MEDIA_EXIT_PIP_REQUEST : MediaUIEvents.MEDIA_ENTER_PIP_REQUEST;
    this.dispatchEvent(new GlobalThis.CustomEvent(eventName, { composed: true, bubbles: true }));
   }
  }
  MediaPipButton.getSlotTemplateHTML = media_pip_button_getSlotTemplateHTML;
  MediaPipButton.getTooltipContentHTML = media_pip_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-pip-button')) {
   GlobalThis.customElements.define('media-pip-button', MediaPipButton);
  }
  var media_pip_button_default = /* unused pure expression or super */ null && MediaPipButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-playback-rate-button.js

  var media_playback_rate_button_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_playback_rate_button_privateGet = (obj, member, getter) => {
   media_playback_rate_button_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_playback_rate_button_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var _rates;

  const media_playback_rate_button_Attributes = {
   RATES: 'rates',
  };
  const DEFAULT_RATES = [1, 1.2, 1.5, 1.7, 2];
  const DEFAULT_RATE = 1;
  function media_playback_rate_button_getSlotTemplateHTML(attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        min-width: 5ch;
        padding: var(--media-button-padding, var(--media-control-padding, 10px 5px));
      }
    </style>
    <slot name="icon">${attrs['mediaplaybackrate'] || DEFAULT_RATE}x</slot>
  `
   );
  }
  function media_playback_rate_button_getTooltipContentHTML() {
   return t('Playback rate');
  }
  class MediaPlaybackRateButton extends MediaChromeButton {
   constructor() {
    var _a;
    super();
    media_playback_rate_button_privateAdd(
     this,
     _rates,
     new AttributeTokenList(this, media_playback_rate_button_Attributes.RATES, {
      defaultValue: DEFAULT_RATES,
     }),
    );
    this.container = this.shadowRoot.querySelector('slot[name="icon"]');
    this.container.innerHTML = `${(_a = this.mediaPlaybackRate) != null ? _a : DEFAULT_RATE}x`;
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_PLAYBACK_RATE, media_playback_rate_button_Attributes.RATES];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === media_playback_rate_button_Attributes.RATES) {
     media_playback_rate_button_privateGet(this, _rates).value = newValue;
    }
    if (attrName === MediaUIAttributes.MEDIA_PLAYBACK_RATE) {
     const newPlaybackRate = newValue ? +newValue : Number.NaN;
     const playbackRate = !Number.isNaN(newPlaybackRate) ? newPlaybackRate : DEFAULT_RATE;
     this.container.innerHTML = `${playbackRate}x`;
     this.setAttribute('aria-label', t('Playback rate {playbackRate}', { playbackRate }));
    }
   }
   /**
    * Get the playback rates for the button.
    */
   get rates() {
    return media_playback_rate_button_privateGet(this, _rates);
   }
   /**
    * Set the playback rates for the button.
    * For React 19+ compatibility, accept a string of space-separated rates.
    */
   set rates(value) {
    if (!value) {
     media_playback_rate_button_privateGet(this, _rates).value = '';
    } else if (Array.isArray(value)) {
     media_playback_rate_button_privateGet(this, _rates).value = value.join(' ');
    } else if (typeof value === 'string') {
     media_playback_rate_button_privateGet(this, _rates).value = value;
    }
   }
   /**
    * @type {number} The current playback rate
    */
   get mediaPlaybackRate() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_PLAYBACK_RATE, DEFAULT_RATE);
   }
   set mediaPlaybackRate(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_PLAYBACK_RATE, value);
   }
   handleClick() {
    var _a, _b;
    const availableRates = Array.from(media_playback_rate_button_privateGet(this, _rates).values(), (str) => +str).sort((a, b) => a - b);
    const detail = (_b = (_a = availableRates.find((r) => r > this.mediaPlaybackRate)) != null ? _a : availableRates[0]) != null ? _b : DEFAULT_RATE;
    const evt = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_PLAYBACK_RATE_REQUEST, { composed: true, bubbles: true, detail });
    this.dispatchEvent(evt);
   }
  }
  _rates = new WeakMap();
  MediaPlaybackRateButton.getSlotTemplateHTML = media_playback_rate_button_getSlotTemplateHTML;
  MediaPlaybackRateButton.getTooltipContentHTML = media_playback_rate_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-playback-rate-button')) {
   GlobalThis.customElements.define('media-playback-rate-button', MediaPlaybackRateButton);
  }
  var media_playback_rate_button_default = /* unused pure expression or super */ null && MediaPlaybackRateButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-play-button.js

  const playIcon = `<svg aria-hidden="true" viewBox="0 0 24 24">
  <path d="m6 21 15-9L6 3v18Z"/>
</svg>`;
  const pauseIcon = `<svg aria-hidden="true" viewBox="0 0 24 24">
  <path d="M6 20h4V4H6v16Zm8-16v16h4V4h-4Z"/>
</svg>`;
  function media_play_button_getSlotTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host([${MediaUIAttributes.MEDIA_PAUSED}]) slot[name=pause],
      :host(:not([${MediaUIAttributes.MEDIA_PAUSED}])) slot[name=play] {
        display: none !important;
      }

      :host([${MediaUIAttributes.MEDIA_PAUSED}]) slot[name=tooltip-pause],
      :host(:not([${MediaUIAttributes.MEDIA_PAUSED}])) slot[name=tooltip-play] {
        display: none;
      }
    </style>

    <slot name="icon">
      <slot name="play">${playIcon}</slot>
      <slot name="pause">${pauseIcon}</slot>
    </slot>
  `
   );
  }
  function media_play_button_getTooltipContentHTML() {
   return (
    /*html*/
    `
    <slot name="tooltip-play">${t('Play')}</slot>
    <slot name="tooltip-pause">${t('Pause')}</slot>
  `
   );
  }
  const media_play_button_updateAriaLabel = (el) => {
   const label = el.mediaPaused ? t('play') : t('pause');
   el.setAttribute('aria-label', label);
  };
  class MediaPlayButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_PAUSED, MediaUIAttributes.MEDIA_ENDED];
   }
   connectedCallback() {
    super.connectedCallback();
    media_play_button_updateAriaLabel(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_PAUSED) {
     media_play_button_updateAriaLabel(this);
    }
   }
   /**
    * Is the media paused
    */
   get mediaPaused() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED);
   }
   set mediaPaused(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED, value);
   }
   handleClick() {
    const eventName = this.mediaPaused ? MediaUIEvents.MEDIA_PLAY_REQUEST : MediaUIEvents.MEDIA_PAUSE_REQUEST;
    this.dispatchEvent(new GlobalThis.CustomEvent(eventName, { composed: true, bubbles: true }));
   }
  }
  MediaPlayButton.getSlotTemplateHTML = media_play_button_getSlotTemplateHTML;
  MediaPlayButton.getTooltipContentHTML = media_play_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-play-button')) {
   GlobalThis.customElements.define('media-play-button', MediaPlayButton);
  }
  var media_play_button_default = /* unused pure expression or super */ null && MediaPlayButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-poster-image.js

  const media_poster_image_Attributes = {
   PLACEHOLDER_SRC: 'placeholdersrc',
   SRC: 'src',
  };
  function media_poster_image_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        pointer-events: none;
        display: var(--media-poster-image-display, inline-block);
        box-sizing: border-box;
      }

      img {
        max-width: 100%;
        max-height: 100%;
        min-width: 100%;
        min-height: 100%;
        background-repeat: no-repeat;
        background-position: var(--media-poster-image-background-position, var(--media-object-position, center));
        background-size: var(--media-poster-image-background-size, var(--media-object-fit, contain));
        object-fit: var(--media-object-fit, contain);
        object-position: var(--media-object-position, center);
      }
    </style>

    <img part="poster img" aria-hidden="true" id="image"/>
  `
   );
  }
  const unsetBackgroundImage = (el) => {
   el.style.removeProperty('background-image');
  };
  const setBackgroundImage = (el, image) => {
   el.style['background-image'] = `url('${image}')`;
  };
  class MediaPosterImage extends GlobalThis.HTMLElement {
   static get observedAttributes() {
    return [media_poster_image_Attributes.PLACEHOLDER_SRC, media_poster_image_Attributes.SRC];
   }
   constructor() {
    super();
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
    this.image = this.shadowRoot.querySelector('#image');
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    if (attrName === media_poster_image_Attributes.SRC) {
     if (newValue == null) {
      this.image.removeAttribute(media_poster_image_Attributes.SRC);
     } else {
      this.image.setAttribute(media_poster_image_Attributes.SRC, newValue);
     }
    }
    if (attrName === media_poster_image_Attributes.PLACEHOLDER_SRC) {
     if (newValue == null) {
      unsetBackgroundImage(this.image);
     } else {
      setBackgroundImage(this.image, newValue);
     }
    }
   }
   /**
    *
    */
   get placeholderSrc() {
    return getStringAttr(this, media_poster_image_Attributes.PLACEHOLDER_SRC);
   }
   set placeholderSrc(value) {
    setStringAttr(this, media_poster_image_Attributes.SRC, value);
   }
   /**
    *
    */
   get src() {
    return getStringAttr(this, media_poster_image_Attributes.SRC);
   }
   set src(value) {
    setStringAttr(this, media_poster_image_Attributes.SRC, value);
   }
  }
  MediaPosterImage.shadowRootOptions = { mode: 'open' };
  MediaPosterImage.getTemplateHTML = media_poster_image_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-poster-image')) {
   GlobalThis.customElements.define('media-poster-image', MediaPosterImage);
  }
  var media_poster_image_default = /* unused pure expression or super */ null && MediaPosterImage; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-preview-chapter-display.js

  var media_preview_chapter_display_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_preview_chapter_display_privateGet = (obj, member, getter) => {
   media_preview_chapter_display_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_preview_chapter_display_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_preview_chapter_display_privateSet = (obj, member, value, setter) => {
   media_preview_chapter_display_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_preview_chapter_display_slot;

  class MediaPreviewChapterDisplay extends MediaTextDisplay {
   constructor() {
    super();
    media_preview_chapter_display_privateAdd(this, media_preview_chapter_display_slot, void 0);
    media_preview_chapter_display_privateSet(this, media_preview_chapter_display_slot, this.shadowRoot.querySelector('slot'));
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_PREVIEW_CHAPTER];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_PREVIEW_CHAPTER) {
     if (newValue !== oldValue && newValue != null) {
      media_preview_chapter_display_privateGet(this, media_preview_chapter_display_slot).textContent = newValue;
      if (newValue !== '') {
       this.setAttribute('aria-valuetext', `chapter: ${newValue}`);
      } else {
       this.removeAttribute('aria-valuetext');
      }
     }
    }
   }
   /**
    * @type {string | undefined} Timeline preview chapter
    */
   get mediaPreviewChapter() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_PREVIEW_CHAPTER);
   }
   set mediaPreviewChapter(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_PREVIEW_CHAPTER, value);
   }
  }
  media_preview_chapter_display_slot = new WeakMap();
  if (!GlobalThis.customElements.get('media-preview-chapter-display')) {
   GlobalThis.customElements.define('media-preview-chapter-display', MediaPreviewChapterDisplay);
  }
  var media_preview_chapter_display_default = /* unused pure expression or super */ null && MediaPreviewChapterDisplay; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-preview-thumbnail.js

  var media_preview_thumbnail_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_preview_thumbnail_privateGet = (obj, member, getter) => {
   media_preview_thumbnail_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_preview_thumbnail_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_preview_thumbnail_privateSet = (obj, member, value, setter) => {
   media_preview_thumbnail_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_preview_thumbnail_mediaController;

  function media_preview_thumbnail_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        box-sizing: border-box;
        display: var(--media-control-display, var(--media-preview-thumbnail-display, inline-block));
        overflow: hidden;
      }

      img {
        display: none;
        position: relative;
      }
    </style>
    <img crossorigin loading="eager" decoding="async">
  `
   );
  }
  class MediaPreviewThumbnail extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_preview_thumbnail_privateAdd(this, media_preview_thumbnail_mediaController, void 0);
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
   }
   static get observedAttributes() {
    return [MediaStateReceiverAttributes.MEDIA_CONTROLLER, MediaUIAttributes.MEDIA_PREVIEW_IMAGE, MediaUIAttributes.MEDIA_PREVIEW_COORDS];
   }
   connectedCallback() {
    var _a, _b, _c;
    const mediaControllerId = this.getAttribute(MediaStateReceiverAttributes.MEDIA_CONTROLLER);
    if (mediaControllerId) {
     media_preview_thumbnail_privateSet(
      this,
      media_preview_thumbnail_mediaController,
      // @ts-ignore
      (_a = this.getRootNode()) == null ? void 0 : _a.getElementById(mediaControllerId),
     );
     (_c = (_b = media_preview_thumbnail_privateGet(this, media_preview_thumbnail_mediaController)) == null ? void 0 : _b.associateElement) == null ? void 0 : _c.call(_b, this);
    }
   }
   disconnectedCallback() {
    var _a, _b;
    (_b = (_a = media_preview_thumbnail_privateGet(this, media_preview_thumbnail_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
    media_preview_thumbnail_privateSet(this, media_preview_thumbnail_mediaController, null);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d, _e;
    if ([MediaUIAttributes.MEDIA_PREVIEW_IMAGE, MediaUIAttributes.MEDIA_PREVIEW_COORDS].includes(attrName)) {
     this.update();
    }
    if (attrName === MediaStateReceiverAttributes.MEDIA_CONTROLLER) {
     if (oldValue) {
      (_b = (_a = media_preview_thumbnail_privateGet(this, media_preview_thumbnail_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
      media_preview_thumbnail_privateSet(this, media_preview_thumbnail_mediaController, null);
     }
     if (newValue && this.isConnected) {
      media_preview_thumbnail_privateSet(this, media_preview_thumbnail_mediaController, (_c = this.getRootNode()) == null ? void 0 : _c.getElementById(newValue));
      (_e = (_d = media_preview_thumbnail_privateGet(this, media_preview_thumbnail_mediaController)) == null ? void 0 : _d.associateElement) == null ? void 0 : _e.call(_d, this);
     }
    }
   }
   /**
    * @type {string | undefined} The url of the preview image
    */
   get mediaPreviewImage() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_PREVIEW_IMAGE);
   }
   set mediaPreviewImage(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_PREVIEW_IMAGE, value);
   }
   /**
    * @type {Array<number> | undefined} Fixed length array [x, y, width, height] or undefined
    */
   get mediaPreviewCoords() {
    const attrVal = this.getAttribute(MediaUIAttributes.MEDIA_PREVIEW_COORDS);
    if (!attrVal) return void 0;
    return attrVal.split(/\s+/).map((coord) => +coord);
   }
   set mediaPreviewCoords(value) {
    if (!value) {
     this.removeAttribute(MediaUIAttributes.MEDIA_PREVIEW_COORDS);
     return;
    }
    this.setAttribute(MediaUIAttributes.MEDIA_PREVIEW_COORDS, value.join(' '));
   }
   update() {
    const coords = this.mediaPreviewCoords;
    const previewImage = this.mediaPreviewImage;
    if (!(coords && previewImage)) return;
    const [x, y, w, h] = coords;
    const src = previewImage.split('#')[0];
    const computedStyle = getComputedStyle(this);
    const { maxWidth, maxHeight, minWidth, minHeight } = computedStyle;
    const maxRatio = Math.min(parseInt(maxWidth) / w, parseInt(maxHeight) / h);
    const minRatio = Math.max(parseInt(minWidth) / w, parseInt(minHeight) / h);
    const isScalingDown = maxRatio < 1;
    const scale = isScalingDown ? maxRatio : minRatio > 1 ? minRatio : 1;
    const { style } = getOrInsertCSSRule(this.shadowRoot, ':host');
    const imgStyle = getOrInsertCSSRule(this.shadowRoot, 'img').style;
    const img = this.shadowRoot.querySelector('img');
    const extremum = isScalingDown ? 'min' : 'max';
    style.setProperty(`${extremum}-width`, 'initial', 'important');
    style.setProperty(`${extremum}-height`, 'initial', 'important');
    style.width = `${w * scale}px`;
    style.height = `${h * scale}px`;
    const resize = () => {
     imgStyle.width = `${this.imgWidth * scale}px`;
     imgStyle.height = `${this.imgHeight * scale}px`;
     imgStyle.display = 'block';
    };
    if (img.src !== src) {
     img.onload = () => {
      this.imgWidth = img.naturalWidth;
      this.imgHeight = img.naturalHeight;
      resize();
     };
     img.src = src;
     resize();
    }
    resize();
    imgStyle.transform = `translate(-${x * scale}px, -${y * scale}px)`;
   }
  }
  media_preview_thumbnail_mediaController = new WeakMap();
  MediaPreviewThumbnail.shadowRootOptions = { mode: 'open' };
  MediaPreviewThumbnail.getTemplateHTML = media_preview_thumbnail_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-preview-thumbnail')) {
   GlobalThis.customElements.define('media-preview-thumbnail', MediaPreviewThumbnail);
  }
  var media_preview_thumbnail_default = MediaPreviewThumbnail; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-preview-time-display.js

  var media_preview_time_display_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_preview_time_display_privateGet = (obj, member, getter) => {
   media_preview_time_display_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_preview_time_display_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_preview_time_display_privateSet = (obj, member, value, setter) => {
   media_preview_time_display_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_preview_time_display_slot;

  class MediaPreviewTimeDisplay extends MediaTextDisplay {
   constructor() {
    super();
    media_preview_time_display_privateAdd(this, media_preview_time_display_slot, void 0);
    media_preview_time_display_privateSet(this, media_preview_time_display_slot, this.shadowRoot.querySelector('slot'));
    media_preview_time_display_privateGet(this, media_preview_time_display_slot).textContent = formatTime(0);
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_PREVIEW_TIME];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_PREVIEW_TIME && newValue != null) {
     media_preview_time_display_privateGet(this, media_preview_time_display_slot).textContent = formatTime(parseFloat(newValue));
    }
   }
   /**
    * Timeline preview time
    */
   get mediaPreviewTime() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_PREVIEW_TIME);
   }
   set mediaPreviewTime(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_PREVIEW_TIME, value);
   }
  }
  media_preview_time_display_slot = new WeakMap();
  if (!GlobalThis.customElements.get('media-preview-time-display')) {
   GlobalThis.customElements.define('media-preview-time-display', MediaPreviewTimeDisplay);
  }
  var media_preview_time_display_default = /* unused pure expression or super */ null && MediaPreviewTimeDisplay; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-seek-backward-button.js

  const media_seek_backward_button_Attributes = {
   SEEK_OFFSET: 'seekoffset',
  };
  const media_seek_backward_button_DEFAULT_SEEK_OFFSET = 30;
  const backwardIcon = (seekOffset) => `
  <svg aria-hidden="true" viewBox="0 0 20 24">
    <defs>
      <style>.text{font-size:8px;font-family:Arial-BoldMT, Arial;font-weight:700;}</style>
    </defs>
    <text class="text value" transform="translate(2.18 19.87)">${seekOffset}</text>
    <path d="M10 6V3L4.37 7 10 10.94V8a5.54 5.54 0 0 1 1.9 10.48v2.12A7.5 7.5 0 0 0 10 6Z"/>
  </svg>`;
  function media_seek_backward_button_getSlotTemplateHTML(_attrs, props) {
   return (
    /*html*/
    `
    <slot name="icon">${backwardIcon(props.seekOffset)}</slot>
  `
   );
  }
  function media_seek_backward_button_getTooltipContentHTML() {
   return t('Seek backward');
  }
  const DEFAULT_TIME = 0;
  class MediaSeekBackwardButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_CURRENT_TIME, media_seek_backward_button_Attributes.SEEK_OFFSET];
   }
   connectedCallback() {
    super.connectedCallback();
    this.seekOffset = getNumericAttr(this, media_seek_backward_button_Attributes.SEEK_OFFSET, media_seek_backward_button_DEFAULT_SEEK_OFFSET);
   }
   attributeChangedCallback(attrName, _oldValue, newValue) {
    super.attributeChangedCallback(attrName, _oldValue, newValue);
    if (attrName === media_seek_backward_button_Attributes.SEEK_OFFSET) {
     this.seekOffset = getNumericAttr(this, media_seek_backward_button_Attributes.SEEK_OFFSET, media_seek_backward_button_DEFAULT_SEEK_OFFSET);
    }
   }
   // Own props
   /**
    * Seek amount in seconds
    */
   get seekOffset() {
    return getNumericAttr(this, media_seek_backward_button_Attributes.SEEK_OFFSET, media_seek_backward_button_DEFAULT_SEEK_OFFSET);
   }
   set seekOffset(value) {
    setNumericAttr(this, media_seek_backward_button_Attributes.SEEK_OFFSET, value);
    this.setAttribute('aria-label', t('seek back {seekOffset} seconds', { seekOffset: this.seekOffset }));
    updateIconText(getSlotted(this, 'icon'), this.seekOffset);
   }
   // Props derived from Media UI Attributes
   /**
    * The current time in seconds
    */
   get mediaCurrentTime() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_CURRENT_TIME, DEFAULT_TIME);
   }
   set mediaCurrentTime(time) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_CURRENT_TIME, time);
   }
   handleClick() {
    const detail = Math.max(this.mediaCurrentTime - this.seekOffset, 0);
    const evt = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_SEEK_REQUEST, {
     composed: true,
     bubbles: true,
     detail,
    });
    this.dispatchEvent(evt);
   }
  }
  MediaSeekBackwardButton.getSlotTemplateHTML = media_seek_backward_button_getSlotTemplateHTML;
  MediaSeekBackwardButton.getTooltipContentHTML = media_seek_backward_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-seek-backward-button')) {
   GlobalThis.customElements.define('media-seek-backward-button', MediaSeekBackwardButton);
  }
  var media_seek_backward_button_default = /* unused pure expression or super */ null && MediaSeekBackwardButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-seek-forward-button.js

  const media_seek_forward_button_Attributes = {
   SEEK_OFFSET: 'seekoffset',
  };
  const media_seek_forward_button_DEFAULT_SEEK_OFFSET = 30;
  const forwardIcon = (seekOffset) => `
  <svg aria-hidden="true" viewBox="0 0 20 24">
    <defs>
      <style>.text{font-size:8px;font-family:Arial-BoldMT, Arial;font-weight:700;}</style>
    </defs>
    <text class="text value" transform="translate(8.9 19.87)">${seekOffset}</text>
    <path d="M10 6V3l5.61 4L10 10.94V8a5.54 5.54 0 0 0-1.9 10.48v2.12A7.5 7.5 0 0 1 10 6Z"/>
  </svg>`;
  function media_seek_forward_button_getSlotTemplateHTML(_attrs, props) {
   return (
    /*html*/
    `
    <slot name="icon">${forwardIcon(props.seekOffset)}</slot>
  `
   );
  }
  function media_seek_forward_button_getTooltipContentHTML() {
   return t('Seek forward');
  }
  const media_seek_forward_button_DEFAULT_TIME = 0;
  class MediaSeekForwardButton extends MediaChromeButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_CURRENT_TIME, media_seek_forward_button_Attributes.SEEK_OFFSET];
   }
   connectedCallback() {
    super.connectedCallback();
    this.seekOffset = getNumericAttr(this, media_seek_forward_button_Attributes.SEEK_OFFSET, media_seek_forward_button_DEFAULT_SEEK_OFFSET);
   }
   attributeChangedCallback(attrName, _oldValue, newValue) {
    super.attributeChangedCallback(attrName, _oldValue, newValue);
    if (attrName === media_seek_forward_button_Attributes.SEEK_OFFSET) {
     this.seekOffset = getNumericAttr(this, media_seek_forward_button_Attributes.SEEK_OFFSET, media_seek_forward_button_DEFAULT_SEEK_OFFSET);
    }
   }
   // Own props
   /**
    * Seek amount in seconds
    */
   get seekOffset() {
    return getNumericAttr(this, media_seek_forward_button_Attributes.SEEK_OFFSET, media_seek_forward_button_DEFAULT_SEEK_OFFSET);
   }
   set seekOffset(value) {
    setNumericAttr(this, media_seek_forward_button_Attributes.SEEK_OFFSET, value);
    this.setAttribute('aria-label', t('seek forward {seekOffset} seconds', { seekOffset: this.seekOffset }));
    updateIconText(getSlotted(this, 'icon'), this.seekOffset);
   }
   // Props derived from Media UI Attributes
   /**
    * The current time in seconds
    */
   get mediaCurrentTime() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_CURRENT_TIME, media_seek_forward_button_DEFAULT_TIME);
   }
   set mediaCurrentTime(time) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_CURRENT_TIME, time);
   }
   handleClick() {
    const detail = this.mediaCurrentTime + this.seekOffset;
    const evt = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_SEEK_REQUEST, {
     composed: true,
     bubbles: true,
     detail,
    });
    this.dispatchEvent(evt);
   }
  }
  MediaSeekForwardButton.getSlotTemplateHTML = media_seek_forward_button_getSlotTemplateHTML;
  MediaSeekForwardButton.getTooltipContentHTML = media_seek_forward_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-seek-forward-button')) {
   GlobalThis.customElements.define('media-seek-forward-button', MediaSeekForwardButton);
  }
  var media_seek_forward_button_default = /* unused pure expression or super */ null && MediaSeekForwardButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-time-display.js

  var media_time_display_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_time_display_privateGet = (obj, member, getter) => {
   media_time_display_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_time_display_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_time_display_privateSet = (obj, member, value, setter) => {
   media_time_display_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_time_display_slot;

  const media_time_display_Attributes = {
   REMAINING: 'remaining',
   SHOW_DURATION: 'showduration',
   NO_TOGGLE: 'notoggle',
  };
  const CombinedAttributes = [...Object.values(media_time_display_Attributes), MediaUIAttributes.MEDIA_CURRENT_TIME, MediaUIAttributes.MEDIA_DURATION, MediaUIAttributes.MEDIA_SEEKABLE];
  const media_time_display_ButtonPressedKeys = ['Enter', ' '];
  const DEFAULT_TIMES_SEP = '&nbsp;/&nbsp;';
  const formatTimesLabel = (el, { timesSep = DEFAULT_TIMES_SEP } = {}) => {
   var _a, _b;
   const currentTime = (_a = el.mediaCurrentTime) != null ? _a : 0;
   const [, seekableEnd] = (_b = el.mediaSeekable) != null ? _b : [];
   let endTime = 0;
   if (Number.isFinite(el.mediaDuration)) {
    endTime = el.mediaDuration;
   } else if (Number.isFinite(seekableEnd)) {
    endTime = seekableEnd;
   }
   const timeLabel = el.remaining ? formatTime(0 - (endTime - currentTime)) : formatTime(currentTime);
   if (!el.showDuration) return timeLabel;
   return `${timeLabel}${timesSep}${formatTime(endTime)}`;
  };
  const DEFAULT_MISSING_TIME_PHRASE = 'video not loaded, unknown time.';
  const updateAriaValueText = (el) => {
   var _a;
   const currentTime = el.mediaCurrentTime;
   const [, seekableEnd] = (_a = el.mediaSeekable) != null ? _a : [];
   let endTime = null;
   if (Number.isFinite(el.mediaDuration)) {
    endTime = el.mediaDuration;
   } else if (Number.isFinite(seekableEnd)) {
    endTime = seekableEnd;
   }
   if (currentTime == null || endTime === null) {
    el.setAttribute('aria-valuetext', DEFAULT_MISSING_TIME_PHRASE);
    return;
   }
   const currentTimePhrase = el.remaining ? formatAsTimePhrase(0 - (endTime - currentTime)) : formatAsTimePhrase(currentTime);
   if (!el.showDuration) {
    el.setAttribute('aria-valuetext', currentTimePhrase);
    return;
   }
   const totalTimePhrase = formatAsTimePhrase(endTime);
   const fullPhrase = `${currentTimePhrase} of ${totalTimePhrase}`;
   el.setAttribute('aria-valuetext', fullPhrase);
  };
  function media_time_display_getSlotTemplateHTML(_attrs, props) {
   return (
    /*html*/
    `
    <slot>${formatTimesLabel(props)}</slot>
  `
   );
  }
  class MediaTimeDisplay extends MediaTextDisplay {
   constructor() {
    super();
    media_time_display_privateAdd(this, media_time_display_slot, void 0);
    media_time_display_privateSet(this, media_time_display_slot, this.shadowRoot.querySelector('slot'));
    media_time_display_privateGet(this, media_time_display_slot).innerHTML = `${formatTimesLabel(this)}`;
   }
   static get observedAttributes() {
    return [...super.observedAttributes, ...CombinedAttributes, 'disabled'];
   }
   connectedCallback() {
    const { style } = getOrInsertCSSRule(this.shadowRoot, ':host(:hover:not([notoggle]))');
    style.setProperty('cursor', 'var(--media-cursor, pointer)');
    style.setProperty('background', 'var(--media-control-hover-background, rgba(50 50 70 / .7))');
    if (!this.hasAttribute('disabled')) {
     this.enable();
    }
    this.setAttribute('role', 'progressbar');
    this.setAttribute('aria-label', t('playback time'));
    const keyUpHandler = (evt) => {
     const { key } = evt;
     if (!media_time_display_ButtonPressedKeys.includes(key)) {
      this.removeEventListener('keyup', keyUpHandler);
      return;
     }
     this.toggleTimeDisplay();
    };
    this.addEventListener('keydown', (evt) => {
     const { metaKey, altKey, key } = evt;
     if (metaKey || altKey || !media_time_display_ButtonPressedKeys.includes(key)) {
      this.removeEventListener('keyup', keyUpHandler);
      return;
     }
     this.addEventListener('keyup', keyUpHandler);
    });
    this.addEventListener('click', this.toggleTimeDisplay);
    super.connectedCallback();
   }
   toggleTimeDisplay() {
    if (this.noToggle) {
     return;
    }
    if (this.hasAttribute('remaining')) {
     this.removeAttribute('remaining');
    } else {
     this.setAttribute('remaining', '');
    }
   }
   disconnectedCallback() {
    this.disable();
    super.disconnectedCallback();
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    if (CombinedAttributes.includes(attrName)) {
     this.update();
    } else if (attrName === 'disabled' && newValue !== oldValue) {
     if (newValue == null) {
      this.enable();
     } else {
      this.disable();
     }
    }
    super.attributeChangedCallback(attrName, oldValue, newValue);
   }
   enable() {
    this.tabIndex = 0;
   }
   disable() {
    this.tabIndex = -1;
   }
   // Own props
   /**
    * Whether to show the remaining time
    */
   get remaining() {
    return getBooleanAttr(this, media_time_display_Attributes.REMAINING);
   }
   set remaining(show) {
    setBooleanAttr(this, media_time_display_Attributes.REMAINING, show);
   }
   /**
    * Whether to show the duration
    */
   get showDuration() {
    return getBooleanAttr(this, media_time_display_Attributes.SHOW_DURATION);
   }
   set showDuration(show) {
    setBooleanAttr(this, media_time_display_Attributes.SHOW_DURATION, show);
   }
   /**
    * Disable the default behavior that toggles between current and remaining time
    */
   get noToggle() {
    return getBooleanAttr(this, media_time_display_Attributes.NO_TOGGLE);
   }
   set noToggle(noToggle) {
    setBooleanAttr(this, media_time_display_Attributes.NO_TOGGLE, noToggle);
   }
   // Props derived from media UI attributes
   /**
    * Get the duration
    */
   get mediaDuration() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_DURATION);
   }
   set mediaDuration(time) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_DURATION, time);
   }
   /**
    * The current time in seconds
    */
   get mediaCurrentTime() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_CURRENT_TIME);
   }
   set mediaCurrentTime(time) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_CURRENT_TIME, time);
   }
   /**
    * Range of values that can be seeked to.
    * An array of two numbers [start, end]
    */
   get mediaSeekable() {
    const seekable = this.getAttribute(MediaUIAttributes.MEDIA_SEEKABLE);
    if (!seekable) return void 0;
    return seekable.split(':').map((time) => +time);
   }
   set mediaSeekable(range) {
    if (range == null) {
     this.removeAttribute(MediaUIAttributes.MEDIA_SEEKABLE);
     return;
    }
    this.setAttribute(MediaUIAttributes.MEDIA_SEEKABLE, range.join(':'));
   }
   update() {
    const timesLabel = formatTimesLabel(this);
    updateAriaValueText(this);
    if (timesLabel !== media_time_display_privateGet(this, media_time_display_slot).innerHTML) {
     media_time_display_privateGet(this, media_time_display_slot).innerHTML = timesLabel;
    }
   }
  }
  media_time_display_slot = new WeakMap();
  MediaTimeDisplay.getSlotTemplateHTML = media_time_display_getSlotTemplateHTML;
  if (!GlobalThis.customElements.get('media-time-display')) {
   GlobalThis.customElements.define('media-time-display', MediaTimeDisplay);
  }
  var media_time_display_default = /* unused pure expression or super */ null && MediaTimeDisplay; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/range-animation.js

  var range_animation_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var range_animation_privateGet = (obj, member, getter) => {
   range_animation_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var range_animation_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var range_animation_privateSet = (obj, member, value, setter) => {
   range_animation_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var __privateWrapper = (obj, member, setter, getter) => ({
   set _(value) {
    range_animation_privateSet(obj, member, value, setter);
   },
   get _() {
    return range_animation_privateGet(obj, member, getter);
   },
  });
  var _range, _startTime, _previousTime, _deltaTime, _frameCount, _updateTimestamp, _updateStartValue, _lastRangeIncrease, _id, _animate;
  class RangeAnimation {
   constructor(range, callback, fps) {
    range_animation_privateAdd(this, _range, void 0);
    range_animation_privateAdd(this, _startTime, void 0);
    range_animation_privateAdd(this, _previousTime, void 0);
    range_animation_privateAdd(this, _deltaTime, void 0);
    range_animation_privateAdd(this, _frameCount, void 0);
    range_animation_privateAdd(this, _updateTimestamp, void 0);
    range_animation_privateAdd(this, _updateStartValue, void 0);
    range_animation_privateAdd(this, _lastRangeIncrease, void 0);
    range_animation_privateAdd(this, _id, 0);
    range_animation_privateAdd(this, _animate, (now = performance.now()) => {
     range_animation_privateSet(this, _id, requestAnimationFrame(range_animation_privateGet(this, _animate)));
     range_animation_privateSet(this, _deltaTime, performance.now() - range_animation_privateGet(this, _previousTime));
     const fpsInterval = 1e3 / this.fps;
     if (range_animation_privateGet(this, _deltaTime) > fpsInterval) {
      range_animation_privateSet(this, _previousTime, now - (range_animation_privateGet(this, _deltaTime) % fpsInterval));
      const fps = 1e3 / ((now - range_animation_privateGet(this, _startTime)) / ++__privateWrapper(this, _frameCount)._);
      const delta = (now - range_animation_privateGet(this, _updateTimestamp)) / 1e3 / this.duration;
      let value = range_animation_privateGet(this, _updateStartValue) + delta * this.playbackRate;
      const increase = value - range_animation_privateGet(this, _range).valueAsNumber;
      if (increase > 0) {
       range_animation_privateSet(this, _lastRangeIncrease, this.playbackRate / this.duration / fps);
      } else {
       range_animation_privateSet(this, _lastRangeIncrease, 0.995 * range_animation_privateGet(this, _lastRangeIncrease));
       value = range_animation_privateGet(this, _range).valueAsNumber + range_animation_privateGet(this, _lastRangeIncrease);
      }
      this.callback(value);
     }
    });
    range_animation_privateSet(this, _range, range);
    this.callback = callback;
    this.fps = fps;
   }
   start() {
    if (range_animation_privateGet(this, _id) !== 0) return;
    range_animation_privateSet(this, _previousTime, performance.now());
    range_animation_privateSet(this, _startTime, range_animation_privateGet(this, _previousTime));
    range_animation_privateSet(this, _frameCount, 0);
    range_animation_privateGet(this, _animate).call(this);
   }
   stop() {
    if (range_animation_privateGet(this, _id) === 0) return;
    cancelAnimationFrame(range_animation_privateGet(this, _id));
    range_animation_privateSet(this, _id, 0);
   }
   update({ start, duration, playbackRate }) {
    const increase = start - range_animation_privateGet(this, _range).valueAsNumber;
    const durationDelta = Math.abs(duration - this.duration);
    if (increase > 0 || increase < -0.03 || durationDelta >= 0.5) {
     this.callback(start);
    }
    range_animation_privateSet(this, _updateStartValue, start);
    range_animation_privateSet(this, _updateTimestamp, performance.now());
    this.duration = duration;
    this.playbackRate = playbackRate;
   }
  }
  _range = new WeakMap();
  _startTime = new WeakMap();
  _previousTime = new WeakMap();
  _deltaTime = new WeakMap();
  _frameCount = new WeakMap();
  _updateTimestamp = new WeakMap();
  _updateStartValue = new WeakMap();
  _lastRangeIncrease = new WeakMap();
  _id = new WeakMap();
  _animate = new WeakMap(); // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-time-range.js

  var media_time_range_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_time_range_privateGet = (obj, member, getter) => {
   media_time_range_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_time_range_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_time_range_privateSet = (obj, member, value, setter) => {
   media_time_range_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_time_range_privateMethod = (obj, member, method) => {
   media_time_range_accessCheck(obj, member, 'access private method');
   return method;
  };
  var _rootNode, _animation, _boxes, _previewTime, _previewBox, _currentBox, _boxPaddingLeft, _boxPaddingRight, _mediaChaptersCues, _toggleRangeAnimation, toggleRangeAnimation_fn, _shouldRangeAnimate, shouldRangeAnimate_fn, _updateRange, _getElementRects, getElementRects_fn, _getBoxPosition, getBoxPosition_fn, _getBoxShiftPosition, getBoxShiftPosition_fn, media_time_range_handlePointerMove, media_time_range_handlePointerMove_fn, _previewRequest, previewRequest_fn, _seekRequest, seekRequest_fn;

  const media_time_range_DEFAULT_MISSING_TIME_PHRASE = 'video not loaded, unknown time.';
  const media_time_range_updateAriaValueText = (el) => {
   const range = el.range;
   const currentTimePhrase = formatAsTimePhrase(+calcTimeFromRangeValue(el));
   const totalTimePhrase = formatAsTimePhrase(+el.mediaSeekableEnd);
   const fullPhrase = !(currentTimePhrase && totalTimePhrase) ? media_time_range_DEFAULT_MISSING_TIME_PHRASE : `${currentTimePhrase} of ${totalTimePhrase}`;
   range.setAttribute('aria-valuetext', fullPhrase);
  };
  function media_time_range_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    ${MediaChromeRange.getTemplateHTML(_attrs)}
    <style>
      :host {
        --media-box-border-radius: 4px;
        --media-box-padding-left: 10px;
        --media-box-padding-right: 10px;
        --media-preview-border-radius: var(--media-box-border-radius);
        --media-box-arrow-offset: var(--media-box-border-radius);
        --_control-background: var(--media-control-background, var(--media-secondary-color, rgb(20 20 30 / .7)));
        --_preview-background: var(--media-preview-background, var(--_control-background));

        ${
         /* 1% rail width trick was off in Safari, contain: layout seems to
    prevent the horizontal overflow as well. */
         ''
        }
        contain: layout;
      }

      #buffered {
        background: var(--media-time-range-buffered-color, rgb(255 255 255 / .4));
        position: absolute;
        height: 100%;
        will-change: width;
      }

      #preview-rail,
      #current-rail {
        width: 100%;
        position: absolute;
        left: 0;
        bottom: 100%;
        pointer-events: none;
        will-change: transform;
      }

      [part~="box"] {
        width: min-content;
        ${/* absolute position is needed here so the box doesn't overflow the bounds */ ''}
        position: absolute;
        bottom: 100%;
        flex-direction: column;
        align-items: center;
        transform: translateX(-50%);
      }

      [part~="current-box"] {
        display: var(--media-current-box-display, var(--media-box-display, flex));
        margin: var(--media-current-box-margin, var(--media-box-margin, 0 0 5px));
        visibility: hidden;
      }

      [part~="preview-box"] {
        display: var(--media-preview-box-display, var(--media-box-display, flex));
        margin: var(--media-preview-box-margin, var(--media-box-margin, 0 0 5px));
        transition-property: var(--media-preview-transition-property, visibility, opacity);
        transition-duration: var(--media-preview-transition-duration-out, .25s);
        transition-delay: var(--media-preview-transition-delay-out, 0s);
        visibility: hidden;
        opacity: 0;
      }

      :host(:is([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}], [${MediaUIAttributes.MEDIA_PREVIEW_TIME}])[dragging]) [part~="preview-box"] {
        transition-duration: var(--media-preview-transition-duration-in, .5s);
        transition-delay: var(--media-preview-transition-delay-in, .25s);
        visibility: visible;
        opacity: 1;
      }

      @media (hover: hover) {
        :host(:is([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}], [${MediaUIAttributes.MEDIA_PREVIEW_TIME}]):hover) [part~="preview-box"] {
          transition-duration: var(--media-preview-transition-duration-in, .5s);
          transition-delay: var(--media-preview-transition-delay-in, .25s);
          visibility: visible;
          opacity: 1;
        }
      }

      media-preview-thumbnail,
      ::slotted(media-preview-thumbnail) {
        visibility: hidden;
        ${/* delay changing these CSS props until the preview box transition is ended */ ''}
        transition: visibility 0s .25s;
        transition-delay: calc(var(--media-preview-transition-delay-out, 0s) + var(--media-preview-transition-duration-out, .25s));
        background: var(--media-preview-thumbnail-background, var(--_preview-background));
        box-shadow: var(--media-preview-thumbnail-box-shadow, 0 0 4px rgb(0 0 0 / .2));
        max-width: var(--media-preview-thumbnail-max-width, 180px);
        max-height: var(--media-preview-thumbnail-max-height, 160px);
        min-width: var(--media-preview-thumbnail-min-width, 120px);
        min-height: var(--media-preview-thumbnail-min-height, 80px);
        border: var(--media-preview-thumbnail-border);
        border-radius: var(--media-preview-thumbnail-border-radius,
          var(--media-preview-border-radius) var(--media-preview-border-radius) 0 0);
      }

      :host([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}][dragging]) media-preview-thumbnail,
      :host([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}][dragging]) ::slotted(media-preview-thumbnail) {
        transition-delay: var(--media-preview-transition-delay-in, .25s);
        visibility: visible;
      }

      @media (hover: hover) {
        :host([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}]:hover) media-preview-thumbnail,
        :host([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}]:hover) ::slotted(media-preview-thumbnail) {
          transition-delay: var(--media-preview-transition-delay-in, .25s);
          visibility: visible;
        }

        :host([${MediaUIAttributes.MEDIA_PREVIEW_TIME}]:hover) {
          --media-time-range-hover-display: block;
        }
      }

      media-preview-chapter-display,
      ::slotted(media-preview-chapter-display) {
        font-size: var(--media-font-size, 13px);
        line-height: 17px;
        min-width: 0;
        visibility: hidden;
        ${/* delay changing these CSS props until the preview box transition is ended */ ''}
        transition: min-width 0s, border-radius 0s, margin 0s, padding 0s, visibility 0s;
        transition-delay: calc(var(--media-preview-transition-delay-out, 0s) + var(--media-preview-transition-duration-out, .25s));
        background: var(--media-preview-chapter-background, var(--_preview-background));
        border-radius: var(--media-preview-chapter-border-radius,
          var(--media-preview-border-radius) var(--media-preview-border-radius)
          var(--media-preview-border-radius) var(--media-preview-border-radius));
        padding: var(--media-preview-chapter-padding, 3.5px 9px);
        margin: var(--media-preview-chapter-margin, 0 0 5px);
        text-shadow: var(--media-preview-chapter-text-shadow, 0 0 4px rgb(0 0 0 / .75));
      }

      :host([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}]) media-preview-chapter-display,
      :host([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}]) ::slotted(media-preview-chapter-display) {
        transition-delay: var(--media-preview-transition-delay-in, .25s);
        border-radius: var(--media-preview-chapter-border-radius, 0);
        padding: var(--media-preview-chapter-padding, 3.5px 9px 0);
        margin: var(--media-preview-chapter-margin, 0);
        min-width: 100%;
      }

      media-preview-chapter-display[${MediaUIAttributes.MEDIA_PREVIEW_CHAPTER}],
      ::slotted(media-preview-chapter-display[${MediaUIAttributes.MEDIA_PREVIEW_CHAPTER}]) {
        visibility: visible;
      }

      media-preview-chapter-display:not([aria-valuetext]),
      ::slotted(media-preview-chapter-display:not([aria-valuetext])) {
        display: none;
      }

      media-preview-time-display,
      ::slotted(media-preview-time-display),
      media-time-display,
      ::slotted(media-time-display) {
        font-size: var(--media-font-size, 13px);
        line-height: 17px;
        min-width: 0;
        ${/* delay changing these CSS props until the preview box transition is ended */ ''}
        transition: min-width 0s, border-radius 0s;
        transition-delay: calc(var(--media-preview-transition-delay-out, 0s) + var(--media-preview-transition-duration-out, .25s));
        background: var(--media-preview-time-background, var(--_preview-background));
        border-radius: var(--media-preview-time-border-radius,
          var(--media-preview-border-radius) var(--media-preview-border-radius)
          var(--media-preview-border-radius) var(--media-preview-border-radius));
        padding: var(--media-preview-time-padding, 3.5px 9px);
        margin: var(--media-preview-time-margin, 0);
        text-shadow: var(--media-preview-time-text-shadow, 0 0 4px rgb(0 0 0 / .75));
        transform: translateX(min(
          max(calc(50% - var(--_box-width) / 2),
          calc(var(--_box-shift, 0))),
          calc(var(--_box-width) / 2 - 50%)
        ));
      }

      :host([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}]) media-preview-time-display,
      :host([${MediaUIAttributes.MEDIA_PREVIEW_IMAGE}]) ::slotted(media-preview-time-display) {
        transition-delay: var(--media-preview-transition-delay-in, .25s);
        border-radius: var(--media-preview-time-border-radius,
          0 0 var(--media-preview-border-radius) var(--media-preview-border-radius));
        min-width: 100%;
      }

      :host([${MediaUIAttributes.MEDIA_PREVIEW_TIME}]:hover) {
        --media-time-range-hover-display: block;
      }

      [part~="arrow"],
      ::slotted([part~="arrow"]) {
        display: var(--media-box-arrow-display, inline-block);
        transform: translateX(min(
          max(calc(50% - var(--_box-width) / 2 + var(--media-box-arrow-offset)),
          calc(var(--_box-shift, 0))),
          calc(var(--_box-width) / 2 - 50% - var(--media-box-arrow-offset))
        ));
        ${/* border-color has to come before border-top-color! */ ''}
        border-color: transparent;
        border-top-color: var(--media-box-arrow-background, var(--_control-background));
        border-width: var(--media-box-arrow-border-width,
          var(--media-box-arrow-height, 5px) var(--media-box-arrow-width, 6px) 0);
        border-style: solid;
        justify-content: center;
        height: 0;
      }
    </style>
    <div id="preview-rail">
      <slot name="preview" part="box preview-box">
        <media-preview-thumbnail>
          <template shadowrootmode="${media_preview_thumbnail_default.shadowRootOptions.mode}">
            ${media_preview_thumbnail_default.getTemplateHTML({})}
          </template>
        </media-preview-thumbnail>
        <media-preview-chapter-display></media-preview-chapter-display>
        <media-preview-time-display></media-preview-time-display>
        <slot name="preview-arrow"><div part="arrow"></div></slot>
      </slot>
    </div>
    <div id="current-rail">
      <slot name="current" part="box current-box">
        ${
         /* Example: add the current time w/ arrow to the playhead
    <media-time-display slot="current"></media-time-display>
    <div part="arrow" slot="current"></div> */
         ''
        }
      </slot>
    </div>
  `
   );
  }
  const calcRangeValueFromTime = (el, time = el.mediaCurrentTime) => {
   const startTime = Number.isFinite(el.mediaSeekableStart) ? el.mediaSeekableStart : 0;
   const endTime = Number.isFinite(el.mediaDuration) ? el.mediaDuration : el.mediaSeekableEnd;
   if (Number.isNaN(endTime)) return 0;
   const value = (time - startTime) / (endTime - startTime);
   return Math.max(0, Math.min(value, 1));
  };
  const calcTimeFromRangeValue = (el, value = el.range.valueAsNumber) => {
   const startTime = Number.isFinite(el.mediaSeekableStart) ? el.mediaSeekableStart : 0;
   const endTime = Number.isFinite(el.mediaDuration) ? el.mediaDuration : el.mediaSeekableEnd;
   if (Number.isNaN(endTime)) return 0;
   return value * (endTime - startTime) + startTime;
  };
  class MediaTimeRange extends MediaChromeRange {
   constructor() {
    super();
    media_time_range_privateAdd(this, _toggleRangeAnimation);
    media_time_range_privateAdd(this, _shouldRangeAnimate);
    media_time_range_privateAdd(this, _getElementRects);
    /**
     * Get the position, max and min for the box in percentage.
     * It's important this is in percentage so when the player is resized
     * the box will move accordingly.
     */
    media_time_range_privateAdd(this, _getBoxPosition);
    media_time_range_privateAdd(this, _getBoxShiftPosition);
    media_time_range_privateAdd(this, media_time_range_handlePointerMove);
    media_time_range_privateAdd(this, _previewRequest);
    media_time_range_privateAdd(this, _seekRequest);
    media_time_range_privateAdd(this, _rootNode, void 0);
    media_time_range_privateAdd(this, _animation, void 0);
    media_time_range_privateAdd(this, _boxes, void 0);
    media_time_range_privateAdd(this, _previewTime, void 0);
    media_time_range_privateAdd(this, _previewBox, void 0);
    media_time_range_privateAdd(this, _currentBox, void 0);
    media_time_range_privateAdd(this, _boxPaddingLeft, void 0);
    media_time_range_privateAdd(this, _boxPaddingRight, void 0);
    media_time_range_privateAdd(this, _mediaChaptersCues, void 0);
    media_time_range_privateAdd(this, _updateRange, (value) => {
     if (this.dragging) return;
     if (isValidNumber(value)) {
      this.range.valueAsNumber = value;
     }
     this.updateBar();
    });
    const track = this.shadowRoot.querySelector('#track');
    track.insertAdjacentHTML('afterbegin', '<div id="buffered" part="buffered"></div>');
    media_time_range_privateSet(this, _boxes, this.shadowRoot.querySelectorAll('[part~="box"]'));
    media_time_range_privateSet(this, _previewBox, this.shadowRoot.querySelector('[part~="preview-box"]'));
    media_time_range_privateSet(this, _currentBox, this.shadowRoot.querySelector('[part~="current-box"]'));
    const computedStyle = getComputedStyle(this);
    media_time_range_privateSet(this, _boxPaddingLeft, parseInt(computedStyle.getPropertyValue('--media-box-padding-left')));
    media_time_range_privateSet(this, _boxPaddingRight, parseInt(computedStyle.getPropertyValue('--media-box-padding-right')));
    media_time_range_privateSet(this, _animation, new RangeAnimation(this.range, media_time_range_privateGet(this, _updateRange), 60));
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_PAUSED, MediaUIAttributes.MEDIA_DURATION, MediaUIAttributes.MEDIA_SEEKABLE, MediaUIAttributes.MEDIA_CURRENT_TIME, MediaUIAttributes.MEDIA_PREVIEW_IMAGE, MediaUIAttributes.MEDIA_PREVIEW_TIME, MediaUIAttributes.MEDIA_PREVIEW_CHAPTER, MediaUIAttributes.MEDIA_BUFFERED, MediaUIAttributes.MEDIA_PLAYBACK_RATE, MediaUIAttributes.MEDIA_LOADING, MediaUIAttributes.MEDIA_ENDED];
   }
   connectedCallback() {
    var _a;
    super.connectedCallback();
    this.range.setAttribute('aria-label', t('seek'));
    media_time_range_privateMethod(this, _toggleRangeAnimation, toggleRangeAnimation_fn).call(this);
    media_time_range_privateSet(this, _rootNode, this.getRootNode());
    (_a = media_time_range_privateGet(this, _rootNode)) == null ? void 0 : _a.addEventListener('transitionstart', this);
   }
   disconnectedCallback() {
    var _a;
    super.disconnectedCallback();
    media_time_range_privateMethod(this, _toggleRangeAnimation, toggleRangeAnimation_fn).call(this);
    (_a = media_time_range_privateGet(this, _rootNode)) == null ? void 0 : _a.removeEventListener('transitionstart', this);
    media_time_range_privateSet(this, _rootNode, null);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (oldValue == newValue) return;
    if (attrName === MediaUIAttributes.MEDIA_CURRENT_TIME || attrName === MediaUIAttributes.MEDIA_PAUSED || attrName === MediaUIAttributes.MEDIA_ENDED || attrName === MediaUIAttributes.MEDIA_LOADING || attrName === MediaUIAttributes.MEDIA_DURATION || attrName === MediaUIAttributes.MEDIA_SEEKABLE) {
     media_time_range_privateGet(this, _animation).update({
      start: calcRangeValueFromTime(this),
      duration: this.mediaSeekableEnd - this.mediaSeekableStart,
      playbackRate: this.mediaPlaybackRate,
     });
     media_time_range_privateMethod(this, _toggleRangeAnimation, toggleRangeAnimation_fn).call(this);
     media_time_range_updateAriaValueText(this);
    } else if (attrName === MediaUIAttributes.MEDIA_BUFFERED) {
     this.updateBufferedBar();
    }
    if (attrName === MediaUIAttributes.MEDIA_DURATION || attrName === MediaUIAttributes.MEDIA_SEEKABLE) {
     this.mediaChaptersCues = media_time_range_privateGet(this, _mediaChaptersCues);
     this.updateBar();
    }
   }
   get mediaChaptersCues() {
    return media_time_range_privateGet(this, _mediaChaptersCues);
   }
   set mediaChaptersCues(value) {
    var _a;
    media_time_range_privateSet(this, _mediaChaptersCues, value);
    this.updateSegments(
     (_a = media_time_range_privateGet(this, _mediaChaptersCues)) == null
      ? void 0
      : _a.map((c) => ({
         start: calcRangeValueFromTime(this, c.startTime),
         end: calcRangeValueFromTime(this, c.endTime),
        })),
    );
   }
   /**
    * Is the media paused
    */
   get mediaPaused() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED);
   }
   set mediaPaused(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_PAUSED, value);
   }
   /**
    * Is the media loading
    */
   get mediaLoading() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_LOADING);
   }
   set mediaLoading(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_LOADING, value);
   }
   /**
    *
    */
   get mediaDuration() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_DURATION);
   }
   set mediaDuration(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_DURATION, value);
   }
   /**
    *
    */
   get mediaCurrentTime() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_CURRENT_TIME);
   }
   set mediaCurrentTime(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_CURRENT_TIME, value);
   }
   /**
    *
    */
   get mediaPlaybackRate() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_PLAYBACK_RATE, 1);
   }
   set mediaPlaybackRate(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_PLAYBACK_RATE, value);
   }
   /**
    * An array of ranges, each range being an array of two numbers.
    * e.g. [[1, 2], [3, 4]]
    */
   get mediaBuffered() {
    const buffered = this.getAttribute(MediaUIAttributes.MEDIA_BUFFERED);
    if (!buffered) return [];
    return buffered.split(' ').map((timePair) => timePair.split(':').map((timeStr) => +timeStr));
   }
   set mediaBuffered(list) {
    if (!list) {
     this.removeAttribute(MediaUIAttributes.MEDIA_BUFFERED);
     return;
    }
    const strVal = list.map((tuple) => tuple.join(':')).join(' ');
    this.setAttribute(MediaUIAttributes.MEDIA_BUFFERED, strVal);
   }
   /**
    * Range of values that can be seeked to
    * An array of two numbers [start, end]
    */
   get mediaSeekable() {
    const seekable = this.getAttribute(MediaUIAttributes.MEDIA_SEEKABLE);
    if (!seekable) return void 0;
    return seekable.split(':').map((time) => +time);
   }
   set mediaSeekable(range) {
    if (range == null) {
     this.removeAttribute(MediaUIAttributes.MEDIA_SEEKABLE);
     return;
    }
    this.setAttribute(MediaUIAttributes.MEDIA_SEEKABLE, range.join(':'));
   }
   /**
    *
    */
   get mediaSeekableEnd() {
    var _a;
    const [, end = this.mediaDuration] = (_a = this.mediaSeekable) != null ? _a : [];
    return end;
   }
   get mediaSeekableStart() {
    var _a;
    const [start = 0] = (_a = this.mediaSeekable) != null ? _a : [];
    return start;
   }
   /**
    * The url of the preview image
    */
   get mediaPreviewImage() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_PREVIEW_IMAGE);
   }
   set mediaPreviewImage(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_PREVIEW_IMAGE, value);
   }
   /**
    *
    */
   get mediaPreviewTime() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_PREVIEW_TIME);
   }
   set mediaPreviewTime(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_PREVIEW_TIME, value);
   }
   /**
    *
    */
   get mediaEnded() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_ENDED);
   }
   set mediaEnded(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_ENDED, value);
   }
   /* Add a buffered progress bar */
   updateBar() {
    super.updateBar();
    this.updateBufferedBar();
    this.updateCurrentBox();
   }
   updateBufferedBar() {
    var _a;
    const buffered = this.mediaBuffered;
    if (!buffered.length) {
     return;
    }
    let relativeBufferedEnd;
    if (!this.mediaEnded) {
     const currentTime = this.mediaCurrentTime;
     const [, bufferedEnd = this.mediaSeekableStart] = (_a = buffered.find(([start, end]) => start <= currentTime && currentTime <= end)) != null ? _a : [];
     relativeBufferedEnd = calcRangeValueFromTime(this, bufferedEnd);
    } else {
     relativeBufferedEnd = 1;
    }
    const { style } = getOrInsertCSSRule(this.shadowRoot, '#buffered');
    style.setProperty('width', `${relativeBufferedEnd * 100}%`);
   }
   updateCurrentBox() {
    const currentSlot = this.shadowRoot.querySelector('slot[name="current"]');
    if (!currentSlot.assignedElements().length) return;
    const currentRailRule = getOrInsertCSSRule(this.shadowRoot, '#current-rail');
    const currentBoxRule = getOrInsertCSSRule(this.shadowRoot, '[part~="current-box"]');
    const rects = media_time_range_privateMethod(this, _getElementRects, getElementRects_fn).call(this, media_time_range_privateGet(this, _currentBox));
    const boxPos = media_time_range_privateMethod(this, _getBoxPosition, getBoxPosition_fn).call(this, rects, this.range.valueAsNumber);
    const boxShift = media_time_range_privateMethod(this, _getBoxShiftPosition, getBoxShiftPosition_fn).call(this, rects, this.range.valueAsNumber);
    currentRailRule.style.transform = `translateX(${boxPos})`;
    currentRailRule.style.setProperty('--_range-width', `${rects.range.width}`);
    currentBoxRule.style.setProperty('--_box-shift', `${boxShift}`);
    currentBoxRule.style.setProperty('--_box-width', `${rects.box.width}px`);
    currentBoxRule.style.setProperty('visibility', 'initial');
   }
   handleEvent(evt) {
    super.handleEvent(evt);
    switch (evt.type) {
     case 'input':
      media_time_range_privateMethod(this, _seekRequest, seekRequest_fn).call(this);
      break;
     case 'pointermove':
      media_time_range_privateMethod(this, media_time_range_handlePointerMove, media_time_range_handlePointerMove_fn).call(this, evt);
      break;
     case 'pointerup':
     case 'pointerleave':
      media_time_range_privateMethod(this, _previewRequest, previewRequest_fn).call(this, null);
      break;
     case 'transitionstart':
      if (containsComposedNode(evt.target, this)) {
       setTimeout(() => media_time_range_privateMethod(this, _toggleRangeAnimation, toggleRangeAnimation_fn).call(this), 0);
      }
      break;
    }
   }
  }
  _rootNode = new WeakMap();
  _animation = new WeakMap();
  _boxes = new WeakMap();
  _previewTime = new WeakMap();
  _previewBox = new WeakMap();
  _currentBox = new WeakMap();
  _boxPaddingLeft = new WeakMap();
  _boxPaddingRight = new WeakMap();
  _mediaChaptersCues = new WeakMap();
  _toggleRangeAnimation = new WeakSet();
  toggleRangeAnimation_fn = function () {
   if (media_time_range_privateMethod(this, _shouldRangeAnimate, shouldRangeAnimate_fn).call(this)) {
    media_time_range_privateGet(this, _animation).start();
   } else {
    media_time_range_privateGet(this, _animation).stop();
   }
  };
  _shouldRangeAnimate = new WeakSet();
  shouldRangeAnimate_fn = function () {
   return this.isConnected && !this.mediaPaused && !this.mediaLoading && !this.mediaEnded && this.mediaSeekableEnd > 0 && isElementVisible(this);
  };
  _updateRange = new WeakMap();
  _getElementRects = new WeakSet();
  getElementRects_fn = function (box) {
   var _a;
   const bounds = (_a = this.getAttribute('bounds') ? closestComposedNode(this, `#${this.getAttribute('bounds')}`) : this.parentElement) != null ? _a : this;
   const boundsRect = bounds.getBoundingClientRect();
   const rangeRect = this.range.getBoundingClientRect();
   const width = box.offsetWidth;
   const min = -(rangeRect.left - boundsRect.left - width / 2);
   const max = boundsRect.right - rangeRect.left - width / 2;
   return {
    box: { width, min, max },
    bounds: boundsRect,
    range: rangeRect,
   };
  };
  _getBoxPosition = new WeakSet();
  getBoxPosition_fn = function (rects, ratio) {
   let position = `${ratio * 100}%`;
   const { width, min, max } = rects.box;
   if (!width) return position;
   if (!Number.isNaN(min)) {
    const pad = `var(--media-box-padding-left)`;
    const minPos = `calc(1 / var(--_range-width) * 100 * ${min}% + ${pad})`;
    position = `max(${minPos}, ${position})`;
   }
   if (!Number.isNaN(max)) {
    const pad = `var(--media-box-padding-right)`;
    const maxPos = `calc(1 / var(--_range-width) * 100 * ${max}% - ${pad})`;
    position = `min(${position}, ${maxPos})`;
   }
   return position;
  };
  _getBoxShiftPosition = new WeakSet();
  getBoxShiftPosition_fn = function (rects, ratio) {
   const { width, min, max } = rects.box;
   const pointerX = ratio * rects.range.width;
   if (pointerX < min + media_time_range_privateGet(this, _boxPaddingLeft)) {
    const offset = rects.range.left - rects.bounds.left - media_time_range_privateGet(this, _boxPaddingLeft);
    return `${pointerX - width / 2 + offset}px`;
   }
   if (pointerX > max - media_time_range_privateGet(this, _boxPaddingRight)) {
    const offset = rects.bounds.right - rects.range.right - media_time_range_privateGet(this, _boxPaddingRight);
    return `${pointerX + width / 2 - offset - rects.range.width}px`;
   }
   return 0;
  };
  media_time_range_handlePointerMove = new WeakSet();
  media_time_range_handlePointerMove_fn = function (evt) {
   const isOverBoxes = [...media_time_range_privateGet(this, _boxes)].some((b) => evt.composedPath().includes(b));
   if (!this.dragging && (isOverBoxes || !evt.composedPath().includes(this))) {
    media_time_range_privateMethod(this, _previewRequest, previewRequest_fn).call(this, null);
    return;
   }
   const duration = this.mediaSeekableEnd;
   if (!duration) return;
   const previewRailRule = getOrInsertCSSRule(this.shadowRoot, '#preview-rail');
   const previewBoxRule = getOrInsertCSSRule(this.shadowRoot, '[part~="preview-box"]');
   const rects = media_time_range_privateMethod(this, _getElementRects, getElementRects_fn).call(this, media_time_range_privateGet(this, _previewBox));
   let pointerRatio = (evt.clientX - rects.range.left) / rects.range.width;
   pointerRatio = Math.max(0, Math.min(1, pointerRatio));
   const boxPos = media_time_range_privateMethod(this, _getBoxPosition, getBoxPosition_fn).call(this, rects, pointerRatio);
   const boxShift = media_time_range_privateMethod(this, _getBoxShiftPosition, getBoxShiftPosition_fn).call(this, rects, pointerRatio);
   previewRailRule.style.transform = `translateX(${boxPos})`;
   previewRailRule.style.setProperty('--_range-width', `${rects.range.width}`);
   previewBoxRule.style.setProperty('--_box-shift', `${boxShift}`);
   previewBoxRule.style.setProperty('--_box-width', `${rects.box.width}px`);
   const diff = Math.round(media_time_range_privateGet(this, _previewTime)) - Math.round(pointerRatio * duration);
   if (Math.abs(diff) < 1 && pointerRatio > 0.01 && pointerRatio < 0.99) return;
   media_time_range_privateSet(this, _previewTime, pointerRatio * duration);
   media_time_range_privateMethod(this, _previewRequest, previewRequest_fn).call(this, media_time_range_privateGet(this, _previewTime));
  };
  _previewRequest = new WeakSet();
  previewRequest_fn = function (detail) {
   this.dispatchEvent(
    new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_PREVIEW_REQUEST, {
     composed: true,
     bubbles: true,
     detail,
    }),
   );
  };
  _seekRequest = new WeakSet();
  seekRequest_fn = function () {
   media_time_range_privateGet(this, _animation).stop();
   const detail = calcTimeFromRangeValue(this);
   this.dispatchEvent(
    new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_SEEK_REQUEST, {
     composed: true,
     bubbles: true,
     detail,
    }),
   );
  };
  MediaTimeRange.shadowRootOptions = { mode: 'open' };
  MediaTimeRange.getTemplateHTML = media_time_range_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-time-range')) {
   GlobalThis.customElements.define('media-time-range', MediaTimeRange);
  }
  var media_time_range_default = /* unused pure expression or super */ null && MediaTimeRange; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-volume-range.js

  const DEFAULT_VOLUME = 1;
  const toVolume = (el) => {
   if (el.mediaMuted) return 0;
   return el.mediaVolume;
  };
  const formatAsPercentString = (value) => `${Math.round(value * 100)}%`;
  class MediaVolumeRange extends MediaChromeRange {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_VOLUME, MediaUIAttributes.MEDIA_MUTED, MediaUIAttributes.MEDIA_VOLUME_UNAVAILABLE];
   }
   constructor() {
    super();
    this.range.addEventListener('input', () => {
     const detail = this.range.value;
     const evt = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_VOLUME_REQUEST, {
      composed: true,
      bubbles: true,
      detail,
     });
     this.dispatchEvent(evt);
    });
   }
   connectedCallback() {
    super.connectedCallback();
    this.range.setAttribute('aria-label', t('volume'));
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_VOLUME || attrName === MediaUIAttributes.MEDIA_MUTED) {
     this.range.valueAsNumber = toVolume(this);
     this.range.setAttribute('aria-valuetext', formatAsPercentString(this.range.valueAsNumber));
     this.updateBar();
    }
   }
   /**
    *
    */
   get mediaVolume() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_VOLUME, DEFAULT_VOLUME);
   }
   set mediaVolume(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_VOLUME, value);
   }
   /**
    * Is the media currently muted
    */
   get mediaMuted() {
    return getBooleanAttr(this, MediaUIAttributes.MEDIA_MUTED);
   }
   set mediaMuted(value) {
    setBooleanAttr(this, MediaUIAttributes.MEDIA_MUTED, value);
   }
   /**
    * The volume unavailability state
    */
   get mediaVolumeUnavailable() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_VOLUME_UNAVAILABLE);
   }
   set mediaVolumeUnavailable(value) {
    setStringAttr(this, MediaUIAttributes.MEDIA_VOLUME_UNAVAILABLE, value);
   }
  }
  if (!GlobalThis.customElements.get('media-volume-range')) {
   GlobalThis.customElements.define('media-volume-range', MediaVolumeRange);
  }
  var media_volume_range_default = /* unused pure expression or super */ null && MediaVolumeRange; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/index.js
  // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/template-parts.js

  var template_parts_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var template_parts_privateGet = (obj, member, getter) => {
   template_parts_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var template_parts_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var template_parts_privateSet = (obj, member, value, setter) => {
   template_parts_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var _parts, _processor, _items, _value, _element, _attributeName, _namespaceURI, _list, list_get, _parentNode, _nodes;

  const ELEMENT = 1;
  const STRING = 0;
  const PART = 1;
  const defaultProcessor = {
   processCallback(instance, parts, state) {
    if (!state) return;
    for (const [expression, part] of parts) {
     if (expression in state) {
      const value = state[expression];
      if (typeof value === 'boolean' && part instanceof AttrPart && typeof part.element[part.attributeName] === 'boolean') {
       part.booleanValue = value;
      } else if (typeof value === 'function' && part instanceof AttrPart) {
       part.element[part.attributeName] = value;
      } else {
       part.value = value;
      }
     }
    }
   },
  };
  class TemplateInstance extends GlobalThis.DocumentFragment {
   constructor(template, state, processor = defaultProcessor) {
    var _a;
    super();
    template_parts_privateAdd(this, _parts, void 0);
    template_parts_privateAdd(this, _processor, void 0);
    this.append(template.content.cloneNode(true));
    template_parts_privateSet(this, _parts, parse(this));
    template_parts_privateSet(this, _processor, processor);
    (_a = processor.createCallback) == null ? void 0 : _a.call(processor, this, template_parts_privateGet(this, _parts), state);
    processor.processCallback(this, template_parts_privateGet(this, _parts), state);
   }
   update(state) {
    template_parts_privateGet(this, _processor).processCallback(this, template_parts_privateGet(this, _parts), state);
   }
  }
  _parts = new WeakMap();
  _processor = new WeakMap();
  const parse = (element, parts = []) => {
   let type, value;
   for (const attr of element.attributes || []) {
    if (attr.value.includes('{{')) {
     const list = new AttrPartList();
     for ([type, value] of tokenize(attr.value)) {
      if (!type) list.append(value);
      else {
       const part = new AttrPart(element, attr.name, attr.namespaceURI);
       list.append(part);
       parts.push([value, part]);
      }
     }
     attr.value = list.toString();
    }
   }
   for (const node of element.childNodes) {
    if (node.nodeType === ELEMENT && !(node instanceof HTMLTemplateElement)) {
     parse(node, parts);
    } else {
     const data = node.data;
     if (node.nodeType === ELEMENT || data.includes('{{')) {
      const items = [];
      if (data) {
       for ([type, value] of tokenize(data))
        if (!type) items.push(new Text(value));
        else {
         const part = new ChildNodePart(element);
         items.push(part);
         parts.push([value, part]);
        }
      } else if (node instanceof HTMLTemplateElement) {
       const part = new InnerTemplatePart(element, node);
       items.push(part);
       parts.push([part.expression, part]);
      }
      node.replaceWith(...items.flatMap((part) => part.replacementNodes || [part]));
     }
    }
   }
   return parts;
  };
  const mem = {};
  const tokenize = (text) => {
   let value = '',
    open = 0,
    tokens = mem[text],
    i = 0,
    c;
   if (tokens) return tokens;
   else tokens = [];
   for (; (c = text[i]); i++) {
    if (c === '{' && text[i + 1] === '{' && text[i - 1] !== '\\' && text[i + 2] && ++open == 1) {
     if (value) tokens.push([STRING, value]);
     value = '';
     i++;
    } else if (c === '}' && text[i + 1] === '}' && text[i - 1] !== '\\' && !--open) {
     tokens.push([PART, value.trim()]);
     value = '';
     i++;
    } else value += c || '';
   }
   if (value) tokens.push([STRING, (open > 0 ? '{{' : '') + value]);
   return (mem[text] = tokens);
  };
  const FRAGMENT = 11;
  class Part {
   get value() {
    return '';
   }
   set value(val) {}
   toString() {
    return this.value;
   }
  }
  const attrPartToList = /* @__PURE__ */ new WeakMap();
  class AttrPartList {
   constructor() {
    template_parts_privateAdd(this, _items, []);
   }
   [Symbol.iterator]() {
    return template_parts_privateGet(this, _items).values();
   }
   get length() {
    return template_parts_privateGet(this, _items).length;
   }
   item(index) {
    return template_parts_privateGet(this, _items)[index];
   }
   append(...items) {
    for (const item of items) {
     if (item instanceof AttrPart) {
      attrPartToList.set(item, this);
     }
     template_parts_privateGet(this, _items).push(item);
    }
   }
   toString() {
    return template_parts_privateGet(this, _items).join('');
   }
  }
  _items = new WeakMap();
  class AttrPart extends Part {
   constructor(element, attributeName, namespaceURI) {
    super();
    template_parts_privateAdd(this, _list);
    template_parts_privateAdd(this, _value, '');
    template_parts_privateAdd(this, _element, void 0);
    template_parts_privateAdd(this, _attributeName, void 0);
    template_parts_privateAdd(this, _namespaceURI, void 0);
    template_parts_privateSet(this, _element, element);
    template_parts_privateSet(this, _attributeName, attributeName);
    template_parts_privateSet(this, _namespaceURI, namespaceURI);
   }
   get attributeName() {
    return template_parts_privateGet(this, _attributeName);
   }
   get attributeNamespace() {
    return template_parts_privateGet(this, _namespaceURI);
   }
   get element() {
    return template_parts_privateGet(this, _element);
   }
   get value() {
    return template_parts_privateGet(this, _value);
   }
   set value(newValue) {
    if (template_parts_privateGet(this, _value) === newValue) return;
    template_parts_privateSet(this, _value, newValue);
    if (!template_parts_privateGet(this, _list, list_get) || template_parts_privateGet(this, _list, list_get).length === 1) {
     if (newValue == null) {
      template_parts_privateGet(this, _element).removeAttributeNS(template_parts_privateGet(this, _namespaceURI), template_parts_privateGet(this, _attributeName));
     } else {
      template_parts_privateGet(this, _element).setAttributeNS(template_parts_privateGet(this, _namespaceURI), template_parts_privateGet(this, _attributeName), newValue);
     }
    } else {
     template_parts_privateGet(this, _element).setAttributeNS(template_parts_privateGet(this, _namespaceURI), template_parts_privateGet(this, _attributeName), template_parts_privateGet(this, _list, list_get).toString());
    }
   }
   get booleanValue() {
    return template_parts_privateGet(this, _element).hasAttributeNS(template_parts_privateGet(this, _namespaceURI), template_parts_privateGet(this, _attributeName));
   }
   set booleanValue(value) {
    if (!template_parts_privateGet(this, _list, list_get) || template_parts_privateGet(this, _list, list_get).length === 1) this.value = value ? '' : null;
    else throw new DOMException('Value is not fully templatized');
   }
  }
  _value = new WeakMap();
  _element = new WeakMap();
  _attributeName = new WeakMap();
  _namespaceURI = new WeakMap();
  _list = new WeakSet();
  list_get = function () {
   return attrPartToList.get(this);
  };
  class ChildNodePart extends Part {
   constructor(parentNode, nodes) {
    super();
    template_parts_privateAdd(this, _parentNode, void 0);
    template_parts_privateAdd(this, _nodes, void 0);
    template_parts_privateSet(this, _parentNode, parentNode);
    template_parts_privateSet(this, _nodes, nodes ? [...nodes] : [new Text()]);
   }
   get replacementNodes() {
    return template_parts_privateGet(this, _nodes);
   }
   get parentNode() {
    return template_parts_privateGet(this, _parentNode);
   }
   get nextSibling() {
    return template_parts_privateGet(this, _nodes)[template_parts_privateGet(this, _nodes).length - 1].nextSibling;
   }
   get previousSibling() {
    return template_parts_privateGet(this, _nodes)[0].previousSibling;
   }
   // FIXME: not sure why do we need string serialization here? Just because parent class has type DOMString?
   get value() {
    return template_parts_privateGet(this, _nodes)
     .map((node) => node.textContent)
     .join('');
   }
   set value(newValue) {
    this.replace(newValue);
   }
   replace(...nodes) {
    const normalisedNodes = nodes.flat().flatMap((node) => (node == null ? [new Text()] : node.forEach ? [...node] : node.nodeType === FRAGMENT ? [...node.childNodes] : node.nodeType ? [node] : [new Text(node)]));
    if (!normalisedNodes.length) normalisedNodes.push(new Text());
    template_parts_privateSet(this, _nodes, swapdom(template_parts_privateGet(this, _nodes)[0].parentNode, template_parts_privateGet(this, _nodes), normalisedNodes, this.nextSibling));
   }
  }
  _parentNode = new WeakMap();
  _nodes = new WeakMap();
  class InnerTemplatePart extends ChildNodePart {
   constructor(parentNode, template) {
    const directive = template.getAttribute('directive') || template.getAttribute('type');
    let expression = template.getAttribute('expression') || template.getAttribute(directive) || '';
    if (expression.startsWith('{{')) expression = expression.trim().slice(2, -2).trim();
    super(parentNode);
    this.expression = expression;
    this.template = template;
    this.directive = directive;
   }
  }
  function swapdom(parent, a, b, end = null) {
   let i = 0,
    cur,
    next,
    bi,
    n = b.length,
    m = a.length;
   while (i < n && i < m && a[i] == b[i]) i++;
   while (i < n && i < m && b[n - 1] == a[m - 1]) end = b[(--m, --n)];
   if (i == m) while (i < n) parent.insertBefore(b[i++], end);
   if (i == n) while (i < m) parent.removeChild(a[i++]);
   else {
    cur = a[i];
    while (i < n) {
     (bi = b[i++]), (next = cur ? cur.nextSibling : end);
     if (cur == bi) cur = next;
     else if (i < n && b[i] == next) parent.replaceChild(bi, cur), (cur = next);
     else parent.insertBefore(bi, cur);
    }
    while (cur != end) (next = cur.nextSibling), parent.removeChild(cur), (cur = next);
   }
   return b;
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/template-processor.js

  const pipeModifiers = {
   string: (value) => String(value),
  };
  class PartialTemplate {
   constructor(template) {
    this.template = template;
    this.state = void 0;
   }
  }
  const templates = /* @__PURE__ */ new WeakMap();
  const templateInstances = /* @__PURE__ */ new WeakMap();
  const Directives = {
   partial: (part, state) => {
    state[part.expression] = new PartialTemplate(part.template);
   },
   if: (part, state) => {
    var _a;
    if (evaluateExpression(part.expression, state)) {
     if (templates.get(part) !== part.template) {
      templates.set(part, part.template);
      const tpl = new TemplateInstance(part.template, state, processor);
      part.replace(tpl);
      templateInstances.set(part, tpl);
     } else {
      (_a = templateInstances.get(part)) == null ? void 0 : _a.update(state);
     }
    } else {
     part.replace('');
     templates.delete(part);
     templateInstances.delete(part);
    }
   },
  };
  const DirectiveNames = Object.keys(Directives);
  const processor = {
   processCallback(instance, parts, state) {
    var _a, _b;
    if (!state) return;
    for (const [expression, part] of parts) {
     if (part instanceof InnerTemplatePart) {
      if (!part.directive) {
       const directive = DirectiveNames.find((n) => part.template.hasAttribute(n));
       if (directive) {
        part.directive = directive;
        part.expression = part.template.getAttribute(directive);
       }
      }
      (_a = Directives[part.directive]) == null ? void 0 : _a.call(Directives, part, state);
      continue;
     }
     let value = evaluateExpression(expression, state);
     if (value instanceof PartialTemplate) {
      if (templates.get(part) !== value.template) {
       templates.set(part, value.template);
       value = new TemplateInstance(value.template, value.state, processor);
       part.value = value;
       templateInstances.set(part, value);
      } else {
       (_b = templateInstances.get(part)) == null ? void 0 : _b.update(value.state);
      }
      continue;
     }
     if (value) {
      if (part instanceof AttrPart) {
       if (part.attributeName.startsWith('aria-')) {
        value = String(value);
       }
      }
      if (part instanceof AttrPart) {
       if (typeof value === 'boolean') {
        part.booleanValue = value;
       } else if (typeof value === 'function') {
        part.element[part.attributeName] = value;
       } else {
        part.value = value;
       }
      } else {
       part.value = value;
       templates.delete(part);
       templateInstances.delete(part);
      }
     } else {
      if (part instanceof AttrPart) {
       part.value = void 0;
      } else {
       part.value = void 0;
       templates.delete(part);
       templateInstances.delete(part);
      }
     }
    }
   },
  };
  const operators = {
   '!': (a) => !a,
   '!!': (a) => !!a,
   '==': (a, b) => a == b,
   '!=': (a, b) => a != b,
   '>': (a, b) => a > b,
   '>=': (a, b) => a >= b,
   '<': (a, b) => a < b,
   '<=': (a, b) => a <= b,
   '??': (a, b) => (a != null ? a : b),
   '|': (a, b) => {
    var _a;
    return (_a = pipeModifiers[b]) == null ? void 0 : _a.call(pipeModifiers, a);
   },
  };
  function tokenizeExpression(expr) {
   return template_processor_tokenize(expr, {
    boolean: /true|false/,
    number: /-?\d+\.?\d*/,
    string: /(["'])((?:\\.|[^\\])*?)\1/,
    operator: /[!=><][=!]?|\?\?|\|/,
    ws: /\s+/,
    param: /[$a-z_][$\w]*/i,
   }).filter(({ type }) => type !== 'ws');
  }
  function evaluateExpression(expr, state = {}) {
   var _a, _b, _c, _d, _e, _f, _g;
   const tokens = tokenizeExpression(expr);
   if (tokens.length === 0 || tokens.some(({ type }) => !type)) {
    return invalidExpression(expr);
   }
   if (((_a = tokens[0]) == null ? void 0 : _a.token) === '>') {
    const partial = state[(_b = tokens[1]) == null ? void 0 : _b.token];
    if (!partial) {
     return invalidExpression(expr);
    }
    const partialState = { ...state };
    partial.state = partialState;
    const args = tokens.slice(2);
    for (let i = 0; i < args.length; i += 3) {
     const name = (_c = args[i]) == null ? void 0 : _c.token;
     const operator = (_d = args[i + 1]) == null ? void 0 : _d.token;
     const value = (_e = args[i + 2]) == null ? void 0 : _e.token;
     if (name && operator === '=') {
      partialState[name] = getParamValue(value, state);
     }
    }
    return partial;
   }
   if (tokens.length === 1) {
    if (!isValidParam(tokens[0])) {
     return invalidExpression(expr);
    }
    return getParamValue(tokens[0].token, state);
   }
   if (tokens.length === 2) {
    const operator = (_f = tokens[0]) == null ? void 0 : _f.token;
    const run = operators[operator];
    if (!run || !isValidParam(tokens[1])) {
     return invalidExpression(expr);
    }
    const a = getParamValue(tokens[1].token, state);
    return run(a);
   }
   if (tokens.length === 3) {
    const operator = (_g = tokens[1]) == null ? void 0 : _g.token;
    const run = operators[operator];
    if (!run || !isValidParam(tokens[0]) || !isValidParam(tokens[2])) {
     return invalidExpression(expr);
    }
    const a = getParamValue(tokens[0].token, state);
    if (operator === '|') {
     return run(a, tokens[2].token);
    }
    const b = getParamValue(tokens[2].token, state);
    return run(a, b);
   }
  }
  function invalidExpression(expr) {
   console.warn(`Warning: invalid expression \`${expr}\``);
   return false;
  }
  function isValidParam({ type }) {
   return ['number', 'boolean', 'string', 'param'].includes(type);
  }
  function getParamValue(raw, state) {
   const firstChar = raw[0];
   const lastChar = raw.slice(-1);
   if (raw === 'true' || raw === 'false') {
    return raw === 'true';
   }
   if (firstChar === lastChar && [`'`, `"`].includes(firstChar)) {
    return raw.slice(1, -1);
   }
   if (isNumericString(raw)) {
    return parseFloat(raw);
   }
   return state[raw];
  }
  function template_processor_tokenize(str, parsers) {
   let len, match, token;
   const tokens = [];
   while (str) {
    token = null;
    len = str.length;
    for (const key in parsers) {
     match = parsers[key].exec(str);
     if (match && match.index < len) {
      token = {
       token: match[0],
       type: key,
       matches: match.slice(1),
      };
      len = match.index;
     }
    }
    if (len) {
     tokens.push({
      token: str.substr(0, len),
      type: void 0,
     });
    }
    if (token) {
     tokens.push(token);
    }
    str = str.substr(len + (token ? token.token.length : 0));
   }
   return tokens;
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/media-theme-element.js

  var media_theme_element_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_theme_element_privateGet = (obj, member, getter) => {
   media_theme_element_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_theme_element_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_theme_element_privateSet = (obj, member, value, setter) => {
   media_theme_element_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_theme_element_privateMethod = (obj, member, method) => {
   media_theme_element_accessCheck(obj, member, 'access private method');
   return method;
  };
  var _template, _prevTemplate, _prevTemplateId, _upgradeProperty, upgradeProperty_fn, _updateTemplate, updateTemplate_fn;

  const observedMediaAttributes = {
   mediatargetlivewindow: 'targetlivewindow',
   mediastreamtype: 'streamtype',
  };
  const prependTemplate = server_safe_globals_Document.createElement('template');
  prependTemplate.innerHTML =
   /*html*/
   `
  <style>
    :host {
      display: inline-block;
      line-height: 0;
    }

    media-controller {
      width: 100%;
      height: 100%;
    }

    media-captions-button:not([mediasubtitleslist]),
    media-captions-menu:not([mediasubtitleslist]),
    media-captions-menu-button:not([mediasubtitleslist]),
    media-audio-track-menu[mediaaudiotrackunavailable],
    media-audio-track-menu-button[mediaaudiotrackunavailable],
    media-rendition-menu[mediarenditionunavailable],
    media-rendition-menu-button[mediarenditionunavailable],
    media-volume-range[mediavolumeunavailable],
    media-airplay-button[mediaairplayunavailable],
    media-fullscreen-button[mediafullscreenunavailable],
    media-cast-button[mediacastunavailable],
    media-pip-button[mediapipunavailable] {
      display: none;
    }
  </style>
`;
  class MediaThemeElement extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_theme_element_privateAdd(this, _upgradeProperty);
    media_theme_element_privateAdd(this, _updateTemplate);
    media_theme_element_privateAdd(this, _template, void 0);
    media_theme_element_privateAdd(this, _prevTemplate, void 0);
    media_theme_element_privateAdd(this, _prevTemplateId, void 0);
    if (this.shadowRoot) {
     this.renderRoot = this.shadowRoot;
    } else {
     this.renderRoot = this.attachShadow({ mode: 'open' });
     this.createRenderer();
    }
    const observer = new MutationObserver((mutationList) => {
     var _a;
     if (this.mediaController && !((_a = this.mediaController) == null ? void 0 : _a.breakpointsComputed)) return;
     if (
      mutationList.some((mutation) => {
       const target = mutation.target;
       if (target === this) return true;
       if (target.localName !== 'media-controller') return false;
       if (observedMediaAttributes[mutation.attributeName]) return true;
       if (mutation.attributeName.startsWith('breakpoint')) return true;
       return false;
      })
     ) {
      this.render();
     }
    });
    observer.observe(this, { attributes: true });
    observer.observe(this.renderRoot, {
     attributes: true,
     subtree: true,
    });
    this.addEventListener(MediaStateChangeEvents.BREAKPOINTS_COMPUTED, this.render);
    media_theme_element_privateMethod(this, _upgradeProperty, upgradeProperty_fn).call(this, 'template');
   }
   /** @type {HTMLElement & { breakpointsComputed?: boolean }} */
   get mediaController() {
    return this.renderRoot.querySelector('media-controller');
   }
   get template() {
    var _a;
    return (_a = media_theme_element_privateGet(this, _template)) != null ? _a : this.constructor.template;
   }
   set template(element) {
    media_theme_element_privateSet(this, _prevTemplateId, null);
    media_theme_element_privateSet(this, _template, element);
    this.createRenderer();
   }
   get props() {
    var _a, _b, _c;
    const observedAttributes = [
     ...Array.from((_b = (_a = this.mediaController) == null ? void 0 : _a.attributes) != null ? _b : []).filter(({ name }) => {
      return observedMediaAttributes[name] || name.startsWith('breakpoint');
     }),
     ...Array.from(this.attributes),
    ];
    const props = {};
    for (const attr of observedAttributes) {
     const name = (_c = observedMediaAttributes[attr.name]) != null ? _c : camelCase(attr.name);
     let { value } = attr;
     if (value != null) {
      if (isNumericString(value)) {
       value = parseFloat(value);
      }
      props[name] = value === '' ? true : value;
     } else {
      props[name] = false;
     }
    }
    return props;
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    if (attrName === 'template' && oldValue != newValue) {
     media_theme_element_privateMethod(this, _updateTemplate, updateTemplate_fn).call(this);
    }
   }
   connectedCallback() {
    media_theme_element_privateMethod(this, _updateTemplate, updateTemplate_fn).call(this);
   }
   createRenderer() {
    if (this.template && this.template !== media_theme_element_privateGet(this, _prevTemplate)) {
     media_theme_element_privateSet(this, _prevTemplate, this.template);
     this.renderer = new TemplateInstance(
      this.template,
      this.props,
      // @ts-ignore
      this.constructor.processor,
     );
     this.renderRoot.textContent = '';
     this.renderRoot.append(prependTemplate.content.cloneNode(true), this.renderer);
    }
   }
   render() {
    var _a;
    (_a = this.renderer) == null ? void 0 : _a.update(this.props);
   }
  }
  _template = new WeakMap();
  _prevTemplate = new WeakMap();
  _prevTemplateId = new WeakMap();
  _upgradeProperty = new WeakSet();
  upgradeProperty_fn = function (prop) {
   if (Object.prototype.hasOwnProperty.call(this, prop)) {
    const value = this[prop];
    delete this[prop];
    this[prop] = value;
   }
  };
  _updateTemplate = new WeakSet();
  updateTemplate_fn = function () {
   var _a;
   const templateId = this.getAttribute('template');
   if (!templateId || templateId === media_theme_element_privateGet(this, _prevTemplateId)) return;
   const rootNode = this.getRootNode();
   const template = (_a = rootNode == null ? void 0 : rootNode.getElementById) == null ? void 0 : _a.call(rootNode, templateId);
   if (template) {
    media_theme_element_privateSet(this, _prevTemplateId, templateId);
    media_theme_element_privateSet(this, _template, template);
    this.createRenderer();
    return;
   }
   if (isValidUrl(templateId)) {
    media_theme_element_privateSet(this, _prevTemplateId, templateId);
    request(templateId)
     .then((data) => {
      const template2 = server_safe_globals_Document.createElement('template');
      template2.innerHTML = data;
      media_theme_element_privateSet(this, _template, template2);
      this.createRenderer();
     })
     .catch(console.error);
   }
  };
  MediaThemeElement.observedAttributes = ['template'];
  MediaThemeElement.processor = processor;
  function isValidUrl(url) {
   if (!/^(\/|\.\/|https?:\/\/)/.test(url)) return false;
   const base = /^https?:\/\//.test(url) ? void 0 : location.origin;
   try {
    new URL(url, base);
   } catch (e) {
    return false;
   }
   return true;
  }
  async function request(resource) {
   const response = await fetch(resource);
   if (response.status !== 200) {
    throw new Error(`Failed to load resource: the server responded with a status of ${response.status}`);
   }
   return response.text();
  }
  if (!GlobalThis.customElements.get('media-theme')) {
   GlobalThis.customElements.define('media-theme', MediaThemeElement);
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/anchor-utils.js

  function computePosition({ anchor, floating, placement }) {
   const rects = getElementRects({ anchor, floating });
   const { x, y } = computeCoordsFromPlacement(rects, placement);
   return { x, y };
  }
  function getElementRects({ anchor, floating }) {
   return {
    anchor: getRectRelativeToOffsetParent(anchor, floating.offsetParent),
    floating: {
     x: 0,
     y: 0,
     width: floating.offsetWidth,
     height: floating.offsetHeight,
    },
   };
  }
  function getRectRelativeToOffsetParent(element, offsetParent) {
   var _a;
   const rect = element.getBoundingClientRect();
   const offsetRect = (_a = offsetParent == null ? void 0 : offsetParent.getBoundingClientRect()) != null ? _a : { x: 0, y: 0 };
   return {
    x: rect.x - offsetRect.x,
    y: rect.y - offsetRect.y,
    width: rect.width,
    height: rect.height,
   };
  }
  function computeCoordsFromPlacement({ anchor, floating }, placement) {
   const alignmentAxis = getSideAxis(placement) === 'x' ? 'y' : 'x';
   const alignLength = alignmentAxis === 'y' ? 'height' : 'width';
   const side = getSide(placement);
   const commonX = anchor.x + anchor.width / 2 - floating.width / 2;
   const commonY = anchor.y + anchor.height / 2 - floating.height / 2;
   const commonAlign = anchor[alignLength] / 2 - floating[alignLength] / 2;
   let coords;
   switch (side) {
    case 'top':
     coords = { x: commonX, y: anchor.y - floating.height };
     break;
    case 'bottom':
     coords = { x: commonX, y: anchor.y + anchor.height };
     break;
    case 'right':
     coords = { x: anchor.x + anchor.width, y: commonY };
     break;
    case 'left':
     coords = { x: anchor.x - floating.width, y: commonY };
     break;
    default:
     coords = { x: anchor.x, y: anchor.y };
   }
   switch (placement.split('-')[1]) {
    case 'start':
     coords[alignmentAxis] -= commonAlign;
     break;
    case 'end':
     coords[alignmentAxis] += commonAlign;
     break;
   }
   return coords;
  }
  function getSide(placement) {
   return placement.split('-')[0];
  }
  function getSideAxis(placement) {
   return ['top', 'bottom'].includes(getSide(placement)) ? 'y' : 'x';
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/utils/events.js

  class InvokeEvent extends Event {
   /**
    * @param init - The event options.
    */
   constructor({ action = 'auto', relatedTarget, ...options }) {
    super('invoke', options);
    this.action = action;
    this.relatedTarget = relatedTarget;
   }
  }
  class ToggleEvent extends Event {
   /**
    * @param init - The event options.
    */
   constructor({ newState, oldState, ...options }) {
    super('toggle', options);
    this.newState = newState;
    this.oldState = oldState;
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-chrome-menu.js

  var media_chrome_menu_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_chrome_menu_privateGet = (obj, member, getter) => {
   media_chrome_menu_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_chrome_menu_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_chrome_menu_privateSet = (obj, member, value, setter) => {
   media_chrome_menu_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_chrome_menu_privateMethod = (obj, member, method) => {
   media_chrome_menu_accessCheck(obj, member, 'access private method');
   return method;
  };
  var media_chrome_menu_mediaController, media_chrome_menu_previouslyFocused, media_chrome_menu_invokerElement, _previousItems, media_chrome_menu_mutationObserver, _isPopover, _cssRule, _handleSlotChange, handleSlotChange_fn, _handleMenuItems, _updateLayoutStyle, updateLayoutStyle_fn, media_chrome_menu_handleInvoke, media_chrome_menu_handleInvoke_fn, media_chrome_menu_handleOpen, media_chrome_menu_handleOpen_fn, media_chrome_menu_handleClosed, media_chrome_menu_handleClosed_fn, _handleBoundsResize, _handleMenuResize, _positionMenu, positionMenu_fn, _resizeMenu, resizeMenu_fn, _handleClick, handleClick_fn, _backButtonElement, backButtonElement_get, _handleToggle, handleToggle_fn, _checkSubmenuHasExpanded, checkSubmenuHasExpanded_fn, media_chrome_menu_handleFocusOut, media_chrome_menu_handleFocusOut_fn, media_chrome_menu_handleKeyDown, media_chrome_menu_handleKeyDown_fn, _getItem, getItem_fn, _getTabItem, getTabItem_fn, _setTabItem, setTabItem_fn, _selectItem, selectItem_fn;

  function createMenuItem({ type, text, value, checked }) {
   const item = server_safe_globals_Document.createElement('media-chrome-menu-item');
   item.type = type != null ? type : '';
   item.part.add('menu-item');
   if (type) item.part.add(type);
   item.value = value;
   item.checked = checked;
   const label = server_safe_globals_Document.createElement('span');
   label.textContent = text;
   item.append(label);
   return item;
  }
  function createIndicator(el, name) {
   let customIndicator = el.querySelector(`:scope > [slot="${name}"]`);
   if ((customIndicator == null ? void 0 : customIndicator.nodeName) == 'SLOT') customIndicator = customIndicator.assignedElements({ flatten: true })[0];
   if (customIndicator) {
    customIndicator = customIndicator.cloneNode(true);
    return customIndicator;
   }
   const fallbackIndicator = el.shadowRoot.querySelector(`[name="${name}"] > svg`);
   if (fallbackIndicator) {
    return fallbackIndicator.cloneNode(true);
   }
   return '';
  }
  function media_chrome_menu_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        font: var(--media-font,
          var(--media-font-weight, normal)
          var(--media-font-size, 14px) /
          var(--media-text-content-height, var(--media-control-height, 24px))
          var(--media-font-family, helvetica neue, segoe ui, roboto, arial, sans-serif));
        color: var(--media-text-color, var(--media-primary-color, rgb(238 238 238)));
        --_menu-bg: rgb(20 20 30 / .8);
        background: var(--media-menu-background, var(--media-control-background, var(--media-secondary-color, var(--_menu-bg))));
        border-radius: var(--media-menu-border-radius);
        border: var(--media-menu-border, none);
        display: var(--media-menu-display, inline-flex);
        transition: var(--media-menu-transition-in,
          visibility 0s,
          opacity .2s ease-out,
          transform .15s ease-out,
          left .2s ease-in-out,
          min-width .2s ease-in-out,
          min-height .2s ease-in-out
        ) !important;
        ${/* ^^Prevent transition override by media-container */ ''}
        visibility: var(--media-menu-visibility, visible);
        opacity: var(--media-menu-opacity, 1);
        max-height: var(--media-menu-max-height, var(--_menu-max-height, 300px));
        transform: var(--media-menu-transform-in, translateY(0) scale(1));
        flex-direction: column;
        ${/* Prevent overflowing a flex container */ ''}
        min-height: 0;
        position: relative;
        bottom: var(--_menu-bottom);
        box-sizing: border-box;
      } 

      @-moz-document url-prefix() {
        :host{
          --_menu-bg: rgb(20 20 30);
        }
      }

      :host([hidden]) {
        transition: var(--media-menu-transition-out,
          visibility .15s ease-in,
          opacity .15s ease-in,
          transform .15s ease-in
        ) !important;
        visibility: var(--media-menu-hidden-visibility, hidden);
        opacity: var(--media-menu-hidden-opacity, 0);
        max-height: var(--media-menu-hidden-max-height,
          var(--media-menu-max-height, var(--_menu-max-height, 300px)));
        transform: var(--media-menu-transform-out, translateY(2px) scale(.99));
        pointer-events: none;
      }

      :host([slot="submenu"]) {
        background: none;
        width: 100%;
        min-height: 100%;
        position: absolute;
        bottom: 0;
        right: -100%;
      }

      #container {
        display: flex;
        flex-direction: column;
        min-height: 0;
        transition: transform .2s ease-out;
        transform: translate(0, 0);
      }

      #container.has-expanded {
        transition: transform .2s ease-in;
        transform: translate(-100%, 0);
      }

      button {
        background: none;
        color: inherit;
        border: none;
        padding: 0;
        font: inherit;
        outline: inherit;
        display: inline-flex;
        align-items: center;
      }

      slot[name="header"][hidden] {
        display: none;
      }

      slot[name="header"] > *,
      slot[name="header"]::slotted(*) {
        padding: .4em .7em;
        border-bottom: 1px solid rgb(255 255 255 / .25);
        cursor: var(--media-cursor, default);
      }

      slot[name="header"] > button[part~="back"],
      slot[name="header"]::slotted(button[part~="back"]) {
        cursor: var(--media-cursor, pointer);
      }

      svg[part~="back"] {
        height: var(--media-menu-icon-height, var(--media-control-height, 24px));
        fill: var(--media-icon-color, var(--media-primary-color, rgb(238 238 238)));
        display: block;
        margin-right: .5ch;
      }

      slot:not([name]) {
        gap: var(--media-menu-gap);
        flex-direction: var(--media-menu-flex-direction, column);
        overflow: var(--media-menu-overflow, hidden auto);
        display: flex;
        min-height: 0;
      }

      :host([role="menu"]) slot:not([name]) {
        padding-block: .4em;
      }

      slot:not([name])::slotted([role="menu"]) {
        background: none;
      }

      media-chrome-menu-item > span {
        margin-right: .5ch;
        max-width: var(--media-menu-item-max-width);
        text-overflow: ellipsis;
        overflow: hidden;
      }
    </style>
    <style id="layout-row" media="width:0">

      slot[name="header"] > *,
      slot[name="header"]::slotted(*) {
        padding: .4em .5em;
      }

      slot:not([name]) {
        gap: var(--media-menu-gap, .25em);
        flex-direction: var(--media-menu-flex-direction, row);
        padding-inline: .5em;
      }

      media-chrome-menu-item {
        padding: .3em .5em;
      }

      media-chrome-menu-item[aria-checked="true"] {
        background: var(--media-menu-item-checked-background, rgb(255 255 255 / .2));
      }

      ${/* In row layout hide the checked indicator completely. */ ''}
      media-chrome-menu-item::part(checked-indicator) {
        display: var(--media-menu-item-checked-indicator-display, none);
      }
    </style>
    <div id="container">
      <slot name="header" hidden>
        <button part="back button" aria-label="Back to previous menu">
          <slot name="back-icon">
            <svg aria-hidden="true" viewBox="0 0 20 24" part="back indicator">
              <path d="m11.88 17.585.742-.669-4.2-4.665 4.2-4.666-.743-.669-4.803 5.335 4.803 5.334Z"/>
            </svg>
          </slot>
          <slot name="title"></slot>
        </button>
      </slot>
      <slot></slot>
    </div>
    <slot name="checked-indicator" hidden></slot>
  `
   );
  }
  const media_chrome_menu_Attributes = {
   STYLE: 'style',
   HIDDEN: 'hidden',
   DISABLED: 'disabled',
   ANCHOR: 'anchor',
  };
  class MediaChromeMenu extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_chrome_menu_privateAdd(this, _handleSlotChange);
    /**
     * Sets the layout style for the menu.
     * It can be a row or column layout. e.g. playback-rate-menu
     */
    media_chrome_menu_privateAdd(this, _updateLayoutStyle);
    media_chrome_menu_privateAdd(this, media_chrome_menu_handleInvoke);
    media_chrome_menu_privateAdd(this, media_chrome_menu_handleOpen);
    media_chrome_menu_privateAdd(this, media_chrome_menu_handleClosed);
    /**
     * Updates the popover menu position based on the anchor element.
     * @param  {number} [menuWidth]
     */
    media_chrome_menu_privateAdd(this, _positionMenu);
    /**
     * Resize this menu to fit the submenu.
     * @param  {boolean} animate
     */
    media_chrome_menu_privateAdd(this, _resizeMenu);
    media_chrome_menu_privateAdd(this, _handleClick);
    media_chrome_menu_privateAdd(this, _backButtonElement);
    /**
     * Handle the toggle event of submenus.
     * Closes all other open submenus when opening a submenu.
     * Resizes this menu to fit the submenu.
     *
     * @param  {ToggleEvent} event
     */
    media_chrome_menu_privateAdd(this, _handleToggle);
    /**
     * Check if any submenu is expanded and update the container class accordingly.
     * When the CSS :has() selector is supported, this can be done with CSS only.
     */
    media_chrome_menu_privateAdd(this, _checkSubmenuHasExpanded);
    media_chrome_menu_privateAdd(this, media_chrome_menu_handleFocusOut);
    media_chrome_menu_privateAdd(this, media_chrome_menu_handleKeyDown);
    media_chrome_menu_privateAdd(this, _getItem);
    media_chrome_menu_privateAdd(this, _getTabItem);
    media_chrome_menu_privateAdd(this, _setTabItem);
    media_chrome_menu_privateAdd(this, _selectItem);
    media_chrome_menu_privateAdd(this, media_chrome_menu_mediaController, null);
    media_chrome_menu_privateAdd(this, media_chrome_menu_previouslyFocused, null);
    media_chrome_menu_privateAdd(this, media_chrome_menu_invokerElement, null);
    media_chrome_menu_privateAdd(this, _previousItems, /* @__PURE__ */ new Set());
    media_chrome_menu_privateAdd(this, media_chrome_menu_mutationObserver, void 0);
    media_chrome_menu_privateAdd(this, _isPopover, false);
    media_chrome_menu_privateAdd(this, _cssRule, null);
    /**
     * Fires an event when a menu item is added or removed.
     * This is needed to update the description slot of an ancestor menu item.
     */
    media_chrome_menu_privateAdd(this, _handleMenuItems, () => {
     const previousItems = media_chrome_menu_privateGet(this, _previousItems);
     const currentItems = new Set(this.items);
     for (const item of previousItems) {
      if (!currentItems.has(item)) {
       this.dispatchEvent(new CustomEvent('removemenuitem', { detail: item }));
      }
     }
     for (const item of currentItems) {
      if (!previousItems.has(item)) {
       this.dispatchEvent(new CustomEvent('addmenuitem', { detail: item }));
      }
     }
     media_chrome_menu_privateSet(this, _previousItems, currentItems);
    });
    media_chrome_menu_privateAdd(this, _handleBoundsResize, () => {
     media_chrome_menu_privateMethod(this, _positionMenu, positionMenu_fn).call(this);
     media_chrome_menu_privateMethod(this, _resizeMenu, resizeMenu_fn).call(this, false);
    });
    media_chrome_menu_privateAdd(this, _handleMenuResize, () => {
     media_chrome_menu_privateMethod(this, _positionMenu, positionMenu_fn).call(this);
    });
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
    this.container = this.shadowRoot.querySelector('#container');
    this.defaultSlot = this.shadowRoot.querySelector('slot:not([name])');
    this.shadowRoot.addEventListener('slotchange', this);
    media_chrome_menu_privateSet(this, media_chrome_menu_mutationObserver, new MutationObserver(media_chrome_menu_privateGet(this, _handleMenuItems)));
    media_chrome_menu_privateGet(this, media_chrome_menu_mutationObserver).observe(this.defaultSlot, { childList: true });
   }
   static get observedAttributes() {
    return [media_chrome_menu_Attributes.DISABLED, media_chrome_menu_Attributes.HIDDEN, media_chrome_menu_Attributes.STYLE, media_chrome_menu_Attributes.ANCHOR, MediaStateReceiverAttributes.MEDIA_CONTROLLER];
   }
   static formatMenuItemText(text, _data) {
    return text;
   }
   enable() {
    this.addEventListener('click', this);
    this.addEventListener('focusout', this);
    this.addEventListener('keydown', this);
    this.addEventListener('invoke', this);
    this.addEventListener('toggle', this);
   }
   disable() {
    this.removeEventListener('click', this);
    this.removeEventListener('focusout', this);
    this.removeEventListener('keyup', this);
    this.removeEventListener('invoke', this);
    this.removeEventListener('toggle', this);
   }
   handleEvent(event) {
    switch (event.type) {
     case 'slotchange':
      media_chrome_menu_privateMethod(this, _handleSlotChange, handleSlotChange_fn).call(this, event);
      break;
     case 'invoke':
      media_chrome_menu_privateMethod(this, media_chrome_menu_handleInvoke, media_chrome_menu_handleInvoke_fn).call(this, event);
      break;
     case 'click':
      media_chrome_menu_privateMethod(this, _handleClick, handleClick_fn).call(this, event);
      break;
     case 'toggle':
      media_chrome_menu_privateMethod(this, _handleToggle, handleToggle_fn).call(this, event);
      break;
     case 'focusout':
      media_chrome_menu_privateMethod(this, media_chrome_menu_handleFocusOut, media_chrome_menu_handleFocusOut_fn).call(this, event);
      break;
     case 'keydown':
      media_chrome_menu_privateMethod(this, media_chrome_menu_handleKeyDown, media_chrome_menu_handleKeyDown_fn).call(this, event);
      break;
    }
   }
   connectedCallback() {
    var _a, _b;
    media_chrome_menu_privateSet(this, _cssRule, insertCSSRule(this.shadowRoot, ':host'));
    media_chrome_menu_privateMethod(this, _updateLayoutStyle, updateLayoutStyle_fn).call(this);
    if (!this.hasAttribute('disabled')) {
     this.enable();
    }
    if (!this.role) {
     this.role = 'menu';
    }
    media_chrome_menu_privateSet(this, media_chrome_menu_mediaController, getAttributeMediaController(this));
    (_b = (_a = media_chrome_menu_privateGet(this, media_chrome_menu_mediaController)) == null ? void 0 : _a.associateElement) == null ? void 0 : _b.call(_a, this);
    if (!this.hidden) {
     observeResize(getBoundsElement(this), media_chrome_menu_privateGet(this, _handleBoundsResize));
     observeResize(this, media_chrome_menu_privateGet(this, _handleMenuResize));
    }
   }
   disconnectedCallback() {
    var _a, _b;
    unobserveResize(getBoundsElement(this), media_chrome_menu_privateGet(this, _handleBoundsResize));
    unobserveResize(this, media_chrome_menu_privateGet(this, _handleMenuResize));
    this.disable();
    (_b = (_a = media_chrome_menu_privateGet(this, media_chrome_menu_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
    media_chrome_menu_privateSet(this, media_chrome_menu_mediaController, null);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    var _a, _b, _c, _d;
    if (attrName === media_chrome_menu_Attributes.HIDDEN && newValue !== oldValue) {
     if (!media_chrome_menu_privateGet(this, _isPopover)) media_chrome_menu_privateSet(this, _isPopover, true);
     if (this.hidden) {
      media_chrome_menu_privateMethod(this, media_chrome_menu_handleClosed, media_chrome_menu_handleClosed_fn).call(this);
     } else {
      media_chrome_menu_privateMethod(this, media_chrome_menu_handleOpen, media_chrome_menu_handleOpen_fn).call(this);
     }
     this.dispatchEvent(
      new ToggleEvent({
       oldState: this.hidden ? 'open' : 'closed',
       newState: this.hidden ? 'closed' : 'open',
       bubbles: true,
      }),
     );
    } else if (attrName === MediaStateReceiverAttributes.MEDIA_CONTROLLER) {
     if (oldValue) {
      (_b = (_a = media_chrome_menu_privateGet(this, media_chrome_menu_mediaController)) == null ? void 0 : _a.unassociateElement) == null ? void 0 : _b.call(_a, this);
      media_chrome_menu_privateSet(this, media_chrome_menu_mediaController, null);
     }
     if (newValue && this.isConnected) {
      media_chrome_menu_privateSet(this, media_chrome_menu_mediaController, getAttributeMediaController(this));
      (_d = (_c = media_chrome_menu_privateGet(this, media_chrome_menu_mediaController)) == null ? void 0 : _c.associateElement) == null ? void 0 : _d.call(_c, this);
     }
    } else if (attrName === media_chrome_menu_Attributes.DISABLED && newValue !== oldValue) {
     if (newValue == null) {
      this.enable();
     } else {
      this.disable();
     }
    } else if (attrName === media_chrome_menu_Attributes.STYLE && newValue !== oldValue) {
     media_chrome_menu_privateMethod(this, _updateLayoutStyle, updateLayoutStyle_fn).call(this);
    }
   }
   formatMenuItemText(text, data) {
    return this.constructor.formatMenuItemText(text, data);
   }
   get anchor() {
    return this.getAttribute('anchor');
   }
   set anchor(value) {
    this.setAttribute('anchor', `${value}`);
   }
   /**
    * Returns the anchor element when it is a floating menu.
    */
   get anchorElement() {
    var _a;
    if (this.anchor) {
     return (_a = getDocumentOrShadowRoot(this)) == null ? void 0 : _a.querySelector(`#${this.anchor}`);
    }
    return null;
   }
   /**
    * Returns the menu items.
    */
   get items() {
    return this.defaultSlot.assignedElements({ flatten: true }).filter(isMenuItem);
   }
   get radioGroupItems() {
    return this.items.filter((item) => item.role === 'menuitemradio');
   }
   get checkedItems() {
    return this.items.filter((item) => item.checked);
   }
   get value() {
    var _a, _b;
    return (_b = (_a = this.checkedItems[0]) == null ? void 0 : _a.value) != null ? _b : '';
   }
   set value(newValue) {
    const item = this.items.find((item2) => item2.value === newValue);
    if (!item) return;
    media_chrome_menu_privateMethod(this, _selectItem, selectItem_fn).call(this, item);
   }
   focus() {
    media_chrome_menu_privateSet(this, media_chrome_menu_previouslyFocused, getActiveElement());
    if (this.items.length) {
     media_chrome_menu_privateMethod(this, _setTabItem, setTabItem_fn).call(this, this.items[0]);
     this.items[0].focus();
     return;
    }
    const focusable = this.querySelector('[autofocus], [tabindex]:not([tabindex="-1"]), [role="menu"]');
    focusable == null ? void 0 : focusable.focus();
   }
   handleSelect(event) {
    var _a;
    const item = media_chrome_menu_privateMethod(this, _getItem, getItem_fn).call(this, event);
    if (!item) return;
    media_chrome_menu_privateMethod(this, _selectItem, selectItem_fn).call(this, item, item.type === 'checkbox');
    if (media_chrome_menu_privateGet(this, media_chrome_menu_invokerElement) && !this.hidden) {
     (_a = media_chrome_menu_privateGet(this, media_chrome_menu_previouslyFocused)) == null ? void 0 : _a.focus();
     this.hidden = true;
    }
   }
   get keysUsed() {
    return ['Enter', 'Escape', 'Tab', ' ', 'ArrowDown', 'ArrowUp', 'Home', 'End'];
   }
   handleMove(event) {
    var _a, _b;
    const { key } = event;
    const items = this.items;
    const currentItem = (_b = (_a = media_chrome_menu_privateMethod(this, _getItem, getItem_fn).call(this, event)) != null ? _a : media_chrome_menu_privateMethod(this, _getTabItem, getTabItem_fn).call(this)) != null ? _b : items[0];
    const currentIndex = items.indexOf(currentItem);
    let index = Math.max(0, currentIndex);
    if (key === 'ArrowDown') {
     index++;
    } else if (key === 'ArrowUp') {
     index--;
    } else if (event.key === 'Home') {
     index = 0;
    } else if (event.key === 'End') {
     index = items.length - 1;
    }
    if (index < 0) {
     index = items.length - 1;
    }
    if (index > items.length - 1) {
     index = 0;
    }
    media_chrome_menu_privateMethod(this, _setTabItem, setTabItem_fn).call(this, items[index]);
    items[index].focus();
   }
  }
  media_chrome_menu_mediaController = new WeakMap();
  media_chrome_menu_previouslyFocused = new WeakMap();
  media_chrome_menu_invokerElement = new WeakMap();
  _previousItems = new WeakMap();
  media_chrome_menu_mutationObserver = new WeakMap();
  _isPopover = new WeakMap();
  _cssRule = new WeakMap();
  _handleSlotChange = new WeakSet();
  handleSlotChange_fn = function (event) {
   const slot = event.target;
   for (const node of slot.assignedNodes({ flatten: true })) {
    if (node.nodeType === 3 && node.textContent.trim() === '') {
     node.remove();
    }
   }
   if (['header', 'title'].includes(slot.name)) {
    const header = this.shadowRoot.querySelector('slot[name="header"]');
    header.hidden = slot.assignedNodes().length === 0;
   }
   if (!slot.name) {
    media_chrome_menu_privateGet(this, _handleMenuItems).call(this);
   }
  };
  _handleMenuItems = new WeakMap();
  _updateLayoutStyle = new WeakSet();
  updateLayoutStyle_fn = function () {
   var _a;
   const layoutRowStyle = this.shadowRoot.querySelector('#layout-row');
   const menuLayout = (_a = getComputedStyle(this).getPropertyValue('--media-menu-layout')) == null ? void 0 : _a.trim();
   layoutRowStyle.setAttribute('media', menuLayout === 'row' ? '' : 'width:0');
  };
  media_chrome_menu_handleInvoke = new WeakSet();
  media_chrome_menu_handleInvoke_fn = function (event) {
   media_chrome_menu_privateSet(this, media_chrome_menu_invokerElement, event.relatedTarget);
   if (!containsComposedNode(this, event.relatedTarget)) {
    this.hidden = !this.hidden;
   }
  };
  media_chrome_menu_handleOpen = new WeakSet();
  media_chrome_menu_handleOpen_fn = function () {
   var _a;
   (_a = media_chrome_menu_privateGet(this, media_chrome_menu_invokerElement)) == null ? void 0 : _a.setAttribute('aria-expanded', 'true');
   this.addEventListener('transitionend', () => this.focus(), { once: true });
   observeResize(getBoundsElement(this), media_chrome_menu_privateGet(this, _handleBoundsResize));
   observeResize(this, media_chrome_menu_privateGet(this, _handleMenuResize));
  };
  media_chrome_menu_handleClosed = new WeakSet();
  media_chrome_menu_handleClosed_fn = function () {
   var _a;
   (_a = media_chrome_menu_privateGet(this, media_chrome_menu_invokerElement)) == null ? void 0 : _a.setAttribute('aria-expanded', 'false');
   unobserveResize(getBoundsElement(this), media_chrome_menu_privateGet(this, _handleBoundsResize));
   unobserveResize(this, media_chrome_menu_privateGet(this, _handleMenuResize));
  };
  _handleBoundsResize = new WeakMap();
  _handleMenuResize = new WeakMap();
  _positionMenu = new WeakSet();
  positionMenu_fn = function (menuWidth) {
   if (this.hasAttribute('mediacontroller') && !this.anchor) return;
   if (this.hidden || !this.anchorElement) return;
   const { x, y } = computePosition({
    anchor: this.anchorElement,
    floating: this,
    placement: 'top-start',
   });
   menuWidth != null ? menuWidth : (menuWidth = this.offsetWidth);
   const bounds = getBoundsElement(this);
   const boundsRect = bounds.getBoundingClientRect();
   const right = boundsRect.width - x - menuWidth;
   const bottom = boundsRect.height - y - this.offsetHeight;
   const { style } = media_chrome_menu_privateGet(this, _cssRule);
   style.setProperty('position', 'absolute');
   style.setProperty('right', `${Math.max(0, right)}px`);
   style.setProperty('--_menu-bottom', `${bottom}px`);
   const computedStyle = getComputedStyle(this);
   const isBottomCalc = style.getPropertyValue('--_menu-bottom') === computedStyle.bottom;
   const realBottom = isBottomCalc ? bottom : parseFloat(computedStyle.bottom);
   const maxHeight = boundsRect.height - realBottom - parseFloat(computedStyle.marginBottom);
   this.style.setProperty('--_menu-max-height', `${maxHeight}px`);
  };
  _resizeMenu = new WeakSet();
  resizeMenu_fn = function (animate) {
   const expandedMenuItem = this.querySelector('[role="menuitem"][aria-haspopup][aria-expanded="true"]');
   const expandedSubmenu = expandedMenuItem == null ? void 0 : expandedMenuItem.querySelector('[role="menu"]');
   const { style } = media_chrome_menu_privateGet(this, _cssRule);
   if (!animate) {
    style.setProperty('--media-menu-transition-in', 'none');
   }
   if (expandedSubmenu) {
    const height = expandedSubmenu.offsetHeight;
    const width = Math.max(expandedSubmenu.offsetWidth, expandedMenuItem.offsetWidth);
    this.style.setProperty('min-width', `${width}px`);
    this.style.setProperty('min-height', `${height}px`);
    media_chrome_menu_privateMethod(this, _positionMenu, positionMenu_fn).call(this, width);
   } else {
    this.style.removeProperty('min-width');
    this.style.removeProperty('min-height');
    media_chrome_menu_privateMethod(this, _positionMenu, positionMenu_fn).call(this);
   }
   style.removeProperty('--media-menu-transition-in');
  };
  _handleClick = new WeakSet();
  handleClick_fn = function (event) {
   var _a;
   event.stopPropagation();
   if (event.composedPath().includes(media_chrome_menu_privateGet(this, _backButtonElement, backButtonElement_get))) {
    (_a = media_chrome_menu_privateGet(this, media_chrome_menu_previouslyFocused)) == null ? void 0 : _a.focus();
    this.hidden = true;
    return;
   }
   const item = media_chrome_menu_privateMethod(this, _getItem, getItem_fn).call(this, event);
   if (!item || item.hasAttribute('disabled')) return;
   media_chrome_menu_privateMethod(this, _setTabItem, setTabItem_fn).call(this, item);
   this.handleSelect(event);
  };
  _backButtonElement = new WeakSet();
  backButtonElement_get = function () {
   var _a;
   const headerSlot = this.shadowRoot.querySelector('slot[name="header"]');
   return (_a = headerSlot.assignedElements({ flatten: true })) == null ? void 0 : _a.find((el) => el.matches('button[part~="back"]'));
  };
  _handleToggle = new WeakSet();
  handleToggle_fn = function (event) {
   if (event.target === this) return;
   media_chrome_menu_privateMethod(this, _checkSubmenuHasExpanded, checkSubmenuHasExpanded_fn).call(this);
   const menuItemsWithSubmenu = Array.from(this.querySelectorAll('[role="menuitem"][aria-haspopup]'));
   for (const item of menuItemsWithSubmenu) {
    if (item.invokeTargetElement == event.target) continue;
    if (event.newState == 'open' && item.getAttribute('aria-expanded') == 'true' && !item.invokeTargetElement.hidden) {
     item.invokeTargetElement.dispatchEvent(new InvokeEvent({ relatedTarget: item }));
    }
   }
   for (const item of menuItemsWithSubmenu) {
    item.setAttribute('aria-expanded', `${!item.submenuElement.hidden}`);
   }
   media_chrome_menu_privateMethod(this, _resizeMenu, resizeMenu_fn).call(this, true);
  };
  _checkSubmenuHasExpanded = new WeakSet();
  checkSubmenuHasExpanded_fn = function () {
   const selector = '[role="menuitem"] > [role="menu"]:not([hidden])';
   const expandedMenuItem = this.querySelector(selector);
   this.container.classList.toggle('has-expanded', !!expandedMenuItem);
  };
  media_chrome_menu_handleFocusOut = new WeakSet();
  media_chrome_menu_handleFocusOut_fn = function (event) {
   var _a;
   if (!containsComposedNode(this, event.relatedTarget)) {
    if (media_chrome_menu_privateGet(this, _isPopover)) {
     (_a = media_chrome_menu_privateGet(this, media_chrome_menu_previouslyFocused)) == null ? void 0 : _a.focus();
    }
    if (media_chrome_menu_privateGet(this, media_chrome_menu_invokerElement) && media_chrome_menu_privateGet(this, media_chrome_menu_invokerElement) !== event.relatedTarget && !this.hidden) {
     this.hidden = true;
    }
   }
  };
  media_chrome_menu_handleKeyDown = new WeakSet();
  media_chrome_menu_handleKeyDown_fn = function (event) {
   var _a, _b, _c, _d, _e;
   const { key, ctrlKey, altKey, metaKey } = event;
   if (ctrlKey || altKey || metaKey) {
    return;
   }
   if (!this.keysUsed.includes(key)) {
    return;
   }
   event.preventDefault();
   event.stopPropagation();
   if (key === 'Tab') {
    if (media_chrome_menu_privateGet(this, _isPopover)) {
     this.hidden = true;
     return;
    }
    if (event.shiftKey) {
     (_b = (_a = this.previousElementSibling) == null ? void 0 : _a.focus) == null ? void 0 : _b.call(_a);
    } else {
     (_d = (_c = this.nextElementSibling) == null ? void 0 : _c.focus) == null ? void 0 : _d.call(_c);
    }
    this.blur();
   } else if (key === 'Escape') {
    (_e = media_chrome_menu_privateGet(this, media_chrome_menu_previouslyFocused)) == null ? void 0 : _e.focus();
    if (media_chrome_menu_privateGet(this, _isPopover)) {
     this.hidden = true;
    }
   } else if (key === 'Enter' || key === ' ') {
    this.handleSelect(event);
   } else {
    this.handleMove(event);
   }
  };
  _getItem = new WeakSet();
  getItem_fn = function (event) {
   return event.composedPath().find((el) => {
    return ['menuitemradio', 'menuitemcheckbox'].includes(el.role);
   });
  };
  _getTabItem = new WeakSet();
  getTabItem_fn = function () {
   return this.items.find((item) => item.tabIndex === 0);
  };
  _setTabItem = new WeakSet();
  setTabItem_fn = function (tabItem) {
   for (const item of this.items) {
    item.tabIndex = item === tabItem ? 0 : -1;
   }
  };
  _selectItem = new WeakSet();
  selectItem_fn = function (item, toggle) {
   const oldCheckedItems = [...this.checkedItems];
   if (item.type === 'radio') {
    this.radioGroupItems.forEach((el) => (el.checked = false));
   }
   if (toggle) {
    item.checked = !item.checked;
   } else {
    item.checked = true;
   }
   if (this.checkedItems.some((opt, i) => opt != oldCheckedItems[i])) {
    this.dispatchEvent(new Event('change', { bubbles: true, composed: true }));
   }
  };
  MediaChromeMenu.shadowRootOptions = { mode: 'open' };
  MediaChromeMenu.getTemplateHTML = media_chrome_menu_getTemplateHTML;
  function isMenuItem(element) {
   return ['menuitem', 'menuitemradio', 'menuitemcheckbox'].includes(element == null ? void 0 : element.role);
  }
  function getBoundsElement(host) {
   var _a;
   return (_a = host.getAttribute('bounds') ? closestComposedNode(host, `#${host.getAttribute('bounds')}`) : getMediaController(host) || host.parentElement) != null ? _a : host;
  }
  if (!GlobalThis.customElements.get('media-chrome-menu')) {
   GlobalThis.customElements.define('media-chrome-menu', MediaChromeMenu);
  }
  var media_chrome_menu_default = /* unused pure expression or super */ null && MediaChromeMenu; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-chrome-menu-item.js

  var media_chrome_menu_item_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_chrome_menu_item_privateGet = (obj, member, getter) => {
   media_chrome_menu_item_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_chrome_menu_item_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_chrome_menu_item_privateSet = (obj, member, value, setter) => {
   media_chrome_menu_item_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_chrome_menu_item_privateMethod = (obj, member, method) => {
   media_chrome_menu_item_accessCheck(obj, member, 'access private method');
   return method;
  };
  var _dirty, _ownerElement, media_chrome_menu_item_handleSlotChange, media_chrome_menu_item_handleSlotChange_fn, _submenuConnected, submenuConnected_fn, _submenuDisconnected, submenuDisconnected_fn, _handleMenuItem, _handleKeyUp, handleKeyUp_fn, media_chrome_menu_item_handleKeyDown, media_chrome_menu_item_handleKeyDown_fn, _reset, reset_fn;

  function media_chrome_menu_item_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        transition: var(--media-menu-item-transition,
          background .15s linear,
          opacity .2s ease-in-out
        );
        outline: var(--media-menu-item-outline, 0);
        outline-offset: var(--media-menu-item-outline-offset, -1px);
        cursor: var(--media-cursor, pointer);
        display: flex;
        align-items: center;
        align-self: stretch;
        justify-self: stretch;
        white-space: nowrap;
        white-space-collapse: collapse;
        text-wrap: nowrap;
        padding: .4em .8em .4em 1em;
      }

      :host(:focus-visible) {
        box-shadow: var(--media-menu-item-focus-shadow, inset 0 0 0 2px rgb(27 127 204 / .9));
        outline: var(--media-menu-item-hover-outline, 0);
        outline-offset: var(--media-menu-item-hover-outline-offset,  var(--media-menu-item-outline-offset, -1px));
      }

      :host(:hover) {
        cursor: var(--media-cursor, pointer);
        background: var(--media-menu-item-hover-background, rgb(92 92 102 / .5));
        outline: var(--media-menu-item-hover-outline);
        outline-offset: var(--media-menu-item-hover-outline-offset,  var(--media-menu-item-outline-offset, -1px));
      }

      :host([aria-checked="true"]) {
        background: var(--media-menu-item-checked-background);
      }

      :host([hidden]) {
        display: none;
      }

      :host([disabled]) {
        pointer-events: none;
        color: rgba(255, 255, 255, .3);
      }

      slot:not([name]) {
        width: 100%;
      }

      slot:not([name="submenu"]) {
        display: inline-flex;
        align-items: center;
        transition: inherit;
        opacity: var(--media-menu-item-opacity, 1);
      }

      slot[name="description"] {
        justify-content: end;
      }

      slot[name="description"] > span {
        display: inline-block;
        margin-inline: 1em .2em;
        max-width: var(--media-menu-item-description-max-width, 100px);
        text-overflow: ellipsis;
        overflow: hidden;
        font-size: .8em;
        font-weight: 400;
        text-align: right;
        position: relative;
        top: .04em;
      }

      slot[name="checked-indicator"] {
        display: none;
      }

      :host(:is([role="menuitemradio"],[role="menuitemcheckbox"])) slot[name="checked-indicator"] {
        display: var(--media-menu-item-checked-indicator-display, inline-block);
      }

      ${/* For all slotted icons in prefix and suffix. */ ''}
      svg, img, ::slotted(svg), ::slotted(img) {
        height: var(--media-menu-item-icon-height, var(--media-control-height, 24px));
        fill: var(--media-icon-color, var(--media-primary-color, rgb(238 238 238)));
        display: block;
      }

      ${/* Only for indicator icons like checked-indicator or captions-indicator. */ ''}
      [part~="indicator"],
      ::slotted([part~="indicator"]) {
        fill: var(--media-menu-item-indicator-fill,
          var(--media-icon-color, var(--media-primary-color, rgb(238 238 238))));
        height: var(--media-menu-item-indicator-height, 1.25em);
        margin-right: .5ch;
      }

      [part~="checked-indicator"] {
        visibility: hidden;
      }

      :host([aria-checked="true"]) [part~="checked-indicator"] {
        visibility: visible;
      }
    </style>
    <slot name="checked-indicator">
      <svg aria-hidden="true" viewBox="0 1 24 24" part="checked-indicator indicator">
        <path d="m10 15.17 9.193-9.191 1.414 1.414-10.606 10.606-6.364-6.364 1.414-1.414 4.95 4.95Z"/>
      </svg>
    </slot>
    <slot name="prefix"></slot>
    <slot></slot>
    <slot name="description"></slot>
    <slot name="suffix">
      ${this.getSuffixSlotInnerHTML(_attrs)}
    </slot>
    <slot name="submenu"></slot>
  `
   );
  }
  function getSuffixSlotInnerHTML(_attrs) {
   return '';
  }
  const media_chrome_menu_item_Attributes = {
   TYPE: 'type',
   VALUE: 'value',
   CHECKED: 'checked',
   DISABLED: 'disabled',
  };
  class MediaChromeMenuItem extends GlobalThis.HTMLElement {
   constructor() {
    super();
    media_chrome_menu_item_privateAdd(this, media_chrome_menu_item_handleSlotChange);
    media_chrome_menu_item_privateAdd(this, _submenuConnected);
    media_chrome_menu_item_privateAdd(this, _submenuDisconnected);
    media_chrome_menu_item_privateAdd(this, _handleKeyUp);
    media_chrome_menu_item_privateAdd(this, media_chrome_menu_item_handleKeyDown);
    media_chrome_menu_item_privateAdd(this, _reset);
    media_chrome_menu_item_privateAdd(this, _dirty, false);
    media_chrome_menu_item_privateAdd(this, _ownerElement, void 0);
    /**
     * If there is a slotted submenu the fallback content of the description slot
     * is populated with the text of the first checked item.
     */
    media_chrome_menu_item_privateAdd(this, _handleMenuItem, () => {
     var _a, _b;
     this.setAttribute('submenusize', `${this.submenuElement.items.length}`);
     const descriptionSlot = this.shadowRoot.querySelector('slot[name="description"]');
     const checkedItem = (_a = this.submenuElement.checkedItems) == null ? void 0 : _a[0];
     const description = (_b = checkedItem == null ? void 0 : checkedItem.dataset.description) != null ? _b : checkedItem == null ? void 0 : checkedItem.text;
     const span = server_safe_globals_Document.createElement('span');
     span.textContent = description != null ? description : '';
     descriptionSlot.replaceChildren(span);
    });
    if (!this.shadowRoot) {
     this.attachShadow(this.constructor.shadowRootOptions);
     const attrs = namedNodeMapToObject(this.attributes);
     this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
    }
    this.shadowRoot.addEventListener('slotchange', this);
   }
   static get observedAttributes() {
    return [media_chrome_menu_item_Attributes.TYPE, media_chrome_menu_item_Attributes.DISABLED, media_chrome_menu_item_Attributes.CHECKED, media_chrome_menu_item_Attributes.VALUE];
   }
   enable() {
    if (!this.hasAttribute('tabindex')) {
     this.setAttribute('tabindex', '-1');
    }
    if (isCheckable(this) && !this.hasAttribute('aria-checked')) {
     this.setAttribute('aria-checked', 'false');
    }
    this.addEventListener('click', this);
    this.addEventListener('keydown', this);
   }
   disable() {
    this.removeAttribute('tabindex');
    this.removeEventListener('click', this);
    this.removeEventListener('keydown', this);
    this.removeEventListener('keyup', this);
   }
   handleEvent(event) {
    switch (event.type) {
     case 'slotchange':
      media_chrome_menu_item_privateMethod(this, media_chrome_menu_item_handleSlotChange, media_chrome_menu_item_handleSlotChange_fn).call(this, event);
      break;
     case 'click':
      this.handleClick(event);
      break;
     case 'keydown':
      media_chrome_menu_item_privateMethod(this, media_chrome_menu_item_handleKeyDown, media_chrome_menu_item_handleKeyDown_fn).call(this, event);
      break;
     case 'keyup':
      media_chrome_menu_item_privateMethod(this, _handleKeyUp, handleKeyUp_fn).call(this, event);
      break;
    }
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    if (attrName === media_chrome_menu_item_Attributes.CHECKED && isCheckable(this) && !media_chrome_menu_item_privateGet(this, _dirty)) {
     this.setAttribute('aria-checked', newValue != null ? 'true' : 'false');
    } else if (attrName === media_chrome_menu_item_Attributes.TYPE && newValue !== oldValue) {
     this.role = 'menuitem' + newValue;
    } else if (attrName === media_chrome_menu_item_Attributes.DISABLED && newValue !== oldValue) {
     if (newValue == null) {
      this.enable();
     } else {
      this.disable();
     }
    }
   }
   connectedCallback() {
    if (!this.hasAttribute(media_chrome_menu_item_Attributes.DISABLED)) {
     this.enable();
    }
    this.role = 'menuitem' + this.type;
    media_chrome_menu_item_privateSet(this, _ownerElement, closestMenuItemsContainer(this, this.parentNode));
    media_chrome_menu_item_privateMethod(this, _reset, reset_fn).call(this);
   }
   disconnectedCallback() {
    this.disable();
    media_chrome_menu_item_privateMethod(this, _reset, reset_fn).call(this);
    media_chrome_menu_item_privateSet(this, _ownerElement, null);
   }
   get invokeTarget() {
    return this.getAttribute('invoketarget');
   }
   set invokeTarget(value) {
    this.setAttribute('invoketarget', `${value}`);
   }
   /**
    * Returns the element with the id specified by the `invoketarget` attribute
    * or the slotted submenu element.
    */
   get invokeTargetElement() {
    var _a;
    if (this.invokeTarget) {
     return (_a = getDocumentOrShadowRoot(this)) == null ? void 0 : _a.querySelector(`#${this.invokeTarget}`);
    }
    return this.submenuElement;
   }
   /**
    * Returns the slotted submenu element.
    */
   get submenuElement() {
    const submenuSlot = this.shadowRoot.querySelector('slot[name="submenu"]');
    return submenuSlot.assignedElements({
     flatten: true,
    })[0];
   }
   get type() {
    var _a;
    return (_a = this.getAttribute(media_chrome_menu_item_Attributes.TYPE)) != null ? _a : '';
   }
   set type(val) {
    this.setAttribute(media_chrome_menu_item_Attributes.TYPE, `${val}`);
   }
   get value() {
    var _a;
    return (_a = this.getAttribute(media_chrome_menu_item_Attributes.VALUE)) != null ? _a : this.text;
   }
   set value(val) {
    this.setAttribute(media_chrome_menu_item_Attributes.VALUE, val);
   }
   get text() {
    var _a;
    return ((_a = this.textContent) != null ? _a : '').trim();
   }
   get checked() {
    if (!isCheckable(this)) return void 0;
    return this.getAttribute('aria-checked') === 'true';
   }
   set checked(value) {
    if (!isCheckable(this)) return;
    media_chrome_menu_item_privateSet(this, _dirty, true);
    this.setAttribute('aria-checked', value ? 'true' : 'false');
    if (value) {
     this.part.add('checked');
    } else {
     this.part.remove('checked');
    }
   }
   handleClick(event) {
    if (isCheckable(this)) return;
    if (this.invokeTargetElement && containsComposedNode(this, event.target)) {
     this.invokeTargetElement.dispatchEvent(new InvokeEvent({ relatedTarget: this }));
    }
   }
   get keysUsed() {
    return ['Enter', ' '];
   }
  }
  _dirty = new WeakMap();
  _ownerElement = new WeakMap();
  media_chrome_menu_item_handleSlotChange = new WeakSet();
  media_chrome_menu_item_handleSlotChange_fn = function (event) {
   const slot = event.target;
   const isDefaultSlot = !(slot == null ? void 0 : slot.name);
   if (isDefaultSlot) {
    for (const node of slot.assignedNodes({ flatten: true })) {
     if (node instanceof Text && node.textContent.trim() === '') {
      node.remove();
     }
    }
   }
   if (slot.name === 'submenu') {
    if (this.submenuElement) {
     media_chrome_menu_item_privateMethod(this, _submenuConnected, submenuConnected_fn).call(this);
    } else {
     media_chrome_menu_item_privateMethod(this, _submenuDisconnected, submenuDisconnected_fn).call(this);
    }
   }
  };
  _submenuConnected = new WeakSet();
  submenuConnected_fn = async function () {
   this.setAttribute('aria-haspopup', 'menu');
   this.setAttribute('aria-expanded', `${!this.submenuElement.hidden}`);
   this.submenuElement.addEventListener('change', media_chrome_menu_item_privateGet(this, _handleMenuItem));
   this.submenuElement.addEventListener('addmenuitem', media_chrome_menu_item_privateGet(this, _handleMenuItem));
   this.submenuElement.addEventListener('removemenuitem', media_chrome_menu_item_privateGet(this, _handleMenuItem));
   media_chrome_menu_item_privateGet(this, _handleMenuItem).call(this);
  };
  _submenuDisconnected = new WeakSet();
  submenuDisconnected_fn = function () {
   this.removeAttribute('aria-haspopup');
   this.removeAttribute('aria-expanded');
   this.submenuElement.removeEventListener('change', media_chrome_menu_item_privateGet(this, _handleMenuItem));
   this.submenuElement.removeEventListener('addmenuitem', media_chrome_menu_item_privateGet(this, _handleMenuItem));
   this.submenuElement.removeEventListener('removemenuitem', media_chrome_menu_item_privateGet(this, _handleMenuItem));
   media_chrome_menu_item_privateGet(this, _handleMenuItem).call(this);
  };
  _handleMenuItem = new WeakMap();
  _handleKeyUp = new WeakSet();
  handleKeyUp_fn = function (event) {
   const { key } = event;
   if (!this.keysUsed.includes(key)) {
    this.removeEventListener('keyup', media_chrome_menu_item_privateMethod(this, _handleKeyUp, handleKeyUp_fn));
    return;
   }
   this.handleClick(event);
  };
  media_chrome_menu_item_handleKeyDown = new WeakSet();
  media_chrome_menu_item_handleKeyDown_fn = function (event) {
   const { metaKey, altKey, key } = event;
   if (metaKey || altKey || !this.keysUsed.includes(key)) {
    this.removeEventListener('keyup', media_chrome_menu_item_privateMethod(this, _handleKeyUp, handleKeyUp_fn));
    return;
   }
   this.addEventListener('keyup', media_chrome_menu_item_privateMethod(this, _handleKeyUp, handleKeyUp_fn), { once: true });
  };
  _reset = new WeakSet();
  reset_fn = function () {
   var _a;
   const items = (_a = media_chrome_menu_item_privateGet(this, _ownerElement)) == null ? void 0 : _a.radioGroupItems;
   if (!items) return;
   let checkedItem = items.filter((item) => item.getAttribute('aria-checked') === 'true').pop();
   if (!checkedItem) checkedItem = items[0];
   for (const item of items) {
    item.setAttribute('aria-checked', 'false');
   }
   checkedItem == null ? void 0 : checkedItem.setAttribute('aria-checked', 'true');
  };
  MediaChromeMenuItem.shadowRootOptions = { mode: 'open' };
  MediaChromeMenuItem.getTemplateHTML = media_chrome_menu_item_getTemplateHTML;
  MediaChromeMenuItem.getSuffixSlotInnerHTML = getSuffixSlotInnerHTML;
  function isCheckable(item) {
   return item.type === 'radio' || item.type === 'checkbox';
  }
  function closestMenuItemsContainer(childNode, parentNode) {
   if (!childNode) return null;
   const { host } = childNode.getRootNode();
   if (!parentNode && host) return closestMenuItemsContainer(childNode, host);
   if (parentNode == null ? void 0 : parentNode.items) return parentNode;
   return closestMenuItemsContainer(parentNode, parentNode == null ? void 0 : parentNode.parentNode);
  }
  if (!GlobalThis.customElements.get('media-chrome-menu-item')) {
   GlobalThis.customElements.define('media-chrome-menu-item', MediaChromeMenuItem);
  }
  var media_chrome_menu_item_default = /* unused pure expression or super */ null && MediaChromeMenuItem; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-settings-menu.js

  function media_settings_menu_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    ${MediaChromeMenu.getTemplateHTML(_attrs)}
    <style>
      :host {
        --_menu-bg: rgb(20 20 30 / .8);
        background: var(--media-settings-menu-background,
            var(--media-menu-background,
              var(--media-control-background,
                var(--media-secondary-color, var(--_menu-bg)))));
        min-width: var(--media-settings-menu-min-width, 170px);
        border-radius: 2px 2px 0 0;
        overflow: hidden;
      }

      @-moz-document url-prefix() {
        :host{
          --_menu-bg: rgb(20 20 30);
        }
      }

      :host([role="menu"]) {
        ${/* Bottom fix setting menu items for animation when the height expands. */ ''}
        justify-content: end;
      }

      slot:not([name]) {
        justify-content: var(--media-settings-menu-justify-content);
        flex-direction: var(--media-settings-menu-flex-direction, column);
        overflow: visible;
      }

      #container.has-expanded {
        --media-settings-menu-item-opacity: 0;
      }
    </style>
  `
   );
  }
  class MediaSettingsMenu extends MediaChromeMenu {
   /**
    * Returns the anchor element when it is a floating menu.
    */
   get anchorElement() {
    if (this.anchor !== 'auto') return super.anchorElement;
    return getMediaController(this).querySelector('media-settings-menu-button');
   }
  }
  MediaSettingsMenu.getTemplateHTML = media_settings_menu_getTemplateHTML;
  if (!GlobalThis.customElements.get('media-settings-menu')) {
   GlobalThis.customElements.define('media-settings-menu', MediaSettingsMenu);
  }
  var media_settings_menu_default = /* unused pure expression or super */ null && MediaSettingsMenu; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-settings-menu-item.js

  function media_settings_menu_item_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    ${MediaChromeMenuItem.getTemplateHTML.call(this, _attrs)}
    <style>
      slot:not([name="submenu"]) {
        opacity: var(--media-settings-menu-item-opacity, var(--media-menu-item-opacity));
      }

      :host([aria-expanded="true"]:hover) {
        background: transparent;
      }
    </style>
  `
   );
  }
  function media_settings_menu_item_getSuffixSlotInnerHTML(_attrs) {
   return (
    /*html*/
    `
    <svg aria-hidden="true" viewBox="0 0 20 24">
      <path d="m8.12 17.585-.742-.669 4.2-4.665-4.2-4.666.743-.669 4.803 5.335-4.803 5.334Z"/>
    </svg>
  `
   );
  }
  class MediaSettingsMenuItem extends MediaChromeMenuItem {}
  MediaSettingsMenuItem.shadowRootOptions = { mode: 'open' };
  MediaSettingsMenuItem.getTemplateHTML = media_settings_menu_item_getTemplateHTML;
  MediaSettingsMenuItem.getSuffixSlotInnerHTML = media_settings_menu_item_getSuffixSlotInnerHTML;
  if (!GlobalThis.customElements.get('media-settings-menu-item')) {
   GlobalThis.customElements.define('media-settings-menu-item', MediaSettingsMenuItem);
  }
  var media_settings_menu_item_default = /* unused pure expression or super */ null && MediaSettingsMenuItem; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-chrome-menu-button.js

  class MediaChromeMenuButton extends MediaChromeButton {
   connectedCallback() {
    super.connectedCallback();
    if (this.invokeTargetElement) {
     this.setAttribute('aria-haspopup', 'menu');
    }
   }
   get invokeTarget() {
    return this.getAttribute('invoketarget');
   }
   set invokeTarget(value) {
    this.setAttribute('invoketarget', `${value}`);
   }
   /**
    * Returns the element with the id specified by the `invoketarget` attribute.
    * @return {HTMLElement | null}
    */
   get invokeTargetElement() {
    var _a;
    if (this.invokeTarget) {
     return (_a = getDocumentOrShadowRoot(this)) == null ? void 0 : _a.querySelector(`#${this.invokeTarget}`);
    }
    return null;
   }
   handleClick() {
    var _a;
    (_a = this.invokeTargetElement) == null ? void 0 : _a.dispatchEvent(new InvokeEvent({ relatedTarget: this }));
   }
  }
  if (!GlobalThis.customElements.get('media-chrome-menu-button')) {
   GlobalThis.customElements.define('media-chrome-menu-button', MediaChromeMenuButton);
  }
  var media_chrome_menu_button_default = /* unused pure expression or super */ null && MediaChromeMenuButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-settings-menu-button.js

  function media_settings_menu_button_getSlotTemplateHTML() {
   return (
    /*html*/
    `
    <style>
      :host([aria-expanded="true"]) slot[name=tooltip] {
        display: none;
      }
    </style>
    <slot name="icon">
      <svg aria-hidden="true" viewBox="0 0 24 24">
        <path d="M4.5 14.5a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5Zm7.5 0a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5Zm7.5 0a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5Z"/>
      </svg>
    </slot>
  `
   );
  }
  function media_settings_menu_button_getTooltipContentHTML() {
   return t('Settings');
  }
  class MediaSettingsMenuButton extends MediaChromeMenuButton {
   static get observedAttributes() {
    return [...super.observedAttributes, 'target'];
   }
   connectedCallback() {
    super.connectedCallback();
    this.setAttribute('aria-label', t('settings'));
   }
   /**
    * Returns the element with the id specified by the `invoketarget` attribute.
    * @return {HTMLElement | null}
    */
   get invokeTargetElement() {
    if (this.invokeTarget != void 0) return super.invokeTargetElement;
    return getMediaController(this).querySelector('media-settings-menu');
   }
  }
  MediaSettingsMenuButton.getSlotTemplateHTML = media_settings_menu_button_getSlotTemplateHTML;
  MediaSettingsMenuButton.getTooltipContentHTML = media_settings_menu_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-settings-menu-button')) {
   GlobalThis.customElements.define('media-settings-menu-button', MediaSettingsMenuButton);
  }
  var media_settings_menu_button_default = /* unused pure expression or super */ null && MediaSettingsMenuButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-audio-track-menu.js

  var media_audio_track_menu_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_audio_track_menu_privateGet = (obj, member, getter) => {
   media_audio_track_menu_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_audio_track_menu_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_audio_track_menu_privateSet = (obj, member, value, setter) => {
   media_audio_track_menu_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_audio_track_menu_privateMethod = (obj, member, method) => {
   media_audio_track_menu_accessCheck(obj, member, 'access private method');
   return method;
  };
  var _audioTrackList, _prevState, _render, render_fn, _onChange, onChange_fn;

  class MediaAudioTrackMenu extends MediaChromeMenu {
   constructor() {
    super(...arguments);
    media_audio_track_menu_privateAdd(this, _render);
    media_audio_track_menu_privateAdd(this, _onChange);
    media_audio_track_menu_privateAdd(this, _audioTrackList, []);
    media_audio_track_menu_privateAdd(this, _prevState, void 0);
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_AUDIO_TRACK_LIST, MediaUIAttributes.MEDIA_AUDIO_TRACK_ENABLED, MediaUIAttributes.MEDIA_AUDIO_TRACK_UNAVAILABLE];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_AUDIO_TRACK_ENABLED && oldValue !== newValue) {
     this.value = newValue;
    } else if (attrName === MediaUIAttributes.MEDIA_AUDIO_TRACK_LIST && oldValue !== newValue) {
     media_audio_track_menu_privateSet(this, _audioTrackList, parseAudioTrackList(newValue != null ? newValue : ''));
     media_audio_track_menu_privateMethod(this, _render, render_fn).call(this);
    }
   }
   connectedCallback() {
    super.connectedCallback();
    this.addEventListener('change', media_audio_track_menu_privateMethod(this, _onChange, onChange_fn));
   }
   disconnectedCallback() {
    super.disconnectedCallback();
    this.removeEventListener('change', media_audio_track_menu_privateMethod(this, _onChange, onChange_fn));
   }
   /**
    * Returns the anchor element when it is a floating menu.
    */
   get anchorElement() {
    var _a;
    if (this.anchor !== 'auto') return super.anchorElement;
    return (_a = getMediaController(this)) == null ? void 0 : _a.querySelector('media-audio-track-menu-button');
   }
   get mediaAudioTrackList() {
    return media_audio_track_menu_privateGet(this, _audioTrackList);
   }
   set mediaAudioTrackList(list) {
    media_audio_track_menu_privateSet(this, _audioTrackList, list);
    media_audio_track_menu_privateMethod(this, _render, render_fn).call(this);
   }
   /**
    * Get enabled audio track id.
    */
   get mediaAudioTrackEnabled() {
    var _a;
    return (_a = getStringAttr(this, MediaUIAttributes.MEDIA_AUDIO_TRACK_ENABLED)) != null ? _a : '';
   }
   set mediaAudioTrackEnabled(id) {
    setStringAttr(this, MediaUIAttributes.MEDIA_AUDIO_TRACK_ENABLED, id);
   }
  }
  _audioTrackList = new WeakMap();
  _prevState = new WeakMap();
  _render = new WeakSet();
  render_fn = function () {
   if (media_audio_track_menu_privateGet(this, _prevState) === JSON.stringify(this.mediaAudioTrackList)) return;
   media_audio_track_menu_privateSet(this, _prevState, JSON.stringify(this.mediaAudioTrackList));
   const audioTrackList = this.mediaAudioTrackList;
   this.defaultSlot.textContent = '';
   for (const audioTrack of audioTrackList) {
    const text = this.formatMenuItemText(audioTrack.label, audioTrack);
    const item = createMenuItem({
     type: 'radio',
     text,
     value: `${audioTrack.id}`,
     checked: audioTrack.enabled,
    });
    item.prepend(createIndicator(this, 'checked-indicator'));
    this.defaultSlot.append(item);
   }
  };
  _onChange = new WeakSet();
  onChange_fn = function () {
   if (this.value == null) return;
   const event = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_AUDIO_TRACK_REQUEST, {
    composed: true,
    bubbles: true,
    detail: this.value,
   });
   this.dispatchEvent(event);
  };
  if (!GlobalThis.customElements.get('media-audio-track-menu')) {
   GlobalThis.customElements.define('media-audio-track-menu', MediaAudioTrackMenu);
  }
  var media_audio_track_menu_default = /* unused pure expression or super */ null && MediaAudioTrackMenu; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-audio-track-menu-button.js

  const audioTrackIcon =
   /*html*/
   `<svg aria-hidden="true" viewBox="0 0 24 24">
  <path d="M11 17H9.5V7H11v10Zm-3-3H6.5v-4H8v4Zm6-5h-1.5v6H14V9Zm3 7h-1.5V8H17v8Z"/>
  <path d="M22 12c0 5.523-4.477 10-10 10S2 17.523 2 12 6.477 2 12 2s10 4.477 10 10Zm-2 0a8 8 0 1 0-16 0 8 8 0 0 0 16 0Z"/>
</svg>`;
  function media_audio_track_menu_button_getSlotTemplateHTML() {
   return (
    /*html*/
    `
    <style>
      :host([aria-expanded="true"]) slot[name=tooltip] {
        display: none;
      }
    </style>
    <slot name="icon">${audioTrackIcon}</slot>
  `
   );
  }
  function media_audio_track_menu_button_getTooltipContentHTML() {
   return t('Audio');
  }
  class MediaAudioTrackMenuButton extends MediaChromeMenuButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_AUDIO_TRACK_ENABLED, MediaUIAttributes.MEDIA_AUDIO_TRACK_UNAVAILABLE];
   }
   connectedCallback() {
    super.connectedCallback();
    this.setAttribute('aria-label', t('Audio'));
   }
   /**
    * Returns the element with the id specified by the `invoketarget` attribute.
    * @return {HTMLElement | null}
    */
   get invokeTargetElement() {
    var _a;
    if (this.invokeTarget != void 0) return super.invokeTargetElement;
    return (_a = getMediaController(this)) == null ? void 0 : _a.querySelector('media-audio-track-menu');
   }
   /**
    * Get enabled audio track id.
    * @return {string}
    */
   get mediaAudioTrackEnabled() {
    var _a;
    return (_a = getStringAttr(this, MediaUIAttributes.MEDIA_AUDIO_TRACK_ENABLED)) != null ? _a : '';
   }
   set mediaAudioTrackEnabled(id) {
    setStringAttr(this, MediaUIAttributes.MEDIA_AUDIO_TRACK_ENABLED, id);
   }
  }
  MediaAudioTrackMenuButton.getSlotTemplateHTML = media_audio_track_menu_button_getSlotTemplateHTML;
  MediaAudioTrackMenuButton.getTooltipContentHTML = media_audio_track_menu_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-audio-track-menu-button')) {
   GlobalThis.customElements.define('media-audio-track-menu-button', MediaAudioTrackMenuButton);
  }
  var media_audio_track_menu_button_default = /* unused pure expression or super */ null && MediaAudioTrackMenuButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-captions-menu.js

  var media_captions_menu_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_captions_menu_privateGet = (obj, member, getter) => {
   media_captions_menu_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_captions_menu_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_captions_menu_privateSet = (obj, member, value, setter) => {
   media_captions_menu_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_captions_menu_privateMethod = (obj, member, method) => {
   media_captions_menu_accessCheck(obj, member, 'access private method');
   return method;
  };
  var media_captions_menu_prevState, media_captions_menu_render, media_captions_menu_render_fn, media_captions_menu_onChange, media_captions_menu_onChange_fn;

  const ccIcon =
   /*html*/
   `
  <svg aria-hidden="true" viewBox="0 0 26 24" part="captions-indicator indicator">
    <path d="M22.83 5.68a2.58 2.58 0 0 0-2.3-2.5c-3.62-.24-11.44-.24-15.06 0a2.58 2.58 0 0 0-2.3 2.5c-.23 4.21-.23 8.43 0 12.64a2.58 2.58 0 0 0 2.3 2.5c3.62.24 11.44.24 15.06 0a2.58 2.58 0 0 0 2.3-2.5c.23-4.21.23-8.43 0-12.64Zm-11.39 9.45a3.07 3.07 0 0 1-1.91.57 3.06 3.06 0 0 1-2.34-1 3.75 3.75 0 0 1-.92-2.67 3.92 3.92 0 0 1 .92-2.77 3.18 3.18 0 0 1 2.43-1 2.94 2.94 0 0 1 2.13.78c.364.359.62.813.74 1.31l-1.43.35a1.49 1.49 0 0 0-1.51-1.17 1.61 1.61 0 0 0-1.29.58 2.79 2.79 0 0 0-.5 1.89 3 3 0 0 0 .49 1.93 1.61 1.61 0 0 0 1.27.58 1.48 1.48 0 0 0 1-.37 2.1 2.1 0 0 0 .59-1.14l1.4.44a3.23 3.23 0 0 1-1.07 1.69Zm7.22 0a3.07 3.07 0 0 1-1.91.57 3.06 3.06 0 0 1-2.34-1 3.75 3.75 0 0 1-.92-2.67 3.88 3.88 0 0 1 .93-2.77 3.14 3.14 0 0 1 2.42-1 3 3 0 0 1 2.16.82 2.8 2.8 0 0 1 .73 1.31l-1.43.35a1.49 1.49 0 0 0-1.51-1.21 1.61 1.61 0 0 0-1.29.58A2.79 2.79 0 0 0 15 12a3 3 0 0 0 .49 1.93 1.61 1.61 0 0 0 1.27.58 1.44 1.44 0 0 0 1-.37 2.1 2.1 0 0 0 .6-1.15l1.4.44a3.17 3.17 0 0 1-1.1 1.7Z"/>
  </svg>`;
  function media_captions_menu_getTemplateHTML(_attrs) {
   return (
    /*html*/
    `
    ${MediaChromeMenu.getTemplateHTML(_attrs)}
    <slot name="captions-indicator" hidden>${ccIcon}</slot>
  `
   );
  }
  class MediaCaptionsMenu extends MediaChromeMenu {
   constructor() {
    super(...arguments);
    media_captions_menu_privateAdd(this, media_captions_menu_render);
    media_captions_menu_privateAdd(this, media_captions_menu_onChange);
    media_captions_menu_privateAdd(this, media_captions_menu_prevState, void 0);
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_SUBTITLES_LIST, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_SUBTITLES_LIST && oldValue !== newValue) {
     media_captions_menu_privateMethod(this, media_captions_menu_render, media_captions_menu_render_fn).call(this);
    } else if (attrName === MediaUIAttributes.MEDIA_SUBTITLES_SHOWING && oldValue !== newValue) {
     this.value = newValue;
    }
   }
   connectedCallback() {
    super.connectedCallback();
    this.addEventListener('change', media_captions_menu_privateMethod(this, media_captions_menu_onChange, media_captions_menu_onChange_fn));
   }
   disconnectedCallback() {
    super.disconnectedCallback();
    this.removeEventListener('change', media_captions_menu_privateMethod(this, media_captions_menu_onChange, media_captions_menu_onChange_fn));
   }
   /**
    * Returns the anchor element when it is a floating menu.
    */
   get anchorElement() {
    if (this.anchor !== 'auto') return super.anchorElement;
    return getMediaController(this).querySelector('media-captions-menu-button');
   }
   /**
    * @type {Array<object>} An array of TextTrack-like objects.
    * Objects must have the properties: kind, language, and label.
    */
   get mediaSubtitlesList() {
    return media_captions_menu_getSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_LIST);
   }
   set mediaSubtitlesList(list) {
    media_captions_menu_setSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_LIST, list);
   }
   /**
    * An array of TextTrack-like objects.
    * Objects must have the properties: kind, language, and label.
    */
   get mediaSubtitlesShowing() {
    return media_captions_menu_getSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING);
   }
   set mediaSubtitlesShowing(list) {
    media_captions_menu_setSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING, list);
   }
  }
  media_captions_menu_prevState = new WeakMap();
  media_captions_menu_render = new WeakSet();
  media_captions_menu_render_fn = function () {
   var _a;
   if (media_captions_menu_privateGet(this, media_captions_menu_prevState) === JSON.stringify(this.mediaSubtitlesList)) return;
   media_captions_menu_privateSet(this, media_captions_menu_prevState, JSON.stringify(this.mediaSubtitlesList));
   this.defaultSlot.textContent = '';
   const isOff = !this.value;
   const item = createMenuItem({
    type: 'radio',
    text: this.formatMenuItemText(t('Off')),
    value: 'off',
    checked: isOff,
   });
   item.prepend(createIndicator(this, 'checked-indicator'));
   this.defaultSlot.append(item);
   const subtitlesList = this.mediaSubtitlesList;
   for (const subs of subtitlesList) {
    const item2 = createMenuItem({
     type: 'radio',
     text: this.formatMenuItemText(subs.label, subs),
     value: formatTextTrackObj(subs),
     checked: this.value == formatTextTrackObj(subs),
    });
    item2.prepend(createIndicator(this, 'checked-indicator'));
    const type = (_a = subs.kind) != null ? _a : 'subs';
    if (type === 'captions') {
     item2.append(createIndicator(this, 'captions-indicator'));
    }
    this.defaultSlot.append(item2);
   }
  };
  media_captions_menu_onChange = new WeakSet();
  media_captions_menu_onChange_fn = function () {
   const showingSubs = this.mediaSubtitlesShowing;
   const showingSubsStr = this.getAttribute(MediaUIAttributes.MEDIA_SUBTITLES_SHOWING);
   const localStateChange = this.value !== showingSubsStr;
   if ((showingSubs == null ? void 0 : showingSubs.length) && localStateChange) {
    this.dispatchEvent(
     new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_DISABLE_SUBTITLES_REQUEST, {
      composed: true,
      bubbles: true,
      detail: showingSubs,
     }),
    );
   }
   if (!this.value || !localStateChange) return;
   const event = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_SHOW_SUBTITLES_REQUEST, {
    composed: true,
    bubbles: true,
    detail: this.value,
   });
   this.dispatchEvent(event);
  };
  MediaCaptionsMenu.getTemplateHTML = media_captions_menu_getTemplateHTML;
  const media_captions_menu_getSubtitlesListAttr = (el, attrName) => {
   const attrVal = el.getAttribute(attrName);
   return attrVal ? parseTextTracksStr(attrVal) : [];
  };
  const media_captions_menu_setSubtitlesListAttr = (el, attrName, list) => {
   if (!(list == null ? void 0 : list.length)) {
    el.removeAttribute(attrName);
    return;
   }
   const newValStr = stringifyTextTrackList(list);
   const oldVal = el.getAttribute(attrName);
   if (oldVal === newValStr) return;
   el.setAttribute(attrName, newValStr);
  };
  if (!GlobalThis.customElements.get('media-captions-menu')) {
   GlobalThis.customElements.define('media-captions-menu', MediaCaptionsMenu);
  }
  var media_captions_menu_default = /* unused pure expression or super */ null && MediaCaptionsMenu; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-captions-menu-button.js

  const media_captions_menu_button_ccIconOn = `<svg aria-hidden="true" viewBox="0 0 26 24">
  <path d="M22.83 5.68a2.58 2.58 0 0 0-2.3-2.5c-3.62-.24-11.44-.24-15.06 0a2.58 2.58 0 0 0-2.3 2.5c-.23 4.21-.23 8.43 0 12.64a2.58 2.58 0 0 0 2.3 2.5c3.62.24 11.44.24 15.06 0a2.58 2.58 0 0 0 2.3-2.5c.23-4.21.23-8.43 0-12.64Zm-11.39 9.45a3.07 3.07 0 0 1-1.91.57 3.06 3.06 0 0 1-2.34-1 3.75 3.75 0 0 1-.92-2.67 3.92 3.92 0 0 1 .92-2.77 3.18 3.18 0 0 1 2.43-1 2.94 2.94 0 0 1 2.13.78c.364.359.62.813.74 1.31l-1.43.35a1.49 1.49 0 0 0-1.51-1.17 1.61 1.61 0 0 0-1.29.58 2.79 2.79 0 0 0-.5 1.89 3 3 0 0 0 .49 1.93 1.61 1.61 0 0 0 1.27.58 1.48 1.48 0 0 0 1-.37 2.1 2.1 0 0 0 .59-1.14l1.4.44a3.23 3.23 0 0 1-1.07 1.69Zm7.22 0a3.07 3.07 0 0 1-1.91.57 3.06 3.06 0 0 1-2.34-1 3.75 3.75 0 0 1-.92-2.67 3.88 3.88 0 0 1 .93-2.77 3.14 3.14 0 0 1 2.42-1 3 3 0 0 1 2.16.82 2.8 2.8 0 0 1 .73 1.31l-1.43.35a1.49 1.49 0 0 0-1.51-1.21 1.61 1.61 0 0 0-1.29.58A2.79 2.79 0 0 0 15 12a3 3 0 0 0 .49 1.93 1.61 1.61 0 0 0 1.27.58 1.44 1.44 0 0 0 1-.37 2.1 2.1 0 0 0 .6-1.15l1.4.44a3.17 3.17 0 0 1-1.1 1.7Z"/>
</svg>`;
  const media_captions_menu_button_ccIconOff = `<svg aria-hidden="true" viewBox="0 0 26 24">
  <path d="M17.73 14.09a1.4 1.4 0 0 1-1 .37 1.579 1.579 0 0 1-1.27-.58A3 3 0 0 1 15 12a2.8 2.8 0 0 1 .5-1.85 1.63 1.63 0 0 1 1.29-.57 1.47 1.47 0 0 1 1.51 1.2l1.43-.34A2.89 2.89 0 0 0 19 9.07a3 3 0 0 0-2.14-.78 3.14 3.14 0 0 0-2.42 1 3.91 3.91 0 0 0-.93 2.78 3.74 3.74 0 0 0 .92 2.66 3.07 3.07 0 0 0 2.34 1 3.07 3.07 0 0 0 1.91-.57 3.17 3.17 0 0 0 1.07-1.74l-1.4-.45c-.083.43-.3.822-.62 1.12Zm-7.22 0a1.43 1.43 0 0 1-1 .37 1.58 1.58 0 0 1-1.27-.58A3 3 0 0 1 7.76 12a2.8 2.8 0 0 1 .5-1.85 1.63 1.63 0 0 1 1.29-.57 1.47 1.47 0 0 1 1.51 1.2l1.43-.34a2.81 2.81 0 0 0-.74-1.32 2.94 2.94 0 0 0-2.13-.78 3.18 3.18 0 0 0-2.43 1 4 4 0 0 0-.92 2.78 3.74 3.74 0 0 0 .92 2.66 3.07 3.07 0 0 0 2.34 1 3.07 3.07 0 0 0 1.91-.57 3.23 3.23 0 0 0 1.07-1.74l-1.4-.45a2.06 2.06 0 0 1-.6 1.07Zm12.32-8.41a2.59 2.59 0 0 0-2.3-2.51C18.72 3.05 15.86 3 13 3c-2.86 0-5.72.05-7.53.17a2.59 2.59 0 0 0-2.3 2.51c-.23 4.207-.23 8.423 0 12.63a2.57 2.57 0 0 0 2.3 2.5c1.81.13 4.67.19 7.53.19 2.86 0 5.72-.06 7.53-.19a2.57 2.57 0 0 0 2.3-2.5c.23-4.207.23-8.423 0-12.63Zm-1.49 12.53a1.11 1.11 0 0 1-.91 1.11c-1.67.11-4.45.18-7.43.18-2.98 0-5.76-.07-7.43-.18a1.11 1.11 0 0 1-.91-1.11c-.21-4.14-.21-8.29 0-12.43a1.11 1.11 0 0 1 .91-1.11C7.24 4.56 10 4.49 13 4.49s5.76.07 7.43.18a1.11 1.11 0 0 1 .91 1.11c.21 4.14.21 8.29 0 12.43Z"/>
</svg>`;
  function media_captions_menu_button_getSlotTemplateHTML() {
   return (
    /*html*/
    `
    <style>
      :host([aria-checked="true"]) slot[name=off] {
        display: none !important;
      }

      ${/* Double negative, but safer if display doesn't equal 'block' */ ''}
      :host(:not([aria-checked="true"])) slot[name=on] {
        display: none !important;
      }

      :host([aria-expanded="true"]) slot[name=tooltip] {
        display: none;
      }
    </style>

    <slot name="icon">
      <slot name="on">${media_captions_menu_button_ccIconOn}</slot>
      <slot name="off">${media_captions_menu_button_ccIconOff}</slot>
    </slot>
  `
   );
  }
  function media_captions_menu_button_getTooltipContentHTML() {
   return t('Captions');
  }
  const media_captions_menu_button_updateAriaChecked = (el) => {
   el.setAttribute('aria-checked', areSubsOn(el).toString());
  };
  class MediaCaptionsMenuButton extends MediaChromeMenuButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_SUBTITLES_LIST, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING];
   }
   connectedCallback() {
    super.connectedCallback();
    this.setAttribute('aria-label', t('closed captions'));
    media_captions_menu_button_updateAriaChecked(this);
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_SUBTITLES_SHOWING) {
     media_captions_menu_button_updateAriaChecked(this);
    }
   }
   /**
    * Returns the element with the id specified by the `invoketarget` attribute.
    * @return {HTMLElement | null}
    */
   get invokeTargetElement() {
    var _a;
    if (this.invokeTarget != void 0) return super.invokeTargetElement;
    return (_a = getMediaController(this)) == null ? void 0 : _a.querySelector('media-captions-menu');
   }
   /**
    * An array of TextTrack-like objects.
    * Objects must have the properties: kind, language, and label.
    */
   get mediaSubtitlesList() {
    return media_captions_menu_button_getSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_LIST);
   }
   set mediaSubtitlesList(list) {
    media_captions_menu_button_setSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_LIST, list);
   }
   /**
    * An array of TextTrack-like objects.
    * Objects must have the properties: kind, language, and label.
    */
   get mediaSubtitlesShowing() {
    return media_captions_menu_button_getSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING);
   }
   set mediaSubtitlesShowing(list) {
    media_captions_menu_button_setSubtitlesListAttr(this, MediaUIAttributes.MEDIA_SUBTITLES_SHOWING, list);
   }
  }
  MediaCaptionsMenuButton.getSlotTemplateHTML = media_captions_menu_button_getSlotTemplateHTML;
  MediaCaptionsMenuButton.getTooltipContentHTML = media_captions_menu_button_getTooltipContentHTML;
  const media_captions_menu_button_getSubtitlesListAttr = (el, attrName) => {
   const attrVal = el.getAttribute(attrName);
   return attrVal ? parseTextTracksStr(attrVal) : [];
  };
  const media_captions_menu_button_setSubtitlesListAttr = (el, attrName, list) => {
   if (!(list == null ? void 0 : list.length)) {
    el.removeAttribute(attrName);
    return;
   }
   const newValStr = stringifyTextTrackList(list);
   const oldVal = el.getAttribute(attrName);
   if (oldVal === newValStr) return;
   el.setAttribute(attrName, newValStr);
  };
  if (!GlobalThis.customElements.get('media-captions-menu-button')) {
   GlobalThis.customElements.define('media-captions-menu-button', MediaCaptionsMenuButton);
  }
  var media_captions_menu_button_default = /* unused pure expression or super */ null && MediaCaptionsMenuButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-playback-rate-menu.js

  var media_playback_rate_menu_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_playback_rate_menu_privateGet = (obj, member, getter) => {
   media_playback_rate_menu_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_playback_rate_menu_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_playback_rate_menu_privateMethod = (obj, member, method) => {
   media_playback_rate_menu_accessCheck(obj, member, 'access private method');
   return method;
  };
  var media_playback_rate_menu_rates, media_playback_rate_menu_render, media_playback_rate_menu_render_fn, media_playback_rate_menu_onChange, media_playback_rate_menu_onChange_fn;

  const media_playback_rate_menu_Attributes = {
   RATES: 'rates',
  };
  class MediaPlaybackRateMenu extends MediaChromeMenu {
   constructor() {
    super();
    media_playback_rate_menu_privateAdd(this, media_playback_rate_menu_render);
    media_playback_rate_menu_privateAdd(this, media_playback_rate_menu_onChange);
    media_playback_rate_menu_privateAdd(
     this,
     media_playback_rate_menu_rates,
     new AttributeTokenList(this, media_playback_rate_menu_Attributes.RATES, {
      defaultValue: DEFAULT_RATES,
     }),
    );
    media_playback_rate_menu_privateMethod(this, media_playback_rate_menu_render, media_playback_rate_menu_render_fn).call(this);
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_PLAYBACK_RATE, media_playback_rate_menu_Attributes.RATES];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_PLAYBACK_RATE && oldValue != newValue) {
     this.value = newValue;
    } else if (attrName === media_playback_rate_menu_Attributes.RATES && oldValue != newValue) {
     media_playback_rate_menu_privateGet(this, media_playback_rate_menu_rates).value = newValue;
     media_playback_rate_menu_privateMethod(this, media_playback_rate_menu_render, media_playback_rate_menu_render_fn).call(this);
    }
   }
   connectedCallback() {
    super.connectedCallback();
    this.addEventListener('change', media_playback_rate_menu_privateMethod(this, media_playback_rate_menu_onChange, media_playback_rate_menu_onChange_fn));
   }
   disconnectedCallback() {
    super.disconnectedCallback();
    this.removeEventListener('change', media_playback_rate_menu_privateMethod(this, media_playback_rate_menu_onChange, media_playback_rate_menu_onChange_fn));
   }
   /**
    * Returns the anchor element when it is a floating menu.
    */
   get anchorElement() {
    if (this.anchor !== 'auto') return super.anchorElement;
    return getMediaController(this).querySelector('media-playback-rate-menu-button');
   }
   /**
    * Get the playback rates for the button.
    */
   get rates() {
    return media_playback_rate_menu_privateGet(this, media_playback_rate_menu_rates);
   }
   /**
    * Set the playback rates for the button.
    * For React 19+ compatibility, accept a string of space-separated rates.
    */
   set rates(value) {
    if (!value) {
     media_playback_rate_menu_privateGet(this, media_playback_rate_menu_rates).value = '';
    } else if (Array.isArray(value)) {
     media_playback_rate_menu_privateGet(this, media_playback_rate_menu_rates).value = value.join(' ');
    } else if (typeof value === 'string') {
     media_playback_rate_menu_privateGet(this, media_playback_rate_menu_rates).value = value;
    }
    media_playback_rate_menu_privateMethod(this, media_playback_rate_menu_render, media_playback_rate_menu_render_fn).call(this);
   }
   /**
    * The current playback rate
    */
   get mediaPlaybackRate() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_PLAYBACK_RATE, DEFAULT_RATE);
   }
   set mediaPlaybackRate(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_PLAYBACK_RATE, value);
   }
  }
  media_playback_rate_menu_rates = new WeakMap();
  media_playback_rate_menu_render = new WeakSet();
  media_playback_rate_menu_render_fn = function () {
   this.defaultSlot.textContent = '';
   for (const rate of media_playback_rate_menu_privateGet(this, media_playback_rate_menu_rates)) {
    const item = createMenuItem({
     type: 'radio',
     text: this.formatMenuItemText(`${rate}x`, rate),
     value: rate,
     checked: this.mediaPlaybackRate === Number(rate),
    });
    item.prepend(createIndicator(this, 'checked-indicator'));
    this.defaultSlot.append(item);
   }
  };
  media_playback_rate_menu_onChange = new WeakSet();
  media_playback_rate_menu_onChange_fn = function () {
   if (!this.value) return;
   const event = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_PLAYBACK_RATE_REQUEST, {
    composed: true,
    bubbles: true,
    detail: this.value,
   });
   this.dispatchEvent(event);
  };
  if (!GlobalThis.customElements.get('media-playback-rate-menu')) {
   GlobalThis.customElements.define('media-playback-rate-menu', MediaPlaybackRateMenu);
  }
  var media_playback_rate_menu_default = /* unused pure expression or super */ null && MediaPlaybackRateMenu; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-playback-rate-menu-button.js

  const media_playback_rate_menu_button_DEFAULT_RATE = 1;
  function media_playback_rate_menu_button_getSlotTemplateHTML(attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        min-width: 5ch;
        padding: var(--media-button-padding, var(--media-control-padding, 10px 5px));
      }
      
      :host([aria-expanded="true"]) slot[name=tooltip] {
        display: none;
      }
    </style>
    <slot name="icon">${attrs['mediaplaybackrate'] || media_playback_rate_menu_button_DEFAULT_RATE}x</slot>
  `
   );
  }
  function media_playback_rate_menu_button_getTooltipContentHTML() {
   return t('Playback rate');
  }
  class MediaPlaybackRateMenuButton extends MediaChromeMenuButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_PLAYBACK_RATE];
   }
   constructor() {
    var _a;
    super();
    this.container = this.shadowRoot.querySelector('slot[name="icon"]');
    this.container.innerHTML = `${(_a = this.mediaPlaybackRate) != null ? _a : media_playback_rate_menu_button_DEFAULT_RATE}x`;
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_PLAYBACK_RATE) {
     const newPlaybackRate = newValue ? +newValue : Number.NaN;
     const playbackRate = !Number.isNaN(newPlaybackRate) ? newPlaybackRate : media_playback_rate_menu_button_DEFAULT_RATE;
     this.container.innerHTML = `${playbackRate}x`;
     this.setAttribute('aria-label', t('Playback rate {playbackRate}', { playbackRate }));
    }
   }
   /**
    * Returns the element with the id specified by the `invoketarget` attribute.
    */
   get invokeTargetElement() {
    if (this.invokeTarget != void 0) return super.invokeTargetElement;
    return getMediaController(this).querySelector('media-playback-rate-menu');
   }
   /**
    * The current playback rate
    */
   get mediaPlaybackRate() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_PLAYBACK_RATE, media_playback_rate_menu_button_DEFAULT_RATE);
   }
   set mediaPlaybackRate(value) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_PLAYBACK_RATE, value);
   }
  }
  MediaPlaybackRateMenuButton.getSlotTemplateHTML = media_playback_rate_menu_button_getSlotTemplateHTML;
  MediaPlaybackRateMenuButton.getTooltipContentHTML = media_playback_rate_menu_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-playback-rate-menu-button')) {
   GlobalThis.customElements.define('media-playback-rate-menu-button', MediaPlaybackRateMenuButton);
  }
  var media_playback_rate_menu_button_default = /* unused pure expression or super */ null && MediaPlaybackRateMenuButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-rendition-menu.js

  var media_rendition_menu_accessCheck = (obj, member, msg) => {
   if (!member.has(obj)) throw TypeError('Cannot ' + msg);
  };
  var media_rendition_menu_privateGet = (obj, member, getter) => {
   media_rendition_menu_accessCheck(obj, member, 'read from private field');
   return getter ? getter.call(obj) : member.get(obj);
  };
  var media_rendition_menu_privateAdd = (obj, member, value) => {
   if (member.has(obj)) throw TypeError('Cannot add the same private member more than once');
   member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
  };
  var media_rendition_menu_privateSet = (obj, member, value, setter) => {
   media_rendition_menu_accessCheck(obj, member, 'write to private field');
   setter ? setter.call(obj, value) : member.set(obj, value);
   return value;
  };
  var media_rendition_menu_privateMethod = (obj, member, method) => {
   media_rendition_menu_accessCheck(obj, member, 'access private method');
   return method;
  };
  var _renditionList, media_rendition_menu_prevState, media_rendition_menu_render, media_rendition_menu_render_fn, media_rendition_menu_onChange, media_rendition_menu_onChange_fn;

  class MediaRenditionMenu extends MediaChromeMenu {
   constructor() {
    super(...arguments);
    media_rendition_menu_privateAdd(this, media_rendition_menu_render);
    media_rendition_menu_privateAdd(this, media_rendition_menu_onChange);
    media_rendition_menu_privateAdd(this, _renditionList, []);
    media_rendition_menu_privateAdd(this, media_rendition_menu_prevState, {});
   }
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_RENDITION_LIST, MediaUIAttributes.MEDIA_RENDITION_SELECTED, MediaUIAttributes.MEDIA_RENDITION_UNAVAILABLE, MediaUIAttributes.MEDIA_HEIGHT];
   }
   attributeChangedCallback(attrName, oldValue, newValue) {
    super.attributeChangedCallback(attrName, oldValue, newValue);
    if (attrName === MediaUIAttributes.MEDIA_RENDITION_SELECTED && oldValue !== newValue) {
     this.value = newValue != null ? newValue : 'auto';
     media_rendition_menu_privateMethod(this, media_rendition_menu_render, media_rendition_menu_render_fn).call(this);
    } else if (attrName === MediaUIAttributes.MEDIA_RENDITION_LIST && oldValue !== newValue) {
     media_rendition_menu_privateSet(this, _renditionList, parseRenditionList(newValue));
     media_rendition_menu_privateMethod(this, media_rendition_menu_render, media_rendition_menu_render_fn).call(this);
    } else if (attrName === MediaUIAttributes.MEDIA_HEIGHT && oldValue !== newValue) {
     media_rendition_menu_privateMethod(this, media_rendition_menu_render, media_rendition_menu_render_fn).call(this);
    }
   }
   connectedCallback() {
    super.connectedCallback();
    this.addEventListener('change', media_rendition_menu_privateMethod(this, media_rendition_menu_onChange, media_rendition_menu_onChange_fn));
   }
   disconnectedCallback() {
    super.disconnectedCallback();
    this.removeEventListener('change', media_rendition_menu_privateMethod(this, media_rendition_menu_onChange, media_rendition_menu_onChange_fn));
   }
   /**
    * Returns the anchor element when it is a floating menu.
    */
   get anchorElement() {
    if (this.anchor !== 'auto') return super.anchorElement;
    return getMediaController(this).querySelector('media-rendition-menu-button');
   }
   get mediaRenditionList() {
    return media_rendition_menu_privateGet(this, _renditionList);
   }
   set mediaRenditionList(list) {
    media_rendition_menu_privateSet(this, _renditionList, list);
    media_rendition_menu_privateMethod(this, media_rendition_menu_render, media_rendition_menu_render_fn).call(this);
   }
   /**
    * Get selected rendition id.
    */
   get mediaRenditionSelected() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_RENDITION_SELECTED);
   }
   set mediaRenditionSelected(id) {
    setStringAttr(this, MediaUIAttributes.MEDIA_RENDITION_SELECTED, id);
   }
   get mediaHeight() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_HEIGHT);
   }
   set mediaHeight(height) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_HEIGHT, height);
   }
  }
  _renditionList = new WeakMap();
  media_rendition_menu_prevState = new WeakMap();
  media_rendition_menu_render = new WeakSet();
  media_rendition_menu_render_fn = function () {
   if (media_rendition_menu_privateGet(this, media_rendition_menu_prevState).mediaRenditionList === JSON.stringify(this.mediaRenditionList) && media_rendition_menu_privateGet(this, media_rendition_menu_prevState).mediaHeight === this.mediaHeight) return;
   media_rendition_menu_privateGet(this, media_rendition_menu_prevState).mediaRenditionList = JSON.stringify(this.mediaRenditionList);
   media_rendition_menu_privateGet(this, media_rendition_menu_prevState).mediaHeight = this.mediaHeight;
   const renditionList = this.mediaRenditionList.sort((a, b) => b.height - a.height);
   for (const rendition of renditionList) {
    rendition.selected = rendition.id === this.mediaRenditionSelected;
   }
   this.defaultSlot.textContent = '';
   const isAuto = !this.mediaRenditionSelected;
   for (const rendition of renditionList) {
    const text2 = this.formatMenuItemText(`${Math.min(rendition.width, rendition.height)}p`, rendition);
    const item2 = createMenuItem({
     type: 'radio',
     text: text2,
     value: `${rendition.id}`,
     checked: rendition.selected && !isAuto,
    });
    item2.prepend(createIndicator(this, 'checked-indicator'));
    this.defaultSlot.append(item2);
   }
   const text = isAuto ? this.formatMenuItemText(`${t('Auto')} (${this.mediaHeight}p)`) : this.formatMenuItemText(t('Auto'));
   const item = createMenuItem({
    type: 'radio',
    text,
    value: 'auto',
    checked: isAuto,
   });
   const autoDescription = this.mediaHeight > 0 ? `${t('Auto')} (${this.mediaHeight}p)` : t('Auto');
   item.dataset.description = autoDescription;
   item.prepend(createIndicator(this, 'checked-indicator'));
   this.defaultSlot.append(item);
  };
  media_rendition_menu_onChange = new WeakSet();
  media_rendition_menu_onChange_fn = function () {
   if (this.value == null) return;
   const event = new GlobalThis.CustomEvent(MediaUIEvents.MEDIA_RENDITION_REQUEST, {
    composed: true,
    bubbles: true,
    detail: this.value,
   });
   this.dispatchEvent(event);
  };
  if (!GlobalThis.customElements.get('media-rendition-menu')) {
   GlobalThis.customElements.define('media-rendition-menu', MediaRenditionMenu);
  }
  var media_rendition_menu_default = /* unused pure expression or super */ null && MediaRenditionMenu; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/media-rendition-menu-button.js

  const renditionIcon =
   /*html*/
   `<svg aria-hidden="true" viewBox="0 0 24 24">
  <path d="M13.5 2.5h2v6h-2v-2h-11v-2h11v-2Zm4 2h4v2h-4v-2Zm-12 4h2v6h-2v-2h-3v-2h3v-2Zm4 2h12v2h-12v-2Zm1 4h2v6h-2v-2h-8v-2h8v-2Zm4 2h7v2h-7v-2Z" />
</svg>`;
  function media_rendition_menu_button_getSlotTemplateHTML() {
   return (
    /*html*/
    `
    <style>
      :host([aria-expanded="true"]) slot[name=tooltip] {
        display: none;
      }
    </style>
    <slot name="icon">${renditionIcon}</slot>
  `
   );
  }
  function media_rendition_menu_button_getTooltipContentHTML() {
   return t('Quality');
  }
  class MediaRenditionMenuButton extends MediaChromeMenuButton {
   static get observedAttributes() {
    return [...super.observedAttributes, MediaUIAttributes.MEDIA_RENDITION_SELECTED, MediaUIAttributes.MEDIA_RENDITION_UNAVAILABLE, MediaUIAttributes.MEDIA_HEIGHT];
   }
   connectedCallback() {
    super.connectedCallback();
    this.setAttribute('aria-label', t('quality'));
   }
   /**
    * Returns the element with the id specified by the `invoketarget` attribute.
    */
   get invokeTargetElement() {
    if (this.invokeTarget != void 0) return super.invokeTargetElement;
    return getMediaController(this).querySelector('media-rendition-menu');
   }
   /**
    * Get selected rendition id.
    */
   get mediaRenditionSelected() {
    return getStringAttr(this, MediaUIAttributes.MEDIA_RENDITION_SELECTED);
   }
   set mediaRenditionSelected(id) {
    setStringAttr(this, MediaUIAttributes.MEDIA_RENDITION_SELECTED, id);
   }
   get mediaHeight() {
    return getNumericAttr(this, MediaUIAttributes.MEDIA_HEIGHT);
   }
   set mediaHeight(height) {
    setNumericAttr(this, MediaUIAttributes.MEDIA_HEIGHT, height);
   }
  }
  MediaRenditionMenuButton.getSlotTemplateHTML = media_rendition_menu_button_getSlotTemplateHTML;
  MediaRenditionMenuButton.getTooltipContentHTML = media_rendition_menu_button_getTooltipContentHTML;
  if (!GlobalThis.customElements.get('media-rendition-menu-button')) {
   GlobalThis.customElements.define('media-rendition-menu-button', MediaRenditionMenuButton);
  }
  var media_rendition_menu_button_default = /* unused pure expression or super */ null && MediaRenditionMenuButton; // CONCATENATED MODULE: ./node_modules/.pnpm/media-chrome@4.11.1_react@18.3.1/node_modules/media-chrome/dist/menu/index.js
  // CONCATENATED MODULE: ./node_modules/.pnpm/@mux+mux-player@3.5.3_react@18.3.1/node_modules/@mux/mux-player/dist/base.mjs

  var base_qe = (t) => {
   throw TypeError(t);
  };
  var base_he = (t, a, e) => a.has(t) || base_qe('Cannot ' + e);
  var dist_base_u = (t, a, e) => (base_he(t, a, 'read from private field'), e ? e.call(t) : a.get(t)),
   base_T = (t, a, e) => (a.has(t) ? base_qe('Cannot add the same private member more than once') : a instanceof WeakSet ? a.add(t) : a.set(t, e)),
   dist_base_C = (t, a, e, i) => (base_he(t, a, 'write to private field'), i ? i.call(t, e) : a.set(t, e), e),
   base_p = (t, a, e) => (base_he(t, a, 'access private method'), e);
  var base_$ = class {
   addEventListener() {}
   removeEventListener() {}
   dispatchEvent(a) {
    return !0;
   }
  };
  if (typeof DocumentFragment == 'undefined') {
   class t extends base_$ {}
   globalThis.DocumentFragment = t;
  }
  var base_G = class extends base_$ {},
   base_ge = class extends base_$ {},
   base_Pt = {
    get(t) {},
    define(t, a, e) {},
    getName(t) {
     return null;
    },
    upgrade(t) {},
    whenDefined(t) {
     return Promise.resolve(base_G);
    },
   },
   base_j,
   base_fe = class {
    constructor(a, e = {}) {
     base_T(this, base_j);
     dist_base_C(this, base_j, e == null ? void 0 : e.detail);
    }
    get detail() {
     return dist_base_u(this, base_j);
    }
    initCustomEvent() {}
   };
  base_j = new WeakMap();
  function base_Dt(t, a) {
   return new base_G();
  }
  var base_Qe = { document: { createElement: base_Dt }, DocumentFragment, customElements: base_Pt, CustomEvent: base_fe, EventTarget: base_$, HTMLElement: base_G, HTMLVideoElement: base_ge },
   base_Je = typeof window == 'undefined' || typeof globalThis.customElements == 'undefined',
   base_k = base_Je ? base_Qe : globalThis,
   dist_base_Y = base_Je ? base_Qe.document : globalThis.document;
  function base_et(t) {
   let a = '';
   return (
    Object.entries(t).forEach(([e, i]) => {
     i != null && (a += `${base_re(e)}: ${i}; `);
    }),
    a ? a.trim() : void 0
   );
  }
  function base_re(t) {
   return t.replace(/([a-z])([A-Z])/g, '$1-$2').toLowerCase();
  }
  function base_oe(t) {
   return t.replace(/[-_]([a-z])/g, (a, e) => e.toUpperCase());
  }
  function base_y(t) {
   if (t == null) return;
   let a = +t;
   return Number.isNaN(a) ? void 0 : a;
  }
  function base_ye(t) {
   let a = base_Ut(t).toString();
   return a ? '?' + a : '';
  }
  function base_Ut(t) {
   let a = {};
   for (let e in t) t[e] != null && (a[e] = t[e]);
   return new URLSearchParams(a);
  }
  var base_ve = (t, a) => (!t || !a ? !1 : t.contains(a) ? !0 : base_ve(t, a.getRootNode().host));
  var dist_base_at = 'mux.com',
   base_Vt = () => {
    try {
     return '3.5.3';
    } catch {}
    return 'UNKNOWN';
   },
   base_Bt = base_Vt(),
   base_se = () => base_Bt,
   base_it = (t, { token: a, customDomain: e = dist_base_at, thumbnailTime: i, programTime: r } = {}) => {
    var l;
    let n = a == null ? i : void 0,
     { aud: d } = (l = dist_ee(a)) != null ? l : {};
    if (!(a && d !== 't')) return `https://image.${e}/${t}/thumbnail.webp${base_ye({ token: a, time: n, program_time: r })}`;
   },
   base_rt = (t, { token: a, customDomain: e = dist_base_at, programStartTime: i, programEndTime: r } = {}) => {
    var d;
    let { aud: n } = (d = dist_ee(a)) != null ? d : {};
    if (!(a && n !== 's')) return `https://image.${e}/${t}/storyboard.vtt${base_ye({ token: a, format: 'webp', program_start_time: i, program_end_time: r })}`;
   },
   base_z = (t) => {
    if (t) {
     if ([dist_.LIVE, dist_.ON_DEMAND].includes(t)) return t;
     if (t != null && t.includes('live')) return dist_.LIVE;
    }
   };
  var base_Ht = { crossorigin: 'crossOrigin', playsinline: 'playsInline' };
  function base_ot(t) {
   var a;
   return (a = base_Ht[t]) != null ? a : base_oe(t);
  }
  var dist_base_P,
   base_D,
   dist_base_v,
   base_ne = class {
    constructor(a, e) {
     base_T(this, dist_base_P);
     base_T(this, base_D);
     base_T(this, dist_base_v, []);
     dist_base_C(this, dist_base_P, a), dist_base_C(this, base_D, e);
    }
    [Symbol.iterator]() {
     return dist_base_u(this, dist_base_v).values();
    }
    get length() {
     return dist_base_u(this, dist_base_v).length;
    }
    get value() {
     var a;
     return (a = dist_base_u(this, dist_base_v).join(' ')) != null ? a : '';
    }
    set value(a) {
     var e;
     a !== this.value && (dist_base_C(this, dist_base_v, []), this.add(...((e = a == null ? void 0 : a.split(' ')) != null ? e : [])));
    }
    toString() {
     return this.value;
    }
    item(a) {
     return dist_base_u(this, dist_base_v)[a];
    }
    values() {
     return dist_base_u(this, dist_base_v).values();
    }
    keys() {
     return dist_base_u(this, dist_base_v).keys();
    }
    forEach(a) {
     dist_base_u(this, dist_base_v).forEach(a);
    }
    add(...a) {
     var e, i;
     a.forEach((r) => {
      this.contains(r) || dist_base_u(this, dist_base_v).push(r);
     }),
      !(this.value === '' && !((e = dist_base_u(this, dist_base_P)) != null && e.hasAttribute(`${dist_base_u(this, base_D)}`))) && ((i = dist_base_u(this, dist_base_P)) == null || i.setAttribute(`${dist_base_u(this, base_D)}`, `${this.value}`));
    }
    remove(...a) {
     var e;
     a.forEach((i) => {
      dist_base_u(this, dist_base_v).splice(dist_base_u(this, dist_base_v).indexOf(i), 1);
     }),
      (e = dist_base_u(this, dist_base_P)) == null || e.setAttribute(`${dist_base_u(this, base_D)}`, `${this.value}`);
    }
    contains(a) {
     return dist_base_u(this, dist_base_v).includes(a);
    }
    toggle(a, e) {
     return typeof e != 'undefined' ? (e ? (this.add(a), !0) : (this.remove(a), !1)) : this.contains(a) ? (this.remove(a), !1) : (this.add(a), !0);
    }
    replace(a, e) {
     this.remove(a), this.add(e);
    }
   };
  (dist_base_P = new WeakMap()), (base_D = new WeakMap()), (dist_base_v = new WeakMap());
  var base_nt = `[mux-player ${base_se()}]`;
  function dist_base_x(...t) {
   console.warn(base_nt, ...t);
  }
  function E(...t) {
   console.error(base_nt, ...t);
  }
  function base_Ee(t) {
   var e;
   let a = (e = t.message) != null ? e : '';
   t.context && (a += ` ${t.context}`),
    t.file &&
     (a += ` ${x('Read more: ')}
https://github.com/muxinc/elements/blob/main/errors/${t.file}`),
    dist_base_x(a);
  }
  var dist_base_g = { AUTOPLAY: 'autoplay', CROSSORIGIN: 'crossorigin', LOOP: 'loop', MUTED: 'muted', PLAYSINLINE: 'playsinline', PRELOAD: 'preload' },
   base_N = { VOLUME: 'volume', PLAYBACKRATE: 'playbackrate', MUTED: 'muted' },
   Va = { ...dist_base_g, ...base_N },
   base_dt = Object.freeze({
    length: 0,
    start(t) {
     let a = t >>> 0;
     if (a >= this.length) throw new DOMException(`Failed to execute 'start' on 'TimeRanges': The index provided (${a}) is greater than or equal to the maximum bound (${this.length}).`);
     return 0;
    },
    end(t) {
     let a = t >>> 0;
     if (a >= this.length) throw new DOMException(`Failed to execute 'end' on 'TimeRanges': The index provided (${a}) is greater than or equal to the maximum bound (${this.length}).`);
     return 0;
    },
   }),
   base_$t = Object.values(dist_base_g).filter((t) => dist_base_g.PLAYSINLINE !== t),
   base_Yt = Object.values(base_N),
   base_Ft = [...base_$t, ...base_Yt],
   base_Ae = class extends base_k.HTMLElement {
    static get observedAttributes() {
     return base_Ft;
    }
    constructor() {
     super();
    }
    attributeChangedCallback(a, e, i) {
     var r, n;
     switch (a) {
      case base_N.MUTED: {
       this.media && ((this.media.muted = i != null), (this.media.defaultMuted = i != null));
       return;
      }
      case base_N.VOLUME: {
       let d = (r = base_y(i)) != null ? r : 1;
       this.media && (this.media.volume = d);
       return;
      }
      case base_N.PLAYBACKRATE: {
       let d = (n = base_y(i)) != null ? n : 1;
       this.media && ((this.media.playbackRate = d), (this.media.defaultPlaybackRate = d));
       return;
      }
     }
    }
    play() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.play()) != null ? e : Promise.reject();
    }
    pause() {
     var a;
     (a = this.media) == null || a.pause();
    }
    load() {
     var a;
     (a = this.media) == null || a.load();
    }
    get media() {
     var a;
     return (a = this.shadowRoot) == null ? void 0 : a.querySelector('mux-video');
    }
    get audioTracks() {
     return this.media.audioTracks;
    }
    get videoTracks() {
     return this.media.videoTracks;
    }
    get audioRenditions() {
     return this.media.audioRenditions;
    }
    get videoRenditions() {
     return this.media.videoRenditions;
    }
    get paused() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.paused) != null ? e : !0;
    }
    get duration() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.duration) != null ? e : NaN;
    }
    get ended() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.ended) != null ? e : !1;
    }
    get buffered() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.buffered) != null ? e : base_dt;
    }
    get seekable() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.seekable) != null ? e : base_dt;
    }
    get readyState() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.readyState) != null ? e : 0;
    }
    get videoWidth() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.videoWidth) != null ? e : 0;
    }
    get videoHeight() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.videoHeight) != null ? e : 0;
    }
    get currentSrc() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.currentSrc) != null ? e : '';
    }
    get currentTime() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.currentTime) != null ? e : 0;
    }
    set currentTime(a) {
     this.media && (this.media.currentTime = Number(a));
    }
    get volume() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.volume) != null ? e : 1;
    }
    set volume(a) {
     this.media && (this.media.volume = Number(a));
    }
    get playbackRate() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.playbackRate) != null ? e : 1;
    }
    set playbackRate(a) {
     this.media && (this.media.playbackRate = Number(a));
    }
    get defaultPlaybackRate() {
     var a;
     return (a = base_y(this.getAttribute(base_N.PLAYBACKRATE))) != null ? a : 1;
    }
    set defaultPlaybackRate(a) {
     a != null ? this.setAttribute(base_N.PLAYBACKRATE, `${a}`) : this.removeAttribute(base_N.PLAYBACKRATE);
    }
    get crossOrigin() {
     return base_X(this, dist_base_g.CROSSORIGIN);
    }
    set crossOrigin(a) {
     this.setAttribute(dist_base_g.CROSSORIGIN, `${a}`);
    }
    get autoplay() {
     return base_X(this, dist_base_g.AUTOPLAY) != null;
    }
    set autoplay(a) {
     a ? this.setAttribute(dist_base_g.AUTOPLAY, typeof a == 'string' ? a : '') : this.removeAttribute(dist_base_g.AUTOPLAY);
    }
    get loop() {
     return base_X(this, dist_base_g.LOOP) != null;
    }
    set loop(a) {
     a ? this.setAttribute(dist_base_g.LOOP, '') : this.removeAttribute(dist_base_g.LOOP);
    }
    get muted() {
     var a, e;
     return (e = (a = this.media) == null ? void 0 : a.muted) != null ? e : !1;
    }
    set muted(a) {
     this.media && (this.media.muted = !!a);
    }
    get defaultMuted() {
     return base_X(this, dist_base_g.MUTED) != null;
    }
    set defaultMuted(a) {
     a ? this.setAttribute(dist_base_g.MUTED, '') : this.removeAttribute(dist_base_g.MUTED);
    }
    get playsInline() {
     return base_X(this, dist_base_g.PLAYSINLINE) != null;
    }
    set playsInline(a) {
     E('playsInline is set to true by default and is not currently supported as a setter.');
    }
    get preload() {
     return this.media ? this.media.preload : this.getAttribute('preload');
    }
    set preload(a) {
     ['', 'none', 'metadata', 'auto'].includes(a) ? this.setAttribute(dist_base_g.PRELOAD, a) : this.removeAttribute(dist_base_g.PRELOAD);
    }
   };
  function base_X(t, a) {
   return t.media ? t.media.getAttribute(a) : t.getAttribute(a);
  }
  var base_Ce = base_Ae;
  var base_lt = `:host {
  --media-control-display: var(--controls);
  --media-loading-indicator-display: var(--loading-indicator);
  --media-dialog-display: var(--dialog);
  --media-play-button-display: var(--play-button);
  --media-live-button-display: var(--live-button);
  --media-seek-backward-button-display: var(--seek-backward-button);
  --media-seek-forward-button-display: var(--seek-forward-button);
  --media-mute-button-display: var(--mute-button);
  --media-captions-button-display: var(--captions-button);
  --media-captions-menu-button-display: var(--captions-menu-button, var(--media-captions-button-display));
  --media-rendition-menu-button-display: var(--rendition-menu-button);
  --media-audio-track-menu-button-display: var(--audio-track-menu-button);
  --media-airplay-button-display: var(--airplay-button);
  --media-pip-button-display: var(--pip-button);
  --media-fullscreen-button-display: var(--fullscreen-button);
  --media-cast-button-display: var(--cast-button, var(--_cast-button-drm-display));
  --media-playback-rate-button-display: var(--playback-rate-button);
  --media-playback-rate-menu-button-display: var(--playback-rate-menu-button);
  --media-volume-range-display: var(--volume-range);
  --media-time-range-display: var(--time-range);
  --media-time-display-display: var(--time-display);
  --media-duration-display-display: var(--duration-display);
  --media-title-display-display: var(--title-display);

  display: inline-block;
  line-height: 0;
  width: 100%;
}

a {
  color: #fff;
  font-size: 0.9em;
  text-decoration: underline;
}

media-theme {
  display: inline-block;
  line-height: 0;
  width: 100%;
  height: 100%;
  direction: ltr;
}

media-poster-image {
  display: inline-block;
  line-height: 0;
  width: 100%;
  height: 100%;
}

media-poster-image:not([src]):not([placeholdersrc]) {
  display: none;
}

::part(top),
[part~='top'] {
  --media-control-display: var(--controls, var(--top-controls));
  --media-play-button-display: var(--play-button, var(--top-play-button));
  --media-live-button-display: var(--live-button, var(--top-live-button));
  --media-seek-backward-button-display: var(--seek-backward-button, var(--top-seek-backward-button));
  --media-seek-forward-button-display: var(--seek-forward-button, var(--top-seek-forward-button));
  --media-mute-button-display: var(--mute-button, var(--top-mute-button));
  --media-captions-button-display: var(--captions-button, var(--top-captions-button));
  --media-captions-menu-button-display: var(
    --captions-menu-button,
    var(--media-captions-button-display, var(--top-captions-menu-button))
  );
  --media-rendition-menu-button-display: var(--rendition-menu-button, var(--top-rendition-menu-button));
  --media-audio-track-menu-button-display: var(--audio-track-menu-button, var(--top-audio-track-menu-button));
  --media-airplay-button-display: var(--airplay-button, var(--top-airplay-button));
  --media-pip-button-display: var(--pip-button, var(--top-pip-button));
  --media-fullscreen-button-display: var(--fullscreen-button, var(--top-fullscreen-button));
  --media-cast-button-display: var(--cast-button, var(--top-cast-button, var(--_cast-button-drm-display)));
  --media-playback-rate-button-display: var(--playback-rate-button, var(--top-playback-rate-button));
  --media-playback-rate-menu-button-display: var(
    --captions-menu-button,
    var(--media-playback-rate-button-display, var(--top-playback-rate-menu-button))
  );
  --media-volume-range-display: var(--volume-range, var(--top-volume-range));
  --media-time-range-display: var(--time-range, var(--top-time-range));
  --media-time-display-display: var(--time-display, var(--top-time-display));
  --media-duration-display-display: var(--duration-display, var(--top-duration-display));
  --media-title-display-display: var(--title-display, var(--top-title-display));
}

::part(center),
[part~='center'] {
  --media-control-display: var(--controls, var(--center-controls));
  --media-play-button-display: var(--play-button, var(--center-play-button));
  --media-live-button-display: var(--live-button, var(--center-live-button));
  --media-seek-backward-button-display: var(--seek-backward-button, var(--center-seek-backward-button));
  --media-seek-forward-button-display: var(--seek-forward-button, var(--center-seek-forward-button));
  --media-mute-button-display: var(--mute-button, var(--center-mute-button));
  --media-captions-button-display: var(--captions-button, var(--center-captions-button));
  --media-captions-menu-button-display: var(
    --captions-menu-button,
    var(--media-captions-button-display, var(--center-captions-menu-button))
  );
  --media-rendition-menu-button-display: var(--rendition-menu-button, var(--center-rendition-menu-button));
  --media-audio-track-menu-button-display: var(--audio-track-menu-button, var(--center-audio-track-menu-button));
  --media-airplay-button-display: var(--airplay-button, var(--center-airplay-button));
  --media-pip-button-display: var(--pip-button, var(--center-pip-button));
  --media-fullscreen-button-display: var(--fullscreen-button, var(--center-fullscreen-button));
  --media-cast-button-display: var(--cast-button, var(--center-cast-button, var(--_cast-button-drm-display)));
  --media-playback-rate-button-display: var(--playback-rate-button, var(--center-playback-rate-button));
  --media-playback-rate-menu-button-display: var(
    --playback-rate-menu-button,
    var(--media-playback-rate-button-display, var(--center-playback-rate-menu-button))
  );
  --media-volume-range-display: var(--volume-range, var(--center-volume-range));
  --media-time-range-display: var(--time-range, var(--center-time-range));
  --media-time-display-display: var(--time-display, var(--center-time-display));
  --media-duration-display-display: var(--duration-display, var(--center-duration-display));
}

::part(bottom),
[part~='bottom'] {
  --media-control-display: var(--controls, var(--bottom-controls));
  --media-play-button-display: var(--play-button, var(--bottom-play-button));
  --media-live-button-display: var(--live-button, var(--bottom-live-button));
  --media-seek-backward-button-display: var(--seek-backward-button, var(--bottom-seek-backward-button));
  --media-seek-forward-button-display: var(--seek-forward-button, var(--bottom-seek-forward-button));
  --media-mute-button-display: var(--mute-button, var(--bottom-mute-button));
  --media-captions-button-display: var(--captions-button, var(--bottom-captions-button));
  --media-captions-menu-button-display: var(
    --captions-menu-button,
    var(--media-captions-button-display, var(--bottom-captions-menu-button))
  );
  --media-rendition-menu-button-display: var(--rendition-menu-button, var(--bottom-rendition-menu-button));
  --media-audio-track-menu-button-display: var(--audio-track-menu-button, var(--bottom-audio-track-menu-button));
  --media-airplay-button-display: var(--airplay-button, var(--bottom-airplay-button));
  --media-pip-button-display: var(--pip-button, var(--bottom-pip-button));
  --media-fullscreen-button-display: var(--fullscreen-button, var(--bottom-fullscreen-button));
  --media-cast-button-display: var(--cast-button, var(--bottom-cast-button, var(--_cast-button-drm-display)));
  --media-playback-rate-button-display: var(--playback-rate-button, var(--bottom-playback-rate-button));
  --media-playback-rate-menu-button-display: var(
    --playback-rate-menu-button,
    var(--media-playback-rate-button-display, var(--bottom-playback-rate-menu-button))
  );
  --media-volume-range-display: var(--volume-range, var(--bottom-volume-range));
  --media-time-range-display: var(--time-range, var(--bottom-time-range));
  --media-time-display-display: var(--time-display, var(--bottom-time-display));
  --media-duration-display-display: var(--duration-display, var(--bottom-duration-display));
  --media-title-display-display: var(--title-display, var(--bottom-title-display));
}

:host([no-tooltips]) {
  --media-tooltip-display: none;
}
`;
  var base_q = new WeakMap(),
   dist_base_e = class t {
    constructor(a, e) {
     this.element = a;
     this.type = e;
     this.element.addEventListener(this.type, this);
     let i = base_q.get(this.element);
     i && i.set(this.type, this);
    }
    set(a) {
     if (typeof a == 'function') this.handleEvent = a.bind(this.element);
     else if (typeof a == 'object' && typeof a.handleEvent == 'function') this.handleEvent = a.handleEvent.bind(a);
     else {
      this.element.removeEventListener(this.type, this);
      let e = base_q.get(this.element);
      e && e.delete(this.type);
     }
    }
    static for(a) {
     base_q.has(a.element) || base_q.set(a.element, new Map());
     let e = a.attributeName.slice(2),
      i = base_q.get(a.element);
     return i && i.has(e) ? i.get(e) : new t(a.element, e);
    }
   };
  function base_Gt(t, a) {
   return t instanceof AttrPart && t.attributeName.startsWith('on') ? (dist_base_e.for(t).set(a), t.element.removeAttributeNS(t.attributeNamespace, t.attributeName), !0) : !1;
  }
  function base_jt(t, a) {
   return a instanceof base_de && t instanceof ChildNodePart ? (a.renderInto(t), !0) : !1;
  }
  function base_zt(t, a) {
   return a instanceof DocumentFragment && t instanceof ChildNodePart ? (a.childNodes.length && t.replace(...a.childNodes), !0) : !1;
  }
  function base_Xt(t, a) {
   if (t instanceof AttrPart) {
    let e = t.attributeNamespace,
     i = t.element.getAttributeNS(e, t.attributeName);
    return String(a) !== i && (t.value = String(a)), !0;
   }
   return (t.value = String(a)), !0;
  }
  function base_qt(t, a) {
   if (t instanceof AttrPart && a instanceof Element) {
    let e = t.element;
    return e[t.attributeName] !== a && (t.element.removeAttributeNS(t.attributeNamespace, t.attributeName), (e[t.attributeName] = a)), !0;
   }
   return !1;
  }
  function base_Qt(t, a) {
   if (typeof a == 'boolean' && t instanceof AttrPart) {
    let e = t.attributeNamespace,
     i = t.element.hasAttributeNS(e, t.attributeName);
    return a !== i && (t.booleanValue = a), !0;
   }
   return !1;
  }
  function base_Jt(t, a) {
   return a === !1 && t instanceof ChildNodePart ? (t.replace(''), !0) : !1;
  }
  function base_ea(t, a) {
   base_qt(t, a) || base_Qt(t, a) || base_Gt(t, a) || base_Jt(t, a) || base_jt(t, a) || base_zt(t, a) || base_Xt(t, a);
  }
  var base_ke = new Map(),
   base_ut = new WeakMap(),
   base_mt = new WeakMap(),
   base_de = class {
    constructor(a, e, i) {
     this.strings = a;
     this.values = e;
     this.processor = i;
     this.stringsKey = this.strings.join('');
    }
    get template() {
     if (base_ke.has(this.stringsKey)) return base_ke.get(this.stringsKey);
     {
      let a = dist_base_Y.createElement('template'),
       e = this.strings.length - 1;
      return (a.innerHTML = this.strings.reduce((i, r, n) => i + r + (n < e ? `{{ ${n} }}` : ''), '')), base_ke.set(this.stringsKey, a), a;
     }
    }
    renderInto(a) {
     var r;
     let e = this.template;
     if (base_ut.get(a) !== e) {
      base_ut.set(a, e);
      let n = new TemplateInstance(e, this.values, this.processor);
      base_mt.set(a, n), a instanceof ChildNodePart ? a.replace(...n.children) : a.appendChild(n);
      return;
     }
     let i = base_mt.get(a);
     (r = i == null ? void 0 : i.update) == null || r.call(i, this.values);
    }
   },
   base_ta = {
    processCallback(t, a, e) {
     var i;
     if (e) {
      for (let [r, n] of a)
       if (r in e) {
        let d = (i = e[r]) != null ? i : '';
        base_ea(n, d);
       }
     }
    },
   };
  function base_Q(t, ...a) {
   return new base_de(t, a, base_ta);
  }
  function base_ct(t, a) {
   t.renderInto(a);
  }
  var base_ia = (t) => {
    let { tokens: a } = t;
    return a.drm ? ':host(:not([cast-receiver])) { --_cast-button-drm-display: none; }' : '';
   },
   base_bt = (t) => base_Q`
  <style>
    ${base_ia(t)}
    ${base_lt}
  </style>
  ${base_sa(t)}
`,
   base_ra = (t) => {
    let a = t.hotKeys ? `${t.hotKeys}` : '';
    return base_z(t.streamType) === 'live' && (a += ' noarrowleft noarrowright'), a;
   },
   base_oa = { TOP: 'top', CENTER: 'center', BOTTOM: 'bottom', LAYER: 'layer', MEDIA_LAYER: 'media-layer', POSTER_LAYER: 'poster-layer', VERTICAL_LAYER: 'vertical-layer', CENTERED_LAYER: 'centered-layer', GESTURE_LAYER: 'gesture-layer', CONTROLLER_LAYER: 'controller', BUTTON: 'button', RANGE: 'range', DISPLAY: 'display', CONTROL_BAR: 'control-bar', MENU_BUTTON: 'menu-button', MENU: 'menu', OPTION: 'option', POSTER: 'poster', LIVE: 'live', PLAY: 'play', PRE_PLAY: 'pre-play', SEEK_BACKWARD: 'seek-backward', SEEK_FORWARD: 'seek-forward', MUTE: 'mute', CAPTIONS: 'captions', AIRPLAY: 'airplay', PIP: 'pip', FULLSCREEN: 'fullscreen', CAST: 'cast', PLAYBACK_RATE: 'playback-rate', VOLUME: 'volume', TIME: 'time', TITLE: 'title', AUDIO_TRACK: 'audio-track', RENDITION: 'rendition' },
   base_na = Object.values(base_oa).join(', '),
   base_sa = (t) => {
    var a, e, i, r, n, d, l, b, S, F, _, A, R, K, h, ie, W, Z, Ie, Pe, De, Ue, Ve, Be, He, Ke, $e, Ye, Fe, We, Ze, Ge, je, ze, Xe;
    return base_Q`
  <media-theme
    template="${t.themeTemplate || !1}"
    defaultstreamtype="${(a = t.defaultStreamType) != null ? a : !1}"
    hotkeys="${base_ra(t) || !1}"
    nohotkeys="${t.noHotKeys || !t.hasSrc || !1}"
    noautoseektolive="${!!((e = t.streamType) != null && e.includes(dist_.LIVE)) && t.targetLiveWindow !== 0}"
    novolumepref="${t.novolumepref || !1}"
    disabled="${!t.hasSrc || t.isDialogOpen}"
    audio="${(i = t.audio) != null ? i : !1}"
    style="${(r = base_et({ '--media-primary-color': t.primaryColor, '--media-secondary-color': t.secondaryColor, '--media-accent-color': t.accentColor })) != null ? r : !1}"
    defaultsubtitles="${!t.defaultHiddenCaptions}"
    forwardseekoffset="${(n = t.forwardSeekOffset) != null ? n : !1}"
    backwardseekoffset="${(d = t.backwardSeekOffset) != null ? d : !1}"
    playbackrates="${(l = t.playbackRates) != null ? l : !1}"
    defaultshowremainingtime="${(b = t.defaultShowRemainingTime) != null ? b : !1}"
    defaultduration="${(S = t.defaultDuration) != null ? S : !1}"
    hideduration="${(F = t.hideDuration) != null ? F : !1}"
    title="${(_ = t.title) != null ? _ : !1}"
    videotitle="${(A = t.videoTitle) != null ? A : !1}"
    proudlydisplaymuxbadge="${(R = t.proudlyDisplayMuxBadge) != null ? R : !1}"
    exportparts="${base_na}"
    onclose="${t.onCloseErrorDialog}"
    onfocusin="${t.onFocusInErrorDialog}"
  >
    <mux-video
      slot="media"
      target-live-window="${(K = t.targetLiveWindow) != null ? K : !1}"
      stream-type="${(h = base_z(t.streamType)) != null ? h : !1}"
      crossorigin="${(ie = t.crossOrigin) != null ? ie : ''}"
      playsinline
      autoplay="${(W = t.autoplay) != null ? W : !1}"
      muted="${(Z = t.muted) != null ? Z : !1}"
      loop="${(Ie = t.loop) != null ? Ie : !1}"
      preload="${(Pe = t.preload) != null ? Pe : !1}"
      debug="${(De = t.debug) != null ? De : !1}"
      prefer-cmcd="${(Ue = t.preferCmcd) != null ? Ue : !1}"
      disable-tracking="${(Ve = t.disableTracking) != null ? Ve : !1}"
      disable-cookies="${(Be = t.disableCookies) != null ? Be : !1}"
      prefer-playback="${(He = t.preferPlayback) != null ? He : !1}"
      start-time="${t.startTime != null ? t.startTime : !1}"
      beacon-collection-domain="${(Ke = t.beaconCollectionDomain) != null ? Ke : !1}"
      player-init-time="${($e = t.playerInitTime) != null ? $e : !1}"
      player-software-name="${(Ye = t.playerSoftwareName) != null ? Ye : !1}"
      player-software-version="${(Fe = t.playerSoftwareVersion) != null ? Fe : !1}"
      env-key="${(We = t.envKey) != null ? We : !1}"
      custom-domain="${(Ze = t.customDomain) != null ? Ze : !1}"
      src="${t.src ? t.src : t.playbackId ? Yr(t) : !1}"
      cast-src="${t.src ? t.src : t.playbackId ? Yr(t) : !1}"
      cast-receiver="${(Ge = t.castReceiver) != null ? Ge : !1}"
      drm-token="${(ze = (je = t.tokens) == null ? void 0 : je.drm) != null ? ze : !1}"
      exportparts="video"
    >
      ${t.storyboard ? base_Q`<track label="thumbnails" default kind="metadata" src="${t.storyboard}" />` : base_Q``}
      <slot></slot>
    </mux-video>
    <slot name="poster" slot="poster">
      <media-poster-image
        part="poster"
        exportparts="poster, img"
        src="${t.poster ? t.poster : !1}"
        placeholdersrc="${(Xe = t.placeholder) != null ? Xe : !1}"
      ></media-poster-image>
    </slot>
  </media-theme>
`;
   };
  var base_ft = (t) => t.charAt(0).toUpperCase() + t.slice(1),
   base_da = (t, a = !1) => {
    var e, i;
    if (t.muxCode) {
     let r = base_ft((e = t.errorCategory) != null ? e : 'video'),
      n = dist_V((i = t.errorCategory) != null ? i : dist_C.VIDEO);
     if (t.muxCode === dist_D.NETWORK_OFFLINE) return x('Your device appears to be offline', a);
     if (t.muxCode === dist_D.NETWORK_TOKEN_EXPIRED) return x('{category} URL has expired', a).format({ category: r });
     if ([dist_D.NETWORK_TOKEN_SUB_MISMATCH, dist_D.NETWORK_TOKEN_AUD_MISMATCH, dist_D.NETWORK_TOKEN_AUD_MISSING, dist_D.NETWORK_TOKEN_MALFORMED].includes(t.muxCode)) return x('{category} URL is formatted incorrectly', a).format({ category: r });
     if (t.muxCode === dist_D.NETWORK_TOKEN_MISSING) return x('Invalid {categoryName} URL', a).format({ categoryName: n });
     if (t.muxCode === dist_D.NETWORK_NOT_FOUND) return x('{category} does not exist', a).format({ category: r });
     if (t.muxCode === dist_D.NETWORK_NOT_READY) {
      let d = t.streamType === 'live' ? 'Live stream' : 'Video';
      return x('{mediaType} is not currently available', a).format({ mediaType: d });
     }
    }
    if (t.code) {
     if (t.code === f.MEDIA_ERR_NETWORK) return x('Network Error', a);
     if (t.code === f.MEDIA_ERR_DECODE) return x('Media Error', a);
     if (t.code === f.MEDIA_ERR_SRC_NOT_SUPPORTED) return x('Source Not Supported', a);
    }
    return x('Error', a);
   },
   base_la = (t, a = !1) => {
    var e, i;
    if (t.muxCode) {
     let r = base_ft((e = t.errorCategory) != null ? e : 'video'),
      n = dist_V((i = t.errorCategory) != null ? i : dist_C.VIDEO);
     return t.muxCode === dist_D.NETWORK_OFFLINE ? x('Check your internet connection and try reloading this video.', a) : t.muxCode === dist_D.NETWORK_TOKEN_EXPIRED ? x('The video\u2019s secured {tokenNamePrefix}-token has expired.', a).format({ tokenNamePrefix: n }) : t.muxCode === dist_D.NETWORK_TOKEN_SUB_MISMATCH ? x('The video\u2019s playback ID does not match the one encoded in the {tokenNamePrefix}-token.', a).format({ tokenNamePrefix: n }) : t.muxCode === dist_D.NETWORK_TOKEN_MALFORMED ? x('{category} URL is formatted incorrectly', a).format({ category: r }) : [dist_D.NETWORK_TOKEN_AUD_MISMATCH, dist_D.NETWORK_TOKEN_AUD_MISSING].includes(t.muxCode) ? x('The {tokenNamePrefix}-token is formatted with incorrect information.', a).format({ tokenNamePrefix: n }) : [dist_D.NETWORK_TOKEN_MISSING, dist_D.NETWORK_INVALID_URL].includes(t.muxCode) ? x('The video URL or {tokenNamePrefix}-token are formatted with incorrect or incomplete information.', a).format({ tokenNamePrefix: n }) : t.muxCode === dist_D.NETWORK_NOT_FOUND ? '' : t.message;
    }
    return t.code && (t.code === f.MEDIA_ERR_NETWORK || t.code === f.MEDIA_ERR_DECODE || t.code === f.MEDIA_ERR_SRC_NOT_SUPPORTED), t.message;
   },
   base_yt = (t, a = !1) => {
    let e = base_da(t, a).toString(),
     i = base_la(t, a).toString();
    return { title: e, message: i };
   },
   base_ua = (t) => {
    if (t.muxCode) {
     if (t.muxCode === dist_D.NETWORK_TOKEN_EXPIRED) return '403-expired-token.md';
     if (t.muxCode === dist_D.NETWORK_TOKEN_MALFORMED) return '403-malformatted-token.md';
     if ([dist_D.NETWORK_TOKEN_AUD_MISMATCH, dist_D.NETWORK_TOKEN_AUD_MISSING].includes(t.muxCode)) return '403-incorrect-aud-value.md';
     if (t.muxCode === dist_D.NETWORK_TOKEN_SUB_MISMATCH) return '403-playback-id-mismatch.md';
     if (t.muxCode === dist_D.NETWORK_TOKEN_MISSING) return 'missing-signed-tokens.md';
     if (t.muxCode === dist_D.NETWORK_NOT_FOUND) return '404-not-found.md';
     if (t.muxCode === dist_D.NETWORK_NOT_READY) return '412-not-playable.md';
    }
    if (t.code) {
     if (t.code === f.MEDIA_ERR_NETWORK) return '';
     if (t.code === f.MEDIA_ERR_DECODE) return 'media-decode-error.md';
     if (t.code === f.MEDIA_ERR_SRC_NOT_SUPPORTED) return 'media-src-not-supported.md';
    }
    return '';
   },
   base_Re = (t, a) => {
    let e = base_ua(t);
    return { message: t.message, context: t.context, file: e };
   };
  var base_vt = `<template id="media-theme-gerwig">
  <style>
    @keyframes pre-play-hide {
      0% {
        transform: scale(1);
        opacity: 1;
      }

      30% {
        transform: scale(0.7);
      }

      100% {
        transform: scale(1.5);
        opacity: 0;
      }
    }

    :host {
      --_primary-color: var(--media-primary-color, #fff);
      --_secondary-color: var(--media-secondary-color, transparent);
      --_accent-color: var(--media-accent-color, #fa50b5);
      --_text-color: var(--media-text-color, #000);

      --media-icon-color: var(--_primary-color);
      --media-control-background: var(--_secondary-color);
      --media-control-hover-background: var(--_accent-color);
      --media-time-buffered-color: rgba(255, 255, 255, 0.4);
      --media-preview-time-text-shadow: none;
      --media-control-height: 14px;
      --media-control-padding: 6px;
      --media-tooltip-container-margin: 6px;
      --media-tooltip-distance: 18px;

      color: var(--_primary-color);
      display: inline-block;
      width: 100%;
      height: 100%;
    }

    :host([audio]) {
      --_secondary-color: var(--media-secondary-color, black);
      --media-preview-time-text-shadow: none;
    }

    :host([audio]) ::slotted([slot='media']) {
      height: 0px;
    }

    :host([audio]) media-loading-indicator {
      display: none;
    }

    :host([audio]) media-controller {
      background: transparent;
    }

    :host([audio]) media-controller::part(vertical-layer) {
      background: transparent;
    }

    :host([audio]) media-control-bar {
      width: 100%;
      background-color: var(--media-control-background);
    }

    /*
     * 0.433s is the transition duration for VTT Regions.
     * Borrowed here, so the captions don't move too fast.
     */
    media-controller {
      --media-webkit-text-track-transform: translateY(0) scale(0.98);
      --media-webkit-text-track-transition: transform 0.433s ease-out 0.3s;
    }
    media-controller:is([mediapaused], :not([userinactive])) {
      --media-webkit-text-track-transform: translateY(-50px) scale(0.98);
      --media-webkit-text-track-transition: transform 0.15s ease;
    }

    /*
     * CSS specific to iOS devices.
     * See: https://stackoverflow.com/questions/30102792/css-media-query-to-target-only-ios-devices/60220757#60220757
     */
    @supports (-webkit-touch-callout: none) {
      /* Disable subtitle adjusting for iOS Safari */
      media-controller[mediaisfullscreen] {
        --media-webkit-text-track-transform: unset;
        --media-webkit-text-track-transition: unset;
      }
    }

    media-time-range {
      --media-box-padding-left: 6px;
      --media-box-padding-right: 6px;
      --media-range-bar-color: var(--_accent-color);
      --media-time-range-buffered-color: var(--_primary-color);
      --media-range-track-color: transparent;
      --media-range-track-background: rgba(255, 255, 255, 0.4);
      --media-range-thumb-background: radial-gradient(
        circle,
        #000 0%,
        #000 25%,
        var(--_accent-color) 25%,
        var(--_accent-color)
      );
      --media-range-thumb-width: 12px;
      --media-range-thumb-height: 12px;
      --media-range-thumb-transform: scale(0);
      --media-range-thumb-transition: transform 0.3s;
      --media-range-thumb-opacity: 1;
      --media-preview-background: var(--_primary-color);
      --media-box-arrow-background: var(--_primary-color);
      --media-preview-thumbnail-border: 5px solid var(--_primary-color);
      --media-preview-border-radius: 5px;
      --media-text-color: var(--_text-color);
      --media-control-hover-background: transparent;
      --media-preview-chapter-text-shadow: none;
      color: var(--_accent-color);
      padding: 0 6px;
    }

    :host([audio]) media-time-range {
      --media-preview-time-padding: 1.5px 6px;
      --media-preview-box-margin: 0 0 -5px;
    }

    media-time-range:hover {
      --media-range-thumb-transform: scale(1);
    }

    media-preview-thumbnail {
      border-bottom-width: 0;
    }

    [part~='menu'] {
      border-radius: 2px;
      border: 1px solid rgba(0, 0, 0, 0.1);
      bottom: 50px;
      padding: 2.5px 10px;
    }

    [part~='menu']::part(indicator) {
      fill: var(--_accent-color);
    }

    [part~='menu']::part(menu-item) {
      box-sizing: border-box;
      display: flex;
      align-items: center;
      padding: 6px 10px;
      min-height: 34px;
    }

    [part~='menu']::part(checked) {
      font-weight: 700;
    }

    media-captions-menu,
    media-rendition-menu,
    media-audio-track-menu,
    media-playback-rate-menu {
      position: absolute; /* ensure they don't take up space in DOM on load */
      --media-menu-background: var(--_primary-color);
      --media-menu-item-checked-background: transparent;
      --media-text-color: var(--_text-color);
      --media-menu-item-hover-background: transparent;
      --media-menu-item-hover-outline: var(--_accent-color) solid 1px;
    }

    media-rendition-menu {
      min-width: 140px;
    }

    /* The icon is a circle so make it 16px high instead of 14px for more balance. */
    media-audio-track-menu-button {
      --media-control-padding: 5px;
      --media-control-height: 16px;
    }

    media-playback-rate-menu-button {
      --media-control-padding: 6px 3px;
      min-width: 4.4ch;
    }

    media-playback-rate-menu {
      --media-menu-flex-direction: row;
      --media-menu-item-checked-background: var(--_accent-color);
      --media-menu-item-checked-indicator-display: none;
      margin-right: 6px;
      padding: 0;
      --media-menu-gap: 0.25em;
    }

    media-playback-rate-menu[part~='menu']::part(menu-item) {
      padding: 6px 6px 6px 8px;
    }

    media-playback-rate-menu[part~='menu']::part(checked) {
      color: #fff;
    }

    :host(:not([audio])) media-time-range {
      /* Adding px is required here for calc() */
      --media-range-padding: 0px;
      background: transparent;
      z-index: 10;
      height: 10px;
      bottom: -3px;
      width: 100%;
    }

    media-control-bar :is([role='button'], [role='switch'], button) {
      line-height: 0;
    }

    media-control-bar :is([part*='button'], [part*='range'], [part*='display']) {
      border-radius: 3px;
    }

    .spacer {
      flex-grow: 1;
      background-color: var(--media-control-background, rgba(20, 20, 30, 0.7));
    }

    media-control-bar[slot~='top-chrome'] {
      min-height: 42px;
      pointer-events: none;
    }

    media-control-bar {
      --gradient-steps:
        hsl(0 0% 0% / 0) 0%, hsl(0 0% 0% / 0.013) 8.1%, hsl(0 0% 0% / 0.049) 15.5%, hsl(0 0% 0% / 0.104) 22.5%,
        hsl(0 0% 0% / 0.175) 29%, hsl(0 0% 0% / 0.259) 35.3%, hsl(0 0% 0% / 0.352) 41.2%, hsl(0 0% 0% / 0.45) 47.1%,
        hsl(0 0% 0% / 0.55) 52.9%, hsl(0 0% 0% / 0.648) 58.8%, hsl(0 0% 0% / 0.741) 64.7%, hsl(0 0% 0% / 0.825) 71%,
        hsl(0 0% 0% / 0.896) 77.5%, hsl(0 0% 0% / 0.951) 84.5%, hsl(0 0% 0% / 0.987) 91.9%, hsl(0 0% 0%) 100%;
    }

    :host([title]:not([audio])) media-control-bar[slot='top-chrome']::before {
      content: '';
      position: absolute;
      width: 100%;
      padding-bottom: min(100px, 25%);
      background: linear-gradient(to top, var(--gradient-steps));
      opacity: 0.8;
      pointer-events: none;
    }

    :host(:not([audio])) media-control-bar[part~='bottom']::before {
      content: '';
      position: absolute;
      width: 100%;
      bottom: 0;
      left: 0;
      padding-bottom: min(100px, 25%);
      background: linear-gradient(to bottom, var(--gradient-steps));
      opacity: 0.8;
      z-index: 1;
      pointer-events: none;
    }

    media-control-bar[part~='bottom'] > * {
      z-index: 20;
    }

    media-control-bar[part~='bottom'] {
      padding: 6px 6px;
    }

    media-control-bar[slot~='top-chrome'] > * {
      --media-control-background: transparent;
      --media-control-hover-background: transparent;
      position: relative;
    }

    media-controller::part(vertical-layer) {
      transition: background-color 1s;
    }

    media-controller:is([mediapaused], :not([userinactive]))::part(vertical-layer) {
      background-color: var(--controls-backdrop-color, var(--controls, transparent));
      transition: background-color 0.25s;
    }

    .center-controls {
      --media-button-icon-width: 100%;
      --media-button-icon-height: auto;
      --media-tooltip-display: none;
      pointer-events: none;
      width: 100%;
      display: flex;
      flex-flow: row;
      align-items: center;
      justify-content: center;
      filter: drop-shadow(0 0 2px rgb(0 0 0 / 0.25)) drop-shadow(0 0 6px rgb(0 0 0 / 0.25));
      paint-order: stroke;
      stroke: rgba(102, 102, 102, 1);
      stroke-width: 0.3px;
      text-shadow:
        0 0 2px rgb(0 0 0 / 0.25),
        0 0 6px rgb(0 0 0 / 0.25);
    }

    .center-controls media-play-button {
      --media-control-background: transparent;
      --media-control-hover-background: transparent;
      --media-control-padding: 0;
      width: 40px;
    }

    [breakpointsm] .center-controls media-play-button {
      width: 90px;
      height: 90px;
      border-radius: 50%;
      transition: background 0.4s;
      padding: 24px;
      --media-control-background: #000;
      --media-control-hover-background: var(--_accent-color);
    }

    .center-controls media-seek-backward-button,
    .center-controls media-seek-forward-button {
      --media-control-background: transparent;
      --media-control-hover-background: transparent;
      padding: 0;
      margin: 0 20px;
      width: max(33px, min(8%, 40px));
    }

    [breakpointsm]:not([audio]) .center-controls.pre-playback {
      display: grid;
      align-items: initial;
      justify-content: initial;
      height: 100%;
      overflow: hidden;
    }

    [breakpointsm]:not([audio]) .center-controls.pre-playback media-play-button {
      place-self: var(--_pre-playback-place, center);
      grid-area: 1 / 1;
      margin: 16px;
    }

    /* Show and hide controls or pre-playback state */

    [breakpointsm]:is([mediahasplayed], :not([mediapaused])):not([audio])
      .center-controls.pre-playback
      media-play-button {
      /* Using \`forwards\` would lead to a laggy UI after the animation got in the end state */
      animation: 0.3s linear pre-play-hide;
      opacity: 0;
      pointer-events: none;
    }

    .autoplay-unmute {
      --media-control-hover-background: transparent;
      width: 100%;
      display: flex;
      align-items: center;
      justify-content: center;
      filter: drop-shadow(0 0 2px rgb(0 0 0 / 0.25)) drop-shadow(0 0 6px rgb(0 0 0 / 0.25));
    }

    .autoplay-unmute-btn {
      --media-control-height: 16px;
      border-radius: 8px;
      background: #000;
      color: var(--_primary-color);
      display: flex;
      align-items: center;
      padding: 8px 16px;
      font-size: 18px;
      font-weight: 500;
      cursor: pointer;
    }

    .autoplay-unmute-btn:hover {
      background: var(--_accent-color);
    }

    [breakpointsm] .autoplay-unmute-btn {
      --media-control-height: 30px;
      padding: 14px 24px;
      font-size: 26px;
    }

    .autoplay-unmute-btn svg {
      margin: 0 6px 0 0;
    }

    [breakpointsm] .autoplay-unmute-btn svg {
      margin: 0 10px 0 0;
    }

    media-controller:not([audio]):not([mediahasplayed]) *:is(media-control-bar, media-time-range) {
      display: none;
    }

    media-error-dialog:not([mediaerrorcode]) {
      opacity: 0;
    }

    media-loading-indicator {
      --media-loading-icon-width: 100%;
      --media-button-icon-height: auto;
      display: var(--media-control-display, var(--media-loading-indicator-display, flex));
      pointer-events: none;
      position: absolute;
      width: min(15%, 150px);
      flex-flow: row;
      align-items: center;
      justify-content: center;
    }

    /* Intentionally don't target the div for transition but the children
     of the div. Prevents messing with media-chrome's autohide feature. */
    media-loading-indicator + div * {
      transition: opacity 0.15s;
      opacity: 1;
    }

    media-loading-indicator[medialoading]:not([mediapaused]) ~ div > * {
      opacity: 0;
      transition-delay: 400ms;
    }

    media-volume-range {
      width: min(100%, 100px);
      --media-range-padding-left: 10px;
      --media-range-padding-right: 10px;
      --media-range-thumb-width: 12px;
      --media-range-thumb-height: 12px;
      --media-range-thumb-background: radial-gradient(
        circle,
        #000 0%,
        #000 25%,
        var(--_primary-color) 25%,
        var(--_primary-color)
      );
      --media-control-hover-background: none;
    }

    media-time-display {
      white-space: nowrap;
    }

    /* Generic style for explicitly disabled controls */
    media-control-bar[part~='bottom'] [disabled],
    media-control-bar[part~='bottom'] [aria-disabled='true'] {
      opacity: 60%;
      cursor: not-allowed;
    }

    media-text-display {
      --media-font-size: 16px;
      --media-control-padding: 14px;
      font-weight: 500;
    }

    media-play-button.animated *:is(g, path) {
      transition: all 0.3s;
    }

    media-play-button.animated[mediapaused] .pause-icon-pt1 {
      opacity: 0;
    }

    media-play-button.animated[mediapaused] .pause-icon-pt2 {
      transform-origin: center center;
      transform: scaleY(0);
    }

    media-play-button.animated[mediapaused] .play-icon {
      clip-path: inset(0 0 0 0);
    }

    media-play-button.animated:not([mediapaused]) .play-icon {
      clip-path: inset(0 0 0 100%);
    }

    media-seek-forward-button,
    media-seek-backward-button {
      --media-font-weight: 400;
    }

    .mute-icon {
      display: inline-block;
    }

    .mute-icon :is(path, g) {
      transition: opacity 0.5s;
    }

    .muted {
      opacity: 0;
    }

    media-mute-button[mediavolumelevel='low'] :is(.volume-medium, .volume-high),
    media-mute-button[mediavolumelevel='medium'] :is(.volume-high) {
      opacity: 0;
    }

    media-mute-button[mediavolumelevel='off'] .unmuted {
      opacity: 0;
    }

    media-mute-button[mediavolumelevel='off'] .muted {
      opacity: 1;
    }

    /**
     * Our defaults for these buttons are to hide them at small sizes
     * users can override this with CSS
     */
    media-controller:not([breakpointsm]):not([audio]) {
      --bottom-play-button: none;
      --bottom-seek-backward-button: none;
      --bottom-seek-forward-button: none;
      --bottom-time-display: none;
      --bottom-playback-rate-menu-button: none;
      --bottom-pip-button: none;
    }

    [part='mux-badge'] {
      position: absolute;
      bottom: 10px;
      right: 10px;
      z-index: 2;
      opacity: 0.6;
      transition:
        opacity 0.2s ease-in-out,
        bottom 0.2s ease-in-out;
    }

    [part='mux-badge']:hover {
      opacity: 1;
    }

    [part='mux-badge'] a {
      font-size: 14px;
      font-family: var(--_font-family);
      color: var(--_primary-color);
      text-decoration: none;
      display: flex;
      align-items: center;
      gap: 5px;
    }

    [part='mux-badge'] .mux-badge-text {
      transition: opacity 0.5s ease-in-out;
      opacity: 0;
    }

    [part='mux-badge'] .mux-badge-logo {
      width: 40px;
      height: auto;
      display: inline-block;
    }

    [part='mux-badge'] .mux-badge-logo svg {
      width: 100%;
      height: 100%;
      fill: white;
    }

    media-controller:not([userinactive]):not([mediahasplayed]) [part='mux-badge'],
    media-controller:not([userinactive]) [part='mux-badge'],
    media-controller[mediahasplayed][mediapaused] [part='mux-badge'] {
      transition: bottom 0.1s ease-in-out;
    }

    media-controller[userinactive]:not([mediapaused]) [part='mux-badge'] {
      transition: bottom 0.2s ease-in-out 0.62s;
    }

    media-controller:not([userinactive]) [part='mux-badge'] .mux-badge-text,
    media-controller[mediahasplayed][mediapaused] [part='mux-badge'] .mux-badge-text {
      opacity: 1;
    }

    media-controller[userinactive]:not([mediapaused]) [part='mux-badge'] .mux-badge-text {
      opacity: 0;
    }

    media-controller[userinactive]:not([mediapaused]) [part='mux-badge'] {
      bottom: 10px;
    }

    media-controller:not([userinactive]):not([mediahasplayed]) [part='mux-badge'] {
      bottom: 10px;
    }

    media-controller:not([userinactive])[mediahasplayed] [part='mux-badge'],
    media-controller[mediahasplayed][mediapaused] [part='mux-badge'] {
      bottom: calc(28px + var(--media-control-height, 0px) + var(--media-control-padding, 0px) * 2);
    }
  </style>

  <template partial="TitleDisplay">
    <template if="videotitle">
      <template if="videotitle != true">
        <media-text-display part="top title display" class="title-display">{{videotitle}}</media-text-display>
      </template>
    </template>
    <template if="!videotitle">
      <template if="title">
        <media-text-display part="top title display" class="title-display">{{title}}</media-text-display>
      </template>
    </template>
  </template>

  <template partial="PlayButton">
    <media-play-button
      part="{{section ?? 'bottom'}} play button"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
      class="animated"
    >
      <svg aria-hidden="true" viewBox="0 0 18 14" slot="icon">
        <g class="play-icon">
          <path
            d="M15.5987 6.2911L3.45577 0.110898C2.83667 -0.204202 2.06287 0.189698 2.06287 0.819798V13.1802C2.06287 13.8103 2.83667 14.2042 3.45577 13.8891L15.5987 7.7089C16.2178 7.3938 16.2178 6.6061 15.5987 6.2911Z"
          />
        </g>
        <g class="pause-icon">
          <path
            class="pause-icon-pt1"
            d="M5.90709 0H2.96889C2.46857 0 2.06299 0.405585 2.06299 0.9059V13.0941C2.06299 13.5944 2.46857 14 2.96889 14H5.90709C6.4074 14 6.81299 13.5944 6.81299 13.0941V0.9059C6.81299 0.405585 6.4074 0 5.90709 0Z"
          />
          <path
            class="pause-icon-pt2"
            d="M15.1571 0H12.2189C11.7186 0 11.313 0.405585 11.313 0.9059V13.0941C11.313 13.5944 11.7186 14 12.2189 14H15.1571C15.6574 14 16.063 13.5944 16.063 13.0941V0.9059C16.063 0.405585 15.6574 0 15.1571 0Z"
          />
        </g>
      </svg>
    </media-play-button>
  </template>

  <template partial="PrePlayButton">
    <media-play-button
      part="{{section ?? 'center'}} play button pre-play"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
    >
      <svg aria-hidden="true" viewBox="0 0 18 14" slot="icon" style="transform: translate(3px, 0)">
        <path
          d="M15.5987 6.2911L3.45577 0.110898C2.83667 -0.204202 2.06287 0.189698 2.06287 0.819798V13.1802C2.06287 13.8103 2.83667 14.2042 3.45577 13.8891L15.5987 7.7089C16.2178 7.3938 16.2178 6.6061 15.5987 6.2911Z"
        />
      </svg>
    </media-play-button>
  </template>

  <template partial="SeekBackwardButton">
    <media-seek-backward-button
      seekoffset="{{backwardseekoffset}}"
      part="{{section ?? 'bottom'}} seek-backward button"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
    >
      <svg viewBox="0 0 22 14" aria-hidden="true" slot="icon">
        <path
          d="M3.65 2.07888L0.0864 6.7279C-0.0288 6.87812 -0.0288 7.12188 0.0864 7.2721L3.65 11.9211C3.7792 12.0896 4 11.9703 4 11.7321V2.26787C4 2.02968 3.7792 1.9104 3.65 2.07888Z"
        />
        <text transform="translate(6 12)" style="font-size: 14px; font-family: 'ArialMT', 'Arial'">
          {{backwardseekoffset}}
        </text>
      </svg>
    </media-seek-backward-button>
  </template>

  <template partial="SeekForwardButton">
    <media-seek-forward-button
      seekoffset="{{forwardseekoffset}}"
      part="{{section ?? 'bottom'}} seek-forward button"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
    >
      <svg viewBox="0 0 22 14" aria-hidden="true" slot="icon">
        <g>
          <text transform="translate(-1 12)" style="font-size: 14px; font-family: 'ArialMT', 'Arial'">
            {{forwardseekoffset}}
          </text>
          <path
            d="M18.35 11.9211L21.9136 7.2721C22.0288 7.12188 22.0288 6.87812 21.9136 6.7279L18.35 2.07888C18.2208 1.91041 18 2.02968 18 2.26787V11.7321C18 11.9703 18.2208 12.0896 18.35 11.9211Z"
          />
        </g>
      </svg>
    </media-seek-forward-button>
  </template>

  <template partial="MuteButton">
    <media-mute-button part="bottom mute button" disabled="{{disabled}}" aria-disabled="{{disabled}}">
      <svg viewBox="0 0 18 14" slot="icon" class="mute-icon" aria-hidden="true">
        <g class="unmuted">
          <path
            d="M6.76786 1.21233L3.98606 3.98924H1.19937C0.593146 3.98924 0.101743 4.51375 0.101743 5.1607V6.96412L0 6.99998L0.101743 7.03583V8.83926C0.101743 9.48633 0.593146 10.0108 1.19937 10.0108H3.98606L6.76773 12.7877C7.23561 13.2547 8 12.9007 8 12.2171V1.78301C8 1.09925 7.23574 0.745258 6.76786 1.21233Z"
          />
          <path
            class="volume-low"
            d="M10 3.54781C10.7452 4.55141 11.1393 5.74511 11.1393 6.99991C11.1393 8.25471 10.7453 9.44791 10 10.4515L10.7988 11.0496C11.6734 9.87201 12.1356 8.47161 12.1356 6.99991C12.1356 5.52821 11.6735 4.12731 10.7988 2.94971L10 3.54781Z"
          />
          <path
            class="volume-medium"
            d="M12.3778 2.40086C13.2709 3.76756 13.7428 5.35806 13.7428 7.00026C13.7428 8.64246 13.2709 10.233 12.3778 11.5992L13.2106 12.1484C14.2107 10.6185 14.739 8.83796 14.739 7.00016C14.739 5.16236 14.2107 3.38236 13.2106 1.85156L12.3778 2.40086Z"
          />
          <path
            class="volume-high"
            d="M15.5981 0.75L14.7478 1.2719C15.7937 2.9919 16.3468 4.9723 16.3468 7C16.3468 9.0277 15.7937 11.0082 14.7478 12.7281L15.5981 13.25C16.7398 11.3722 17.343 9.211 17.343 7C17.343 4.789 16.7398 2.6268 15.5981 0.75Z"
          />
        </g>
        <g class="muted">
          <path
            fill-rule="evenodd"
            clip-rule="evenodd"
            d="M4.39976 4.98924H1.19937C1.19429 4.98924 1.17777 4.98961 1.15296 5.01609C1.1271 5.04369 1.10174 5.09245 1.10174 5.1607V8.83926C1.10174 8.90761 1.12714 8.95641 1.15299 8.984C1.17779 9.01047 1.1943 9.01084 1.19937 9.01084H4.39977L7 11.6066V2.39357L4.39976 4.98924ZM7.47434 1.92006C7.4743 1.9201 7.47439 1.92002 7.47434 1.92006V1.92006ZM6.76773 12.7877L3.98606 10.0108H1.19937C0.593146 10.0108 0.101743 9.48633 0.101743 8.83926V7.03583L0 6.99998L0.101743 6.96412V5.1607C0.101743 4.51375 0.593146 3.98924 1.19937 3.98924H3.98606L6.76786 1.21233C7.23574 0.745258 8 1.09925 8 1.78301V12.2171C8 12.9007 7.23561 13.2547 6.76773 12.7877Z"
          />
          <path
            fill-rule="evenodd"
            clip-rule="evenodd"
            d="M15.2677 9.30323C15.463 9.49849 15.7796 9.49849 15.9749 9.30323C16.1701 9.10796 16.1701 8.79138 15.9749 8.59612L14.2071 6.82841L15.9749 5.06066C16.1702 4.8654 16.1702 4.54882 15.9749 4.35355C15.7796 4.15829 15.4631 4.15829 15.2678 4.35355L13.5 6.1213L11.7322 4.35348C11.537 4.15822 11.2204 4.15822 11.0251 4.35348C10.8298 4.54874 10.8298 4.86532 11.0251 5.06058L12.7929 6.82841L11.0251 8.59619C10.8299 8.79146 10.8299 9.10804 11.0251 9.3033C11.2204 9.49856 11.537 9.49856 11.7323 9.3033L13.5 7.53552L15.2677 9.30323Z"
          />
        </g>
      </svg>
    </media-mute-button>
  </template>

  <template partial="PipButton">
    <media-pip-button part="bottom pip button" disabled="{{disabled}}" aria-disabled="{{disabled}}">
      <svg viewBox="0 0 18 14" aria-hidden="true" slot="icon">
        <path
          d="M15.9891 0H2.011C0.9004 0 0 0.9003 0 2.0109V11.989C0 13.0996 0.9004 14 2.011 14H15.9891C17.0997 14 18 13.0997 18 11.9891V2.0109C18 0.9003 17.0997 0 15.9891 0ZM17 11.9891C17 12.5465 16.5465 13 15.9891 13H2.011C1.4536 13 1.0001 12.5465 1.0001 11.9891V2.0109C1.0001 1.4535 1.4536 0.9999 2.011 0.9999H15.9891C16.5465 0.9999 17 1.4535 17 2.0109V11.9891Z"
        />
        <path
          d="M15.356 5.67822H8.19523C8.03253 5.67822 7.90063 5.81012 7.90063 5.97282V11.3836C7.90063 11.5463 8.03253 11.6782 8.19523 11.6782H15.356C15.5187 11.6782 15.6506 11.5463 15.6506 11.3836V5.97282C15.6506 5.81012 15.5187 5.67822 15.356 5.67822Z"
        />
      </svg>
    </media-pip-button>
  </template>

  <template partial="CaptionsMenu">
    <media-captions-menu-button part="bottom captions button">
      <svg aria-hidden="true" viewBox="0 0 18 14" slot="on">
        <path
          d="M15.989 0H2.011C0.9004 0 0 0.9003 0 2.0109V11.9891C0 13.0997 0.9004 14 2.011 14H15.989C17.0997 14 18 13.0997 18 11.9891V2.0109C18 0.9003 17.0997 0 15.989 0ZM4.2292 8.7639C4.5954 9.1902 5.0935 9.4031 5.7233 9.4031C6.1852 9.4031 6.5544 9.301 6.8302 9.0969C7.1061 8.8933 7.2863 8.614 7.3702 8.26H8.4322C8.3062 8.884 8.0093 9.3733 7.5411 9.7273C7.0733 10.0813 6.4703 10.2581 5.732 10.2581C5.108 10.2581 4.5699 10.1219 4.1168 9.8489C3.6637 9.5759 3.3141 9.1946 3.0685 8.7058C2.8224 8.2165 2.6994 7.6511 2.6994 7.009C2.6994 6.3611 2.8224 5.7927 3.0685 5.3034C3.3141 4.8146 3.6637 4.4323 4.1168 4.1559C4.5699 3.88 5.108 3.7418 5.732 3.7418C6.4703 3.7418 7.0733 3.922 7.5411 4.2818C8.0094 4.6422 8.3062 5.1461 8.4322 5.794H7.3702C7.2862 5.4283 7.106 5.1368 6.8302 4.921C6.5544 4.7052 6.1852 4.5968 5.7233 4.5968C5.0934 4.5968 4.5954 4.8116 4.2292 5.2404C3.8635 5.6696 3.6804 6.259 3.6804 7.009C3.6804 7.7531 3.8635 8.3381 4.2292 8.7639ZM11.0974 8.7639C11.4636 9.1902 11.9617 9.4031 12.5915 9.4031C13.0534 9.4031 13.4226 9.301 13.6984 9.0969C13.9743 8.8933 14.1545 8.614 14.2384 8.26H15.3004C15.1744 8.884 14.8775 9.3733 14.4093 9.7273C13.9415 10.0813 13.3385 10.2581 12.6002 10.2581C11.9762 10.2581 11.4381 10.1219 10.985 9.8489C10.5319 9.5759 10.1823 9.1946 9.9367 8.7058C9.6906 8.2165 9.5676 7.6511 9.5676 7.009C9.5676 6.3611 9.6906 5.7927 9.9367 5.3034C10.1823 4.8146 10.5319 4.4323 10.985 4.1559C11.4381 3.88 11.9762 3.7418 12.6002 3.7418C13.3385 3.7418 13.9415 3.922 14.4093 4.2818C14.8776 4.6422 15.1744 5.1461 15.3004 5.794H14.2384C14.1544 5.4283 13.9742 5.1368 13.6984 4.921C13.4226 4.7052 13.0534 4.5968 12.5915 4.5968C11.9616 4.5968 11.4636 4.8116 11.0974 5.2404C10.7317 5.6696 10.5486 6.259 10.5486 7.009C10.5486 7.7531 10.7317 8.3381 11.0974 8.7639Z"
        />
      </svg>
      <svg aria-hidden="true" viewBox="0 0 18 14" slot="off">
        <path
          d="M5.73219 10.258C5.10819 10.258 4.57009 10.1218 4.11699 9.8488C3.66389 9.5758 3.31429 9.1945 3.06869 8.7057C2.82259 8.2164 2.69958 7.651 2.69958 7.0089C2.69958 6.361 2.82259 5.7926 3.06869 5.3033C3.31429 4.8145 3.66389 4.4322 4.11699 4.1558C4.57009 3.8799 5.10819 3.7417 5.73219 3.7417C6.47049 3.7417 7.07348 3.9219 7.54128 4.2817C8.00958 4.6421 8.30638 5.146 8.43238 5.7939H7.37039C7.28639 5.4282 7.10618 5.1367 6.83039 4.9209C6.55459 4.7051 6.18538 4.5967 5.72348 4.5967C5.09358 4.5967 4.59559 4.8115 4.22939 5.2403C3.86369 5.6695 3.68058 6.2589 3.68058 7.0089C3.68058 7.753 3.86369 8.338 4.22939 8.7638C4.59559 9.1901 5.09368 9.403 5.72348 9.403C6.18538 9.403 6.55459 9.3009 6.83039 9.0968C7.10629 8.8932 7.28649 8.6139 7.37039 8.2599H8.43238C8.30638 8.8839 8.00948 9.3732 7.54128 9.7272C7.07348 10.0812 6.47049 10.258 5.73219 10.258Z"
        />
        <path
          d="M12.6003 10.258C11.9763 10.258 11.4382 10.1218 10.9851 9.8488C10.532 9.5758 10.1824 9.1945 9.93685 8.7057C9.69075 8.2164 9.56775 7.651 9.56775 7.0089C9.56775 6.361 9.69075 5.7926 9.93685 5.3033C10.1824 4.8145 10.532 4.4322 10.9851 4.1558C11.4382 3.8799 11.9763 3.7417 12.6003 3.7417C13.3386 3.7417 13.9416 3.9219 14.4094 4.2817C14.8777 4.6421 15.1745 5.146 15.3005 5.7939H14.2385C14.1545 5.4282 13.9743 5.1367 13.6985 4.9209C13.4227 4.7051 13.0535 4.5967 12.5916 4.5967C11.9617 4.5967 11.4637 4.8115 11.0975 5.2403C10.7318 5.6695 10.5487 6.2589 10.5487 7.0089C10.5487 7.753 10.7318 8.338 11.0975 8.7638C11.4637 9.1901 11.9618 9.403 12.5916 9.403C13.0535 9.403 13.4227 9.3009 13.6985 9.0968C13.9744 8.8932 14.1546 8.6139 14.2385 8.2599H15.3005C15.1745 8.8839 14.8776 9.3732 14.4094 9.7272C13.9416 10.0812 13.3386 10.258 12.6003 10.258Z"
        />
        <path
          d="M15.9891 1C16.5465 1 17 1.4535 17 2.011V11.9891C17 12.5465 16.5465 13 15.9891 13H2.0109C1.4535 13 1 12.5465 1 11.9891V2.0109C1 1.4535 1.4535 0.9999 2.0109 0.9999L15.9891 1ZM15.9891 0H2.0109C0.9003 0 0 0.9003 0 2.0109V11.9891C0 13.0997 0.9003 14 2.0109 14H15.9891C17.0997 14 18 13.0997 18 11.9891V2.0109C18 0.9003 17.0997 0 15.9891 0Z"
        />
      </svg>
    </media-captions-menu-button>
    <media-captions-menu
      hidden
      anchor="auto"
      part="bottom captions menu"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
      exportparts="menu-item"
    >
      <div slot="checked-indicator">
        <style>
          .indicator {
            position: relative;
            top: 1px;
            width: 0.9em;
            height: auto;
            fill: var(--_accent-color);
            margin-right: 5px;
          }

          [aria-checked='false'] .indicator {
            display: none;
          }
        </style>
        <svg viewBox="0 0 14 18" class="indicator">
          <path
            d="M12.252 3.48c-.115.033-.301.161-.425.291-.059.063-1.407 1.815-2.995 3.894s-2.897 3.79-2.908 3.802c-.013.014-.661-.616-1.672-1.624-.908-.905-1.702-1.681-1.765-1.723-.401-.27-.783-.211-1.176.183a1.285 1.285 0 0 0-.261.342.582.582 0 0 0-.082.35c0 .165.01.205.08.35.075.153.213.296 2.182 2.271 1.156 1.159 2.17 2.159 2.253 2.222.189.143.338.196.539.194.203-.003.412-.104.618-.299.205-.193 6.7-8.693 6.804-8.903a.716.716 0 0 0 .085-.345c.01-.179.005-.203-.062-.339-.124-.252-.45-.531-.746-.639a.784.784 0 0 0-.469-.027"
            fill-rule="evenodd"
          />
        </svg></div
    ></media-captions-menu>
  </template>

  <template partial="AirplayButton">
    <media-airplay-button part="bottom airplay button" disabled="{{disabled}}" aria-disabled="{{disabled}}">
      <svg viewBox="0 0 18 14" aria-hidden="true" slot="icon">
        <path
          d="M16.1383 0H1.8618C0.8335 0 0 0.8335 0 1.8617V10.1382C0 11.1664 0.8335 12 1.8618 12H3.076C3.1204 11.9433 3.1503 11.8785 3.2012 11.826L4.004 11H1.8618C1.3866 11 1 10.6134 1 10.1382V1.8617C1 1.3865 1.3866 0.9999 1.8618 0.9999H16.1383C16.6135 0.9999 17.0001 1.3865 17.0001 1.8617V10.1382C17.0001 10.6134 16.6135 11 16.1383 11H13.9961L14.7989 11.826C14.8499 11.8785 14.8798 11.9432 14.9241 12H16.1383C17.1665 12 18.0001 11.1664 18.0001 10.1382V1.8617C18 0.8335 17.1665 0 16.1383 0Z"
        />
        <path
          d="M9.55061 8.21903C9.39981 8.06383 9.20001 7.98633 9.00011 7.98633C8.80021 7.98633 8.60031 8.06383 8.44951 8.21903L4.09771 12.697C3.62471 13.1838 3.96961 13.9998 4.64831 13.9998H13.3518C14.0304 13.9998 14.3754 13.1838 13.9023 12.697L9.55061 8.21903Z"
        />
      </svg>
    </media-airplay-button>
  </template>

  <template partial="FullscreenButton">
    <media-fullscreen-button part="bottom fullscreen button" disabled="{{disabled}}" aria-disabled="{{disabled}}">
      <svg viewBox="0 0 18 14" aria-hidden="true" slot="enter">
        <path
          d="M1.00745 4.39539L1.01445 1.98789C1.01605 1.43049 1.47085 0.978289 2.02835 0.979989L6.39375 0.992589L6.39665 -0.007411L2.03125 -0.020011C0.920646 -0.023211 0.0176463 0.874489 0.0144463 1.98509L0.00744629 4.39539H1.00745Z"
        />
        <path
          d="M17.0144 2.03431L17.0076 4.39541H18.0076L18.0144 2.03721C18.0176 0.926712 17.1199 0.0237125 16.0093 0.0205125L11.6439 0.0078125L11.641 1.00781L16.0064 1.02041C16.5638 1.02201 17.016 1.47681 17.0144 2.03431Z"
        />
        <path
          d="M16.9925 9.60498L16.9855 12.0124C16.9839 12.5698 16.5291 13.022 15.9717 13.0204L11.6063 13.0078L11.6034 14.0078L15.9688 14.0204C17.0794 14.0236 17.9823 13.1259 17.9855 12.0153L17.9925 9.60498H16.9925Z"
        />
        <path
          d="M0.985626 11.9661L0.992426 9.60498H-0.0074737L-0.0142737 11.9632C-0.0174737 13.0738 0.880226 13.9767 1.99083 13.98L6.35623 13.9926L6.35913 12.9926L1.99373 12.98C1.43633 12.9784 0.983926 12.5236 0.985626 11.9661Z"
        />
      </svg>
      <svg viewBox="0 0 18 14" aria-hidden="true" slot="exit">
        <path
          d="M5.39655 -0.0200195L5.38955 2.38748C5.38795 2.94488 4.93315 3.39708 4.37565 3.39538L0.0103463 3.38278L0.00744629 4.38278L4.37285 4.39538C5.48345 4.39858 6.38635 3.50088 6.38965 2.39028L6.39665 -0.0200195H5.39655Z"
        />
        <path
          d="M12.6411 2.36891L12.6479 0.0078125H11.6479L11.6411 2.36601C11.6379 3.47651 12.5356 4.37951 13.6462 4.38271L18.0116 4.39531L18.0145 3.39531L13.6491 3.38271C13.0917 3.38111 12.6395 2.92641 12.6411 2.36891Z"
        />
        <path
          d="M12.6034 14.0204L12.6104 11.613C12.612 11.0556 13.0668 10.6034 13.6242 10.605L17.9896 10.6176L17.9925 9.61759L13.6271 9.60499C12.5165 9.60179 11.6136 10.4995 11.6104 11.6101L11.6034 14.0204H12.6034Z"
        />
        <path
          d="M5.359 11.6315L5.3522 13.9926H6.3522L6.359 11.6344C6.3622 10.5238 5.4645 9.62088 4.3539 9.61758L-0.0115043 9.60498L-0.0144043 10.605L4.351 10.6176C4.9084 10.6192 5.3607 11.074 5.359 11.6315Z"
        />
      </svg>
    </media-fullscreen-button>
  </template>

  <template partial="CastButton">
    <media-cast-button part="bottom cast button" disabled="{{disabled}}" aria-disabled="{{disabled}}">
      <svg viewBox="0 0 18 14" aria-hidden="true" slot="enter">
        <path
          d="M16.0072 0H2.0291C0.9185 0 0.0181 0.9003 0.0181 2.011V5.5009C0.357 5.5016 0.6895 5.5275 1.0181 5.5669V2.011C1.0181 1.4536 1.4716 1 2.029 1H16.0072C16.5646 1 17.0181 1.4536 17.0181 2.011V11.9891C17.0181 12.5465 16.5646 13 16.0072 13H8.4358C8.4746 13.3286 8.4999 13.6611 8.4999 13.9999H16.0071C17.1177 13.9999 18.018 13.0996 18.018 11.989V2.011C18.0181 0.9003 17.1178 0 16.0072 0ZM0 6.4999V7.4999C3.584 7.4999 6.5 10.4159 6.5 13.9999H7.5C7.5 9.8642 4.1357 6.4999 0 6.4999ZM0 8.7499V9.7499C2.3433 9.7499 4.25 11.6566 4.25 13.9999H5.25C5.25 11.1049 2.895 8.7499 0 8.7499ZM0.0181 11V14H3.0181C3.0181 12.3431 1.675 11 0.0181 11Z"
        />
      </svg>
      <svg viewBox="0 0 18 14" aria-hidden="true" slot="exit">
        <path
          d="M15.9891 0H2.01103C0.900434 0 3.35947e-05 0.9003 3.35947e-05 2.011V5.5009C0.338934 5.5016 0.671434 5.5275 1.00003 5.5669V2.011C1.00003 1.4536 1.45353 1 2.01093 1H15.9891C16.5465 1 17 1.4536 17 2.011V11.9891C17 12.5465 16.5465 13 15.9891 13H8.41773C8.45653 13.3286 8.48183 13.6611 8.48183 13.9999H15.989C17.0996 13.9999 17.9999 13.0996 17.9999 11.989V2.011C18 0.9003 17.0997 0 15.9891 0ZM-0.0180664 6.4999V7.4999C3.56593 7.4999 6.48193 10.4159 6.48193 13.9999H7.48193C7.48193 9.8642 4.11763 6.4999 -0.0180664 6.4999ZM-0.0180664 8.7499V9.7499C2.32523 9.7499 4.23193 11.6566 4.23193 13.9999H5.23193C5.23193 11.1049 2.87693 8.7499 -0.0180664 8.7499ZM3.35947e-05 11V14H3.00003C3.00003 12.3431 1.65693 11 3.35947e-05 11Z"
        />
        <path d="M2.15002 5.634C5.18352 6.4207 7.57252 8.8151 8.35282 11.8499H15.8501V2.1499H2.15002V5.634Z" />
      </svg>
    </media-cast-button>
  </template>

  <template partial="LiveButton">
    <media-live-button part="{{section ?? 'top'}} live button" disabled="{{disabled}}" aria-disabled="{{disabled}}">
      <span slot="text">Live</span>
    </media-live-button>
  </template>

  <template partial="PlaybackRateMenu">
    <media-playback-rate-menu-button part="bottom playback-rate button"></media-playback-rate-menu-button>
    <media-playback-rate-menu
      hidden
      anchor="auto"
      rates="{{playbackrates}}"
      exportparts="menu-item"
      part="bottom playback-rate menu"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
    ></media-playback-rate-menu>
  </template>

  <template partial="VolumeRange">
    <media-volume-range
      part="bottom volume range"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
    ></media-volume-range>
  </template>

  <template partial="TimeDisplay">
    <media-time-display
      remaining="{{defaultshowremainingtime}}"
      showduration="{{!hideduration}}"
      part="bottom time display"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
    ></media-time-display>
  </template>

  <template partial="TimeRange">
    <media-time-range part="bottom time range" disabled="{{disabled}}" aria-disabled="{{disabled}}">
      <media-preview-thumbnail slot="preview"></media-preview-thumbnail>
      <media-preview-chapter-display slot="preview"></media-preview-chapter-display>
      <media-preview-time-display slot="preview"></media-preview-time-display>
      <div slot="preview" part="arrow"></div>
    </media-time-range>
  </template>

  <template partial="AudioTrackMenu">
    <media-audio-track-menu-button part="bottom audio-track button">
      <svg aria-hidden="true" slot="icon" viewBox="0 0 18 16">
        <path d="M9 15A7 7 0 1 1 9 1a7 7 0 0 1 0 14Zm0 1A8 8 0 1 0 9 0a8 8 0 0 0 0 16Z" />
        <path
          d="M5.2 6.3a.5.5 0 0 1 .5.5v2.4a.5.5 0 1 1-1 0V6.8a.5.5 0 0 1 .5-.5Zm2.4-2.4a.5.5 0 0 1 .5.5v7.2a.5.5 0 0 1-1 0V4.4a.5.5 0 0 1 .5-.5ZM10 5.5a.5.5 0 0 1 .5.5v4a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5Zm2.4-.8a.5.5 0 0 1 .5.5v5.6a.5.5 0 0 1-1 0V5.2a.5.5 0 0 1 .5-.5Z"
        />
      </svg>
    </media-audio-track-menu-button>
    <media-audio-track-menu
      hidden
      anchor="auto"
      part="bottom audio-track menu"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
      exportparts="menu-item"
    >
      <div slot="checked-indicator">
        <style>
          .indicator {
            position: relative;
            top: 1px;
            width: 0.9em;
            height: auto;
            fill: var(--_accent-color);
            margin-right: 5px;
          }

          [aria-checked='false'] .indicator {
            display: none;
          }
        </style>
        <svg viewBox="0 0 14 18" class="indicator">
          <path
            d="M12.252 3.48c-.115.033-.301.161-.425.291-.059.063-1.407 1.815-2.995 3.894s-2.897 3.79-2.908 3.802c-.013.014-.661-.616-1.672-1.624-.908-.905-1.702-1.681-1.765-1.723-.401-.27-.783-.211-1.176.183a1.285 1.285 0 0 0-.261.342.582.582 0 0 0-.082.35c0 .165.01.205.08.35.075.153.213.296 2.182 2.271 1.156 1.159 2.17 2.159 2.253 2.222.189.143.338.196.539.194.203-.003.412-.104.618-.299.205-.193 6.7-8.693 6.804-8.903a.716.716 0 0 0 .085-.345c.01-.179.005-.203-.062-.339-.124-.252-.45-.531-.746-.639a.784.784 0 0 0-.469-.027"
            fill-rule="evenodd"
          />
        </svg>
      </div>
    </media-audio-track-menu>
  </template>

  <template partial="RenditionMenu">
    <media-rendition-menu-button part="bottom rendition button">
      <svg aria-hidden="true" slot="icon" viewBox="0 0 18 14">
        <path
          d="M2.25 9a2 2 0 1 0 0-4 2 2 0 0 0 0 4ZM9 9a2 2 0 1 0 0-4 2 2 0 0 0 0 4Zm6.75 0a2 2 0 1 0 0-4 2 2 0 0 0 0 4Z"
        />
      </svg>
    </media-rendition-menu-button>
    <media-rendition-menu
      hidden
      anchor="auto"
      part="bottom rendition menu"
      disabled="{{disabled}}"
      aria-disabled="{{disabled}}"
    >
      <div slot="checked-indicator">
        <style>
          .indicator {
            position: relative;
            top: 1px;
            width: 0.9em;
            height: auto;
            fill: var(--_accent-color);
            margin-right: 5px;
          }

          [aria-checked='false'] .indicator {
            opacity: 0;
          }
        </style>
        <svg viewBox="0 0 14 18" class="indicator">
          <path
            d="M12.252 3.48c-.115.033-.301.161-.425.291-.059.063-1.407 1.815-2.995 3.894s-2.897 3.79-2.908 3.802c-.013.014-.661-.616-1.672-1.624-.908-.905-1.702-1.681-1.765-1.723-.401-.27-.783-.211-1.176.183a1.285 1.285 0 0 0-.261.342.582.582 0 0 0-.082.35c0 .165.01.205.08.35.075.153.213.296 2.182 2.271 1.156 1.159 2.17 2.159 2.253 2.222.189.143.338.196.539.194.203-.003.412-.104.618-.299.205-.193 6.7-8.693 6.804-8.903a.716.716 0 0 0 .085-.345c.01-.179.005-.203-.062-.339-.124-.252-.45-.531-.746-.639a.784.784 0 0 0-.469-.027"
            fill-rule="evenodd"
          />
        </svg>
      </div>
    </media-rendition-menu>
  </template>

  <template partial="MuxBadge">
    <div part="mux-badge">
      <a href="https://www.mux.com/player" target="_blank">
        <span class="mux-badge-text">Powered by</span>
        <div class="mux-badge-logo">
          <svg
            viewBox="0 0 1600 500"
            style="fill-rule: evenodd; clip-rule: evenodd; stroke-linejoin: round; stroke-miterlimit: 2"
          >
            <g>
              <path
                d="M994.287,93.486c-17.121,-0 -31,-13.879 -31,-31c0,-17.121 13.879,-31 31,-31c17.121,-0 31,13.879 31,31c0,17.121 -13.879,31 -31,31m0,-93.486c-34.509,-0 -62.484,27.976 -62.484,62.486l0,187.511c0,68.943 -56.09,125.033 -125.032,125.033c-68.942,-0 -125.03,-56.09 -125.03,-125.033l0,-187.511c0,-34.51 -27.976,-62.486 -62.485,-62.486c-34.509,-0 -62.484,27.976 -62.484,62.486l0,187.511c0,137.853 112.149,250.003 249.999,250.003c137.851,-0 250.001,-112.15 250.001,-250.003l0,-187.511c0,-34.51 -27.976,-62.486 -62.485,-62.486"
                style="fill-rule: nonzero"
              ></path>
              <path
                d="M1537.51,468.511c-17.121,-0 -31,-13.879 -31,-31c0,-17.121 13.879,-31 31,-31c17.121,-0 31,13.879 31,31c0,17.121 -13.879,31 -31,31m-275.883,-218.509l-143.33,143.329c-24.402,24.402 -24.402,63.966 0,88.368c24.402,24.402 63.967,24.402 88.369,-0l143.33,-143.329l143.328,143.329c24.402,24.4 63.967,24.402 88.369,-0c24.403,-24.402 24.403,-63.966 0.001,-88.368l-143.33,-143.329l0.001,-0.004l143.329,-143.329c24.402,-24.402 24.402,-63.965 0,-88.367c-24.402,-24.402 -63.967,-24.402 -88.369,-0l-143.329,143.328l-143.329,-143.328c-24.402,-24.401 -63.967,-24.402 -88.369,-0c-24.402,24.402 -24.402,63.965 0,88.367l143.329,143.329l0,0.004Z"
                style="fill-rule: nonzero"
              ></path>
              <path
                d="M437.511,468.521c-17.121,-0 -31,-13.879 -31,-31c0,-17.121 13.879,-31 31,-31c17.121,-0 31,13.879 31,31c0,17.121 -13.879,31 -31,31m23.915,-463.762c-23.348,-9.672 -50.226,-4.327 -68.096,13.544l-143.331,143.329l-143.33,-143.329c-17.871,-17.871 -44.747,-23.216 -68.096,-13.544c-23.349,9.671 -38.574,32.455 -38.574,57.729l0,375.026c0,34.51 27.977,62.486 62.487,62.486c34.51,-0 62.486,-27.976 62.486,-62.486l0,-224.173l80.843,80.844c24.404,24.402 63.965,24.402 88.369,-0l80.843,-80.844l0,224.173c0,34.51 27.976,62.486 62.486,62.486c34.51,-0 62.486,-27.976 62.486,-62.486l0,-375.026c0,-25.274 -15.224,-48.058 -38.573,-57.729"
                style="fill-rule: nonzero"
              ></path>
            </g>
          </svg>
        </div>
      </a>
    </div>
  </template>

  <media-controller
    part="controller"
    defaultstreamtype="{{defaultstreamtype ?? 'on-demand'}}"
    breakpoints="sm:470"
    gesturesdisabled="{{disabled}}"
    hotkeys="{{hotkeys}}"
    nohotkeys="{{nohotkeys}}"
    novolumepref="{{novolumepref}}"
    audio="{{audio}}"
    noautoseektolive="{{noautoseektolive}}"
    defaultsubtitles="{{defaultsubtitles}}"
    defaultduration="{{defaultduration ?? false}}"
    keyboardforwardseekoffset="{{forwardseekoffset}}"
    keyboardbackwardseekoffset="{{backwardseekoffset}}"
    exportparts="layer, media-layer, poster-layer, vertical-layer, centered-layer, gesture-layer"
    style="--_pre-playback-place:{{preplaybackplace ?? 'center'}}"
  >
    <slot name="media" slot="media"></slot>
    <slot name="poster" slot="poster"></slot>

    <media-loading-indicator slot="centered-chrome" noautohide></media-loading-indicator>
    <media-error-dialog slot="dialog" noautohide></media-error-dialog>

    <template if="!audio">
      <!-- Pre-playback UI -->
      <!-- same for both on-demand and live -->
      <div slot="centered-chrome" class="center-controls pre-playback">
        <template if="!breakpointsm">{{>PlayButton section="center"}}</template>
        <template if="breakpointsm">{{>PrePlayButton section="center"}}</template>
      </div>

      <!-- Mux Badge -->
      <template if="proudlydisplaymuxbadge"> {{>MuxBadge}} </template>

      <!-- Autoplay centered unmute button -->
      <!--
        todo: figure out how show this with available state variables
        needs to show when:
        - autoplay is enabled
        - playback has been successful
        - audio is muted
        - in place / instead of the pre-plaback play button
        - not to show again after user has interacted with this button
          - OR user has interacted with the mute button in the control bar
      -->
      <!--
        There should be a >MuteButton to the left of the "Unmute" text, but a templating bug
        makes it appear even if commented out in the markup, add it back when code is un-commented
      -->
      <!-- <div slot="centered-chrome" class="autoplay-unmute">
        <div role="button" class="autoplay-unmute-btn">Unmute</div>
      </div> -->

      <template if="streamtype == 'on-demand'">
        <template if="breakpointsm">
          <media-control-bar part="control-bar top" slot="top-chrome">{{>TitleDisplay}} </media-control-bar>
        </template>
        {{>TimeRange}}
        <media-control-bar part="control-bar bottom">
          {{>PlayButton}} {{>SeekBackwardButton}} {{>SeekForwardButton}} {{>TimeDisplay}} {{>MuteButton}}
          {{>VolumeRange}}
          <div class="spacer"></div>
          {{>RenditionMenu}} {{>PlaybackRateMenu}} {{>AudioTrackMenu}} {{>CaptionsMenu}} {{>AirplayButton}}
          {{>CastButton}} {{>PipButton}} {{>FullscreenButton}}
        </media-control-bar>
      </template>

      <template if="streamtype == 'live'">
        <media-control-bar part="control-bar top" slot="top-chrome">
          {{>LiveButton}}
          <template if="breakpointsm"> {{>TitleDisplay}} </template>
        </media-control-bar>
        <template if="targetlivewindow > 0">{{>TimeRange}}</template>
        <media-control-bar part="control-bar bottom">
          {{>PlayButton}}
          <template if="targetlivewindow > 0">{{>SeekBackwardButton}} {{>SeekForwardButton}}</template>
          {{>MuteButton}} {{>VolumeRange}}
          <div class="spacer"></div>
          {{>RenditionMenu}} {{>AudioTrackMenu}} {{>CaptionsMenu}} {{>AirplayButton}} {{>CastButton}} {{>PipButton}}
          {{>FullscreenButton}}
        </media-control-bar>
      </template>
    </template>

    <template if="audio">
      <template if="streamtype == 'on-demand'">
        <template if="title">
          <media-control-bar part="control-bar top">{{>TitleDisplay}}</media-control-bar>
        </template>
        <media-control-bar part="control-bar bottom">
          {{>PlayButton}}
          <template if="breakpointsm"> {{>SeekBackwardButton}} {{>SeekForwardButton}} </template>
          {{>MuteButton}}
          <template if="breakpointsm">{{>VolumeRange}}</template>
          {{>TimeDisplay}} {{>TimeRange}}
          <template if="breakpointsm">{{>PlaybackRateMenu}}</template>
          {{>AirplayButton}} {{>CastButton}}
        </media-control-bar>
      </template>

      <template if="streamtype == 'live'">
        <template if="title">
          <media-control-bar part="control-bar top">{{>TitleDisplay}}</media-control-bar>
        </template>
        <media-control-bar part="control-bar bottom">
          {{>PlayButton}} {{>LiveButton section="bottom"}} {{>MuteButton}}
          <template if="breakpointsm">
            {{>VolumeRange}}
            <template if="targetlivewindow > 0"> {{>SeekBackwardButton}} {{>SeekForwardButton}} </template>
          </template>
          <template if="targetlivewindow > 0"> {{>TimeDisplay}} {{>TimeRange}} </template>
          <template if="!targetlivewindow"><div class="spacer"></div></template>
          {{>AirplayButton}} {{>CastButton}}
        </media-control-bar>
      </template>
    </template>

    <slot></slot>
  </media-controller>
</template>
`;
  var base_xe = dist_base_Y.createElement('template');
  'innerHTML' in base_xe && (base_xe.innerHTML = base_vt);
  var base_Tt,
   base_Et,
   base_me = class extends MediaThemeElement {};
  base_me.template = (base_Et = (base_Tt = base_xe.content) == null ? void 0 : base_Tt.children) == null ? void 0 : base_Et[0];
  base_k.customElements.get('media-theme-gerwig') || base_k.customElements.define('media-theme-gerwig', base_me);
  var base_fa = 'gerwig',
   base_M = { SRC: 'src', POSTER: 'poster' },
   base_o = { STYLE: 'style', DEFAULT_HIDDEN_CAPTIONS: 'default-hidden-captions', PRIMARY_COLOR: 'primary-color', SECONDARY_COLOR: 'secondary-color', ACCENT_COLOR: 'accent-color', FORWARD_SEEK_OFFSET: 'forward-seek-offset', BACKWARD_SEEK_OFFSET: 'backward-seek-offset', PLAYBACK_TOKEN: 'playback-token', THUMBNAIL_TOKEN: 'thumbnail-token', STORYBOARD_TOKEN: 'storyboard-token', DRM_TOKEN: 'drm-token', STORYBOARD_SRC: 'storyboard-src', THUMBNAIL_TIME: 'thumbnail-time', AUDIO: 'audio', NOHOTKEYS: 'nohotkeys', HOTKEYS: 'hotkeys', PLAYBACK_RATES: 'playbackrates', DEFAULT_SHOW_REMAINING_TIME: 'default-show-remaining-time', DEFAULT_DURATION: 'default-duration', TITLE: 'title', VIDEO_TITLE: 'video-title', PLACEHOLDER: 'placeholder', THEME: 'theme', DEFAULT_STREAM_TYPE: 'default-stream-type', TARGET_LIVE_WINDOW: 'target-live-window', EXTRA_SOURCE_PARAMS: 'extra-source-params', NO_VOLUME_PREF: 'no-volume-pref', CAST_RECEIVER: 'cast-receiver', NO_TOOLTIPS: 'no-tooltips', PROUDLY_DISPLAY_MUX_BADGE: 'proudly-display-mux-badge' },
   base_Se = ['audio', 'backwardseekoffset', 'defaultduration', 'defaultshowremainingtime', 'defaultsubtitles', 'noautoseektolive', 'disabled', 'exportparts', 'forwardseekoffset', 'hideduration', 'hotkeys', 'nohotkeys', 'playbackrates', 'defaultstreamtype', 'streamtype', 'style', 'targetlivewindow', 'template', 'title', 'videotitle', 'novolumepref', 'proudlydisplaymuxbadge'];
  function base_ya(t, a) {
   var i, r;
   return { src: !t.playbackId && t.src, playbackId: t.playbackId, hasSrc: !!t.playbackId || !!t.src || !!t.currentSrc, poster: t.poster, storyboard: t.storyboard, storyboardSrc: t.getAttribute(base_o.STORYBOARD_SRC), placeholder: t.getAttribute('placeholder'), themeTemplate: base_Ta(t), thumbnailTime: !t.tokens.thumbnail && t.thumbnailTime, autoplay: t.autoplay, crossOrigin: t.crossOrigin, loop: t.loop, noHotKeys: t.hasAttribute(base_o.NOHOTKEYS), hotKeys: t.getAttribute(base_o.HOTKEYS), muted: t.muted, paused: t.paused, preload: t.preload, envKey: t.envKey, preferCmcd: t.preferCmcd, debug: t.debug, disableTracking: t.disableTracking, disableCookies: t.disableCookies, tokens: t.tokens, beaconCollectionDomain: t.beaconCollectionDomain, maxResolution: t.maxResolution, minResolution: t.minResolution, programStartTime: t.programStartTime, programEndTime: t.programEndTime, assetStartTime: t.assetStartTime, assetEndTime: t.assetEndTime, renditionOrder: t.renditionOrder, metadata: t.metadata, playerInitTime: t.playerInitTime, playerSoftwareName: t.playerSoftwareName, playerSoftwareVersion: t.playerSoftwareVersion, startTime: t.startTime, preferPlayback: t.preferPlayback, audio: t.audio, defaultStreamType: t.defaultStreamType, targetLiveWindow: t.getAttribute(base_e.TARGET_LIVE_WINDOW), streamType: base_z(t.getAttribute(base_e.STREAM_TYPE)), primaryColor: t.getAttribute(base_o.PRIMARY_COLOR), secondaryColor: t.getAttribute(base_o.SECONDARY_COLOR), accentColor: t.getAttribute(base_o.ACCENT_COLOR), forwardSeekOffset: t.forwardSeekOffset, backwardSeekOffset: t.backwardSeekOffset, defaultHiddenCaptions: t.defaultHiddenCaptions, defaultDuration: t.defaultDuration, defaultShowRemainingTime: t.defaultShowRemainingTime, hideDuration: base_Ea(t), playbackRates: t.getAttribute(base_o.PLAYBACK_RATES), customDomain: (i = t.getAttribute(base_e.CUSTOM_DOMAIN)) != null ? i : void 0, title: t.getAttribute(base_o.TITLE), videoTitle: (r = t.getAttribute(base_o.VIDEO_TITLE)) != null ? r : t.getAttribute(base_o.TITLE), novolumepref: t.hasAttribute(base_o.NO_VOLUME_PREF), proudlyDisplayMuxBadge: t.hasAttribute(base_o.PROUDLY_DISPLAY_MUX_BADGE), castReceiver: t.castReceiver, ...a, extraSourceParams: t.extraSourceParams };
  }
  var base_va = media_error_dialog_default.formatErrorMessage;
  media_error_dialog_default.formatErrorMessage = (t) => {
   var a, e;
   if (t instanceof f) {
    let i = base_yt(t, !1);
    return `
      ${i != null && i.title ? `<h3>${i.title}</h3>` : ''}
      ${
       (i != null && i.message) || (i != null && i.linkUrl)
        ? `<p>
        ${i == null ? void 0 : i.message}
        ${
         i != null && i.linkUrl
          ? `<a
              href="${i.linkUrl}"
              target="_blank"
              rel="external noopener"
              aria-label="${(a = i.linkText) != null ? a : ''} ${x('(opens in a new window)')}"
              >${(e = i.linkText) != null ? e : i.linkUrl}</a
            >`
          : ''
        }
      </p>`
        : ''
      }
    `;
   }
   return base_va(t);
  };
  function base_Ta(t) {
   var e, i;
   let a = t.theme;
   if (a) {
    let r = (i = (e = t.getRootNode()) == null ? void 0 : e.getElementById) == null ? void 0 : i.call(e, a);
    if (r && r instanceof HTMLTemplateElement) return r;
    a.startsWith('media-theme-') || (a = `media-theme-${a}`);
    let n = base_k.customElements.get(a);
    if (n != null && n.template) return n.template;
   }
  }
  function base_Ea(t) {
   var e;
   let a = (e = t.mediaController) == null ? void 0 : e.querySelector('media-time-display');
   return a && getComputedStyle(a).getPropertyValue('--media-duration-display-display').trim() === 'none';
  }
  function base_t(t) {
   let a = t.videoTitle ? { video_title: t.videoTitle } : {};
   return t
    .getAttributeNames()
    .filter((e) => e.startsWith('metadata-'))
    .reduce((e, i) => {
     let r = t.getAttribute(i);
     return r !== null && (e[i.replace(/^metadata-/, '').replace(/-/g, '_')] = r), e;
    }, a);
  }
  var base_Aa = Object.values(base_e),
   Ca = Object.values(base_M),
   base_ka = Object.values(base_o),
   base_Rt = base_se(),
   base_xt = 'mux-player',
   base_Ot = { isDialogOpen: !1 },
   base_a = { redundant_streams: !0 },
   base_J,
   base_ee,
   base_te,
   base_I,
   base_ae,
   base_H,
   base_m,
   base_w,
   base_Mt,
   base_we,
   dist_base_B,
   base_St,
   base_Nt,
   base_wt,
   base_It,
   base_Ne = class extends base_Ce {
    constructor() {
     super();
     base_T(this, base_m);
     base_T(this, base_J);
     base_T(this, base_ee, !1);
     base_T(this, base_te, {});
     base_T(this, base_I, !0);
     base_T(this, base_ae, new base_ne(this, 'hotkeys'));
     base_T(this, base_H, {
      ...base_Ot,
      onCloseErrorDialog: (e) => {
       var r;
       ((r = e.composedPath()[0]) == null ? void 0 : r.localName) === 'media-error-dialog' && base_p(this, base_m, base_we).call(this, { isDialogOpen: !1 });
      },
      onFocusInErrorDialog: (e) => {
       var n;
       if (((n = e.composedPath()[0]) == null ? void 0 : n.localName) !== 'media-error-dialog') return;
       base_ve(this, dist_base_Y.activeElement) || e.preventDefault();
      },
     });
     dist_base_C(this, base_J, dist_Wr()), this.attachShadow({ mode: 'open' }), base_p(this, base_m, base_Mt).call(this), this.isConnected && base_p(this, base_m, base_w).call(this);
    }
    static get NAME() {
     return base_xt;
    }
    static get VERSION() {
     return base_Rt;
    }
    static get observedAttributes() {
     var e;
     return [...((e = base_Ce.observedAttributes) != null ? e : []), ...Ca, ...base_Aa, ...base_ka];
    }
    get mediaTheme() {
     var e;
     return (e = this.shadowRoot) == null ? void 0 : e.querySelector('media-theme');
    }
    get mediaController() {
     var e, i;
     return (i = (e = this.mediaTheme) == null ? void 0 : e.shadowRoot) == null ? void 0 : i.querySelector('media-controller');
    }
    connectedCallback() {
     let e = this.media;
     e && (e.metadata = base_t(this));
    }
    attributeChangedCallback(e, i, r) {
     switch ((base_p(this, base_m, base_w).call(this), super.attributeChangedCallback(e, i, r), e)) {
      case base_o.HOTKEYS:
       dist_base_u(this, base_ae).value = r;
       break;
      case base_o.THUMBNAIL_TIME: {
       r != null && this.tokens.thumbnail && dist_base_x(x('Use of thumbnail-time with thumbnail-token is currently unsupported. Ignore thumbnail-time.').toString());
       break;
      }
      case base_o.THUMBNAIL_TOKEN: {
       if (r) {
        let d = dist_ee(r);
        if (d) {
         let { aud: l } = d,
          b = dist_se.THUMBNAIL;
         l !== b && dist_base_x(x('The {tokenNamePrefix}-token has an incorrect aud value: {aud}. aud value should be {expectedAud}.').format({ aud: l, expectedAud: b, tokenNamePrefix: 'thumbnail' }));
        }
       }
       break;
      }
      case base_o.STORYBOARD_TOKEN: {
       if (r) {
        let d = dist_ee(r);
        if (d) {
         let { aud: l } = d,
          b = dist_se.STORYBOARD;
         l !== b && dist_base_x(x('The {tokenNamePrefix}-token has an incorrect aud value: {aud}. aud value should be {expectedAud}.').format({ aud: l, expectedAud: b, tokenNamePrefix: 'storyboard' }));
        }
       }
       break;
      }
      case base_o.DRM_TOKEN: {
       if (r) {
        let d = dist_ee(r);
        if (d) {
         let { aud: l } = d,
          b = dist_se.DRM;
         l !== b && dist_base_x(x('The {tokenNamePrefix}-token has an incorrect aud value: {aud}. aud value should be {expectedAud}.').format({ aud: l, expectedAud: b, tokenNamePrefix: 'drm' }));
        }
       }
       break;
      }
      case base_e.PLAYBACK_ID: {
       r != null && r.includes('?token') && E(x('The specificed playback ID {playbackId} contains a token which must be provided via the playback-token attribute.').format({ playbackId: r }));
       break;
      }
      case base_e.STREAM_TYPE:
       r && ![dist_.LIVE, dist_.ON_DEMAND, dist_.UNKNOWN].includes(r) ? (['ll-live', 'live:dvr', 'll-live:dvr'].includes(this.streamType) ? (this.targetLiveWindow = r.includes('dvr') ? Number.POSITIVE_INFINITY : 0) : base_Ee({ file: 'invalid-stream-type.md', message: x('Invalid stream-type value supplied: `{streamType}`. Please provide stream-type as either: `on-demand` or `live`').format({ streamType: this.streamType }) })) : r === dist_.LIVE ? this.getAttribute(base_o.TARGET_LIVE_WINDOW) == null && (this.targetLiveWindow = 0) : (this.targetLiveWindow = Number.NaN);
     }
     [base_e.PLAYBACK_ID, base_M.SRC, base_o.PLAYBACK_TOKEN].includes(e) && i !== r && dist_base_C(this, base_H, { ...dist_base_u(this, base_H), ...base_Ot }), base_p(this, base_m, dist_base_B).call(this, { [base_ot(e)]: r });
    }
    async requestFullscreen(e) {
     var i;
     if (!(!this.mediaController || this.mediaController.hasAttribute(MediaUIAttributes.MEDIA_IS_FULLSCREEN)))
      return (
       (i = this.mediaController) == null || i.dispatchEvent(new base_k.CustomEvent(MediaUIEvents.MEDIA_ENTER_FULLSCREEN_REQUEST, { composed: !0, bubbles: !0 })),
       new Promise((r, n) => {
        var d;
        (d = this.mediaController) == null || d.addEventListener(MediaStateChangeEvents.MEDIA_IS_FULLSCREEN, () => r(), { once: !0 });
       })
      );
    }
    async exitFullscreen() {
     var e;
     if (!(!this.mediaController || !this.mediaController.hasAttribute(MediaUIAttributes.MEDIA_IS_FULLSCREEN)))
      return (
       (e = this.mediaController) == null || e.dispatchEvent(new base_k.CustomEvent(MediaUIEvents.MEDIA_EXIT_FULLSCREEN_REQUEST, { composed: !0, bubbles: !0 })),
       new Promise((i, r) => {
        var n;
        (n = this.mediaController) == null || n.addEventListener(MediaStateChangeEvents.MEDIA_IS_FULLSCREEN, () => i(), { once: !0 });
       })
      );
    }
    get preferCmcd() {
     var e;
     return (e = this.getAttribute(base_e.PREFER_CMCD)) != null ? e : void 0;
    }
    set preferCmcd(e) {
     e !== this.preferCmcd && (e ? (dist_jt.includes(e) ? this.setAttribute(base_e.PREFER_CMCD, e) : dist_base_x(`Invalid value for preferCmcd. Must be one of ${dist_jt.join()}`)) : this.removeAttribute(base_e.PREFER_CMCD));
    }
    get hasPlayed() {
     var e, i;
     return (i = (e = this.mediaController) == null ? void 0 : e.hasAttribute(MediaUIAttributes.MEDIA_HAS_PLAYED)) != null ? i : !1;
    }
    get inLiveWindow() {
     var e;
     return (e = this.mediaController) == null ? void 0 : e.hasAttribute(MediaUIAttributes.MEDIA_TIME_IS_LIVE);
    }
    get _hls() {
     var e;
     return (e = this.media) == null ? void 0 : e._hls;
    }
    get mux() {
     var e;
     return (e = this.media) == null ? void 0 : e.mux;
    }
    get theme() {
     var e;
     return (e = this.getAttribute(base_o.THEME)) != null ? e : base_fa;
    }
    set theme(e) {
     this.setAttribute(base_o.THEME, `${e}`);
    }
    get themeProps() {
     let e = this.mediaTheme;
     if (!e) return;
     let i = {};
     for (let r of e.getAttributeNames()) {
      if (base_Se.includes(r)) continue;
      let n = e.getAttribute(r);
      i[base_oe(r)] = n === '' ? !0 : n;
     }
     return i;
    }
    set themeProps(e) {
     var r, n;
     base_p(this, base_m, base_w).call(this);
     let i = { ...this.themeProps, ...e };
     for (let d in i) {
      if (base_Se.includes(d)) continue;
      let l = e == null ? void 0 : e[d];
      typeof l == 'boolean' || l == null ? (r = this.mediaTheme) == null || r.toggleAttribute(base_re(d), !!l) : (n = this.mediaTheme) == null || n.setAttribute(base_re(d), l);
     }
    }
    get playbackId() {
     var e;
     return (e = this.getAttribute(base_e.PLAYBACK_ID)) != null ? e : void 0;
    }
    set playbackId(e) {
     e ? this.setAttribute(base_e.PLAYBACK_ID, e) : this.removeAttribute(base_e.PLAYBACK_ID);
    }
    get src() {
     var e, i;
     return this.playbackId ? ((e = base_U(this, base_M.SRC)) != null ? e : void 0) : (i = this.getAttribute(base_M.SRC)) != null ? i : void 0;
    }
    set src(e) {
     e ? this.setAttribute(base_M.SRC, e) : this.removeAttribute(base_M.SRC);
    }
    get poster() {
     var r;
     let e = this.getAttribute(base_M.POSTER);
     if (e != null) return e;
     let { tokens: i } = this;
     if (i.playback && !i.thumbnail) {
      dist_base_x('Missing expected thumbnail token. No poster image will be shown');
      return;
     }
     if (this.playbackId && !this.audio) return base_it(this.playbackId, { customDomain: this.customDomain, thumbnailTime: (r = this.thumbnailTime) != null ? r : this.startTime, programTime: this.programStartTime, token: i.thumbnail });
    }
    set poster(e) {
     e || e === '' ? this.setAttribute(base_M.POSTER, e) : this.removeAttribute(base_M.POSTER);
    }
    get storyboardSrc() {
     var e;
     return (e = this.getAttribute(base_o.STORYBOARD_SRC)) != null ? e : void 0;
    }
    set storyboardSrc(e) {
     e ? this.setAttribute(base_o.STORYBOARD_SRC, e) : this.removeAttribute(base_o.STORYBOARD_SRC);
    }
    get storyboard() {
     let { tokens: e } = this;
     if (this.storyboardSrc && !e.storyboard) return this.storyboardSrc;
     if (!(this.audio || !this.playbackId || !this.streamType || [dist_.LIVE, dist_.UNKNOWN].includes(this.streamType) || (e.playback && !e.storyboard))) return base_rt(this.playbackId, { customDomain: this.customDomain, token: e.storyboard, programStartTime: this.programStartTime, programEndTime: this.programEndTime });
    }
    get audio() {
     return this.hasAttribute(base_o.AUDIO);
    }
    set audio(e) {
     if (!e) {
      this.removeAttribute(base_o.AUDIO);
      return;
     }
     this.setAttribute(base_o.AUDIO, '');
    }
    get hotkeys() {
     return dist_base_u(this, base_ae);
    }
    get nohotkeys() {
     return this.hasAttribute(base_o.NOHOTKEYS);
    }
    set nohotkeys(e) {
     if (!e) {
      this.removeAttribute(base_o.NOHOTKEYS);
      return;
     }
     this.setAttribute(base_o.NOHOTKEYS, '');
    }
    get thumbnailTime() {
     return base_y(this.getAttribute(base_o.THUMBNAIL_TIME));
    }
    set thumbnailTime(e) {
     this.setAttribute(base_o.THUMBNAIL_TIME, `${e}`);
    }
    get videoTitle() {
     var e, i;
     return (i = (e = this.getAttribute(base_o.VIDEO_TITLE)) != null ? e : this.getAttribute(base_o.TITLE)) != null ? i : '';
    }
    set videoTitle(e) {
     e !== this.videoTitle && (e ? this.setAttribute(base_o.VIDEO_TITLE, e) : this.removeAttribute(base_o.VIDEO_TITLE));
    }
    get placeholder() {
     var e;
     return (e = base_U(this, base_o.PLACEHOLDER)) != null ? e : '';
    }
    set placeholder(e) {
     this.setAttribute(base_o.PLACEHOLDER, `${e}`);
    }
    get primaryColor() {
     var i, r;
     let e = this.getAttribute(base_o.PRIMARY_COLOR);
     if (e != null || (this.mediaTheme && ((e = (r = (i = base_k.getComputedStyle(this.mediaTheme)) == null ? void 0 : i.getPropertyValue('--_primary-color')) == null ? void 0 : r.trim()), e))) return e;
    }
    set primaryColor(e) {
     this.setAttribute(base_o.PRIMARY_COLOR, `${e}`);
    }
    get secondaryColor() {
     var i, r;
     let e = this.getAttribute(base_o.SECONDARY_COLOR);
     if (e != null || (this.mediaTheme && ((e = (r = (i = base_k.getComputedStyle(this.mediaTheme)) == null ? void 0 : i.getPropertyValue('--_secondary-color')) == null ? void 0 : r.trim()), e))) return e;
    }
    set secondaryColor(e) {
     this.setAttribute(base_o.SECONDARY_COLOR, `${e}`);
    }
    get accentColor() {
     var i, r;
     let e = this.getAttribute(base_o.ACCENT_COLOR);
     if (e != null || (this.mediaTheme && ((e = (r = (i = base_k.getComputedStyle(this.mediaTheme)) == null ? void 0 : i.getPropertyValue('--_accent-color')) == null ? void 0 : r.trim()), e))) return e;
    }
    set accentColor(e) {
     this.setAttribute(base_o.ACCENT_COLOR, `${e}`);
    }
    get defaultShowRemainingTime() {
     return this.hasAttribute(base_o.DEFAULT_SHOW_REMAINING_TIME);
    }
    set defaultShowRemainingTime(e) {
     e ? this.setAttribute(base_o.DEFAULT_SHOW_REMAINING_TIME, '') : this.removeAttribute(base_o.DEFAULT_SHOW_REMAINING_TIME);
    }
    get playbackRates() {
     if (this.hasAttribute(base_o.PLAYBACK_RATES))
      return this.getAttribute(base_o.PLAYBACK_RATES)
       .trim()
       .split(/\s*,?\s+/)
       .map((e) => Number(e))
       .filter((e) => !Number.isNaN(e))
       .sort((e, i) => e - i);
    }
    set playbackRates(e) {
     if (!e) {
      this.removeAttribute(base_o.PLAYBACK_RATES);
      return;
     }
     this.setAttribute(base_o.PLAYBACK_RATES, e.join(' '));
    }
    get forwardSeekOffset() {
     var e;
     return (e = base_y(this.getAttribute(base_o.FORWARD_SEEK_OFFSET))) != null ? e : 10;
    }
    set forwardSeekOffset(e) {
     this.setAttribute(base_o.FORWARD_SEEK_OFFSET, `${e}`);
    }
    get backwardSeekOffset() {
     var e;
     return (e = base_y(this.getAttribute(base_o.BACKWARD_SEEK_OFFSET))) != null ? e : 10;
    }
    set backwardSeekOffset(e) {
     this.setAttribute(base_o.BACKWARD_SEEK_OFFSET, `${e}`);
    }
    get defaultHiddenCaptions() {
     return this.hasAttribute(base_o.DEFAULT_HIDDEN_CAPTIONS);
    }
    set defaultHiddenCaptions(e) {
     e ? this.setAttribute(base_o.DEFAULT_HIDDEN_CAPTIONS, '') : this.removeAttribute(base_o.DEFAULT_HIDDEN_CAPTIONS);
    }
    get defaultDuration() {
     return base_y(this.getAttribute(base_o.DEFAULT_DURATION));
    }
    set defaultDuration(e) {
     e == null ? this.removeAttribute(base_o.DEFAULT_DURATION) : this.setAttribute(base_o.DEFAULT_DURATION, `${e}`);
    }
    get playerInitTime() {
     return this.hasAttribute(base_e.PLAYER_INIT_TIME) ? base_y(this.getAttribute(base_e.PLAYER_INIT_TIME)) : dist_base_u(this, base_J);
    }
    set playerInitTime(e) {
     e != this.playerInitTime && (e == null ? this.removeAttribute(base_e.PLAYER_INIT_TIME) : this.setAttribute(base_e.PLAYER_INIT_TIME, `${+e}`));
    }
    get playerSoftwareName() {
     var e;
     return (e = this.getAttribute(base_e.PLAYER_SOFTWARE_NAME)) != null ? e : base_xt;
    }
    get playerSoftwareVersion() {
     var e;
     return (e = this.getAttribute(base_e.PLAYER_SOFTWARE_VERSION)) != null ? e : base_Rt;
    }
    get beaconCollectionDomain() {
     var e;
     return (e = this.getAttribute(base_e.BEACON_COLLECTION_DOMAIN)) != null ? e : void 0;
    }
    set beaconCollectionDomain(e) {
     e !== this.beaconCollectionDomain && (e ? this.setAttribute(base_e.BEACON_COLLECTION_DOMAIN, e) : this.removeAttribute(base_e.BEACON_COLLECTION_DOMAIN));
    }
    get maxResolution() {
     var e;
     return (e = this.getAttribute(base_e.MAX_RESOLUTION)) != null ? e : void 0;
    }
    set maxResolution(e) {
     e !== this.maxResolution && (e ? this.setAttribute(base_e.MAX_RESOLUTION, e) : this.removeAttribute(base_e.MAX_RESOLUTION));
    }
    get minResolution() {
     var e;
     return (e = this.getAttribute(base_e.MIN_RESOLUTION)) != null ? e : void 0;
    }
    set minResolution(e) {
     e !== this.minResolution && (e ? this.setAttribute(base_e.MIN_RESOLUTION, e) : this.removeAttribute(base_e.MIN_RESOLUTION));
    }
    get renditionOrder() {
     var e;
     return (e = this.getAttribute(base_e.RENDITION_ORDER)) != null ? e : void 0;
    }
    set renditionOrder(e) {
     e !== this.renditionOrder && (e ? this.setAttribute(base_e.RENDITION_ORDER, e) : this.removeAttribute(base_e.RENDITION_ORDER));
    }
    get programStartTime() {
     return base_y(this.getAttribute(base_e.PROGRAM_START_TIME));
    }
    set programStartTime(e) {
     e == null ? this.removeAttribute(base_e.PROGRAM_START_TIME) : this.setAttribute(base_e.PROGRAM_START_TIME, `${e}`);
    }
    get programEndTime() {
     return base_y(this.getAttribute(base_e.PROGRAM_END_TIME));
    }
    set programEndTime(e) {
     e == null ? this.removeAttribute(base_e.PROGRAM_END_TIME) : this.setAttribute(base_e.PROGRAM_END_TIME, `${e}`);
    }
    get assetStartTime() {
     return base_y(this.getAttribute(base_e.ASSET_START_TIME));
    }
    set assetStartTime(e) {
     e == null ? this.removeAttribute(base_e.ASSET_START_TIME) : this.setAttribute(base_e.ASSET_START_TIME, `${e}`);
    }
    get assetEndTime() {
     return base_y(this.getAttribute(base_e.ASSET_END_TIME));
    }
    set assetEndTime(e) {
     e == null ? this.removeAttribute(base_e.ASSET_END_TIME) : this.setAttribute(base_e.ASSET_END_TIME, `${e}`);
    }
    get extraSourceParams() {
     return this.hasAttribute(base_o.EXTRA_SOURCE_PARAMS) ? [...new URLSearchParams(this.getAttribute(base_o.EXTRA_SOURCE_PARAMS)).entries()].reduce((e, [i, r]) => ((e[i] = r), e), {}) : base_a;
    }
    set extraSourceParams(e) {
     e == null ? this.removeAttribute(base_o.EXTRA_SOURCE_PARAMS) : this.setAttribute(base_o.EXTRA_SOURCE_PARAMS, new URLSearchParams(e).toString());
    }
    get customDomain() {
     var e;
     return (e = this.getAttribute(base_e.CUSTOM_DOMAIN)) != null ? e : void 0;
    }
    set customDomain(e) {
     e !== this.customDomain && (e ? this.setAttribute(base_e.CUSTOM_DOMAIN, e) : this.removeAttribute(base_e.CUSTOM_DOMAIN));
    }
    get envKey() {
     var e;
     return (e = base_U(this, base_e.ENV_KEY)) != null ? e : void 0;
    }
    set envKey(e) {
     this.setAttribute(base_e.ENV_KEY, `${e}`);
    }
    get noVolumePref() {
     return this.hasAttribute(base_o.NO_VOLUME_PREF);
    }
    set noVolumePref(e) {
     e ? this.setAttribute(base_o.NO_VOLUME_PREF, '') : this.removeAttribute(base_o.NO_VOLUME_PREF);
    }
    get debug() {
     return base_U(this, base_e.DEBUG) != null;
    }
    set debug(e) {
     e ? this.setAttribute(base_e.DEBUG, '') : this.removeAttribute(base_e.DEBUG);
    }
    get disableTracking() {
     return base_U(this, base_e.DISABLE_TRACKING) != null;
    }
    set disableTracking(e) {
     this.toggleAttribute(base_e.DISABLE_TRACKING, !!e);
    }
    get disableCookies() {
     return base_U(this, base_e.DISABLE_COOKIES) != null;
    }
    set disableCookies(e) {
     e ? this.setAttribute(base_e.DISABLE_COOKIES, '') : this.removeAttribute(base_e.DISABLE_COOKIES);
    }
    get streamType() {
     var e, i, r;
     return (r = (i = this.getAttribute(base_e.STREAM_TYPE)) != null ? i : (e = this.media) == null ? void 0 : e.streamType) != null ? r : dist_.UNKNOWN;
    }
    set streamType(e) {
     this.setAttribute(base_e.STREAM_TYPE, `${e}`);
    }
    get defaultStreamType() {
     var e, i, r;
     return (r = (i = this.getAttribute(base_o.DEFAULT_STREAM_TYPE)) != null ? i : (e = this.mediaController) == null ? void 0 : e.getAttribute(base_o.DEFAULT_STREAM_TYPE)) != null ? r : dist_.ON_DEMAND;
    }
    set defaultStreamType(e) {
     e ? this.setAttribute(base_o.DEFAULT_STREAM_TYPE, e) : this.removeAttribute(base_o.DEFAULT_STREAM_TYPE);
    }
    get targetLiveWindow() {
     var e, i;
     return this.hasAttribute(base_o.TARGET_LIVE_WINDOW) ? +this.getAttribute(base_o.TARGET_LIVE_WINDOW) : (i = (e = this.media) == null ? void 0 : e.targetLiveWindow) != null ? i : Number.NaN;
    }
    set targetLiveWindow(e) {
     e == this.targetLiveWindow || (Number.isNaN(e) && Number.isNaN(this.targetLiveWindow)) || (e == null ? this.removeAttribute(base_o.TARGET_LIVE_WINDOW) : this.setAttribute(base_o.TARGET_LIVE_WINDOW, `${+e}`));
    }
    get liveEdgeStart() {
     var e;
     return (e = this.media) == null ? void 0 : e.liveEdgeStart;
    }
    get startTime() {
     return base_y(base_U(this, base_e.START_TIME));
    }
    set startTime(e) {
     this.setAttribute(base_e.START_TIME, `${e}`);
    }
    get preferPlayback() {
     let e = this.getAttribute(base_e.PREFER_PLAYBACK);
     if (e === dist_X.MSE || e === dist_X.NATIVE) return e;
    }
    set preferPlayback(e) {
     e !== this.preferPlayback && (e === dist_X.MSE || e === dist_X.NATIVE ? this.setAttribute(base_e.PREFER_PLAYBACK, e) : this.removeAttribute(base_e.PREFER_PLAYBACK));
    }
    get metadata() {
     var e;
     return (e = this.media) == null ? void 0 : e.metadata;
    }
    set metadata(e) {
     if ((base_p(this, base_m, base_w).call(this), !this.media)) {
      E('underlying media element missing when trying to set metadata. metadata will not be set.');
      return;
     }
     this.media.metadata = { ...base_t(this), ...e };
    }
    get _hlsConfig() {
     var e;
     return (e = this.media) == null ? void 0 : e._hlsConfig;
    }
    set _hlsConfig(e) {
     if ((base_p(this, base_m, base_w).call(this), !this.media)) {
      E('underlying media element missing when trying to set _hlsConfig. _hlsConfig will not be set.');
      return;
     }
     this.media._hlsConfig = e;
    }
    async addCuePoints(e) {
     var i;
     if ((base_p(this, base_m, base_w).call(this), !this.media)) {
      E('underlying media element missing when trying to addCuePoints. cuePoints will not be added.');
      return;
     }
     return (i = this.media) == null ? void 0 : i.addCuePoints(e);
    }
    get activeCuePoint() {
     var e;
     return (e = this.media) == null ? void 0 : e.activeCuePoint;
    }
    get cuePoints() {
     var e, i;
     return (i = (e = this.media) == null ? void 0 : e.cuePoints) != null ? i : [];
    }
    addChapters(e) {
     var i;
     if ((base_p(this, base_m, base_w).call(this), !this.media)) {
      E('underlying media element missing when trying to addChapters. chapters will not be added.');
      return;
     }
     return (i = this.media) == null ? void 0 : i.addChapters(e);
    }
    get activeChapter() {
     var e;
     return (e = this.media) == null ? void 0 : e.activeChapter;
    }
    get chapters() {
     var e, i;
     return (i = (e = this.media) == null ? void 0 : e.chapters) != null ? i : [];
    }
    getStartDate() {
     var e;
     return (e = this.media) == null ? void 0 : e.getStartDate();
    }
    get currentPdt() {
     var e;
     return (e = this.media) == null ? void 0 : e.currentPdt;
    }
    get tokens() {
     let e = this.getAttribute(base_o.PLAYBACK_TOKEN),
      i = this.getAttribute(base_o.DRM_TOKEN),
      r = this.getAttribute(base_o.THUMBNAIL_TOKEN),
      n = this.getAttribute(base_o.STORYBOARD_TOKEN);
     return { ...dist_base_u(this, base_te), ...(e != null ? { playback: e } : {}), ...(i != null ? { drm: i } : {}), ...(r != null ? { thumbnail: r } : {}), ...(n != null ? { storyboard: n } : {}) };
    }
    set tokens(e) {
     dist_base_C(this, base_te, e != null ? e : {});
    }
    get playbackToken() {
     var e;
     return (e = this.getAttribute(base_o.PLAYBACK_TOKEN)) != null ? e : void 0;
    }
    set playbackToken(e) {
     this.setAttribute(base_o.PLAYBACK_TOKEN, `${e}`);
    }
    get drmToken() {
     var e;
     return (e = this.getAttribute(base_o.DRM_TOKEN)) != null ? e : void 0;
    }
    set drmToken(e) {
     this.setAttribute(base_o.DRM_TOKEN, `${e}`);
    }
    get thumbnailToken() {
     var e;
     return (e = this.getAttribute(base_o.THUMBNAIL_TOKEN)) != null ? e : void 0;
    }
    set thumbnailToken(e) {
     this.setAttribute(base_o.THUMBNAIL_TOKEN, `${e}`);
    }
    get storyboardToken() {
     var e;
     return (e = this.getAttribute(base_o.STORYBOARD_TOKEN)) != null ? e : void 0;
    }
    set storyboardToken(e) {
     this.setAttribute(base_o.STORYBOARD_TOKEN, `${e}`);
    }
    addTextTrack(e, i, r, n) {
     var l;
     let d = (l = this.media) == null ? void 0 : l.nativeEl;
     if (d) return dist_ne(d, e, i, r, n);
    }
    removeTextTrack(e) {
     var r;
     let i = (r = this.media) == null ? void 0 : r.nativeEl;
     if (i) return dist_st(i, e);
    }
    get textTracks() {
     var e;
     return (e = this.media) == null ? void 0 : e.textTracks;
    }
    get castReceiver() {
     var e;
     return (e = this.getAttribute(base_o.CAST_RECEIVER)) != null ? e : void 0;
    }
    set castReceiver(e) {
     e !== this.castReceiver && (e ? this.setAttribute(base_o.CAST_RECEIVER, e) : this.removeAttribute(base_o.CAST_RECEIVER));
    }
    get castCustomData() {
     var e;
     return (e = this.media) == null ? void 0 : e.castCustomData;
    }
    set castCustomData(e) {
     if (!this.media) {
      E('underlying media element missing when trying to set castCustomData. castCustomData will not be set.');
      return;
     }
     this.media.castCustomData = e;
    }
    get noTooltips() {
     return this.hasAttribute(base_o.NO_TOOLTIPS);
    }
    set noTooltips(e) {
     if (!e) {
      this.removeAttribute(base_o.NO_TOOLTIPS);
      return;
     }
     this.setAttribute(base_o.NO_TOOLTIPS, '');
    }
    get proudlyDisplayMuxBadge() {
     return this.hasAttribute(base_o.PROUDLY_DISPLAY_MUX_BADGE);
    }
    set proudlyDisplayMuxBadge(e) {
     e ? this.setAttribute(base_o.PROUDLY_DISPLAY_MUX_BADGE, '') : this.removeAttribute(base_o.PROUDLY_DISPLAY_MUX_BADGE);
    }
   };
  (base_J = new WeakMap()),
   (base_ee = new WeakMap()),
   (base_te = new WeakMap()),
   (base_I = new WeakMap()),
   (base_ae = new WeakMap()),
   (base_H = new WeakMap()),
   (base_m = new WeakSet()),
   (base_w = function () {
    var e, i, r, n;
    if (!dist_base_u(this, base_ee)) {
     dist_base_C(this, base_ee, !0), base_p(this, base_m, dist_base_B).call(this);
     try {
      if ((customElements.upgrade(this.mediaTheme), !(this.mediaTheme instanceof base_k.HTMLElement))) throw '';
     } catch {
      E('<media-theme> failed to upgrade!');
     }
     try {
      customElements.upgrade(this.media);
     } catch {
      E('underlying media element failed to upgrade!');
     }
     try {
      if ((customElements.upgrade(this.mediaController), !(this.mediaController instanceof media_controller_default))) throw '';
     } catch {
      E('<media-controller> failed to upgrade!');
     }
     base_p(this, base_m, base_St).call(this), base_p(this, base_m, base_Nt).call(this), base_p(this, base_m, base_wt).call(this), dist_base_C(this, base_I, (i = (e = this.mediaController) == null ? void 0 : e.hasAttribute(Attributes.USER_INACTIVE)) != null ? i : !0), base_p(this, base_m, base_It).call(this), (r = this.media) == null || r.addEventListener('streamtypechange', () => base_p(this, base_m, dist_base_B).call(this)), (n = this.media) == null || n.addEventListener('loadstart', () => base_p(this, base_m, dist_base_B).call(this));
    }
   }),
   (base_Mt = function () {
    var e, i;
    try {
     (e = window == null ? void 0 : window.CSS) == null || e.registerProperty({ name: '--media-primary-color', syntax: '<color>', inherits: !0 }), (i = window == null ? void 0 : window.CSS) == null || i.registerProperty({ name: '--media-secondary-color', syntax: '<color>', inherits: !0 });
    } catch {}
   }),
   (base_we = function (e) {
    Object.assign(dist_base_u(this, base_H), e), base_p(this, base_m, dist_base_B).call(this);
   }),
   (dist_base_B = function (e = {}) {
    base_ct(base_bt(base_ya(this, { ...dist_base_u(this, base_H), ...e })), this.shadowRoot);
   }),
   (base_St = function () {
    let e = (r) => {
     var l, b;
     if (!(r != null && r.startsWith('theme-'))) return;
     let n = r.replace(/^theme-/, '');
     if (base_Se.includes(n)) return;
     let d = this.getAttribute(r);
     d != null ? (l = this.mediaTheme) == null || l.setAttribute(n, d) : (b = this.mediaTheme) == null || b.removeAttribute(n);
    };
    new MutationObserver((r) => {
     for (let { attributeName: n } of r) e(n);
    }).observe(this, { attributes: !0 }),
     this.getAttributeNames().forEach(e);
   }),
   (base_Nt = function () {
    let e = (i) => {
     var d;
     let r = (d = this.media) == null ? void 0 : d.error;
     if (!(r instanceof f)) {
      let { message: l, code: b } = r != null ? r : {};
      r = new f(l, b);
     }
     if (!(r != null && r.fatal)) {
      dist_base_x(r), r.data && dist_base_x(`${r.name} data:`, r.data);
      return;
     }
     let n = base_Re(r, !1);
     n.message && base_Ee(n), E(r), r.data && E(`${r.name} data:`, r.data), base_p(this, base_m, base_we).call(this, { isDialogOpen: !0 });
    };
    this.addEventListener('error', e),
     this.media &&
      (this.media.errorTranslator = (i = {}) => {
       var n, d, l;
       if (!(((n = this.media) == null ? void 0 : n.error) instanceof f)) return i;
       let r = base_Re((d = this.media) == null ? void 0 : d.error, !1);
       return { player_error_code: (l = this.media) == null ? void 0 : l.error.code, player_error_message: r.message ? String(r.message) : i.player_error_message, player_error_context: r.context ? String(r.context) : i.player_error_context };
      });
   }),
   (base_wt = function () {
    var i, r, n, d;
    let e = () => base_p(this, base_m, dist_base_B).call(this);
    (r = (i = this.media) == null ? void 0 : i.textTracks) == null || r.addEventListener('addtrack', e), (d = (n = this.media) == null ? void 0 : n.textTracks) == null || d.addEventListener('removetrack', e);
   }),
   (base_It = function () {
    var S, F;
    if (!/Firefox/i.test(navigator.userAgent)) return;
    let i,
     r = new WeakMap(),
     n = () => this.streamType === dist_.LIVE && !this.secondaryColor && this.offsetWidth >= 800,
     d = (_, A, R = !1) => {
      if (n()) return;
      Array.from((_ && _.activeCues) || []).forEach((h) => {
       if (!(!h.snapToLines || h.line < -5 || (h.line >= 0 && h.line < 10)))
        if (!A || this.paused) {
         let ie = h.text.split(`
`).length,
          W = -3;
         this.streamType === dist_.LIVE && (W = -2);
         let Z = W - ie;
         if (h.line === Z && !R) return;
         r.has(h) || r.set(h, h.line), (h.line = Z);
        } else
         setTimeout(() => {
          h.line = r.get(h) || 'auto';
         }, 500);
      });
     },
     l = () => {
      var _, A;
      d(i, (A = (_ = this.mediaController) == null ? void 0 : _.hasAttribute(Attributes.USER_INACTIVE)) != null ? A : !1);
     },
     b = () => {
      var R, K;
      let A = Array.from(((K = (R = this.mediaController) == null ? void 0 : R.media) == null ? void 0 : K.textTracks) || []).filter((h) => ['subtitles', 'captions'].includes(h.kind) && h.mode === 'showing')[0];
      A !== i && (i == null || i.removeEventListener('cuechange', l)), (i = A), i == null || i.addEventListener('cuechange', l), d(i, dist_base_u(this, base_I));
     };
    b(),
     (S = this.textTracks) == null || S.addEventListener('change', b),
     (F = this.textTracks) == null || F.addEventListener('addtrack', b),
     this.addEventListener('userinactivechange', () => {
      var A, R;
      let _ = (R = (A = this.mediaController) == null ? void 0 : A.hasAttribute(Attributes.USER_INACTIVE)) != null ? R : !0;
      dist_base_u(this, base_I) !== _ && (dist_base_C(this, base_I, _), d(i, dist_base_u(this, base_I)));
     });
   });
  function base_U(t, a) {
   return t.media ? t.media.getAttribute(a) : t.getAttribute(a);
  }
  var base_Ei = base_Ne; // CONCATENATED MODULE: ./node_modules/.pnpm/@mux+mux-player@3.5.3_react@18.3.1/node_modules/@mux/mux-player/dist/index.mjs

  var mux_player_dist_c = (e) => {
   throw TypeError(e);
  };
  var dist_d = (e, t, n) => t.has(e) || mux_player_dist_c('Cannot ' + n);
  var mux_player_dist_g = (e, t, n) => (dist_d(e, t, 'read from private field'), n ? n.call(e) : t.get(e)),
   mux_player_dist_p = (e, t, n) => (t.has(e) ? mux_player_dist_c('Cannot add the same private member more than once') : t instanceof WeakSet ? t.add(e) : t.set(e, n)),
   mux_player_dist_f = (e, t, n, i) => (dist_d(e, t, 'write to private field'), i ? i.call(e, n) : t.set(e, n), n);
  var dist_o = class {
   addEventListener() {}
   removeEventListener() {}
   dispatchEvent(t) {
    return !0;
   }
  };
  if (typeof DocumentFragment == 'undefined') {
   class e extends dist_o {}
   globalThis.DocumentFragment = e;
  }
  var dist_s = class extends dist_o {},
   dist_a = class extends dist_o {},
   mux_player_dist_b = {
    get(e) {},
    define(e, t, n) {},
    getName(e) {
     return null;
    },
    upgrade(e) {},
    whenDefined(e) {
     return Promise.resolve(dist_s);
    },
   },
   dist_r,
   mux_player_dist_m = class {
    constructor(t, n = {}) {
     mux_player_dist_p(this, dist_r);
     mux_player_dist_f(this, dist_r, n == null ? void 0 : n.detail);
    }
    get detail() {
     return mux_player_dist_g(this, dist_r);
    }
    initCustomEvent() {}
   };
  dist_r = new WeakMap();
  function mux_player_dist_y(e, t) {
   return new dist_s();
  }
  var dist_h = { document: { createElement: mux_player_dist_y }, DocumentFragment, customElements: mux_player_dist_b, CustomEvent: mux_player_dist_m, EventTarget: dist_o, HTMLElement: dist_s, HTMLVideoElement: dist_a },
   dist_E = typeof window == 'undefined' || typeof globalThis.customElements == 'undefined',
   dist_l = dist_E ? dist_h : globalThis,
   mux_player_dist_x = dist_E ? dist_h.document : globalThis.document;
  dist_l.customElements.get('mux-player') || (dist_l.customElements.define('mux-player', base_Ei), (dist_l.MuxPlayerElement = base_Ei));
  var mux_player_dist_F = /* unused pure expression or super */ null && u; // CONCATENATED MODULE: ./node_modules/.pnpm/@mux+mux-player-react@3.5.3_@types+react-dom@18.3.5_@types+react@18.3.18__@types+react@18.3.1_y6klro52633js4weoramfh7gxq/node_modules/@mux/mux-player-react/dist/index.mjs

  ('use client');
  var dist_M = parseInt(react.version) >= 19,
   mux_player_react_dist_E = { className: 'class', classname: 'class', htmlFor: 'for', crossOrigin: 'crossorigin', viewBox: 'viewBox', playsInline: 'playsinline', autoPlay: 'autoplay', playbackRate: 'playbackrate' },
   mux_player_react_dist_B = (e) => e == null,
   mux_player_react_dist_ee = (e, t) => (mux_player_react_dist_B(t) ? !1 : e in t),
   mux_player_react_dist_te = (e) => e.replace(/[A-Z]/g, (t) => `-${t.toLowerCase()}`),
   mux_player_react_dist_ne = (e, t) => {
    if (!(!dist_M && typeof t == 'boolean' && !t)) {
     if (mux_player_react_dist_ee(e, mux_player_react_dist_E)) return mux_player_react_dist_E[e];
     if (typeof t != 'undefined') return /[A-Z]/.test(e) ? mux_player_react_dist_te(e) : e;
    }
   };
  var dist_ae = (e, t) => (!dist_M && typeof e == 'boolean' ? '' : e),
   dist_P = (e = {}) => {
    let { ref: t, ...n } = e;
    return Object.entries(n).reduce((o, [a, l]) => {
     let i = mux_player_react_dist_ne(a, l);
     if (!i) return o;
     let c = dist_ae(l, a);
     return (o[i] = c), o;
    }, {});
   };
  function mux_player_react_dist_x(e, t) {
   if (typeof e == 'function') return e(t);
   e != null && (e.current = t);
  }
  function mux_player_react_dist_re(...e) {
   return (t) => {
    let n = !1,
     o = e.map((a) => {
      let l = mux_player_react_dist_x(a, t);
      return !n && typeof l == 'function' && (n = !0), l;
     });
    if (n)
     return () => {
      for (let a = 0; a < o.length; a++) {
       let l = o[a];
       typeof l == 'function' ? l() : mux_player_react_dist_x(e[a], null);
      }
     };
   };
  }
  function mux_player_react_dist_f(...e) {
   return react.useCallback(mux_player_react_dist_re(...e), e);
  }
  var dist_oe = Object.prototype.hasOwnProperty,
   dist_ue = (e, t) => {
    if (Object.is(e, t)) return !0;
    if (typeof e != 'object' || e === null || typeof t != 'object' || t === null) return !1;
    if (Array.isArray(e)) return !Array.isArray(t) || e.length !== t.length ? !1 : e.some((a, l) => t[l] === a);
    let n = Object.keys(e),
     o = Object.keys(t);
    if (n.length !== o.length) return !1;
    for (let a = 0; a < n.length; a++) if (!dist_oe.call(t, n[a]) || !Object.is(e[n[a]], t[n[a]])) return !1;
    return !0;
   },
   mux_player_react_dist_p = (e, t, n) => !dist_ue(t, e[n]),
   mux_player_react_dist_se = (e, t, n) => {
    e[n] = t;
   },
   mux_player_react_dist_ie = (e, t, n, o = mux_player_react_dist_se, a = mux_player_react_dist_p) =>
    (0, react.useEffect)(() => {
     let l = n == null ? void 0 : n.current;
     l && a(l, t, e) && o(l, t, e);
    }, [n == null ? void 0 : n.current, t]),
   mux_player_react_dist_u = mux_player_react_dist_ie;
  var mux_player_react_dist_ye = () => {
    try {
     return '3.5.3';
    } catch {}
    return 'UNKNOWN';
   },
   dist_me = mux_player_react_dist_ye(),
   mux_player_react_dist_g = () => dist_me;
  var mux_player_react_dist_r = (e, t, n) =>
   (0, react.useEffect)(() => {
    let o = t == null ? void 0 : t.current;
    if (!o || !n) return;
    let a = e,
     l = n;
    return (
     o.addEventListener(a, l),
     () => {
      o.removeEventListener(a, l);
     }
    );
   }, [t == null ? void 0 : t.current, n, e]);
  var mux_player_react_dist_Pe = react.forwardRef(({ children: e, ...t }, n) => react.createElement('mux-player', { suppressHydrationWarning: !0, ...dist_P(t), ref: n }, e)),
   dist_xe = (e, t) => {
    let { onAbort: n, onCanPlay: o, onCanPlayThrough: a, onEmptied: l, onLoadStart: i, onLoadedData: c, onLoadedMetadata: v, onProgress: R, onDurationChange: T, onVolumeChange: h, onRateChange: b, onResize: C, onWaiting: k, onPlay: O, onPlaying: S, onTimeUpdate: w, onPause: N, onSeeking: L, onSeeked: A, onStalled: I, onSuspend: _, onEnded: K, onError: H, onCuePointChange: D, onChapterChange: V, metadata: W, tokens: U, paused: z, playbackId: F, playbackRates: G, currentTime: Z, themeProps: j, extraSourceParams: q, castCustomData: J, _hlsConfig: Y, ...$ } = t;
    return (
     mux_player_react_dist_u('tokens', U, e),
     mux_player_react_dist_u('playbackId', F, e),
     mux_player_react_dist_u('playbackRates', G, e),
     mux_player_react_dist_u('metadata', W, e),
     mux_player_react_dist_u('extraSourceParams', q, e),
     mux_player_react_dist_u('_hlsConfig', Y, e),
     mux_player_react_dist_u('themeProps', j, e),
     mux_player_react_dist_u('castCustomData', J, e),
     mux_player_react_dist_u(
      'paused',
      z,
      e,
      (s, y) => {
       y != null && (y ? s.pause() : s.play());
      },
      (s, y, Q) => (s.hasAttribute('autoplay') && !s.hasPlayed ? !1 : mux_player_react_dist_p(s, y, Q)),
     ),
     mux_player_react_dist_u('currentTime', Z, e, (s, y) => {
      y != null && (s.currentTime = y);
     }),
     mux_player_react_dist_r('abort', e, n),
     mux_player_react_dist_r('canplay', e, o),
     mux_player_react_dist_r('canplaythrough', e, a),
     mux_player_react_dist_r('emptied', e, l),
     mux_player_react_dist_r('loadstart', e, i),
     mux_player_react_dist_r('loadeddata', e, c),
     mux_player_react_dist_r('loadedmetadata', e, v),
     mux_player_react_dist_r('progress', e, R),
     mux_player_react_dist_r('durationchange', e, T),
     mux_player_react_dist_r('volumechange', e, h),
     mux_player_react_dist_r('ratechange', e, b),
     mux_player_react_dist_r('resize', e, C),
     mux_player_react_dist_r('waiting', e, k),
     mux_player_react_dist_r('play', e, O),
     mux_player_react_dist_r('playing', e, S),
     mux_player_react_dist_r('timeupdate', e, w),
     mux_player_react_dist_r('pause', e, N),
     mux_player_react_dist_r('seeking', e, L),
     mux_player_react_dist_r('seeked', e, A),
     mux_player_react_dist_r('stalled', e, I),
     mux_player_react_dist_r('suspend', e, _),
     mux_player_react_dist_r('ended', e, K),
     mux_player_react_dist_r('error', e, H),
     mux_player_react_dist_r('cuepointchange', e, D),
     mux_player_react_dist_r('chapterchange', e, V),
     [$]
    );
   },
   mux_player_react_dist_de = mux_player_react_dist_g(),
   mux_player_react_dist_fe = 'mux-player-react',
   mux_player_react_dist_ge = react.forwardRef((e, t) => {
    var i;
    let n = (0, react.useRef)(null),
     o = mux_player_react_dist_f(n, t),
     [a] = dist_xe(n, e),
     [l] = (0, react.useState)((i = e.playerInitTime) != null ? i : dist_Wr());
    return react.createElement(mux_player_react_dist_Pe, { ref: o, defaultHiddenCaptions: e.defaultHiddenCaptions, playerSoftwareName: mux_player_react_dist_fe, playerSoftwareVersion: mux_player_react_dist_de, playerInitTime: l, ...a });
   }),
   mux_player_react_dist_ze = mux_player_react_dist_ge;
  //# sourceMappingURL=index.mjs.map

  /***/
 },

 /***/ 60922: /***/ (__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {
  /* harmony export */ __webpack_require__.d(__webpack_exports__, {
   /* harmony export */ zM: () => /* binding */ CustomVideoElement,
   /* harmony export */
  });
  /* unused harmony exports Attributes, CustomAudioElement, CustomMediaMixin, Events */
  const Events = ['abort', 'canplay', 'canplaythrough', 'durationchange', 'emptied', 'encrypted', 'ended', 'error', 'loadeddata', 'loadedmetadata', 'loadstart', 'pause', 'play', 'playing', 'progress', 'ratechange', 'seeked', 'seeking', 'stalled', 'suspend', 'timeupdate', 'volumechange', 'waiting', 'waitingforkey', 'resize', 'enterpictureinpicture', 'leavepictureinpicture', 'webkitbeginfullscreen', 'webkitendfullscreen', 'webkitpresentationmodechanged'];
  const Attributes = ['autopictureinpicture', 'disablepictureinpicture', 'disableremoteplayback', 'autoplay', 'controls', 'controlslist', 'crossorigin', 'loop', 'muted', 'playsinline', 'poster', 'preload', 'src'];
  function getAudioTemplateHTML(attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        display: inline-flex;
        line-height: 0;
        flex-direction: column;
        justify-content: end;
      }

      audio {
        width: 100%;
      }
    </style>
    <slot name="media">
      <audio${serializeAttributes(attrs)}></audio>
    </slot>
    <slot></slot>
  `
   );
  }
  function getVideoTemplateHTML(attrs) {
   return (
    /*html*/
    `
    <style>
      :host {
        display: inline-block;
        line-height: 0;
      }

      video {
        max-width: 100%;
        max-height: 100%;
        min-width: 100%;
        min-height: 100%;
        object-fit: var(--media-object-fit, contain);
        object-position: var(--media-object-position, 50% 50%);
      }

      video::-webkit-media-text-track-container {
        transform: var(--media-webkit-text-track-transform);
        transition: var(--media-webkit-text-track-transition);
      }
    </style>
    <slot name="media">
      <video${serializeAttributes(attrs)}></video>
    </slot>
    <slot></slot>
  `
   );
  }
  function CustomMediaMixin(superclass, { tag, is }) {
   const nativeElTest = globalThis.document?.createElement?.(tag, { is });
   const nativeElProps = nativeElTest ? getNativeElProps(nativeElTest) : [];
   return class CustomMedia extends superclass {
    static getTemplateHTML = tag.endsWith('audio') ? getAudioTemplateHTML : getVideoTemplateHTML;
    static shadowRootOptions = { mode: 'open' };
    static Events = Events;
    static #isDefined = false;
    static get observedAttributes() {
     CustomMedia.#define();
     const natAttrs = nativeElTest?.constructor?.observedAttributes ?? [];
     return [...natAttrs, ...Attributes];
    }
    static #define() {
     if (this.#isDefined) return;
     this.#isDefined = true;
     const propsToAttrs = new Set(this.observedAttributes);
     propsToAttrs.delete('muted');
     for (const prop of nativeElProps) {
      if (prop in this.prototype) continue;
      if (typeof nativeElTest[prop] === 'function') {
       this.prototype[prop] = function (...args) {
        this.#init();
        const fn = () => {
         if (this.call) return this.call(prop, ...args);
         const nativeFn = this.nativeEl?.[prop];
         return nativeFn?.apply(this.nativeEl, args);
        };
        return fn();
       };
      } else {
       const config = {
        get() {
         this.#init();
         const attr = prop.toLowerCase();
         if (propsToAttrs.has(attr)) {
          const val = this.getAttribute(attr);
          return val === null ? false : val === '' ? true : val;
         }
         return this.get?.(prop) ?? this.nativeEl?.[prop];
        },
       };
       if (prop !== prop.toUpperCase()) {
        config.set = function (val) {
         this.#init();
         const attr = prop.toLowerCase();
         if (propsToAttrs.has(attr)) {
          if (val === true || val === false || val == null) {
           this.toggleAttribute(attr, Boolean(val));
          } else {
           this.setAttribute(attr, val);
          }
          return;
         }
         if (this.set) {
          this.set(prop, val);
          return;
         }
         if (this.nativeEl) {
          this.nativeEl[prop] = val;
         }
        };
       }
       Object.defineProperty(this.prototype, prop, config);
      }
     }
    }
    // Private fields
    #isInit = false;
    #nativeEl = null;
    #childMap = /* @__PURE__ */ new Map();
    #childObserver;
    get;
    set;
    call;
    // If the custom element is defined before the custom element's HTML is parsed
    // no attributes will be available in the constructor (construction process).
    // Wait until initializing in the attributeChangedCallback or
    // connectedCallback or accessing any properties.
    get nativeEl() {
     this.#init();
     return this.#nativeEl ?? this.querySelector(':scope > [slot=media]') ?? this.querySelector(tag) ?? this.shadowRoot?.querySelector(tag) ?? null;
    }
    set nativeEl(val) {
     this.#nativeEl = val;
    }
    get defaultMuted() {
     return this.hasAttribute('muted');
    }
    set defaultMuted(val) {
     this.toggleAttribute('muted', val);
    }
    get src() {
     return this.getAttribute('src');
    }
    set src(val) {
     this.setAttribute('src', `${val}`);
    }
    get preload() {
     return this.getAttribute('preload') ?? this.nativeEl?.preload;
    }
    set preload(val) {
     this.setAttribute('preload', `${val}`);
    }
    #init() {
     if (this.#isInit) return;
     this.#isInit = true;
     this.init();
    }
    init() {
     if (!this.shadowRoot) {
      this.attachShadow({ mode: 'open' });
      const attrs = namedNodeMapToObject(this.attributes);
      if (is) attrs.is = is;
      if (tag) attrs.part = tag;
      this.shadowRoot.innerHTML = this.constructor.getTemplateHTML(attrs);
     }
     this.nativeEl.muted = this.hasAttribute('muted');
     for (const prop of nativeElProps) {
      this.#upgradeProperty(prop);
     }
     this.#childObserver = new MutationObserver(this.#syncMediaChildAttribute.bind(this));
     this.shadowRoot.addEventListener('slotchange', () => this.#syncMediaChildren());
     this.#syncMediaChildren();
     for (const type of this.constructor.Events) {
      this.shadowRoot.addEventListener(type, this, true);
     }
    }
    handleEvent(event) {
     if (event.target === this.nativeEl) {
      this.dispatchEvent(new CustomEvent(event.type, { detail: event.detail }));
     }
    }
    #syncMediaChildren() {
     const removeNativeChildren = new Map(this.#childMap);
     const defaultSlot = this.shadowRoot?.querySelector('slot:not([name])');
     const mediaChildren = defaultSlot?.assignedElements({ flatten: true }).filter((el) => ['track', 'source'].includes(el.localName));
     mediaChildren.forEach((el) => {
      removeNativeChildren.delete(el);
      let clone = this.#childMap.get(el);
      if (!clone) {
       clone = el.cloneNode();
       this.#childMap.set(el, clone);
       this.#childObserver?.observe(el, { attributes: true });
      }
      this.nativeEl?.append(clone);
      this.#enableDefaultTrack(clone);
     });
     removeNativeChildren.forEach((clone, el) => {
      clone.remove();
      this.#childMap.delete(el);
     });
    }
    #syncMediaChildAttribute(mutations) {
     for (const mutation of mutations) {
      if (mutation.type === 'attributes') {
       const { target, attributeName } = mutation;
       const clone = this.#childMap.get(target);
       if (clone && attributeName) {
        clone.setAttribute(attributeName, target.getAttribute(attributeName) ?? '');
        this.#enableDefaultTrack(clone);
       }
      }
     }
    }
    #enableDefaultTrack(trackEl) {
     if (trackEl && trackEl.localName === 'track' && trackEl.default && (trackEl.kind === 'chapters' || trackEl.kind === 'metadata') && trackEl.track.mode === 'disabled') {
      trackEl.track.mode = 'hidden';
     }
    }
    #upgradeProperty(prop) {
     if (Object.prototype.hasOwnProperty.call(this, prop)) {
      const value = this[prop];
      delete this[prop];
      this[prop] = value;
     }
    }
    attributeChangedCallback(attrName, oldValue, newValue) {
     this.#init();
     this.#forwardAttribute(attrName, oldValue, newValue);
    }
    #forwardAttribute(attrName, _oldValue, newValue) {
     if (['id', 'class'].includes(attrName)) return;
     if (!CustomMedia.observedAttributes.includes(attrName) && this.constructor.observedAttributes.includes(attrName)) {
      return;
     }
     if (newValue === null) {
      this.nativeEl?.removeAttribute(attrName);
     } else if (this.nativeEl?.getAttribute(attrName) !== newValue) {
      this.nativeEl?.setAttribute(attrName, newValue);
     }
    }
    connectedCallback() {
     this.#init();
    }
   };
  }
  function getNativeElProps(nativeElTest) {
   const nativeElProps = [];
   for (let proto = Object.getPrototypeOf(nativeElTest); proto && proto !== HTMLElement.prototype; proto = Object.getPrototypeOf(proto)) {
    const props = Object.getOwnPropertyNames(proto);
    nativeElProps.push(...props);
   }
   return nativeElProps;
  }
  function serializeAttributes(attrs) {
   let html = '';
   for (const key in attrs) {
    if (!Attributes.includes(key)) continue;
    const value = attrs[key];
    if (value === '') html += ` ${key}`;
    else html += ` ${key}="${value}"`;
   }
   return html;
  }
  function namedNodeMapToObject(namedNodeMap) {
   const obj = {};
   for (const attr of namedNodeMap) {
    obj[attr.name] = attr.value;
   }
   return obj;
  }
  const CustomVideoElement = CustomMediaMixin(globalThis.HTMLElement ?? class {}, {
   tag: 'video',
  });
  const CustomAudioElement = CustomMediaMixin(globalThis.HTMLElement ?? class {}, {
   tag: 'audio',
  });

  /***/
 },

 /***/ 91899: /***/ (__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {
  /* harmony export */ __webpack_require__.d(__webpack_exports__, {
   /* harmony export */ ZP: () => /* binding */ Hls,
   /* harmony export */
  });
  /* unused harmony exports AbrController, AttrList, AudioStreamController, AudioTrackController, BasePlaylistController, BaseSegment, BaseStreamController, BufferController, CMCDController, CapLevelController, ChunkMetadata, ContentSteeringController, Cues, DateRange, EMEController, ErrorActionFlags, ErrorController, ErrorDetails, ErrorTypes, Events, FPSController, FetchLoader, Fragment, Hls, HlsSkip, HlsUrlParameters, KeySystemFormats, KeySystems, Level, LevelDetails, LevelKey, LoadStats, M3U8Parser, MetadataSchema, NetworkErrorAction, Part, PlaylistLevelType, SubtitleStreamController, SubtitleTrackController, TimelineController, XhrLoader, fetchSupported, getMediaSource, isMSESupported, isSupported, requestMediaKeySystemAccess */
  // https://caniuse.com/mdn-javascript_builtins_number_isfinite
  const isFiniteNumber =
   Number.isFinite ||
   function (value) {
    return typeof value === 'number' && isFinite(value);
   };

  // https://caniuse.com/mdn-javascript_builtins_number_issafeinteger
  const isSafeInteger =
   Number.isSafeInteger ||
   function (value) {
    return typeof value === 'number' && Math.abs(value) <= MAX_SAFE_INTEGER;
   };
  const MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;

  let ErrorTypes = /*#__PURE__*/ (function (ErrorTypes) {
   // Identifier for a network error (loading error / timeout ...)
   ErrorTypes['NETWORK_ERROR'] = 'networkError';
   // Identifier for a media Error (video/parsing/mediasource error)
   ErrorTypes['MEDIA_ERROR'] = 'mediaError';
   // EME (encrypted media extensions) errors
   ErrorTypes['KEY_SYSTEM_ERROR'] = 'keySystemError';
   // Identifier for a mux Error (demuxing/remuxing)
   ErrorTypes['MUX_ERROR'] = 'muxError';
   // Identifier for all other errors
   ErrorTypes['OTHER_ERROR'] = 'otherError';
   return ErrorTypes;
  })({});
  let ErrorDetails = /*#__PURE__*/ (function (ErrorDetails) {
   ErrorDetails['KEY_SYSTEM_NO_KEYS'] = 'keySystemNoKeys';
   ErrorDetails['KEY_SYSTEM_NO_ACCESS'] = 'keySystemNoAccess';
   ErrorDetails['KEY_SYSTEM_NO_SESSION'] = 'keySystemNoSession';
   ErrorDetails['KEY_SYSTEM_NO_CONFIGURED_LICENSE'] = 'keySystemNoConfiguredLicense';
   ErrorDetails['KEY_SYSTEM_LICENSE_REQUEST_FAILED'] = 'keySystemLicenseRequestFailed';
   ErrorDetails['KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED'] = 'keySystemServerCertificateRequestFailed';
   ErrorDetails['KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED'] = 'keySystemServerCertificateUpdateFailed';
   ErrorDetails['KEY_SYSTEM_SESSION_UPDATE_FAILED'] = 'keySystemSessionUpdateFailed';
   ErrorDetails['KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED'] = 'keySystemStatusOutputRestricted';
   ErrorDetails['KEY_SYSTEM_STATUS_INTERNAL_ERROR'] = 'keySystemStatusInternalError';
   ErrorDetails['KEY_SYSTEM_DESTROY_MEDIA_KEYS_ERROR'] = 'keySystemDestroyMediaKeysError';
   ErrorDetails['KEY_SYSTEM_DESTROY_CLOSE_SESSION_ERROR'] = 'keySystemDestroyCloseSessionError';
   ErrorDetails['KEY_SYSTEM_DESTROY_REMOVE_SESSION_ERROR'] = 'keySystemDestroyRemoveSessionError';
   // Identifier for a manifest load error - data: { url : faulty URL, response : { code: error code, text: error text }}
   ErrorDetails['MANIFEST_LOAD_ERROR'] = 'manifestLoadError';
   // Identifier for a manifest load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}
   ErrorDetails['MANIFEST_LOAD_TIMEOUT'] = 'manifestLoadTimeOut';
   // Identifier for a manifest parsing error - data: { url : faulty URL, reason : error reason}
   ErrorDetails['MANIFEST_PARSING_ERROR'] = 'manifestParsingError';
   // Identifier for a manifest with only incompatible codecs error - data: { url : faulty URL, reason : error reason}
   ErrorDetails['MANIFEST_INCOMPATIBLE_CODECS_ERROR'] = 'manifestIncompatibleCodecsError';
   // Identifier for a level which contains no fragments - data: { url: faulty URL, reason: "no fragments found in level", level: index of the bad level }
   ErrorDetails['LEVEL_EMPTY_ERROR'] = 'levelEmptyError';
   // Identifier for a level load error - data: { url : faulty URL, response : { code: error code, text: error text }}
   ErrorDetails['LEVEL_LOAD_ERROR'] = 'levelLoadError';
   // Identifier for a level load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}
   ErrorDetails['LEVEL_LOAD_TIMEOUT'] = 'levelLoadTimeOut';
   // Identifier for a level parse error - data: { url : faulty URL, error: Error, reason: error message }
   ErrorDetails['LEVEL_PARSING_ERROR'] = 'levelParsingError';
   // Identifier for a level switch error - data: { level : faulty level Id, event : error description}
   ErrorDetails['LEVEL_SWITCH_ERROR'] = 'levelSwitchError';
   // Identifier for an audio track load error - data: { url : faulty URL, response : { code: error code, text: error text }}
   ErrorDetails['AUDIO_TRACK_LOAD_ERROR'] = 'audioTrackLoadError';
   // Identifier for an audio track load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}
   ErrorDetails['AUDIO_TRACK_LOAD_TIMEOUT'] = 'audioTrackLoadTimeOut';
   // Identifier for a subtitle track load error - data: { url : faulty URL, response : { code: error code, text: error text }}
   ErrorDetails['SUBTITLE_LOAD_ERROR'] = 'subtitleTrackLoadError';
   // Identifier for a subtitle track load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}
   ErrorDetails['SUBTITLE_TRACK_LOAD_TIMEOUT'] = 'subtitleTrackLoadTimeOut';
   // Identifier for fragment load error - data: { frag : fragment object, response : { code: error code, text: error text }}
   ErrorDetails['FRAG_LOAD_ERROR'] = 'fragLoadError';
   // Identifier for fragment load timeout error - data: { frag : fragment object}
   ErrorDetails['FRAG_LOAD_TIMEOUT'] = 'fragLoadTimeOut';
   // Identifier for a fragment decryption error event - data: {id : demuxer Id,frag: fragment object, reason : parsing error description }
   ErrorDetails['FRAG_DECRYPT_ERROR'] = 'fragDecryptError';
   // Identifier for a fragment parsing error event - data: { id : demuxer Id, reason : parsing error description }
   // will be renamed DEMUX_PARSING_ERROR and switched to MUX_ERROR in the next major release
   ErrorDetails['FRAG_PARSING_ERROR'] = 'fragParsingError';
   // Identifier for a fragment or part load skipped because of a GAP tag or attribute
   ErrorDetails['FRAG_GAP'] = 'fragGap';
   // Identifier for a remux alloc error event - data: { id : demuxer Id, frag : fragment object, bytes : nb of bytes on which allocation failed , reason : error text }
   ErrorDetails['REMUX_ALLOC_ERROR'] = 'remuxAllocError';
   // Identifier for decrypt key load error - data: { frag : fragment object, response : { code: error code, text: error text }}
   ErrorDetails['KEY_LOAD_ERROR'] = 'keyLoadError';
   // Identifier for decrypt key load timeout error - data: { frag : fragment object}
   ErrorDetails['KEY_LOAD_TIMEOUT'] = 'keyLoadTimeOut';
   // Triggered when an exception occurs while adding a sourceBuffer to MediaSource - data : { error : exception , mimeType : mimeType }
   ErrorDetails['BUFFER_ADD_CODEC_ERROR'] = 'bufferAddCodecError';
   // Triggered when source buffer(s) could not be created using level (manifest CODECS attribute), parsed media, or best guess codec(s) - data: { reason : error reason }
   ErrorDetails['BUFFER_INCOMPATIBLE_CODECS_ERROR'] = 'bufferIncompatibleCodecsError';
   // Identifier for a buffer append error - data: append error description
   ErrorDetails['BUFFER_APPEND_ERROR'] = 'bufferAppendError';
   // Identifier for a buffer appending error event - data: appending error description
   ErrorDetails['BUFFER_APPENDING_ERROR'] = 'bufferAppendingError';
   // Identifier for a buffer stalled error event
   ErrorDetails['BUFFER_STALLED_ERROR'] = 'bufferStalledError';
   // Identifier for a buffer full event
   ErrorDetails['BUFFER_FULL_ERROR'] = 'bufferFullError';
   // Identifier for a buffer seek over hole event
   ErrorDetails['BUFFER_SEEK_OVER_HOLE'] = 'bufferSeekOverHole';
   // Identifier for a buffer nudge on stall (playback is stuck although currentTime is in a buffered area)
   ErrorDetails['BUFFER_NUDGE_ON_STALL'] = 'bufferNudgeOnStall';
   // Identifier for a Interstitial Asset List load error - data: { url: faulty URL, response: { code: error code, text: error text } }
   ErrorDetails['ASSET_LIST_LOAD_ERROR'] = 'assetListLoadError';
   // Identifier for a Interstitial Asset List load timeout - data: { url: faulty URL, response: { code: error code, text: error text } }
   ErrorDetails['ASSET_LIST_LOAD_TIMEOUT'] = 'assetListLoadTimeout';
   // Identifier for a Interstitial Asset List parsing error - data: { url : faulty URL, reason : error reason, response : { code: error code, text: error text }}
   ErrorDetails['ASSET_LIST_PARSING_ERROR'] = 'assetListParsingError';
   // Identifier for a Interstitial Asset List parsing error - data: { url : faulty URL, reason : error reason, response : { code: error code, text: error text }}
   ErrorDetails['INTERSTITIAL_ASSET_ITEM_ERROR'] = 'interstitialAssetItemError';
   // Identifier for an internal exception happening inside hls.js while handling an event
   ErrorDetails['INTERNAL_EXCEPTION'] = 'internalException';
   // Identifier for an internal call to abort a loader
   ErrorDetails['INTERNAL_ABORTED'] = 'aborted';
   // Triggered when attachMedia fails
   ErrorDetails['ATTACH_MEDIA_ERROR'] = 'attachMediaError';
   // Uncategorized error
   ErrorDetails['UNKNOWN'] = 'unknown';
   return ErrorDetails;
  })({});

  let Events = /*#__PURE__*/ (function (Events) {
   // Fired before MediaSource is attaching to media element
   Events['MEDIA_ATTACHING'] = 'hlsMediaAttaching';
   // Fired when MediaSource has been successfully attached to media element
   Events['MEDIA_ATTACHED'] = 'hlsMediaAttached';
   // Fired before detaching MediaSource from media element
   Events['MEDIA_DETACHING'] = 'hlsMediaDetaching';
   // Fired when MediaSource has been detached from media element
   Events['MEDIA_DETACHED'] = 'hlsMediaDetached';
   // Fired when HTMLMediaElement dispatches "ended" event, or stalls at end of VOD program
   Events['MEDIA_ENDED'] = 'hlsMediaEnded';
   // Fired after playback stall is resolved with playing, seeked, or ended event following BUFFER_STALLED_ERROR
   Events['STALL_RESOLVED'] = 'hlsStallResolved';
   // Fired when the buffer is going to be reset
   Events['BUFFER_RESET'] = 'hlsBufferReset';
   // Fired when we know about the codecs that we need buffers for to push into - data: {tracks : { container, codec, levelCodec, initSegment, metadata }}
   Events['BUFFER_CODECS'] = 'hlsBufferCodecs';
   // fired when sourcebuffers have been created - data: { tracks : tracks }
   Events['BUFFER_CREATED'] = 'hlsBufferCreated';
   // fired when we append a segment to the buffer - data: { segment: segment object }
   Events['BUFFER_APPENDING'] = 'hlsBufferAppending';
   // fired when we are done with appending a media segment to the buffer - data : { parent : segment parent that triggered BUFFER_APPENDING, pending : nb of segments waiting for appending for this segment parent}
   Events['BUFFER_APPENDED'] = 'hlsBufferAppended';
   // fired when the stream is finished and we want to notify the media buffer that there will be no more data - data: { }
   Events['BUFFER_EOS'] = 'hlsBufferEos';
   // fired when all buffers are full to the end of the program, after calling MediaSource.endOfStream() (unless restricted)
   Events['BUFFERED_TO_END'] = 'hlsBufferedToEnd';
   // fired when the media buffer should be flushed - data { startOffset, endOffset }
   Events['BUFFER_FLUSHING'] = 'hlsBufferFlushing';
   // fired when the media buffer has been flushed - data: { }
   Events['BUFFER_FLUSHED'] = 'hlsBufferFlushed';
   // fired to signal that a manifest loading starts - data: { url : manifestURL}
   Events['MANIFEST_LOADING'] = 'hlsManifestLoading';
   // fired after manifest has been loaded - data: { levels : [available quality levels], audioTracks : [ available audio tracks ], url : manifestURL, stats : LoaderStats }
   Events['MANIFEST_LOADED'] = 'hlsManifestLoaded';
   // fired after manifest has been parsed - data: { levels : [available quality levels], firstLevel : index of first quality level appearing in Manifest}
   Events['MANIFEST_PARSED'] = 'hlsManifestParsed';
   // fired when a level switch is requested - data: { level : id of new level }
   Events['LEVEL_SWITCHING'] = 'hlsLevelSwitching';
   // fired when a level switch is effective - data: { level : id of new level }
   Events['LEVEL_SWITCHED'] = 'hlsLevelSwitched';
   // fired when a level playlist loading starts - data: { url : level URL, level : id of level being loaded}
   Events['LEVEL_LOADING'] = 'hlsLevelLoading';
   // fired when a level playlist loading finishes - data: { details : levelDetails object, level : id of loaded level, stats : LoaderStats }
   Events['LEVEL_LOADED'] = 'hlsLevelLoaded';
   // fired when a level's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, level : id of updated level }
   Events['LEVEL_UPDATED'] = 'hlsLevelUpdated';
   // fired when a level's PTS information has been updated after parsing a fragment - data: { details : levelDetails object, level : id of updated level, drift: PTS drift observed when parsing last fragment }
   Events['LEVEL_PTS_UPDATED'] = 'hlsLevelPtsUpdated';
   // fired to notify that levels have changed after removing a level - data: { levels : [available quality levels] }
   Events['LEVELS_UPDATED'] = 'hlsLevelsUpdated';
   // fired to notify that audio track lists has been updated - data: { audioTracks : audioTracks }
   Events['AUDIO_TRACKS_UPDATED'] = 'hlsAudioTracksUpdated';
   // fired when an audio track switching is requested - data: { id : audio track id }
   Events['AUDIO_TRACK_SWITCHING'] = 'hlsAudioTrackSwitching';
   // fired when an audio track switch actually occurs - data: { id : audio track id }
   Events['AUDIO_TRACK_SWITCHED'] = 'hlsAudioTrackSwitched';
   // fired when an audio track loading starts - data: { url : audio track URL, id : audio track id }
   Events['AUDIO_TRACK_LOADING'] = 'hlsAudioTrackLoading';
   // fired when an audio track loading finishes - data: { details : levelDetails object, id : audio track id, stats : LoaderStats }
   Events['AUDIO_TRACK_LOADED'] = 'hlsAudioTrackLoaded';
   // fired when an audio tracks's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, id : track id }
   Events['AUDIO_TRACK_UPDATED'] = 'hlsAudioTrackUpdated';
   // fired to notify that subtitle track lists has been updated - data: { subtitleTracks : subtitleTracks }
   Events['SUBTITLE_TRACKS_UPDATED'] = 'hlsSubtitleTracksUpdated';
   // fired to notify that subtitle tracks were cleared as a result of stopping the media
   Events['SUBTITLE_TRACKS_CLEARED'] = 'hlsSubtitleTracksCleared';
   // fired when an subtitle track switch occurs - data: { id : subtitle track id }
   Events['SUBTITLE_TRACK_SWITCH'] = 'hlsSubtitleTrackSwitch';
   // fired when a subtitle track loading starts - data: { url : subtitle track URL, id : subtitle track id }
   Events['SUBTITLE_TRACK_LOADING'] = 'hlsSubtitleTrackLoading';
   // fired when a subtitle track loading finishes - data: { details : levelDetails object, id : subtitle track id, stats : LoaderStats }
   Events['SUBTITLE_TRACK_LOADED'] = 'hlsSubtitleTrackLoaded';
   // fired when a subtitle  racks's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, id : track id }
   Events['SUBTITLE_TRACK_UPDATED'] = 'hlsSubtitleTrackUpdated';
   // fired when a subtitle fragment has been processed - data: { success : boolean, frag : the processed frag }
   Events['SUBTITLE_FRAG_PROCESSED'] = 'hlsSubtitleFragProcessed';
   // fired when a set of VTTCues to be managed externally has been parsed - data: { type: string, track: string, cues: [ VTTCue ] }
   Events['CUES_PARSED'] = 'hlsCuesParsed';
   // fired when a text track to be managed externally is found - data: { tracks: [ { label: string, kind: string, default: boolean } ] }
   Events['NON_NATIVE_TEXT_TRACKS_FOUND'] = 'hlsNonNativeTextTracksFound';
   // fired when the first timestamp is found - data: { id : demuxer id, initPTS: initPTS, timescale: timescale, frag : fragment object }
   Events['INIT_PTS_FOUND'] = 'hlsInitPtsFound';
   // fired when a fragment loading starts - data: { frag : fragment object }
   Events['FRAG_LOADING'] = 'hlsFragLoading';
   // fired when a fragment loading is progressing - data: { frag : fragment object, { trequest, tfirst, loaded } }
   // FRAG_LOAD_PROGRESS = 'hlsFragLoadProgress',
   // Identifier for fragment load aborting for emergency switch down - data: { frag : fragment object }
   Events['FRAG_LOAD_EMERGENCY_ABORTED'] = 'hlsFragLoadEmergencyAborted';
   // fired when a fragment loading is completed - data: { frag : fragment object, payload : fragment payload, stats : LoaderStats }
   Events['FRAG_LOADED'] = 'hlsFragLoaded';
   // fired when a fragment has finished decrypting - data: { id : demuxer id, frag: fragment object, payload : fragment payload, stats : { tstart, tdecrypt } }
   Events['FRAG_DECRYPTED'] = 'hlsFragDecrypted';
   // fired when Init Segment has been extracted from fragment - data: { id : demuxer id, frag: fragment object, moov : moov MP4 box, codecs : codecs found while parsing fragment }
   Events['FRAG_PARSING_INIT_SEGMENT'] = 'hlsFragParsingInitSegment';
   // fired when parsing sei text is completed - data: { id : demuxer id, frag: fragment object, samples : [ sei samples pes ] }
   Events['FRAG_PARSING_USERDATA'] = 'hlsFragParsingUserdata';
   // fired when parsing id3 is completed - data: { id : demuxer id, frag: fragment object, samples : [ id3 samples pes ] }
   Events['FRAG_PARSING_METADATA'] = 'hlsFragParsingMetadata';
   // fired when data have been extracted from fragment - data: { id : demuxer id, frag: fragment object, data1 : moof MP4 box or TS fragments, data2 : mdat MP4 box or null}
   // FRAG_PARSING_DATA = 'hlsFragParsingData',
   // fired when fragment parsing is completed - data: { id : demuxer id, frag: fragment object }
   Events['FRAG_PARSED'] = 'hlsFragParsed';
   // fired when fragment remuxed MP4 boxes have all been appended into SourceBuffer - data: { id : demuxer id, frag : fragment object, stats : LoaderStats }
   Events['FRAG_BUFFERED'] = 'hlsFragBuffered';
   // fired when fragment matching with current media position is changing - data : { id : demuxer id, frag : fragment object }
   Events['FRAG_CHANGED'] = 'hlsFragChanged';
   // Identifier for a FPS drop event - data: { currentDropped, currentDecoded, totalDroppedFrames }
   Events['FPS_DROP'] = 'hlsFpsDrop';
   // triggered when FPS drop triggers auto level capping - data: { level, droppedLevel }
   Events['FPS_DROP_LEVEL_CAPPING'] = 'hlsFpsDropLevelCapping';
   // triggered when maxAutoLevel changes - data { autoLevelCapping, levels, maxAutoLevel, minAutoLevel, maxHdcpLevel }
   Events['MAX_AUTO_LEVEL_UPDATED'] = 'hlsMaxAutoLevelUpdated';
   // Identifier for an error event - data: { type : error type, details : error details, fatal : if true, hls.js cannot/will not try to recover, if false, hls.js will try to recover,other error specific data }
   Events['ERROR'] = 'hlsError';
   // fired when hls.js instance starts destroying. Different from MEDIA_DETACHED as one could want to detach and reattach a media to the instance of hls.js to handle mid-rolls for example - data: { }
   Events['DESTROYING'] = 'hlsDestroying';
   // fired when a decrypt key loading starts - data: { frag : fragment object }
   Events['KEY_LOADING'] = 'hlsKeyLoading';
   // fired when a decrypt key loading is completed - data: { frag : fragment object, keyInfo : KeyLoaderInfo }
   Events['KEY_LOADED'] = 'hlsKeyLoaded';
   // deprecated; please use BACK_BUFFER_REACHED - data : { bufferEnd: number }
   Events['LIVE_BACK_BUFFER_REACHED'] = 'hlsLiveBackBufferReached';
   // fired when the back buffer is reached as defined by the backBufferLength config option - data : { bufferEnd: number }
   Events['BACK_BUFFER_REACHED'] = 'hlsBackBufferReached';
   // fired after steering manifest has been loaded - data: { steeringManifest: SteeringManifest object, url: steering manifest URL }
   Events['STEERING_MANIFEST_LOADED'] = 'hlsSteeringManifestLoaded';
   // fired when asset list has begun loading
   Events['ASSET_LIST_LOADING'] = 'hlsAssetListLoading';
   // fired when a valid asset list is loaded
   Events['ASSET_LIST_LOADED'] = 'hlsAssetListLoaded';
   // fired when the list of Interstitial Events and Interstitial Schedule is updated
   Events['INTERSTITIALS_UPDATED'] = 'hlsInterstitialsUpdated';
   // fired when the buffer reaches an Interstitial Schedule boundary (both Primary segments and Interstitial Assets)
   Events['INTERSTITIALS_BUFFERED_TO_BOUNDARY'] = 'hlsInterstitialsBufferedToBoundary';
   // fired when a player instance for an Interstitial Asset has been created
   Events['INTERSTITIAL_ASSET_PLAYER_CREATED'] = 'hlsInterstitialAssetPlayerCreated';
   // Interstitial playback started
   Events['INTERSTITIAL_STARTED'] = 'hlsInterstitialStarted';
   // InterstitialAsset playback started
   Events['INTERSTITIAL_ASSET_STARTED'] = 'hlsInterstitialAssetStarted';
   // InterstitialAsset playback ended
   Events['INTERSTITIAL_ASSET_ENDED'] = 'hlsInterstitialAssetEnded';
   // InterstitialAsset playback errored
   Events['INTERSTITIAL_ASSET_ERROR'] = 'hlsInterstitialAssetError';
   // Interstitial playback ended
   Events['INTERSTITIAL_ENDED'] = 'hlsInterstitialEnded';
   // Interstitial schedule resumed primary playback
   Events['INTERSTITIALS_PRIMARY_RESUMED'] = 'hlsInterstitialsPrimaryResumed';
   // Interstitial players dispatch this event when playout limit is reached
   Events['PLAYOUT_LIMIT_REACHED'] = 'hlsPlayoutLimitReached';
   // Event DateRange cue "enter" event dispatched
   Events['EVENT_CUE_ENTER'] = 'hlsEventCueEnter';
   return Events;
  })({});

  /**
   * Defines each Event type and payload by Event name. Used in {@link hls.js#HlsEventEmitter} to strongly type the event listener API.
   */

  var PlaylistContextType = {
   MANIFEST: 'manifest',
   LEVEL: 'level',
   AUDIO_TRACK: 'audioTrack',
   SUBTITLE_TRACK: 'subtitleTrack',
  };
  var PlaylistLevelType = {
   MAIN: 'main',
   AUDIO: 'audio',
   SUBTITLE: 'subtitle',
  };

  /*
   * compute an Exponential Weighted moving average
   * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average
   *  - heavily inspired from shaka-player
   */

  class EWMA {
   //  About half of the estimated value will be from the last |halfLife| samples by weight.
   constructor(halfLife, estimate = 0, weight = 0) {
    this.halfLife = void 0;
    this.alpha_ = void 0;
    this.estimate_ = void 0;
    this.totalWeight_ = void 0;
    this.halfLife = halfLife;
    // Larger values of alpha expire historical data more slowly.
    this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;
    this.estimate_ = estimate;
    this.totalWeight_ = weight;
   }
   sample(weight, value) {
    const adjAlpha = Math.pow(this.alpha_, weight);
    this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;
    this.totalWeight_ += weight;
   }
   getTotalWeight() {
    return this.totalWeight_;
   }
   getEstimate() {
    if (this.alpha_) {
     const zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);
     if (zeroFactor) {
      return this.estimate_ / zeroFactor;
     }
    }
    return this.estimate_;
   }
  }

  /*
   * EWMA Bandwidth Estimator
   *  - heavily inspired from shaka-player
   * Tracks bandwidth samples and estimates available bandwidth.
   * Based on the minimum of two exponentially-weighted moving averages with
   * different half-lives.
   */

  class EwmaBandWidthEstimator {
   constructor(slow, fast, defaultEstimate, defaultTTFB = 100) {
    this.defaultEstimate_ = void 0;
    this.minWeight_ = void 0;
    this.minDelayMs_ = void 0;
    this.slow_ = void 0;
    this.fast_ = void 0;
    this.defaultTTFB_ = void 0;
    this.ttfb_ = void 0;
    this.defaultEstimate_ = defaultEstimate;
    this.minWeight_ = 0.001;
    this.minDelayMs_ = 50;
    this.slow_ = new EWMA(slow);
    this.fast_ = new EWMA(fast);
    this.defaultTTFB_ = defaultTTFB;
    this.ttfb_ = new EWMA(slow);
   }
   update(slow, fast) {
    const { slow_, fast_, ttfb_ } = this;
    if (slow_.halfLife !== slow) {
     this.slow_ = new EWMA(slow, slow_.getEstimate(), slow_.getTotalWeight());
    }
    if (fast_.halfLife !== fast) {
     this.fast_ = new EWMA(fast, fast_.getEstimate(), fast_.getTotalWeight());
    }
    if (ttfb_.halfLife !== slow) {
     this.ttfb_ = new EWMA(slow, ttfb_.getEstimate(), ttfb_.getTotalWeight());
    }
   }
   sample(durationMs, numBytes) {
    durationMs = Math.max(durationMs, this.minDelayMs_);
    const numBits = 8 * numBytes;
    // weight is duration in seconds
    const durationS = durationMs / 1000;
    // value is bandwidth in bits/s
    const bandwidthInBps = numBits / durationS;
    this.fast_.sample(durationS, bandwidthInBps);
    this.slow_.sample(durationS, bandwidthInBps);
   }
   sampleTTFB(ttfb) {
    // weight is frequency curve applied to TTFB in seconds
    // (longer times have less weight with expected input under 1 second)
    const seconds = ttfb / 1000;
    const weight = Math.sqrt(2) * Math.exp(-Math.pow(seconds, 2) / 2);
    this.ttfb_.sample(weight, Math.max(ttfb, 5));
   }
   canEstimate() {
    return this.fast_.getTotalWeight() >= this.minWeight_;
   }
   getEstimate() {
    if (this.canEstimate()) {
     // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));
     // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));
     // Take the minimum of these two estimates.  This should have the effect of
     // adapting down quickly, but up more slowly.
     return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());
    } else {
     return this.defaultEstimate_;
    }
   }
   getEstimateTTFB() {
    if (this.ttfb_.getTotalWeight() >= this.minWeight_) {
     return this.ttfb_.getEstimate();
    } else {
     return this.defaultTTFB_;
    }
   }
   get defaultEstimate() {
    return this.defaultEstimate_;
   }
   destroy() {}
  }

  function _defineProperty(e, r, t) {
   return (
    (r = _toPropertyKey(r)) in e
     ? Object.defineProperty(e, r, {
        value: t,
        enumerable: true,
        configurable: true,
        writable: true,
       })
     : (e[r] = t),
    e
   );
  }
  function _extends() {
   return (
    (_extends = Object.assign
     ? Object.assign.bind()
     : function (n) {
        for (var e = 1; e < arguments.length; e++) {
         var t = arguments[e];
         for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]);
        }
        return n;
       }),
    _extends.apply(null, arguments)
   );
  }
  function ownKeys(e, r) {
   var t = Object.keys(e);
   if (Object.getOwnPropertySymbols) {
    var o = Object.getOwnPropertySymbols(e);
    r &&
     (o = o.filter(function (r) {
      return Object.getOwnPropertyDescriptor(e, r).enumerable;
     })),
     t.push.apply(t, o);
   }
   return t;
  }
  function _objectSpread2(e) {
   for (var r = 1; r < arguments.length; r++) {
    var t = null != arguments[r] ? arguments[r] : {};
    r % 2
     ? ownKeys(Object(t), true).forEach(function (r) {
        _defineProperty(e, r, t[r]);
       })
     : Object.getOwnPropertyDescriptors
       ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t))
       : ownKeys(Object(t)).forEach(function (r) {
          Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r));
         });
   }
   return e;
  }
  function _toPrimitive(t, r) {
   if ('object' != typeof t || !t) return t;
   var e = t[Symbol.toPrimitive];
   if (void 0 !== e) {
    var i = e.call(t, r);
    if ('object' != typeof i) return i;
    throw new TypeError('@@toPrimitive must return a primitive value.');
   }
   return ('string' === r ? String : Number)(t);
  }
  function _toPropertyKey(t) {
   var i = _toPrimitive(t, 'string');
   return 'symbol' == typeof i ? i : i + '';
  }

  class Logger {
   constructor(label, logger) {
    this.trace = void 0;
    this.debug = void 0;
    this.log = void 0;
    this.warn = void 0;
    this.info = void 0;
    this.error = void 0;
    const lb = `[${label}]:`;
    this.trace = noop;
    this.debug = logger.debug.bind(null, lb);
    this.log = logger.log.bind(null, lb);
    this.warn = logger.warn.bind(null, lb);
    this.info = logger.info.bind(null, lb);
    this.error = logger.error.bind(null, lb);
   }
  }
  const noop = function noop() {};
  const fakeLogger = {
   trace: noop,
   debug: noop,
   log: noop,
   warn: noop,
   info: noop,
   error: noop,
  };
  function createLogger() {
   return _extends({}, fakeLogger);
  }

  // let lastCallTime;
  // function formatMsgWithTimeInfo(type, msg) {
  //   const now = Date.now();
  //   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';
  //   lastCallTime = now;
  //   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';
  //   return msg;
  // }

  function consolePrintFn(type, id) {
   const func = self.console[type];
   return func ? func.bind(self.console, `${id ? '[' + id + '] ' : ''}[${type}] >`) : noop;
  }
  function getLoggerFn(key, debugConfig, id) {
   return debugConfig[key] ? debugConfig[key].bind(debugConfig) : consolePrintFn(key, id);
  }
  const exportedLogger = createLogger();
  function enableLogs(debugConfig, context, id) {
   // check that console is available
   const newLogger = createLogger();
   if ((typeof console === 'object' && debugConfig === true) || typeof debugConfig === 'object') {
    const keys = [
     // Remove out from list here to hard-disable a log-level
     // 'trace',
     'debug',
     'log',
     'info',
     'warn',
     'error',
    ];
    keys.forEach((key) => {
     newLogger[key] = getLoggerFn(key, debugConfig, id);
    });
    // Some browsers don't allow to use bind on console object anyway
    // fallback to default if needed
    try {
     newLogger.log(`Debug logs enabled for "${context}" in hls.js version ${'1.6.10'}`);
    } catch (e) {
     /* log fn threw an exception. All logger methods are no-ops. */
     return createLogger();
    }
    // global exported logger uses the same functions as new logger without `id`
    keys.forEach((key) => {
     exportedLogger[key] = getLoggerFn(key, debugConfig);
    });
   } else {
    // Reset global exported logger
    _extends(exportedLogger, newLogger);
   }
   return newLogger;
  }
  const logger = exportedLogger;

  function getMediaSource(preferManagedMediaSource = true) {
   if (typeof self === 'undefined') return undefined;
   const mms = (preferManagedMediaSource || !self.MediaSource) && self.ManagedMediaSource;
   return mms || self.MediaSource || self.WebKitMediaSource;
  }
  function isManagedMediaSource(source) {
   return typeof self !== 'undefined' && source === self.ManagedMediaSource;
  }
  function isCompatibleTrackChange(currentTracks, requiredTracks) {
   const trackNames = Object.keys(currentTracks);
   const requiredTrackNames = Object.keys(requiredTracks);
   const trackCount = trackNames.length;
   const requiredTrackCount = requiredTrackNames.length;
   return !trackCount || !requiredTrackCount || (trackCount === requiredTrackCount && !trackNames.some((name) => requiredTrackNames.indexOf(name) === -1));
  }

  // http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197
  // http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt
  /* utf.js - UTF-8 <=> UTF-16 convertion
   *
   * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>
   * Version: 1.0
   * LastModified: Dec 25 1999
   * This library is free.  You can redistribute it and/or modify it.
   */
  /**
   * Converts a UTF-8 array to a string.
   *
   * @param array - The UTF-8 array to convert
   *
   * @returns The string
   *
   * @group Utils
   *
   * @beta
   */
  function utf8ArrayToStr(array, exitOnNull = false) {
   if (typeof TextDecoder !== 'undefined') {
    const decoder = new TextDecoder('utf-8');
    const decoded = decoder.decode(array);
    if (exitOnNull) {
     // grab up to the first null
     const idx = decoded.indexOf('\0');
     return idx !== -1 ? decoded.substring(0, idx) : decoded;
    }
    // remove any null characters
    return decoded.replace(/\0/g, '');
   }
   const len = array.length;
   let c;
   let char2;
   let char3;
   let out = '';
   let i = 0;
   while (i < len) {
    c = array[i++];
    if (c === 0x00 && exitOnNull) {
     return out;
    } else if (c === 0x00 || c === 0x03) {
     // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it
     continue;
    }
    switch (c >> 4) {
     case 0:
     case 1:
     case 2:
     case 3:
     case 4:
     case 5:
     case 6:
     case 7:
      // 0xxxxxxx
      out += String.fromCharCode(c);
      break;
     case 12:
     case 13:
      // 110x xxxx   10xx xxxx
      char2 = array[i++];
      out += String.fromCharCode(((c & 0x1f) << 6) | (char2 & 0x3f));
      break;
     case 14:
      // 1110 xxxx  10xx xxxx  10xx xxxx
      char2 = array[i++];
      char3 = array[i++];
      out += String.fromCharCode(((c & 0x0f) << 12) | ((char2 & 0x3f) << 6) | ((char3 & 0x3f) << 0));
      break;
    }
   }
   return out;
  }

  /**
   *  hex dump helper class
   */

  const Hex = {
   hexDump: function (array) {
    let str = '';
    for (let i = 0; i < array.length; i++) {
     let h = array[i].toString(16);
     if (h.length < 2) {
      h = '0' + h;
     }
     str += h;
    }
    return str;
   },
  };
  function hexToArrayBuffer(str) {
   return Uint8Array.from(
    str
     .replace(/^0x/, '')
     .replace(/([\da-fA-F]{2}) ?/g, '0x$1 ')
     .replace(/ +$/, '')
     .split(' '),
   ).buffer;
  }

  function getDefaultExportFromCjs(x) {
   return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
  }

  var urlToolkit = { exports: {} };

  var hasRequiredUrlToolkit;

  function requireUrlToolkit() {
   if (hasRequiredUrlToolkit) return urlToolkit.exports;
   hasRequiredUrlToolkit = 1;
   (function (module, exports) {
    // see https://tools.ietf.org/html/rfc1808

    (function (root) {
     var URL_REGEX = /^(?=((?:[a-zA-Z0-9+\-.]+:)?))\1(?=((?:\/\/[^\/?#]*)?))\2(?=((?:(?:[^?#\/]*\/)*[^;?#\/]*)?))\3((?:;[^?#]*)?)(\?[^#]*)?(#[^]*)?$/;
     var FIRST_SEGMENT_REGEX = /^(?=([^\/?#]*))\1([^]*)$/;
     var SLASH_DOT_REGEX = /(?:\/|^)\.(?=\/)/g;
     var SLASH_DOT_DOT_REGEX = /(?:\/|^)\.\.\/(?!\.\.\/)[^\/]*(?=\/)/g;

     var URLToolkit = {
      // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //
      // E.g
      // With opts.alwaysNormalize = false (default, spec compliant)
      // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g
      // With opts.alwaysNormalize = true (not spec compliant)
      // http://a.com/b/cd + /e/f/../g => http://a.com/e/g
      buildAbsoluteURL: function (baseURL, relativeURL, opts) {
       opts = opts || {};
       // remove any remaining space and CRLF
       baseURL = baseURL.trim();
       relativeURL = relativeURL.trim();
       if (!relativeURL) {
        // 2a) If the embedded URL is entirely empty, it inherits the
        // entire base URL (i.e., is set equal to the base URL)
        // and we are done.
        if (!opts.alwaysNormalize) {
         return baseURL;
        }
        var basePartsForNormalise = URLToolkit.parseURL(baseURL);
        if (!basePartsForNormalise) {
         throw new Error('Error trying to parse base URL.');
        }
        basePartsForNormalise.path = URLToolkit.normalizePath(basePartsForNormalise.path);
        return URLToolkit.buildURLFromParts(basePartsForNormalise);
       }
       var relativeParts = URLToolkit.parseURL(relativeURL);
       if (!relativeParts) {
        throw new Error('Error trying to parse relative URL.');
       }
       if (relativeParts.scheme) {
        // 2b) If the embedded URL starts with a scheme name, it is
        // interpreted as an absolute URL and we are done.
        if (!opts.alwaysNormalize) {
         return relativeURL;
        }
        relativeParts.path = URLToolkit.normalizePath(relativeParts.path);
        return URLToolkit.buildURLFromParts(relativeParts);
       }
       var baseParts = URLToolkit.parseURL(baseURL);
       if (!baseParts) {
        throw new Error('Error trying to parse base URL.');
       }
       if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {
        // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc
        // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'
        var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);
        baseParts.netLoc = pathParts[1];
        baseParts.path = pathParts[2];
       }
       if (baseParts.netLoc && !baseParts.path) {
        baseParts.path = '/';
       }
       var builtParts = {
        // 2c) Otherwise, the embedded URL inherits the scheme of
        // the base URL.
        scheme: baseParts.scheme,
        netLoc: relativeParts.netLoc,
        path: null,
        params: relativeParts.params,
        query: relativeParts.query,
        fragment: relativeParts.fragment,
       };
       if (!relativeParts.netLoc) {
        // 3) If the embedded URL's <net_loc> is non-empty, we skip to
        // Step 7.  Otherwise, the embedded URL inherits the <net_loc>
        // (if any) of the base URL.
        builtParts.netLoc = baseParts.netLoc;
        // 4) If the embedded URL path is preceded by a slash "/", the
        // path is not relative and we skip to Step 7.
        if (relativeParts.path[0] !== '/') {
         if (!relativeParts.path) {
          // 5) If the embedded URL path is empty (and not preceded by a
          // slash), then the embedded URL inherits the base URL path
          builtParts.path = baseParts.path;
          // 5a) if the embedded URL's <params> is non-empty, we skip to
          // step 7; otherwise, it inherits the <params> of the base
          // URL (if any) and
          if (!relativeParts.params) {
           builtParts.params = baseParts.params;
           // 5b) if the embedded URL's <query> is non-empty, we skip to
           // step 7; otherwise, it inherits the <query> of the base
           // URL (if any) and we skip to step 7.
           if (!relativeParts.query) {
            builtParts.query = baseParts.query;
           }
          }
         } else {
          // 6) The last segment of the base URL's path (anything
          // following the rightmost slash "/", or the entire path if no
          // slash is present) is removed and the embedded URL's path is
          // appended in its place.
          var baseURLPath = baseParts.path;
          var newPath = baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) + relativeParts.path;
          builtParts.path = URLToolkit.normalizePath(newPath);
         }
        }
       }
       if (builtParts.path === null) {
        builtParts.path = opts.alwaysNormalize ? URLToolkit.normalizePath(relativeParts.path) : relativeParts.path;
       }
       return URLToolkit.buildURLFromParts(builtParts);
      },
      parseURL: function (url) {
       var parts = URL_REGEX.exec(url);
       if (!parts) {
        return null;
       }
       return {
        scheme: parts[1] || '',
        netLoc: parts[2] || '',
        path: parts[3] || '',
        params: parts[4] || '',
        query: parts[5] || '',
        fragment: parts[6] || '',
       };
      },
      normalizePath: function (path) {
       // The following operations are
       // then applied, in order, to the new path:
       // 6a) All occurrences of "./", where "." is a complete path
       // segment, are removed.
       // 6b) If the path ends with "." as a complete path segment,
       // that "." is removed.
       path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');
       // 6c) All occurrences of "<segment>/../", where <segment> is a
       // complete path segment not equal to "..", are removed.
       // Removal of these path segments is performed iteratively,
       // removing the leftmost matching pattern on each iteration,
       // until no matching pattern remains.
       // 6d) If the path ends with "<segment>/..", where <segment> is a
       // complete path segment not equal to "..", that
       // "<segment>/.." is removed.
       while (path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length) {}
       return path.split('').reverse().join('');
      },
      buildURLFromParts: function (parts) {
       return parts.scheme + parts.netLoc + parts.path + parts.params + parts.query + parts.fragment;
      },
     };

     module.exports = URLToolkit;
    })();
   })(urlToolkit);
   return urlToolkit.exports;
  }

  var urlToolkitExports = requireUrlToolkit();

  class LoadStats {
   constructor() {
    this.aborted = false;
    this.loaded = 0;
    this.retry = 0;
    this.total = 0;
    this.chunkCount = 0;
    this.bwEstimate = 0;
    this.loading = {
     start: 0,
     first: 0,
     end: 0,
    };
    this.parsing = {
     start: 0,
     end: 0,
    };
    this.buffering = {
     start: 0,
     first: 0,
     end: 0,
    };
   }
  }

  var ElementaryStreamTypes = {
   AUDIO: 'audio',
   VIDEO: 'video',
   AUDIOVIDEO: 'audiovideo',
  };
  class BaseSegment {
   constructor(base) {
    this._byteRange = null;
    this._url = null;
    this._stats = null;
    this._streams = null;
    // baseurl is the URL to the playlist
    this.base = void 0;
    // relurl is the portion of the URL that comes from inside the playlist.
    this.relurl = void 0;
    if (typeof base === 'string') {
     base = {
      url: base,
     };
    }
    this.base = base;
    makeEnumerable(this, 'stats');
   }

   // setByteRange converts a EXT-X-BYTERANGE attribute into a two element array
   setByteRange(value, previous) {
    const params = value.split('@', 2);
    let start;
    if (params.length === 1) {
     start = (previous == null ? void 0 : previous.byteRangeEndOffset) || 0;
    } else {
     start = parseInt(params[1]);
    }
    this._byteRange = [start, parseInt(params[0]) + start];
   }
   get baseurl() {
    return this.base.url;
   }
   get byteRange() {
    if (this._byteRange === null) {
     return [];
    }
    return this._byteRange;
   }
   get byteRangeStartOffset() {
    return this.byteRange[0];
   }
   get byteRangeEndOffset() {
    return this.byteRange[1];
   }
   get elementaryStreams() {
    if (this._streams === null) {
     this._streams = {
      [ElementaryStreamTypes.AUDIO]: null,
      [ElementaryStreamTypes.VIDEO]: null,
      [ElementaryStreamTypes.AUDIOVIDEO]: null,
     };
    }
    return this._streams;
   }
   set elementaryStreams(value) {
    this._streams = value;
   }
   get hasStats() {
    return this._stats !== null;
   }
   get hasStreams() {
    return this._streams !== null;
   }
   get stats() {
    if (this._stats === null) {
     this._stats = new LoadStats();
    }
    return this._stats;
   }
   set stats(value) {
    this._stats = value;
   }
   get url() {
    if (!this._url && this.baseurl && this.relurl) {
     this._url = urlToolkitExports.buildAbsoluteURL(this.baseurl, this.relurl, {
      alwaysNormalize: true,
     });
    }
    return this._url || '';
   }
   set url(value) {
    this._url = value;
   }
   clearElementaryStreamInfo() {
    const { elementaryStreams } = this;
    elementaryStreams[ElementaryStreamTypes.AUDIO] = null;
    elementaryStreams[ElementaryStreamTypes.VIDEO] = null;
    elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO] = null;
   }
  }
  function isMediaFragment(frag) {
   return frag.sn !== 'initSegment';
  }

  /**
   * Object representing parsed data from an HLS Segment. Found in {@link hls.js#LevelDetails.fragments}.
   */
  class Fragment extends BaseSegment {
   constructor(type, base) {
    super(base);
    this._decryptdata = null;
    this._programDateTime = null;
    this._ref = null;
    // Approximate bit rate of the fragment expressed in bits per second (bps) as indicated by the last EXT-X-BITRATE (kbps) tag
    this._bitrate = void 0;
    this.rawProgramDateTime = null;
    this.tagList = [];
    // EXTINF has to be present for a m3u8 to be considered valid
    this.duration = 0;
    // sn notates the sequence number for a segment, and if set to a string can be 'initSegment'
    this.sn = 0;
    // levelkeys are the EXT-X-KEY tags that apply to this segment for decryption
    // core difference from the private field _decryptdata is the lack of the initialized IV
    // _decryptdata will set the IV for this segment based on the segment number in the fragment
    this.levelkeys = void 0;
    // A string representing the fragment type
    this.type = void 0;
    // A reference to the loader. Set while the fragment is loading, and removed afterwards. Used to abort fragment loading
    this.loader = null;
    // A reference to the key loader. Set while the key is loading, and removed afterwards. Used to abort key loading
    this.keyLoader = null;
    // The level/track index to which the fragment belongs
    this.level = -1;
    // The continuity counter of the fragment
    this.cc = 0;
    // The starting Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.
    this.startPTS = void 0;
    // The ending Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.
    this.endPTS = void 0;
    // The starting Decode Time Stamp (DTS) of the fragment. Set after transmux complete.
    this.startDTS = void 0;
    // The ending Decode Time Stamp (DTS) of the fragment. Set after transmux complete.
    this.endDTS = void 0;
    // The start time of the fragment, as listed in the manifest. Updated after transmux complete.
    this.start = 0;
    // The offset time (seconds) of the fragment from the start of the Playlist
    this.playlistOffset = 0;
    // Set by `updateFragPTSDTS` in level-helper
    this.deltaPTS = void 0;
    // The maximum starting Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.
    this.maxStartPTS = void 0;
    // The minimum ending Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.
    this.minEndPTS = void 0;
    // Init Segment bytes (unset for media segments)
    this.data = void 0;
    // A flag indicating whether the segment was downloaded in order to test bitrate, and was not buffered
    this.bitrateTest = false;
    // #EXTINF  segment title
    this.title = null;
    // The Media Initialization Section for this segment
    this.initSegment = null;
    // Fragment is the last fragment in the media playlist
    this.endList = void 0;
    // Fragment is marked by an EXT-X-GAP tag indicating that it does not contain media data and should not be loaded
    this.gap = void 0;
    // Deprecated
    this.urlId = 0;
    this.type = type;
   }
   get byteLength() {
    if (this.hasStats) {
     const total = this.stats.total;
     if (total) {
      return total;
     }
    }
    if (this.byteRange.length) {
     const start = this.byteRange[0];
     const end = this.byteRange[1];
     if (isFiniteNumber(start) && isFiniteNumber(end)) {
      return end - start;
     }
    }
    return null;
   }
   get bitrate() {
    if (this.byteLength) {
     return (this.byteLength * 8) / this.duration;
    }
    if (this._bitrate) {
     return this._bitrate;
    }
    return null;
   }
   set bitrate(value) {
    this._bitrate = value;
   }
   get decryptdata() {
    const { levelkeys } = this;
    if (!levelkeys && !this._decryptdata) {
     return null;
    }
    if (!this._decryptdata && this.levelkeys && !this.levelkeys.NONE) {
     const key = this.levelkeys.identity;
     if (key) {
      this._decryptdata = key.getDecryptData(this.sn);
     } else {
      const keyFormats = Object.keys(this.levelkeys);
      if (keyFormats.length === 1) {
       const levelKey = (this._decryptdata = this.levelkeys[keyFormats[0]] || null);
       if (levelKey) {
        return levelKey.getDecryptData(this.sn);
       }
      }
     }
    }
    return this._decryptdata;
   }
   get end() {
    return this.start + this.duration;
   }
   get endProgramDateTime() {
    if (this.programDateTime === null) {
     return null;
    }
    const duration = !isFiniteNumber(this.duration) ? 0 : this.duration;
    return this.programDateTime + duration * 1000;
   }
   get encrypted() {
    var _this$_decryptdata;
    // At the m3u8-parser level we need to add support for manifest signalled keyformats
    // when we want the fragment to start reporting that it is encrypted.
    // Currently, keyFormat will only be set for identity keys
    if ((_this$_decryptdata = this._decryptdata) != null && _this$_decryptdata.encrypted) {
     return true;
    } else if (this.levelkeys) {
     var _this$levelkeys$keyFo;
     const keyFormats = Object.keys(this.levelkeys);
     const len = keyFormats.length;
     if (len > 1 || (len === 1 && (_this$levelkeys$keyFo = this.levelkeys[keyFormats[0]]) != null && _this$levelkeys$keyFo.encrypted)) {
      return true;
     }
    }
    return false;
   }
   get programDateTime() {
    if (this._programDateTime === null && this.rawProgramDateTime) {
     this.programDateTime = Date.parse(this.rawProgramDateTime);
    }
    return this._programDateTime;
   }
   set programDateTime(value) {
    if (!isFiniteNumber(value)) {
     this._programDateTime = this.rawProgramDateTime = null;
     return;
    }
    this._programDateTime = value;
   }
   get ref() {
    if (!isMediaFragment(this)) {
     return null;
    }
    if (!this._ref) {
     this._ref = {
      base: this.base,
      start: this.start,
      duration: this.duration,
      sn: this.sn,
      programDateTime: this.programDateTime,
     };
    }
    return this._ref;
   }
   addStart(value) {
    this.setStart(this.start + value);
   }
   setStart(value) {
    this.start = value;
    if (this._ref) {
     this._ref.start = value;
    }
   }
   setDuration(value) {
    this.duration = value;
    if (this._ref) {
     this._ref.duration = value;
    }
   }
   setKeyFormat(keyFormat) {
    if (this.levelkeys) {
     const key = this.levelkeys[keyFormat];
     if (key && !this._decryptdata) {
      this._decryptdata = key.getDecryptData(this.sn);
     }
    }
   }
   abortRequests() {
    var _this$loader, _this$keyLoader;
    (_this$loader = this.loader) == null || _this$loader.abort();
    (_this$keyLoader = this.keyLoader) == null || _this$keyLoader.abort();
   }
   setElementaryStreamInfo(type, startPTS, endPTS, startDTS, endDTS, partial = false) {
    const { elementaryStreams } = this;
    const info = elementaryStreams[type];
    if (!info) {
     elementaryStreams[type] = {
      startPTS,
      endPTS,
      startDTS,
      endDTS,
      partial,
     };
     return;
    }
    info.startPTS = Math.min(info.startPTS, startPTS);
    info.endPTS = Math.max(info.endPTS, endPTS);
    info.startDTS = Math.min(info.startDTS, startDTS);
    info.endDTS = Math.max(info.endDTS, endDTS);
   }
  }

  /**
   * Object representing parsed data from an HLS Partial Segment. Found in {@link hls.js#LevelDetails.partList}.
   */
  class Part extends BaseSegment {
   constructor(partAttrs, frag, base, index, previous) {
    super(base);
    this.fragOffset = 0;
    this.duration = 0;
    this.gap = false;
    this.independent = false;
    this.relurl = void 0;
    this.fragment = void 0;
    this.index = void 0;
    this.duration = partAttrs.decimalFloatingPoint('DURATION');
    this.gap = partAttrs.bool('GAP');
    this.independent = partAttrs.bool('INDEPENDENT');
    this.relurl = partAttrs.enumeratedString('URI');
    this.fragment = frag;
    this.index = index;
    const byteRange = partAttrs.enumeratedString('BYTERANGE');
    if (byteRange) {
     this.setByteRange(byteRange, previous);
    }
    if (previous) {
     this.fragOffset = previous.fragOffset + previous.duration;
    }
   }
   get start() {
    return this.fragment.start + this.fragOffset;
   }
   get end() {
    return this.start + this.duration;
   }
   get loaded() {
    const { elementaryStreams } = this;
    return !!(elementaryStreams.audio || elementaryStreams.video || elementaryStreams.audiovideo);
   }
  }
  function getOwnPropertyDescriptorFromPrototypeChain(object, property) {
   const prototype = Object.getPrototypeOf(object);
   if (prototype) {
    const propertyDescriptor = Object.getOwnPropertyDescriptor(prototype, property);
    if (propertyDescriptor) {
     return propertyDescriptor;
    }
    return getOwnPropertyDescriptorFromPrototypeChain(prototype, property);
   }
  }
  function makeEnumerable(object, property) {
   const d = getOwnPropertyDescriptorFromPrototypeChain(object, property);
   if (d) {
    d.enumerable = true;
    Object.defineProperty(object, property, d);
   }
  }

  const UINT32_MAX$1 = Math.pow(2, 32) - 1;
  const push = [].push;

  // We are using fixed track IDs for driving the MP4 remuxer
  // instead of following the TS PIDs.
  // There is no reason not to do this and some browsers/SourceBuffer-demuxers
  // may not like if there are TrackID "switches"
  // See https://github.com/video-dev/hls.js/issues/1331
  // Here we are mapping our internal track types to constant MP4 track IDs
  // With MSE currently one can only have one track of each, and we are muxing
  // whatever video/audio rendition in them.
  const RemuxerTrackIdConfig = {
   video: 1,
   audio: 2,
   id3: 3,
   text: 4,
  };
  function bin2str(data) {
   return String.fromCharCode.apply(null, data);
  }
  function readUint16(buffer, offset) {
   const val = (buffer[offset] << 8) | buffer[offset + 1];
   return val < 0 ? 65536 + val : val;
  }
  function readUint32(buffer, offset) {
   const val = readSint32(buffer, offset);
   return val < 0 ? 4294967296 + val : val;
  }
  function readUint64(buffer, offset) {
   let result = readUint32(buffer, offset);
   result *= Math.pow(2, 32);
   result += readUint32(buffer, offset + 4);
   return result;
  }
  function readSint32(buffer, offset) {
   return (buffer[offset] << 24) | (buffer[offset + 1] << 16) | (buffer[offset + 2] << 8) | buffer[offset + 3];
  }

  // Find "moof" box
  function hasMoofData(data) {
   const end = data.byteLength;
   for (let i = 0; i < end; ) {
    const size = readUint32(data, i);
    if (size > 8 && data[i + 4] === 0x6d && data[i + 5] === 0x6f && data[i + 6] === 0x6f && data[i + 7] === 0x66) {
     return true;
    }
    i = size > 1 ? i + size : end;
   }
   return false;
  }

  // Find the data for a box specified by its path
  function findBox(data, path) {
   const results = [];
   if (!path.length) {
    // short-circuit the search for empty paths
    return results;
   }
   const end = data.byteLength;
   for (let i = 0; i < end; ) {
    const size = readUint32(data, i);
    const type = bin2str(data.subarray(i + 4, i + 8));
    const endbox = size > 1 ? i + size : end;
    if (type === path[0]) {
     if (path.length === 1) {
      // this is the end of the path and we've found the box we were
      // looking for
      results.push(data.subarray(i + 8, endbox));
     } else {
      // recursively search for the next box along the path
      const subresults = findBox(data.subarray(i + 8, endbox), path.slice(1));
      if (subresults.length) {
       push.apply(results, subresults);
      }
     }
    }
    i = endbox;
   }

   // we've finished searching all of data
   return results;
  }
  function parseSegmentIndex(sidx) {
   const references = [];
   const version = sidx[0];

   // set initial offset, we skip the reference ID (not needed)
   let index = 8;
   const timescale = readUint32(sidx, index);
   index += 4;
   let earliestPresentationTime = 0;
   let firstOffset = 0;
   if (version === 0) {
    earliestPresentationTime = readUint32(sidx, index);
    firstOffset = readUint32(sidx, index + 4);
    index += 8;
   } else {
    earliestPresentationTime = readUint64(sidx, index);
    firstOffset = readUint64(sidx, index + 8);
    index += 16;
   }

   // skip reserved
   index += 2;
   let startByte = sidx.length + firstOffset;
   const referencesCount = readUint16(sidx, index);
   index += 2;
   for (let i = 0; i < referencesCount; i++) {
    let referenceIndex = index;
    const referenceInfo = readUint32(sidx, referenceIndex);
    referenceIndex += 4;
    const referenceSize = referenceInfo & 0x7fffffff;
    const referenceType = (referenceInfo & 0x80000000) >>> 31;
    if (referenceType === 1) {
     logger.warn('SIDX has hierarchical references (not supported)');
     return null;
    }
    const subsegmentDuration = readUint32(sidx, referenceIndex);
    referenceIndex += 4;
    references.push({
     referenceSize,
     subsegmentDuration,
     // unscaled
     info: {
      duration: subsegmentDuration / timescale,
      start: startByte,
      end: startByte + referenceSize - 1,
     },
    });
    startByte += referenceSize;

    // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits
    // for |sapDelta|.
    referenceIndex += 4;

    // skip to next ref
    index = referenceIndex;
   }
   return {
    earliestPresentationTime,
    timescale,
    version,
    referencesCount,
    references,
   };
  }

  /**
   * Parses an MP4 initialization segment and extracts stream type and
   * timescale values for any declared tracks. Timescale values indicate the
   * number of clock ticks per second to assume for time-based values
   * elsewhere in the MP4.
   *
   * To determine the start time of an MP4, you need two pieces of
   * information: the timescale unit and the earliest base media decode
   * time. Multiple timescales can be specified within an MP4 but the
   * base media decode time is always expressed in the timescale from
   * the media header box for the track:
   * ```
   * moov > trak > mdia > mdhd.timescale
   * moov > trak > mdia > hdlr
   * ```
   * @param initSegment the bytes of the init segment
   * @returns a hash of track type to timescale values or null if
   * the init segment is malformed.
   */

  function parseInitSegment(initSegment) {
   const result = [];
   const traks = findBox(initSegment, ['moov', 'trak']);
   for (let i = 0; i < traks.length; i++) {
    const trak = traks[i];
    const tkhd = findBox(trak, ['tkhd'])[0];
    if (tkhd) {
     let version = tkhd[0];
     const trackId = readUint32(tkhd, version === 0 ? 12 : 20);
     const mdhd = findBox(trak, ['mdia', 'mdhd'])[0];
     if (mdhd) {
      version = mdhd[0];
      const timescale = readUint32(mdhd, version === 0 ? 12 : 20);
      const hdlr = findBox(trak, ['mdia', 'hdlr'])[0];
      if (hdlr) {
       const hdlrType = bin2str(hdlr.subarray(8, 12));
       const type = {
        soun: ElementaryStreamTypes.AUDIO,
        vide: ElementaryStreamTypes.VIDEO,
       }[hdlrType];
       // Parse codec details
       const stsdBox = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];
       const stsd = parseStsd(stsdBox);
       if (type) {
        // Add 'audio', 'video', and 'audiovideo' track records that will map to SourceBuffers
        result[trackId] = {
         timescale,
         type,
         stsd,
        };
        result[type] = _objectSpread2(
         {
          timescale,
          id: trackId,
         },
         stsd,
        );
       } else {
        // Add 'meta' and other track records
        result[trackId] = {
         timescale,
         type: hdlrType,
         stsd,
        };
       }
      }
     }
    }
   }
   const trex = findBox(initSegment, ['moov', 'mvex', 'trex']);
   trex.forEach((trex) => {
    const trackId = readUint32(trex, 4);
    const track = result[trackId];
    if (track) {
     track.default = {
      duration: readUint32(trex, 12),
      flags: readUint32(trex, 20),
     };
    }
   });
   return result;
  }
  function parseStsd(stsd) {
   const sampleEntries = stsd.subarray(8);
   const sampleEntriesEnd = sampleEntries.subarray(8 + 78);
   const fourCC = bin2str(sampleEntries.subarray(4, 8));
   let codec = fourCC;
   let supplemental;
   const encrypted = fourCC === 'enca' || fourCC === 'encv';
   if (encrypted) {
    const encBox = findBox(sampleEntries, [fourCC])[0];
    const encBoxChildren = encBox.subarray(fourCC === 'enca' ? 28 : 78);
    const sinfs = findBox(encBoxChildren, ['sinf']);
    sinfs.forEach((sinf) => {
     const schm = findBox(sinf, ['schm'])[0];
     if (schm) {
      const scheme = bin2str(schm.subarray(4, 8));
      if (scheme === 'cbcs' || scheme === 'cenc') {
       const frma = findBox(sinf, ['frma'])[0];
       if (frma) {
        // for encrypted content codec fourCC will be in frma
        codec = bin2str(frma);
       }
      }
     }
    });
   }
   const codecFourCC = codec;
   switch (codec) {
    case 'avc1':
    case 'avc2':
    case 'avc3':
    case 'avc4': {
     // extract profile + compatibility + level out of avcC box
     const avcCBox = findBox(sampleEntriesEnd, ['avcC'])[0];
     if (avcCBox && avcCBox.length > 3) {
      codec += '.' + toHex(avcCBox[1]) + toHex(avcCBox[2]) + toHex(avcCBox[3]);
      supplemental = parseSupplementalDoViCodec(codecFourCC === 'avc1' ? 'dva1' : 'dvav', sampleEntriesEnd);
     }
     break;
    }
    case 'mp4a': {
     const codecBox = findBox(sampleEntries, [fourCC])[0];
     const esdsBox = findBox(codecBox.subarray(28), ['esds'])[0];
     if (esdsBox && esdsBox.length > 7) {
      let i = 4;
      // ES Descriptor tag
      if (esdsBox[i++] !== 0x03) {
       break;
      }
      i = skipBERInteger(esdsBox, i);
      i += 2; // skip es_id;
      const flags = esdsBox[i++];
      if (flags & 0x80) {
       i += 2; // skip dependency es_id
      }
      if (flags & 0x40) {
       i += esdsBox[i++]; // skip URL
      }
      // Decoder config descriptor
      if (esdsBox[i++] !== 0x04) {
       break;
      }
      i = skipBERInteger(esdsBox, i);
      const objectType = esdsBox[i++];
      if (objectType === 0x40) {
       codec += '.' + toHex(objectType);
      } else {
       break;
      }
      i += 12;
      // Decoder specific info
      if (esdsBox[i++] !== 0x05) {
       break;
      }
      i = skipBERInteger(esdsBox, i);
      const firstByte = esdsBox[i++];
      let audioObjectType = (firstByte & 0xf8) >> 3;
      if (audioObjectType === 31) {
       audioObjectType += 1 + ((firstByte & 0x7) << 3) + ((esdsBox[i] & 0xe0) >> 5);
      }
      codec += '.' + audioObjectType;
     }
     break;
    }
    case 'hvc1':
    case 'hev1': {
     const hvcCBox = findBox(sampleEntriesEnd, ['hvcC'])[0];
     if (hvcCBox && hvcCBox.length > 12) {
      const profileByte = hvcCBox[1];
      const profileSpace = ['', 'A', 'B', 'C'][profileByte >> 6];
      const generalProfileIdc = profileByte & 0x1f;
      const profileCompat = readUint32(hvcCBox, 2);
      const tierFlag = (profileByte & 0x20) >> 5 ? 'H' : 'L';
      const levelIDC = hvcCBox[12];
      const constraintIndicator = hvcCBox.subarray(6, 12);
      codec += '.' + profileSpace + generalProfileIdc;
      codec += '.' + reverse32BitInt(profileCompat).toString(16).toUpperCase();
      codec += '.' + tierFlag + levelIDC;
      let constraintString = '';
      for (let i = constraintIndicator.length; i--; ) {
       const byte = constraintIndicator[i];
       if (byte || constraintString) {
        const encodedByte = byte.toString(16).toUpperCase();
        constraintString = '.' + encodedByte + constraintString;
       }
      }
      codec += constraintString;
     }
     supplemental = parseSupplementalDoViCodec(codecFourCC == 'hev1' ? 'dvhe' : 'dvh1', sampleEntriesEnd);
     break;
    }
    case 'dvh1':
    case 'dvhe':
    case 'dvav':
    case 'dva1':
    case 'dav1': {
     codec = parseSupplementalDoViCodec(codec, sampleEntriesEnd) || codec;
     break;
    }
    case 'vp09': {
     const vpcCBox = findBox(sampleEntriesEnd, ['vpcC'])[0];
     if (vpcCBox && vpcCBox.length > 6) {
      const profile = vpcCBox[4];
      const level = vpcCBox[5];
      const bitDepth = (vpcCBox[6] >> 4) & 0x0f;
      codec += '.' + addLeadingZero(profile) + '.' + addLeadingZero(level) + '.' + addLeadingZero(bitDepth);
     }
     break;
    }
    case 'av01': {
     const av1CBox = findBox(sampleEntriesEnd, ['av1C'])[0];
     if (av1CBox && av1CBox.length > 2) {
      const profile = av1CBox[1] >>> 5;
      const level = av1CBox[1] & 0x1f;
      const tierFlag = av1CBox[2] >>> 7 ? 'H' : 'M';
      const highBitDepth = (av1CBox[2] & 0x40) >> 6;
      const twelveBit = (av1CBox[2] & 0x20) >> 5;
      const bitDepth = profile === 2 && highBitDepth ? (twelveBit ? 12 : 10) : highBitDepth ? 10 : 8;
      const monochrome = (av1CBox[2] & 0x10) >> 4;
      const chromaSubsamplingX = (av1CBox[2] & 0x08) >> 3;
      const chromaSubsamplingY = (av1CBox[2] & 0x04) >> 2;
      const chromaSamplePosition = av1CBox[2] & 0x03;
      // TODO: parse color_description_present_flag
      // default it to BT.709/limited range for now
      // more info https://aomediacodec.github.io/av1-isobmff/#av1codecconfigurationbox-syntax
      const colorPrimaries = 1;
      const transferCharacteristics = 1;
      const matrixCoefficients = 1;
      const videoFullRangeFlag = 0;
      codec += '.' + profile + '.' + addLeadingZero(level) + tierFlag + '.' + addLeadingZero(bitDepth) + '.' + monochrome + '.' + chromaSubsamplingX + chromaSubsamplingY + chromaSamplePosition + '.' + addLeadingZero(colorPrimaries) + '.' + addLeadingZero(transferCharacteristics) + '.' + addLeadingZero(matrixCoefficients) + '.' + videoFullRangeFlag;
      supplemental = parseSupplementalDoViCodec('dav1', sampleEntriesEnd);
     }
     break;
    }
   }
   return {
    codec,
    encrypted,
    supplemental,
   };
  }
  function parseSupplementalDoViCodec(fourCC, sampleEntriesEnd) {
   const dvvCResult = findBox(sampleEntriesEnd, ['dvvC']); // used by DoVi Profile 8 to 10
   const dvXCBox = dvvCResult.length ? dvvCResult[0] : findBox(sampleEntriesEnd, ['dvcC'])[0]; // used by DoVi Profiles up to 7 and 20
   if (dvXCBox) {
    const doViProfile = (dvXCBox[2] >> 1) & 0x7f;
    const doViLevel = ((dvXCBox[2] << 5) & 0x20) | ((dvXCBox[3] >> 3) & 0x1f);
    return fourCC + '.' + addLeadingZero(doViProfile) + '.' + addLeadingZero(doViLevel);
   }
  }
  function reverse32BitInt(val) {
   let result = 0;
   for (let i = 0; i < 32; i++) {
    result |= ((val >> i) & 1) << (32 - 1 - i);
   }
   return result >>> 0;
  }
  function skipBERInteger(bytes, i) {
   const limit = i + 5;
   while (bytes[i++] & 0x80 && i < limit) {
    /* do nothing */
   }
   return i;
  }
  function toHex(x) {
   return ('0' + x.toString(16).toUpperCase()).slice(-2);
  }
  function addLeadingZero(num) {
   return (num < 10 ? '0' : '') + num;
  }
  function patchEncyptionData(initSegment, decryptdata) {
   if (!initSegment || !decryptdata) {
    return;
   }
   const keyId = decryptdata.keyId;
   if (keyId && decryptdata.isCommonEncryption) {
    const traks = findBox(initSegment, ['moov', 'trak']);
    traks.forEach((trak) => {
     const stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];

     // skip the sample entry count
     const sampleEntries = stsd.subarray(8);
     let encBoxes = findBox(sampleEntries, ['enca']);
     const isAudio = encBoxes.length > 0;
     if (!isAudio) {
      encBoxes = findBox(sampleEntries, ['encv']);
     }
     encBoxes.forEach((enc) => {
      const encBoxChildren = isAudio ? enc.subarray(28) : enc.subarray(78);
      const sinfBoxes = findBox(encBoxChildren, ['sinf']);
      sinfBoxes.forEach((sinf) => {
       const tenc = parseSinf(sinf);
       if (tenc) {
        // Look for default key id (keyID offset is always 8 within the tenc box):
        const tencKeyId = tenc.subarray(8, 24);
        if (!tencKeyId.some((b) => b !== 0)) {
         logger.log(`[eme] Patching keyId in 'enc${isAudio ? 'a' : 'v'}>sinf>>tenc' box: ${Hex.hexDump(tencKeyId)} -> ${Hex.hexDump(keyId)}`);
         tenc.set(keyId, 8);
        }
       }
      });
     });
    });
   }
  }
  function parseSinf(sinf) {
   const schm = findBox(sinf, ['schm'])[0];
   if (schm) {
    const scheme = bin2str(schm.subarray(4, 8));
    if (scheme === 'cbcs' || scheme === 'cenc') {
     return findBox(sinf, ['schi', 'tenc'])[0];
    }
   }
   return null;
  }

  /*
  For Reference:
  aligned(8) class TrackFragmentHeaderBox
           extends FullBox(tfhd, 0, tf_flags){
     unsigned int(32)  track_ID;
     // all the following are optional fields
     unsigned int(64)  base_data_offset;
     unsigned int(32)  sample_description_index;
     unsigned int(32)  default_sample_duration;
     unsigned int(32)  default_sample_size;
     unsigned int(32)  default_sample_flags
  }
 */

  function getSampleData(data, initData, logger) {
   const tracks = {};
   const trafs = findBox(data, ['moof', 'traf']);
   for (let i = 0; i < trafs.length; i++) {
    const traf = trafs[i];
    // There is only one tfhd & trun per traf
    // This is true for CMAF style content, and we should perhaps check the ftyp
    // and only look for a single trun then, but for ISOBMFF we should check
    // for multiple track runs.
    const tfhd = findBox(traf, ['tfhd'])[0];
    // get the track id from the tfhd
    const id = readUint32(tfhd, 4);
    const track = initData[id];
    if (!track) {
     continue;
    }
    tracks[id] ||
     (tracks[id] = {
      start: NaN,
      duration: 0,
      sampleCount: 0,
      timescale: track.timescale,
      type: track.type,
     });
    const trackTimes = tracks[id];
    // get start DTS
    const tfdt = findBox(traf, ['tfdt'])[0];
    if (tfdt) {
     const version = tfdt[0];
     let baseTime = readUint32(tfdt, 4);
     if (version === 1) {
      // If value is too large, assume signed 64-bit. Negative track fragment decode times are invalid, but they exist in the wild.
      // This prevents large values from being used for initPTS, which can cause playlist sync issues.
      // https://github.com/video-dev/hls.js/issues/5303
      if (baseTime === UINT32_MAX$1) {
       logger.warn(`[mp4-demuxer]: Ignoring assumed invalid signed 64-bit track fragment decode time`);
      } else {
       baseTime *= UINT32_MAX$1 + 1;
       baseTime += readUint32(tfdt, 8);
      }
     }
     if (isFiniteNumber(baseTime) && (!isFiniteNumber(trackTimes.start) || baseTime < trackTimes.start)) {
      trackTimes.start = baseTime;
     }
    }
    const trackDefault = track.default;
    const tfhdFlags = readUint32(tfhd, 0) | (trackDefault == null ? void 0 : trackDefault.flags);
    let defaultSampleDuration = (trackDefault == null ? void 0 : trackDefault.duration) || 0;
    if (tfhdFlags & 0x000008) {
     // 0x000008 indicates the presence of the default_sample_duration field
     if (tfhdFlags & 0x000002) {
      // 0x000002 indicates the presence of the sample_description_index field, which precedes default_sample_duration
      // If present, the default_sample_duration exists at byte offset 12
      defaultSampleDuration = readUint32(tfhd, 12);
     } else {
      // Otherwise, the duration is at byte offset 8
      defaultSampleDuration = readUint32(tfhd, 8);
     }
    }
    const truns = findBox(traf, ['trun']);
    let sampleDTS = trackTimes.start || 0;
    let rawDuration = 0;
    let sampleDuration = defaultSampleDuration;
    for (let j = 0; j < truns.length; j++) {
     const trun = truns[j];
     const sampleCount = readUint32(trun, 4);
     const sampleIndex = trackTimes.sampleCount;
     trackTimes.sampleCount += sampleCount;
     // Get duration from samples
     const dataOffsetPresent = trun[3] & 0x01;
     const firstSampleFlagsPresent = trun[3] & 0x04;
     const sampleDurationPresent = trun[2] & 0x01;
     const sampleSizePresent = trun[2] & 0x02;
     const sampleFlagsPresent = trun[2] & 0x04;
     const sampleCompositionTimeOffsetPresent = trun[2] & 0x08;
     let offset = 8;
     let remaining = sampleCount;
     if (dataOffsetPresent) {
      offset += 4;
     }
     if (firstSampleFlagsPresent && sampleCount) {
      const isNonSyncSample = trun[offset + 1] & 0x01;
      if (!isNonSyncSample && trackTimes.keyFrameIndex === undefined) {
       trackTimes.keyFrameIndex = sampleIndex;
      }
      offset += 4;
      if (sampleDurationPresent) {
       sampleDuration = readUint32(trun, offset);
       offset += 4;
      } else {
       sampleDuration = defaultSampleDuration;
      }
      if (sampleSizePresent) {
       offset += 4;
      }
      if (sampleCompositionTimeOffsetPresent) {
       offset += 4;
      }
      sampleDTS += sampleDuration;
      rawDuration += sampleDuration;
      remaining--;
     }
     while (remaining--) {
      if (sampleDurationPresent) {
       sampleDuration = readUint32(trun, offset);
       offset += 4;
      } else {
       sampleDuration = defaultSampleDuration;
      }
      if (sampleSizePresent) {
       offset += 4;
      }
      if (sampleFlagsPresent) {
       const isNonSyncSample = trun[offset + 1] & 0x01;
       if (!isNonSyncSample) {
        if (trackTimes.keyFrameIndex === undefined) {
         trackTimes.keyFrameIndex = trackTimes.sampleCount - (remaining + 1);
         trackTimes.keyFrameStart = sampleDTS;
        }
       }
       offset += 4;
      }
      if (sampleCompositionTimeOffsetPresent) {
       offset += 4;
      }
      sampleDTS += sampleDuration;
      rawDuration += sampleDuration;
     }
     if (!rawDuration && defaultSampleDuration) {
      rawDuration += defaultSampleDuration * sampleCount;
     }
    }
    trackTimes.duration += rawDuration;
   }
   if (!Object.keys(tracks).some((trackId) => tracks[trackId].duration)) {
    // If duration samples are not available in the traf use sidx subsegment_duration
    let sidxMinStart = Infinity;
    let sidxMaxEnd = 0;
    const sidxs = findBox(data, ['sidx']);
    for (let i = 0; i < sidxs.length; i++) {
     const sidx = parseSegmentIndex(sidxs[i]);
     if (sidx != null && sidx.references) {
      sidxMinStart = Math.min(sidxMinStart, sidx.earliestPresentationTime / sidx.timescale);
      const subSegmentDuration = sidx.references.reduce((dur, ref) => dur + ref.info.duration || 0, 0);
      sidxMaxEnd = Math.max(sidxMaxEnd, subSegmentDuration + sidx.earliestPresentationTime / sidx.timescale);
     }
    }
    if (sidxMaxEnd && isFiniteNumber(sidxMaxEnd)) {
     Object.keys(tracks).forEach((trackId) => {
      if (!tracks[trackId].duration) {
       tracks[trackId].duration = sidxMaxEnd * tracks[trackId].timescale - tracks[trackId].start;
      }
     });
    }
   }
   return tracks;
  }

  // TODO: Check if the last moof+mdat pair is part of the valid range
  function segmentValidRange(data) {
   const segmentedRange = {
    valid: null,
    remainder: null,
   };
   const moofs = findBox(data, ['moof']);
   if (moofs.length < 2) {
    segmentedRange.remainder = data;
    return segmentedRange;
   }
   const last = moofs[moofs.length - 1];
   // Offset by 8 bytes; findBox offsets the start by as much
   segmentedRange.valid = data.slice(0, last.byteOffset - 8);
   segmentedRange.remainder = data.slice(last.byteOffset - 8);
   return segmentedRange;
  }
  function appendUint8Array(data1, data2) {
   const temp = new Uint8Array(data1.length + data2.length);
   temp.set(data1);
   temp.set(data2, data1.length);
   return temp;
  }
  function parseSamples(timeOffset, track) {
   const seiSamples = [];
   const videoData = track.samples;
   const timescale = track.timescale;
   const trackId = track.id;
   let isHEVCFlavor = false;
   const moofs = findBox(videoData, ['moof']);
   moofs.map((moof) => {
    const moofOffset = moof.byteOffset - 8;
    const trafs = findBox(moof, ['traf']);
    trafs.map((traf) => {
     // get the base media decode time from the tfdt
     const baseTime = findBox(traf, ['tfdt']).map((tfdt) => {
      const version = tfdt[0];
      let result = readUint32(tfdt, 4);
      if (version === 1) {
       result *= Math.pow(2, 32);
       result += readUint32(tfdt, 8);
      }
      return result / timescale;
     })[0];
     if (baseTime !== undefined) {
      timeOffset = baseTime;
     }
     return findBox(traf, ['tfhd']).map((tfhd) => {
      const id = readUint32(tfhd, 4);
      const tfhdFlags = readUint32(tfhd, 0) & 0xffffff;
      const baseDataOffsetPresent = (tfhdFlags & 0x000001) !== 0;
      const sampleDescriptionIndexPresent = (tfhdFlags & 0x000002) !== 0;
      const defaultSampleDurationPresent = (tfhdFlags & 0x000008) !== 0;
      let defaultSampleDuration = 0;
      const defaultSampleSizePresent = (tfhdFlags & 0x000010) !== 0;
      let defaultSampleSize = 0;
      const defaultSampleFlagsPresent = (tfhdFlags & 0x000020) !== 0;
      let tfhdOffset = 8;
      if (id === trackId) {
       if (baseDataOffsetPresent) {
        tfhdOffset += 8;
       }
       if (sampleDescriptionIndexPresent) {
        tfhdOffset += 4;
       }
       if (defaultSampleDurationPresent) {
        defaultSampleDuration = readUint32(tfhd, tfhdOffset);
        tfhdOffset += 4;
       }
       if (defaultSampleSizePresent) {
        defaultSampleSize = readUint32(tfhd, tfhdOffset);
        tfhdOffset += 4;
       }
       if (defaultSampleFlagsPresent) {
        tfhdOffset += 4;
       }
       if (track.type === 'video') {
        isHEVCFlavor = isHEVC(track.codec);
       }
       findBox(traf, ['trun']).map((trun) => {
        const version = trun[0];
        const flags = readUint32(trun, 0) & 0xffffff;
        const dataOffsetPresent = (flags & 0x000001) !== 0;
        let dataOffset = 0;
        const firstSampleFlagsPresent = (flags & 0x000004) !== 0;
        const sampleDurationPresent = (flags & 0x000100) !== 0;
        let sampleDuration = 0;
        const sampleSizePresent = (flags & 0x000200) !== 0;
        let sampleSize = 0;
        const sampleFlagsPresent = (flags & 0x000400) !== 0;
        const sampleCompositionOffsetsPresent = (flags & 0x000800) !== 0;
        let compositionOffset = 0;
        const sampleCount = readUint32(trun, 4);
        let trunOffset = 8; // past version, flags, and sample count

        if (dataOffsetPresent) {
         dataOffset = readUint32(trun, trunOffset);
         trunOffset += 4;
        }
        if (firstSampleFlagsPresent) {
         trunOffset += 4;
        }
        let sampleOffset = dataOffset + moofOffset;
        for (let ix = 0; ix < sampleCount; ix++) {
         if (sampleDurationPresent) {
          sampleDuration = readUint32(trun, trunOffset);
          trunOffset += 4;
         } else {
          sampleDuration = defaultSampleDuration;
         }
         if (sampleSizePresent) {
          sampleSize = readUint32(trun, trunOffset);
          trunOffset += 4;
         } else {
          sampleSize = defaultSampleSize;
         }
         if (sampleFlagsPresent) {
          trunOffset += 4;
         }
         if (sampleCompositionOffsetsPresent) {
          if (version === 0) {
           compositionOffset = readUint32(trun, trunOffset);
          } else {
           compositionOffset = readSint32(trun, trunOffset);
          }
          trunOffset += 4;
         }
         if (track.type === ElementaryStreamTypes.VIDEO) {
          let naluTotalSize = 0;
          while (naluTotalSize < sampleSize) {
           const naluSize = readUint32(videoData, sampleOffset);
           sampleOffset += 4;
           if (isSEIMessage(isHEVCFlavor, videoData[sampleOffset])) {
            const data = videoData.subarray(sampleOffset, sampleOffset + naluSize);
            parseSEIMessageFromNALu(data, isHEVCFlavor ? 2 : 1, timeOffset + compositionOffset / timescale, seiSamples);
           }
           sampleOffset += naluSize;
           naluTotalSize += naluSize + 4;
          }
         }
         timeOffset += sampleDuration / timescale;
        }
       });
      }
     });
    });
   });
   return seiSamples;
  }
  function isHEVC(codec) {
   if (!codec) {
    return false;
   }
   const baseCodec = codec.substring(0, 4);
   return (
    baseCodec === 'hvc1' ||
    baseCodec === 'hev1' ||
    // Dolby Vision
    baseCodec === 'dvh1' ||
    baseCodec === 'dvhe'
   );
  }
  function isSEIMessage(isHEVCFlavor, naluHeader) {
   if (isHEVCFlavor) {
    const naluType = (naluHeader >> 1) & 0x3f;
    return naluType === 39 || naluType === 40;
   } else {
    const naluType = naluHeader & 0x1f;
    return naluType === 6;
   }
  }
  function parseSEIMessageFromNALu(unescapedData, headerSize, pts, samples) {
   const data = discardEPB(unescapedData);
   let seiPtr = 0;
   // skip nal header
   seiPtr += headerSize;
   let payloadType = 0;
   let payloadSize = 0;
   let b = 0;
   while (seiPtr < data.length) {
    payloadType = 0;
    do {
     if (seiPtr >= data.length) {
      break;
     }
     b = data[seiPtr++];
     payloadType += b;
    } while (b === 0xff);

    // Parse payload size.
    payloadSize = 0;
    do {
     if (seiPtr >= data.length) {
      break;
     }
     b = data[seiPtr++];
     payloadSize += b;
    } while (b === 0xff);
    const leftOver = data.length - seiPtr;
    // Create a variable to process the payload
    let payPtr = seiPtr;

    // Increment the seiPtr to the end of the payload
    if (payloadSize < leftOver) {
     seiPtr += payloadSize;
    } else if (payloadSize > leftOver) {
     // Some type of corruption has happened?
     logger.error(`Malformed SEI payload. ${payloadSize} is too small, only ${leftOver} bytes left to parse.`);
     // We might be able to parse some data, but let's be safe and ignore it.
     break;
    }
    if (payloadType === 4) {
     const countryCode = data[payPtr++];
     if (countryCode === 181) {
      const providerCode = readUint16(data, payPtr);
      payPtr += 2;
      if (providerCode === 49) {
       const userStructure = readUint32(data, payPtr);
       payPtr += 4;
       if (userStructure === 0x47413934) {
        const userDataType = data[payPtr++];

        // Raw CEA-608 bytes wrapped in CEA-708 packet
        if (userDataType === 3) {
         const firstByte = data[payPtr++];
         const totalCCs = 0x1f & firstByte;
         const enabled = 0x40 & firstByte;
         const totalBytes = enabled ? 2 + totalCCs * 3 : 0;
         const byteArray = new Uint8Array(totalBytes);
         if (enabled) {
          byteArray[0] = firstByte;
          for (let i = 1; i < totalBytes; i++) {
           byteArray[i] = data[payPtr++];
          }
         }
         samples.push({
          type: userDataType,
          payloadType,
          pts,
          bytes: byteArray,
         });
        }
       }
      }
     }
    } else if (payloadType === 5) {
     if (payloadSize > 16) {
      const uuidStrArray = [];
      for (let i = 0; i < 16; i++) {
       const _b = data[payPtr++].toString(16);
       uuidStrArray.push(_b.length == 1 ? '0' + _b : _b);
       if (i === 3 || i === 5 || i === 7 || i === 9) {
        uuidStrArray.push('-');
       }
      }
      const length = payloadSize - 16;
      const userDataBytes = new Uint8Array(length);
      for (let i = 0; i < length; i++) {
       userDataBytes[i] = data[payPtr++];
      }
      samples.push({
       payloadType,
       pts,
       uuid: uuidStrArray.join(''),
       userData: utf8ArrayToStr(userDataBytes),
       userDataBytes,
      });
     }
    }
   }
  }

  /**
   * remove Emulation Prevention bytes from a RBSP
   */
  function discardEPB(data) {
   const length = data.byteLength;
   const EPBPositions = [];
   let i = 1;

   // Find all `Emulation Prevention Bytes`
   while (i < length - 2) {
    if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {
     EPBPositions.push(i + 2);
     i += 2;
    } else {
     i++;
    }
   }

   // If no Emulation Prevention Bytes were found just return the original
   // array
   if (EPBPositions.length === 0) {
    return data;
   }

   // Create a new array to hold the NAL unit data
   const newLength = length - EPBPositions.length;
   const newData = new Uint8Array(newLength);
   let sourceIndex = 0;
   for (i = 0; i < newLength; sourceIndex++, i++) {
    if (sourceIndex === EPBPositions[0]) {
     // Skip this byte
     sourceIndex++;
     // Remove this position index
     EPBPositions.shift();
    }
    newData[i] = data[sourceIndex];
   }
   return newData;
  }
  function parseEmsg(data) {
   const version = data[0];
   let schemeIdUri = '';
   let value = '';
   let timeScale = 0;
   let presentationTimeDelta = 0;
   let presentationTime = 0;
   let eventDuration = 0;
   let id = 0;
   let offset = 0;
   if (version === 0) {
    while (bin2str(data.subarray(offset, offset + 1)) !== '\0') {
     schemeIdUri += bin2str(data.subarray(offset, offset + 1));
     offset += 1;
    }
    schemeIdUri += bin2str(data.subarray(offset, offset + 1));
    offset += 1;
    while (bin2str(data.subarray(offset, offset + 1)) !== '\0') {
     value += bin2str(data.subarray(offset, offset + 1));
     offset += 1;
    }
    value += bin2str(data.subarray(offset, offset + 1));
    offset += 1;
    timeScale = readUint32(data, 12);
    presentationTimeDelta = readUint32(data, 16);
    eventDuration = readUint32(data, 20);
    id = readUint32(data, 24);
    offset = 28;
   } else if (version === 1) {
    offset += 4;
    timeScale = readUint32(data, offset);
    offset += 4;
    const leftPresentationTime = readUint32(data, offset);
    offset += 4;
    const rightPresentationTime = readUint32(data, offset);
    offset += 4;
    presentationTime = 2 ** 32 * leftPresentationTime + rightPresentationTime;
    if (!isSafeInteger(presentationTime)) {
     presentationTime = Number.MAX_SAFE_INTEGER;
     logger.warn('Presentation time exceeds safe integer limit and wrapped to max safe integer in parsing emsg box');
    }
    eventDuration = readUint32(data, offset);
    offset += 4;
    id = readUint32(data, offset);
    offset += 4;
    while (bin2str(data.subarray(offset, offset + 1)) !== '\0') {
     schemeIdUri += bin2str(data.subarray(offset, offset + 1));
     offset += 1;
    }
    schemeIdUri += bin2str(data.subarray(offset, offset + 1));
    offset += 1;
    while (bin2str(data.subarray(offset, offset + 1)) !== '\0') {
     value += bin2str(data.subarray(offset, offset + 1));
     offset += 1;
    }
    value += bin2str(data.subarray(offset, offset + 1));
    offset += 1;
   }
   const payload = data.subarray(offset, data.byteLength);
   return {
    schemeIdUri,
    value,
    timeScale,
    presentationTime,
    presentationTimeDelta,
    eventDuration,
    id,
    payload,
   };
  }
  function mp4Box(type, ...payload) {
   const len = payload.length;
   let size = 8;
   let i = len;
   while (i--) {
    size += payload[i].byteLength;
   }
   const result = new Uint8Array(size);
   result[0] = (size >> 24) & 0xff;
   result[1] = (size >> 16) & 0xff;
   result[2] = (size >> 8) & 0xff;
   result[3] = size & 0xff;
   result.set(type, 4);
   for (i = 0, size = 8; i < len; i++) {
    result.set(payload[i], size);
    size += payload[i].byteLength;
   }
   return result;
  }
  function mp4pssh(systemId, keyids, data) {
   if (systemId.byteLength !== 16) {
    throw new RangeError('Invalid system id');
   }
   let version;
   let kids;
   {
    version = 0;
    kids = new Uint8Array();
   }
   let kidCount;
   if (version > 0) {
    kidCount = new Uint8Array(4);
    if (keyids.length > 0) {
     new DataView(kidCount.buffer).setUint32(0, keyids.length, false);
    }
   } else {
    kidCount = new Uint8Array();
   }
   const dataSize = new Uint8Array(4);
   if (data.byteLength > 0) {
    new DataView(dataSize.buffer).setUint32(0, data.byteLength, false);
   }
   return mp4Box(
    [112, 115, 115, 104],
    new Uint8Array([
     version,
     0x00,
     0x00,
     0x00, // Flags
    ]),
    systemId,
    // 16 bytes
    kidCount,
    kids,
    dataSize,
    data,
   );
  }

  const userAgentHevcSupportIsInaccurate = () => {
   return /\(Windows.+Firefox\//i.test(navigator.userAgent);
  };

  // from http://mp4ra.org/codecs.html
  // values indicate codec selection preference (lower is higher priority)
  const sampleEntryCodesISO = {
   audio: {
    a3ds: 1,
    'ac-3': 0.95,
    'ac-4': 1,
    alac: 0.9,
    alaw: 1,
    dra1: 1,
    'dts+': 1,
    'dts-': 1,
    dtsc: 1,
    dtse: 1,
    dtsh: 1,
    'ec-3': 0.9,
    enca: 1,
    fLaC: 0.9,
    // MP4-RA listed codec entry for FLAC
    flac: 0.9,
    // legacy browser codec name for FLAC
    FLAC: 0.9,
    // some manifests may list "FLAC" with Apple's tools
    g719: 1,
    g726: 1,
    m4ae: 1,
    mha1: 1,
    mha2: 1,
    mhm1: 1,
    mhm2: 1,
    mlpa: 1,
    mp4a: 1,
    'raw ': 1,
    Opus: 1,
    opus: 1,
    // browsers expect this to be lowercase despite MP4RA says 'Opus'
    samr: 1,
    sawb: 1,
    sawp: 1,
    sevc: 1,
    sqcp: 1,
    ssmv: 1,
    twos: 1,
    ulaw: 1,
   },
   video: {
    avc1: 1,
    avc2: 1,
    avc3: 1,
    avc4: 1,
    avcp: 1,
    av01: 0.8,
    dav1: 0.8,
    drac: 1,
    dva1: 1,
    dvav: 1,
    dvh1: 0.7,
    dvhe: 0.7,
    encv: 1,
    hev1: 0.75,
    hvc1: 0.75,
    mjp2: 1,
    mp4v: 1,
    mvc1: 1,
    mvc2: 1,
    mvc3: 1,
    mvc4: 1,
    resv: 1,
    rv60: 1,
    s263: 1,
    svc1: 1,
    svc2: 1,
    'vc-1': 1,
    vp08: 1,
    vp09: 0.9,
   },
   text: {
    stpp: 1,
    wvtt: 1,
   },
  };
  function isCodecType(codec, type) {
   const typeCodes = sampleEntryCodesISO[type];
   return !!typeCodes && !!typeCodes[codec.slice(0, 4)];
  }
  function areCodecsMediaSourceSupported(codecs, type, preferManagedMediaSource = true) {
   return !codecs.split(',').some((codec) => !isCodecMediaSourceSupported(codec, type, preferManagedMediaSource));
  }
  function isCodecMediaSourceSupported(codec, type, preferManagedMediaSource = true) {
   var _MediaSource$isTypeSu;
   const MediaSource = getMediaSource(preferManagedMediaSource);
   return (_MediaSource$isTypeSu = MediaSource == null ? void 0 : MediaSource.isTypeSupported(mimeTypeForCodec(codec, type))) != null ? _MediaSource$isTypeSu : false;
  }
  function mimeTypeForCodec(codec, type) {
   return `${type}/mp4;codecs=${codec}`;
  }
  function videoCodecPreferenceValue(videoCodec) {
   if (videoCodec) {
    const fourCC = videoCodec.substring(0, 4);
    return sampleEntryCodesISO.video[fourCC];
   }
   return 2;
  }
  function codecsSetSelectionPreferenceValue(codecSet) {
   const limitedHevcSupport = userAgentHevcSupportIsInaccurate();
   return codecSet.split(',').reduce((num, fourCC) => {
    const lowerPriority = limitedHevcSupport && isHEVC(fourCC);
    const preferenceValue = lowerPriority ? 9 : sampleEntryCodesISO.video[fourCC];
    if (preferenceValue) {
     return (preferenceValue * 2 + num) / (num ? 3 : 2);
    }
    return (sampleEntryCodesISO.audio[fourCC] + num) / (num ? 2 : 1);
   }, 0);
  }
  const CODEC_COMPATIBLE_NAMES = {};
  function getCodecCompatibleNameLower(lowerCaseCodec, preferManagedMediaSource = true) {
   if (CODEC_COMPATIBLE_NAMES[lowerCaseCodec]) {
    return CODEC_COMPATIBLE_NAMES[lowerCaseCodec];
   }
   const codecsToCheck = {
    // Idealy fLaC and Opus would be first (spec-compliant) but
    // some browsers will report that fLaC is supported then fail.
    // see: https://bugs.chromium.org/p/chromium/issues/detail?id=1422728
    flac: ['flac', 'fLaC', 'FLAC'],
    opus: ['opus', 'Opus'],
    // Replace audio codec info if browser does not support mp4a.40.34,
    // and demuxer can fallback to 'audio/mpeg' or 'audio/mp4;codecs="mp3"'
    'mp4a.40.34': ['mp3'],
   }[lowerCaseCodec];
   for (let i = 0; i < codecsToCheck.length; i++) {
    var _getMediaSource;
    if (isCodecMediaSourceSupported(codecsToCheck[i], 'audio', preferManagedMediaSource)) {
     CODEC_COMPATIBLE_NAMES[lowerCaseCodec] = codecsToCheck[i];
     return codecsToCheck[i];
    } else if (codecsToCheck[i] === 'mp3' && (_getMediaSource = getMediaSource(preferManagedMediaSource)) != null && _getMediaSource.isTypeSupported('audio/mpeg')) {
     return '';
    }
   }
   return lowerCaseCodec;
  }
  const AUDIO_CODEC_REGEXP = /flac|opus|mp4a\.40\.34/i;
  function getCodecCompatibleName(codec, preferManagedMediaSource = true) {
   return codec.replace(AUDIO_CODEC_REGEXP, (m) => getCodecCompatibleNameLower(m.toLowerCase(), preferManagedMediaSource));
  }
  function replaceVideoCodec(originalCodecs, newVideoCodec) {
   const codecs = [];
   if (originalCodecs) {
    const allCodecs = originalCodecs.split(',');
    for (let i = 0; i < allCodecs.length; i++) {
     if (!isCodecType(allCodecs[i], 'video')) {
      codecs.push(allCodecs[i]);
     }
    }
   }
   if (newVideoCodec) {
    codecs.push(newVideoCodec);
   }
   return codecs.join(',');
  }
  function pickMostCompleteCodecName(parsedCodec, levelCodec) {
   // Parsing of mp4a codecs strings in mp4-tools from media is incomplete as of d8c6c7a
   // so use level codec is parsed codec is unavailable or incomplete
   if (parsedCodec && (parsedCodec.length > 4 || ['ac-3', 'ec-3', 'alac', 'fLaC', 'Opus'].indexOf(parsedCodec) !== -1)) {
    if (isCodecSupportedAsType(parsedCodec, 'audio') || isCodecSupportedAsType(parsedCodec, 'video')) {
     return parsedCodec;
    }
   }
   if (levelCodec) {
    const levelCodecs = levelCodec.split(',');
    if (levelCodecs.length > 1) {
     if (parsedCodec) {
      for (let i = levelCodecs.length; i--; ) {
       if (levelCodecs[i].substring(0, 4) === parsedCodec.substring(0, 4)) {
        return levelCodecs[i];
       }
      }
     }
     return levelCodecs[0];
    }
   }
   return levelCodec || parsedCodec;
  }
  function isCodecSupportedAsType(codec, type) {
   return isCodecType(codec, type) && isCodecMediaSourceSupported(codec, type);
  }
  function convertAVC1ToAVCOTI(videoCodecs) {
   // Convert avc1 codec string from RFC-4281 to RFC-6381 for MediaSource.isTypeSupported
   // Examples: avc1.66.30 to avc1.42001e and avc1.77.30,avc1.66.30 to avc1.4d001e,avc1.42001e.
   const codecs = videoCodecs.split(',');
   for (let i = 0; i < codecs.length; i++) {
    const avcdata = codecs[i].split('.');
    // only convert codec strings starting with avc1 (Examples: avc1.64001f,dvh1.05.07)
    if (avcdata.length > 2 && avcdata[0] === 'avc1') {
     codecs[i] = `avc1.${parseInt(avcdata[1]).toString(16)}${('000' + parseInt(avcdata[2]).toString(16)).slice(-4)}`;
    }
   }
   return codecs.join(',');
  }
  function fillInMissingAV01Params(videoCodec) {
   // Used to fill in incomplete AV1 playlist CODECS strings for mediaCapabilities.decodingInfo queries
   if (videoCodec.startsWith('av01.')) {
    const av1params = videoCodec.split('.');
    const placeholders = ['0', '111', '01', '01', '01', '0'];
    for (let i = av1params.length; i > 4 && i < 10; i++) {
     av1params[i] = placeholders[i - 4];
    }
    return av1params.join('.');
   }
   return videoCodec;
  }
  function getM2TSSupportedAudioTypes(preferManagedMediaSource) {
   const MediaSource = getMediaSource(preferManagedMediaSource) || {
    isTypeSupported: () => false,
   };
   return {
    mpeg: MediaSource.isTypeSupported('audio/mpeg'),
    mp3: MediaSource.isTypeSupported('audio/mp4; codecs="mp3"'),
    ac3: MediaSource.isTypeSupported('audio/mp4; codecs="ac-3"'),
   };
  }
  function getCodecsForMimeType(mimeType) {
   return mimeType.replace(/^.+codecs=["']?([^"']+).*$/, '$1');
  }

  const SUPPORTED_INFO_DEFAULT = {
   supported: true,
   configurations: [],
   decodingInfoResults: [
    {
     supported: true,
     powerEfficient: true,
     smooth: true,
    },
   ],
  };
  function getUnsupportedResult(error, configurations) {
   return {
    supported: false,
    configurations,
    decodingInfoResults: [
     {
      supported: false,
      smooth: false,
      powerEfficient: false,
     },
    ],
    error,
   };
  }
  function requiresMediaCapabilitiesDecodingInfo(level, audioTracksByGroup, currentVideoRange, currentFrameRate, currentBw, audioPreference) {
   // Only test support when configuration is exceeds minimum options
   const videoCodecs = level.videoCodec;
   const audioGroups = level.audioCodec ? level.audioGroups : null;
   const audioCodecPreference = audioPreference == null ? void 0 : audioPreference.audioCodec;
   const channelsPreference = audioPreference == null ? void 0 : audioPreference.channels;
   const maxChannels = channelsPreference ? parseInt(channelsPreference) : audioCodecPreference ? Infinity : 2;
   let audioChannels = null;
   if (audioGroups != null && audioGroups.length) {
    try {
     if (audioGroups.length === 1 && audioGroups[0]) {
      audioChannels = audioTracksByGroup.groups[audioGroups[0]].channels;
     } else {
      audioChannels = audioGroups.reduce(
       (acc, groupId) => {
        if (groupId) {
         const audioTrackGroup = audioTracksByGroup.groups[groupId];
         if (!audioTrackGroup) {
          throw new Error(`Audio track group ${groupId} not found`);
         }
         // Sum all channel key values
         Object.keys(audioTrackGroup.channels).forEach((key) => {
          acc[key] = (acc[key] || 0) + audioTrackGroup.channels[key];
         });
        }
        return acc;
       },
       {
        2: 0,
       },
      );
     }
    } catch (error) {
     return true;
    }
   }
   return (
    (videoCodecs !== undefined &&
     // Force media capabilities check for HEVC to avoid failure on Windows
     (videoCodecs.split(',').some((videoCodec) => isHEVC(videoCodec)) || (level.width > 1920 && level.height > 1088) || (level.height > 1920 && level.width > 1088) || level.frameRate > Math.max(currentFrameRate, 30) || (level.videoRange !== 'SDR' && level.videoRange !== currentVideoRange) || level.bitrate > Math.max(currentBw, 8e6))) ||
    (!!audioChannels && isFiniteNumber(maxChannels) && Object.keys(audioChannels).some((channels) => parseInt(channels) > maxChannels))
   );
  }
  function getMediaDecodingInfoPromise(level, audioTracksByGroup, mediaCapabilities, cache = {}) {
   const videoCodecs = level.videoCodec;
   if ((!videoCodecs && !level.audioCodec) || !mediaCapabilities) {
    return Promise.resolve(SUPPORTED_INFO_DEFAULT);
   }
   const configurations = [];
   const videoDecodeList = makeVideoConfigurations(level);
   const videoCount = videoDecodeList.length;
   const audioDecodeList = makeAudioConfigurations(level, audioTracksByGroup, videoCount > 0);
   const audioCount = audioDecodeList.length;
   for (let i = videoCount || 1 * audioCount || 1; i--; ) {
    const configuration = {
     type: 'media-source',
    };
    if (videoCount) {
     configuration.video = videoDecodeList[i % videoCount];
    }
    if (audioCount) {
     configuration.audio = audioDecodeList[i % audioCount];
     const audioBitrate = configuration.audio.bitrate;
     if (configuration.video && audioBitrate) {
      configuration.video.bitrate -= audioBitrate;
     }
    }
    configurations.push(configuration);
   }
   if (videoCodecs) {
    // Override Windows Firefox HEVC MediaCapabilities result (https://github.com/video-dev/hls.js/issues/7046)
    const ua = navigator.userAgent;
    if (videoCodecs.split(',').some((videoCodec) => isHEVC(videoCodec)) && userAgentHevcSupportIsInaccurate()) {
     return Promise.resolve(getUnsupportedResult(new Error(`Overriding Windows Firefox HEVC MediaCapabilities result based on user-agent string: (${ua})`), configurations));
    }
   }
   return Promise.all(
    configurations.map((configuration) => {
     // Cache MediaCapabilities promises
     const decodingInfoKey = getMediaDecodingInfoKey(configuration);
     return cache[decodingInfoKey] || (cache[decodingInfoKey] = mediaCapabilities.decodingInfo(configuration));
    }),
   )
    .then((decodingInfoResults) => ({
     supported: !decodingInfoResults.some((info) => !info.supported),
     configurations,
     decodingInfoResults,
    }))
    .catch((error) => ({
     supported: false,
     configurations,
     decodingInfoResults: [],
     error,
    }));
  }
  function makeVideoConfigurations(level) {
   var _level$videoCodec;
   const videoCodecs = (_level$videoCodec = level.videoCodec) == null ? void 0 : _level$videoCodec.split(',');
   const bitrate = getVariantDecodingBitrate(level);
   const width = level.width || 640;
   const height = level.height || 480;
   // Assume a framerate of 30fps since MediaCapabilities will not accept Level default of 0.
   const framerate = level.frameRate || 30;
   const videoRange = level.videoRange.toLowerCase();
   return videoCodecs
    ? videoCodecs.map((videoCodec) => {
       const videoConfiguration = {
        contentType: mimeTypeForCodec(fillInMissingAV01Params(videoCodec), 'video'),
        width,
        height,
        bitrate,
        framerate,
       };
       if (videoRange !== 'sdr') {
        videoConfiguration.transferFunction = videoRange;
       }
       return videoConfiguration;
      })
    : [];
  }
  function makeAudioConfigurations(level, audioTracksByGroup, hasVideo) {
   var _level$audioCodec;
   const audioCodecs = (_level$audioCodec = level.audioCodec) == null ? void 0 : _level$audioCodec.split(',');
   const combinedBitrate = getVariantDecodingBitrate(level);
   if (audioCodecs && level.audioGroups) {
    return level.audioGroups.reduce((configurations, audioGroupId) => {
     var _audioTracksByGroup$g;
     const tracks = audioGroupId ? ((_audioTracksByGroup$g = audioTracksByGroup.groups[audioGroupId]) == null ? void 0 : _audioTracksByGroup$g.tracks) : null;
     if (tracks) {
      return tracks.reduce((configs, audioTrack) => {
       if (audioTrack.groupId === audioGroupId) {
        const channelsNumber = parseFloat(audioTrack.channels || '');
        audioCodecs.forEach((audioCodec) => {
         const audioConfiguration = {
          contentType: mimeTypeForCodec(audioCodec, 'audio'),
          bitrate: hasVideo ? estimatedAudioBitrate(audioCodec, combinedBitrate) : combinedBitrate,
         };
         if (channelsNumber) {
          audioConfiguration.channels = '' + channelsNumber;
         }
         configs.push(audioConfiguration);
        });
       }
       return configs;
      }, configurations);
     }
     return configurations;
    }, []);
   }
   return [];
  }
  function estimatedAudioBitrate(audioCodec, levelBitrate) {
   if (levelBitrate <= 1) {
    return 1;
   }
   let audioBitrate = 128000;
   if (audioCodec === 'ec-3') {
    audioBitrate = 768000;
   } else if (audioCodec === 'ac-3') {
    audioBitrate = 640000;
   }
   return Math.min(levelBitrate / 2, audioBitrate); // Don't exceed some % of level bitrate
  }
  function getVariantDecodingBitrate(level) {
   return Math.ceil(Math.max(level.bitrate * 0.9, level.averageBitrate) / 1000) * 1000 || 1;
  }
  function getMediaDecodingInfoKey(config) {
   let key = '';
   const { audio, video } = config;
   if (video) {
    const codec = getCodecsForMimeType(video.contentType);
    key += `${codec}_r${video.height}x${video.width}f${Math.ceil(video.framerate)}${video.transferFunction || 'sd'}_${Math.ceil(video.bitrate / 1e5)}`;
   }
   if (audio) {
    const codec = getCodecsForMimeType(audio.contentType);
    key += `${video ? '_' : ''}${codec}_c${audio.channels}`;
   }
   return key;
  }

  const HdcpLevels = ['NONE', 'TYPE-0', 'TYPE-1', null];
  function isHdcpLevel(value) {
   return HdcpLevels.indexOf(value) > -1;
  }
  const VideoRangeValues = ['SDR', 'PQ', 'HLG'];
  function isVideoRange(value) {
   return !!value && VideoRangeValues.indexOf(value) > -1;
  }
  var HlsSkip = {
   No: '',
   Yes: 'YES',
   v2: 'v2',
  };
  function getSkipValue(details) {
   const { canSkipUntil, canSkipDateRanges, age } = details;
   // A Client SHOULD NOT request a Playlist Delta Update unless it already
   // has a version of the Playlist that is no older than one-half of the Skip Boundary.
   // @see: https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis#section-6.3.7
   const playlistRecentEnough = age < canSkipUntil / 2;
   if (canSkipUntil && playlistRecentEnough) {
    if (canSkipDateRanges) {
     return HlsSkip.v2;
    }
    return HlsSkip.Yes;
   }
   return HlsSkip.No;
  }
  class HlsUrlParameters {
   constructor(msn, part, skip) {
    this.msn = void 0;
    this.part = void 0;
    this.skip = void 0;
    this.msn = msn;
    this.part = part;
    this.skip = skip;
   }
   addDirectives(uri) {
    const url = new self.URL(uri);
    if (this.msn !== undefined) {
     url.searchParams.set('_HLS_msn', this.msn.toString());
    }
    if (this.part !== undefined) {
     url.searchParams.set('_HLS_part', this.part.toString());
    }
    if (this.skip) {
     url.searchParams.set('_HLS_skip', this.skip);
    }
    return url.href;
   }
  }
  class Level {
   constructor(data) {
    this._attrs = void 0;
    this.audioCodec = void 0;
    this.bitrate = void 0;
    this.codecSet = void 0;
    this.url = void 0;
    this.frameRate = void 0;
    this.height = void 0;
    this.id = void 0;
    this.name = void 0;
    this.supplemental = void 0;
    this.videoCodec = void 0;
    this.width = void 0;
    this.details = void 0;
    this.fragmentError = 0;
    this.loadError = 0;
    this.loaded = void 0;
    this.realBitrate = 0;
    this.supportedPromise = void 0;
    this.supportedResult = void 0;
    this._avgBitrate = 0;
    this._audioGroups = void 0;
    this._subtitleGroups = void 0;
    // Deprecated (retained for backwards compatibility)
    this._urlId = 0;
    this.url = [data.url];
    this._attrs = [data.attrs];
    this.bitrate = data.bitrate;
    if (data.details) {
     this.details = data.details;
    }
    this.id = data.id || 0;
    this.name = data.name;
    this.width = data.width || 0;
    this.height = data.height || 0;
    this.frameRate = data.attrs.optionalFloat('FRAME-RATE', 0);
    this._avgBitrate = data.attrs.decimalInteger('AVERAGE-BANDWIDTH');
    this.audioCodec = data.audioCodec;
    this.videoCodec = data.videoCodec;
    this.codecSet = [data.videoCodec, data.audioCodec]
     .filter((c) => !!c)
     .map((s) => s.substring(0, 4))
     .join(',');
    if ('supplemental' in data) {
     var _data$supplemental;
     this.supplemental = data.supplemental;
     const supplementalVideo = (_data$supplemental = data.supplemental) == null ? void 0 : _data$supplemental.videoCodec;
     if (supplementalVideo && supplementalVideo !== data.videoCodec) {
      this.codecSet += `,${supplementalVideo.substring(0, 4)}`;
     }
    }
    this.addGroupId('audio', data.attrs.AUDIO);
    this.addGroupId('text', data.attrs.SUBTITLES);
   }
   get maxBitrate() {
    return Math.max(this.realBitrate, this.bitrate);
   }
   get averageBitrate() {
    return this._avgBitrate || this.realBitrate || this.bitrate;
   }
   get attrs() {
    return this._attrs[0];
   }
   get codecs() {
    return this.attrs.CODECS || '';
   }
   get pathwayId() {
    return this.attrs['PATHWAY-ID'] || '.';
   }
   get videoRange() {
    return this.attrs['VIDEO-RANGE'] || 'SDR';
   }
   get score() {
    return this.attrs.optionalFloat('SCORE', 0);
   }
   get uri() {
    return this.url[0] || '';
   }
   hasAudioGroup(groupId) {
    return hasGroup(this._audioGroups, groupId);
   }
   hasSubtitleGroup(groupId) {
    return hasGroup(this._subtitleGroups, groupId);
   }
   get audioGroups() {
    return this._audioGroups;
   }
   get subtitleGroups() {
    return this._subtitleGroups;
   }
   addGroupId(type, groupId) {
    if (!groupId) {
     return;
    }
    if (type === 'audio') {
     let audioGroups = this._audioGroups;
     if (!audioGroups) {
      audioGroups = this._audioGroups = [];
     }
     if (audioGroups.indexOf(groupId) === -1) {
      audioGroups.push(groupId);
     }
    } else if (type === 'text') {
     let subtitleGroups = this._subtitleGroups;
     if (!subtitleGroups) {
      subtitleGroups = this._subtitleGroups = [];
     }
     if (subtitleGroups.indexOf(groupId) === -1) {
      subtitleGroups.push(groupId);
     }
    }
   }

   // Deprecated methods (retained for backwards compatibility)
   get urlId() {
    return 0;
   }
   set urlId(value) {}
   get audioGroupIds() {
    return this.audioGroups ? [this.audioGroupId] : undefined;
   }
   get textGroupIds() {
    return this.subtitleGroups ? [this.textGroupId] : undefined;
   }
   get audioGroupId() {
    var _this$audioGroups;
    return (_this$audioGroups = this.audioGroups) == null ? void 0 : _this$audioGroups[0];
   }
   get textGroupId() {
    var _this$subtitleGroups;
    return (_this$subtitleGroups = this.subtitleGroups) == null ? void 0 : _this$subtitleGroups[0];
   }
   addFallback() {}
  }
  function hasGroup(groups, groupId) {
   if (!groupId || !groups) {
    return false;
   }
   return groups.indexOf(groupId) !== -1;
  }

  /**
   * @returns Whether we can detect and validate HDR capability within the window context
   */
  function isHdrSupported() {
   if (typeof matchMedia === 'function') {
    const mediaQueryList = matchMedia('(dynamic-range: high)');
    const badQuery = matchMedia('bad query');
    if (mediaQueryList.media !== badQuery.media) {
     return mediaQueryList.matches === true;
    }
   }
   return false;
  }

  /**
   * Sanitizes inputs to return the active video selection options for HDR/SDR.
   * When both inputs are null:
   *
   *    `{ preferHDR: false, allowedVideoRanges: [] }`
   *
   * When `currentVideoRange` non-null, maintain the active range:
   *
   *    `{ preferHDR: currentVideoRange !== 'SDR', allowedVideoRanges: [currentVideoRange] }`
   *
   * When VideoSelectionOption non-null:
   *
   *  - Allow all video ranges if `allowedVideoRanges` unspecified.
   *  - If `preferHDR` is non-null use the value to filter `allowedVideoRanges`.
   *  - Else check window for HDR support and set `preferHDR` to the result.
   *
   * @param currentVideoRange
   * @param videoPreference
   */
  function getVideoSelectionOptions(currentVideoRange, videoPreference) {
   let preferHDR = false;
   let allowedVideoRanges = [];
   if (currentVideoRange) {
    preferHDR = currentVideoRange !== 'SDR';
    allowedVideoRanges = [currentVideoRange];
   }
   if (videoPreference) {
    allowedVideoRanges = videoPreference.allowedVideoRanges || VideoRangeValues.slice(0);
    const allowAutoPreferHDR = allowedVideoRanges.join('') !== 'SDR' && !videoPreference.videoCodec;
    preferHDR = videoPreference.preferHDR !== undefined ? videoPreference.preferHDR : allowAutoPreferHDR && isHdrSupported();
    if (!preferHDR) {
     allowedVideoRanges = ['SDR'];
    }
   }
   return {
    preferHDR,
    allowedVideoRanges,
   };
  }

  const omitCircularRefsReplacer = (replacer) => {
   const known = new WeakSet();
   return (_, value) => {
    if (replacer) {
     value = replacer(_, value);
    }
    if (typeof value === 'object' && value !== null) {
     if (known.has(value)) {
      return;
     }
     known.add(value);
    }
    return value;
   };
  };
  const stringify = (object, replacer) => JSON.stringify(object, omitCircularRefsReplacer(replacer));

  function getStartCodecTier(codecTiers, currentVideoRange, currentBw, audioPreference, videoPreference) {
   const codecSets = Object.keys(codecTiers);
   const channelsPreference = audioPreference == null ? void 0 : audioPreference.channels;
   const audioCodecPreference = audioPreference == null ? void 0 : audioPreference.audioCodec;
   const videoCodecPreference = videoPreference == null ? void 0 : videoPreference.videoCodec;
   const preferStereo = channelsPreference && parseInt(channelsPreference) === 2;
   // Use first level set to determine stereo, and minimum resolution and framerate
   let hasStereo = false;
   let hasCurrentVideoRange = false;
   let minHeight = Infinity;
   let minFramerate = Infinity;
   let minBitrate = Infinity;
   let minIndex = Infinity;
   let selectedScore = 0;
   let videoRanges = [];
   const { preferHDR, allowedVideoRanges } = getVideoSelectionOptions(currentVideoRange, videoPreference);
   for (let i = codecSets.length; i--; ) {
    const tier = codecTiers[codecSets[i]];
    hasStereo || (hasStereo = tier.channels[2] > 0);
    minHeight = Math.min(minHeight, tier.minHeight);
    minFramerate = Math.min(minFramerate, tier.minFramerate);
    minBitrate = Math.min(minBitrate, tier.minBitrate);
    const matchingVideoRanges = allowedVideoRanges.filter((range) => tier.videoRanges[range] > 0);
    if (matchingVideoRanges.length > 0) {
     hasCurrentVideoRange = true;
    }
   }
   minHeight = isFiniteNumber(minHeight) ? minHeight : 0;
   minFramerate = isFiniteNumber(minFramerate) ? minFramerate : 0;
   const maxHeight = Math.max(1080, minHeight);
   const maxFramerate = Math.max(30, minFramerate);
   minBitrate = isFiniteNumber(minBitrate) ? minBitrate : currentBw;
   currentBw = Math.max(minBitrate, currentBw);
   // If there are no variants with matching preference, set currentVideoRange to undefined
   if (!hasCurrentVideoRange) {
    currentVideoRange = undefined;
   }
   const hasMultipleSets = codecSets.length > 1;
   const codecSet = codecSets.reduce((selected, candidate) => {
    // Remove candiates which do not meet bitrate, default audio, stereo or channels preference, 1080p or lower, 30fps or lower, or SDR/HDR selection if present
    const candidateTier = codecTiers[candidate];
    if (candidate === selected) {
     return selected;
    }
    videoRanges = hasCurrentVideoRange ? allowedVideoRanges.filter((range) => candidateTier.videoRanges[range] > 0) : [];
    if (hasMultipleSets) {
     if (candidateTier.minBitrate > currentBw) {
      logStartCodecCandidateIgnored(candidate, `min bitrate of ${candidateTier.minBitrate} > current estimate of ${currentBw}`);
      return selected;
     }
     if (!candidateTier.hasDefaultAudio) {
      logStartCodecCandidateIgnored(candidate, `no renditions with default or auto-select sound found`);
      return selected;
     }
     if (audioCodecPreference && candidate.indexOf(audioCodecPreference.substring(0, 4)) % 5 !== 0) {
      logStartCodecCandidateIgnored(candidate, `audio codec preference "${audioCodecPreference}" not found`);
      return selected;
     }
     if (channelsPreference && !preferStereo) {
      if (!candidateTier.channels[channelsPreference]) {
       logStartCodecCandidateIgnored(candidate, `no renditions with ${channelsPreference} channel sound found (channels options: ${Object.keys(candidateTier.channels)})`);
       return selected;
      }
     } else if ((!audioCodecPreference || preferStereo) && hasStereo && candidateTier.channels['2'] === 0) {
      logStartCodecCandidateIgnored(candidate, `no renditions with stereo sound found`);
      return selected;
     }
     if (candidateTier.minHeight > maxHeight) {
      logStartCodecCandidateIgnored(candidate, `min resolution of ${candidateTier.minHeight} > maximum of ${maxHeight}`);
      return selected;
     }
     if (candidateTier.minFramerate > maxFramerate) {
      logStartCodecCandidateIgnored(candidate, `min framerate of ${candidateTier.minFramerate} > maximum of ${maxFramerate}`);
      return selected;
     }
     if (!videoRanges.some((range) => candidateTier.videoRanges[range] > 0)) {
      logStartCodecCandidateIgnored(candidate, `no variants with VIDEO-RANGE of ${stringify(videoRanges)} found`);
      return selected;
     }
     if (videoCodecPreference && candidate.indexOf(videoCodecPreference.substring(0, 4)) % 5 !== 0) {
      logStartCodecCandidateIgnored(candidate, `video codec preference "${videoCodecPreference}" not found`);
      return selected;
     }
     if (candidateTier.maxScore < selectedScore) {
      logStartCodecCandidateIgnored(candidate, `max score of ${candidateTier.maxScore} < selected max of ${selectedScore}`);
      return selected;
     }
    }
    // Remove candiates with less preferred codecs or more errors
    if (selected && (codecsSetSelectionPreferenceValue(candidate) >= codecsSetSelectionPreferenceValue(selected) || candidateTier.fragmentError > codecTiers[selected].fragmentError)) {
     return selected;
    }
    minIndex = candidateTier.minIndex;
    selectedScore = candidateTier.maxScore;
    return candidate;
   }, undefined);
   return {
    codecSet,
    videoRanges,
    preferHDR,
    minFramerate,
    minBitrate,
    minIndex,
   };
  }
  function logStartCodecCandidateIgnored(codeSet, reason) {
   logger.log(`[abr] start candidates with "${codeSet}" ignored because ${reason}`);
  }
  function getAudioTracksByGroup(allAudioTracks) {
   return allAudioTracks.reduce(
    (audioTracksByGroup, track) => {
     let trackGroup = audioTracksByGroup.groups[track.groupId];
     if (!trackGroup) {
      trackGroup = audioTracksByGroup.groups[track.groupId] = {
       tracks: [],
       channels: {
        2: 0,
       },
       hasDefault: false,
       hasAutoSelect: false,
      };
     }
     trackGroup.tracks.push(track);
     const channelsKey = track.channels || '2';
     trackGroup.channels[channelsKey] = (trackGroup.channels[channelsKey] || 0) + 1;
     trackGroup.hasDefault = trackGroup.hasDefault || track.default;
     trackGroup.hasAutoSelect = trackGroup.hasAutoSelect || track.autoselect;
     if (trackGroup.hasDefault) {
      audioTracksByGroup.hasDefaultAudio = true;
     }
     if (trackGroup.hasAutoSelect) {
      audioTracksByGroup.hasAutoSelectAudio = true;
     }
     return audioTracksByGroup;
    },
    {
     hasDefaultAudio: false,
     hasAutoSelectAudio: false,
     groups: {},
    },
   );
  }
  function getCodecTiers(levels, audioTracksByGroup, minAutoLevel, maxAutoLevel) {
   return levels.slice(minAutoLevel, maxAutoLevel + 1).reduce((tiers, level, index) => {
    if (!level.codecSet) {
     return tiers;
    }
    const audioGroups = level.audioGroups;
    let tier = tiers[level.codecSet];
    if (!tier) {
     tiers[level.codecSet] = tier = {
      minBitrate: Infinity,
      minHeight: Infinity,
      minFramerate: Infinity,
      minIndex: index,
      maxScore: 0,
      videoRanges: {
       SDR: 0,
      },
      channels: {
       2: 0,
      },
      hasDefaultAudio: !audioGroups,
      fragmentError: 0,
     };
    }
    tier.minBitrate = Math.min(tier.minBitrate, level.bitrate);
    const lesserWidthOrHeight = Math.min(level.height, level.width);
    tier.minHeight = Math.min(tier.minHeight, lesserWidthOrHeight);
    tier.minFramerate = Math.min(tier.minFramerate, level.frameRate);
    tier.minIndex = Math.min(tier.minIndex, index);
    tier.maxScore = Math.max(tier.maxScore, level.score);
    tier.fragmentError += level.fragmentError;
    tier.videoRanges[level.videoRange] = (tier.videoRanges[level.videoRange] || 0) + 1;
    if (audioGroups) {
     audioGroups.forEach((audioGroupId) => {
      if (!audioGroupId) {
       return;
      }
      const audioGroup = audioTracksByGroup.groups[audioGroupId];
      if (!audioGroup) {
       return;
      }
      // Default audio is any group with DEFAULT=YES, or if missing then any group with AUTOSELECT=YES, or all variants
      tier.hasDefaultAudio = tier.hasDefaultAudio || audioTracksByGroup.hasDefaultAudio ? audioGroup.hasDefault : audioGroup.hasAutoSelect || (!audioTracksByGroup.hasDefaultAudio && !audioTracksByGroup.hasAutoSelectAudio);
      Object.keys(audioGroup.channels).forEach((channels) => {
       tier.channels[channels] = (tier.channels[channels] || 0) + audioGroup.channels[channels];
      });
     });
    }
    return tiers;
   }, {});
  }
  function getBasicSelectionOption(option) {
   if (!option) {
    return option;
   }
   const { lang, assocLang, characteristics, channels, audioCodec } = option;
   return {
    lang,
    assocLang,
    characteristics,
    channels,
    audioCodec,
   };
  }
  function findMatchingOption(option, tracks, matchPredicate) {
   if ('attrs' in option) {
    const index = tracks.indexOf(option);
    if (index !== -1) {
     return index;
    }
   }
   for (let i = 0; i < tracks.length; i++) {
    const track = tracks[i];
    if (matchesOption(option, track, matchPredicate)) {
     return i;
    }
   }
   return -1;
  }
  function matchesOption(option, track, matchPredicate) {
   const { groupId, name, lang, assocLang, default: isDefault } = option;
   const forced = option.forced;
   return (groupId === undefined || track.groupId === groupId) && (name === undefined || track.name === name) && (lang === undefined || languagesMatch(lang, track.lang)) && (lang === undefined || track.assocLang === assocLang) && (isDefault === undefined || track.default === isDefault) && (forced === undefined || track.forced === forced) && (!('characteristics' in option) || characteristicsMatch(option.characteristics || '', track.characteristics)) && (matchPredicate === undefined || matchPredicate(option, track));
  }
  function languagesMatch(languageA, languageB = '--') {
   if (languageA.length === languageB.length) {
    return languageA === languageB;
   }
   return languageA.startsWith(languageB) || languageB.startsWith(languageA);
  }
  function characteristicsMatch(characteristicsA, characteristicsB = '') {
   const arrA = characteristicsA.split(',');
   const arrB = characteristicsB.split(',');
   // Expects each item to be unique:
   return arrA.length === arrB.length && !arrA.some((el) => arrB.indexOf(el) === -1);
  }
  function audioMatchPredicate(option, track) {
   const { audioCodec, channels } = option;
   return (audioCodec === undefined || (track.audioCodec || '').substring(0, 4) === audioCodec.substring(0, 4)) && (channels === undefined || channels === (track.channels || '2'));
  }
  function findClosestLevelWithAudioGroup(option, levels, allAudioTracks, searchIndex, matchPredicate) {
   const currentLevel = levels[searchIndex];
   // Are there variants with same URI as current level?
   // If so, find a match that does not require any level URI change
   const variants = levels.reduce((variantMap, level, index) => {
    const uri = level.uri;
    const renditions = variantMap[uri] || (variantMap[uri] = []);
    renditions.push(index);
    return variantMap;
   }, {});
   const renditions = variants[currentLevel.uri];
   if (renditions.length > 1) {
    searchIndex = Math.max.apply(Math, renditions);
   }
   // Find best match
   const currentVideoRange = currentLevel.videoRange;
   const currentFrameRate = currentLevel.frameRate;
   const currentVideoCodec = currentLevel.codecSet.substring(0, 4);
   const matchingVideo = searchDownAndUpList(levels, searchIndex, (level) => {
    if (level.videoRange !== currentVideoRange || level.frameRate !== currentFrameRate || level.codecSet.substring(0, 4) !== currentVideoCodec) {
     return false;
    }
    const audioGroups = level.audioGroups;
    const tracks = allAudioTracks.filter((track) => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);
    return findMatchingOption(option, tracks, matchPredicate) > -1;
   });
   if (matchingVideo > -1) {
    return matchingVideo;
   }
   return searchDownAndUpList(levels, searchIndex, (level) => {
    const audioGroups = level.audioGroups;
    const tracks = allAudioTracks.filter((track) => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);
    return findMatchingOption(option, tracks, matchPredicate) > -1;
   });
  }
  function searchDownAndUpList(arr, searchIndex, predicate) {
   for (let i = searchIndex; i > -1; i--) {
    if (predicate(arr[i])) {
     return i;
    }
   }
   for (let i = searchIndex + 1; i < arr.length; i++) {
    if (predicate(arr[i])) {
     return i;
    }
   }
   return -1;
  }
  function useAlternateAudio(audioTrackUrl, hls) {
   var _hls$loadLevelObj;
   return !!audioTrackUrl && audioTrackUrl !== ((_hls$loadLevelObj = hls.loadLevelObj) == null ? void 0 : _hls$loadLevelObj.uri);
  }

  class AbrController extends Logger {
   constructor(_hls) {
    super('abr', _hls.logger);
    this.hls = void 0;
    this.lastLevelLoadSec = 0;
    this.lastLoadedFragLevel = -1;
    this.firstSelection = -1;
    this._nextAutoLevel = -1;
    this.nextAutoLevelKey = '';
    this.audioTracksByGroup = null;
    this.codecTiers = null;
    this.timer = -1;
    this.fragCurrent = null;
    this.partCurrent = null;
    this.bitrateTestDelay = 0;
    this.rebufferNotice = -1;
    this.supportedCache = {};
    this.bwEstimator = void 0;
    /*
        This method monitors the download rate of the current fragment, and will downswitch if that fragment will not load
        quickly enough to prevent underbuffering
      */
    this._abandonRulesCheck = (levelLoaded) => {
     var _ref;
     const { fragCurrent: frag, partCurrent: part, hls } = this;
     const { autoLevelEnabled, media } = hls;
     if (!frag || !media) {
      return;
     }
     const now = performance.now();
     const stats = part ? part.stats : frag.stats;
     const duration = part ? part.duration : frag.duration;
     const timeLoading = now - stats.loading.start;
     const minAutoLevel = hls.minAutoLevel;
     const loadingFragForLevel = frag.level;
     const currentAutoLevel = this._nextAutoLevel;
     // If frag loading is aborted, complete, or from lowest level, stop timer and return
     if (stats.aborted || (stats.loaded && stats.loaded === stats.total) || loadingFragForLevel <= minAutoLevel) {
      this.clearTimer();
      // reset forced auto level value so that next level will be selected
      this._nextAutoLevel = -1;
      return;
     }

     // This check only runs if we're in ABR mode
     if (!autoLevelEnabled) {
      return;
     }

     // Must be loading/loaded a new level or be in a playing state
     const fragBlockingSwitch = currentAutoLevel > -1 && currentAutoLevel !== loadingFragForLevel;
     const levelChange = !!levelLoaded || fragBlockingSwitch;
     if (!levelChange && (media.paused || !media.playbackRate || !media.readyState)) {
      return;
     }
     const bufferInfo = hls.mainForwardBufferInfo;
     if (!levelChange && bufferInfo === null) {
      return;
     }
     const ttfbEstimate = this.bwEstimator.getEstimateTTFB();
     const playbackRate = Math.abs(media.playbackRate);
     // To maintain stable adaptive playback, only begin monitoring frag loading after half or more of its playback duration has passed
     if (timeLoading <= Math.max(ttfbEstimate, 1000 * (duration / (playbackRate * 2)))) {
      return;
     }

     // bufferStarvationDelay is an estimate of the amount time (in seconds) it will take to exhaust the buffer
     const bufferStarvationDelay = bufferInfo ? bufferInfo.len / playbackRate : 0;
     const ttfb = stats.loading.first ? stats.loading.first - stats.loading.start : -1;
     const loadedFirstByte = stats.loaded && ttfb > -1;
     const bwEstimate = this.getBwEstimate();
     const levels = hls.levels;
     const level = levels[loadingFragForLevel];
     const expectedLen = Math.max(stats.loaded, Math.round((duration * (frag.bitrate || level.averageBitrate)) / 8));
     let timeStreaming = loadedFirstByte ? timeLoading - ttfb : timeLoading;
     if (timeStreaming < 1 && loadedFirstByte) {
      timeStreaming = Math.min(timeLoading, (stats.loaded * 8) / bwEstimate);
     }
     const loadRate = loadedFirstByte ? (stats.loaded * 1000) / timeStreaming : 0;
     // fragLoadDelay is an estimate of the time (in seconds) it will take to buffer the remainder of the fragment
     const ttfbSeconds = ttfbEstimate / 1000;
     const fragLoadedDelay = loadRate ? (expectedLen - stats.loaded) / loadRate : (expectedLen * 8) / bwEstimate + ttfbSeconds;
     // Only downswitch if the time to finish loading the current fragment is greater than the amount of buffer left
     if (fragLoadedDelay <= bufferStarvationDelay) {
      return;
     }
     const bwe = loadRate ? loadRate * 8 : bwEstimate;
     const live = ((_ref = (levelLoaded == null ? void 0 : levelLoaded.details) || this.hls.latestLevelDetails) == null ? void 0 : _ref.live) === true;
     const abrBandWidthUpFactor = this.hls.config.abrBandWidthUpFactor;
     let fragLevelNextLoadedDelay = Number.POSITIVE_INFINITY;
     let nextLoadLevel;
     // Iterate through lower level and try to find the largest one that avoids rebuffering
     for (nextLoadLevel = loadingFragForLevel - 1; nextLoadLevel > minAutoLevel; nextLoadLevel--) {
      // compute time to load next fragment at lower level
      // 8 = bits per byte (bps/Bps)
      const levelNextBitrate = levels[nextLoadLevel].maxBitrate;
      const requiresLevelLoad = !levels[nextLoadLevel].details || live;
      fragLevelNextLoadedDelay = this.getTimeToLoadFrag(ttfbSeconds, bwe, duration * levelNextBitrate, requiresLevelLoad);
      if (fragLevelNextLoadedDelay < Math.min(bufferStarvationDelay, duration + ttfbSeconds)) {
       break;
      }
     }
     // Only emergency switch down if it takes less time to load a new fragment at lowest level instead of continuing
     // to load the current one
     if (fragLevelNextLoadedDelay >= fragLoadedDelay) {
      return;
     }

     // if estimated load time of new segment is completely unreasonable, ignore and do not emergency switch down
     if (fragLevelNextLoadedDelay > duration * 10) {
      return;
     }
     if (loadedFirstByte) {
      // If there has been loading progress, sample bandwidth using loading time offset by minimum TTFB time
      this.bwEstimator.sample(timeLoading - Math.min(ttfbEstimate, ttfb), stats.loaded);
     } else {
      // If there has been no loading progress, sample TTFB
      this.bwEstimator.sampleTTFB(timeLoading);
     }
     const nextLoadLevelBitrate = levels[nextLoadLevel].maxBitrate;
     if (this.getBwEstimate() * abrBandWidthUpFactor > nextLoadLevelBitrate) {
      this.resetEstimator(nextLoadLevelBitrate);
     }
     const bestSwitchLevel = this.findBestLevel(nextLoadLevelBitrate, minAutoLevel, nextLoadLevel, 0, bufferStarvationDelay, 1, 1);
     if (bestSwitchLevel > -1) {
      nextLoadLevel = bestSwitchLevel;
     }
     this.warn(`Fragment ${frag.sn}${part ? ' part ' + part.index : ''} of level ${loadingFragForLevel} is loading too slowly;
      Fragment duration: ${frag.duration.toFixed(3)}
      Time to underbuffer: ${bufferStarvationDelay.toFixed(3)} s
      Estimated load time for current fragment: ${fragLoadedDelay.toFixed(3)} s
      Estimated load time for down switch fragment: ${fragLevelNextLoadedDelay.toFixed(3)} s
      TTFB estimate: ${ttfb | 0} ms
      Current BW estimate: ${isFiniteNumber(bwEstimate) ? bwEstimate | 0 : 'Unknown'} bps
      New BW estimate: ${this.getBwEstimate() | 0} bps
      Switching to level ${nextLoadLevel} @ ${nextLoadLevelBitrate | 0} bps`);
     hls.nextLoadLevel = hls.nextAutoLevel = nextLoadLevel;
     this.clearTimer();
     const abortAndSwitch = () => {
      // Are nextLoadLevel details available or is stream-controller still in "WAITING_LEVEL" state?
      this.clearTimer();
      if (this.fragCurrent === frag && this.hls.loadLevel === nextLoadLevel && nextLoadLevel > 0) {
       const bufferStarvationDelay = this.getStarvationDelay();
       this.warn(`Aborting inflight request ${nextLoadLevel > 0 ? 'and switching down' : ''}
      Fragment duration: ${frag.duration.toFixed(3)} s
      Time to underbuffer: ${bufferStarvationDelay.toFixed(3)} s`);
       frag.abortRequests();
       this.fragCurrent = this.partCurrent = null;
       if (nextLoadLevel > minAutoLevel) {
        let lowestSwitchLevel = this.findBestLevel(this.hls.levels[minAutoLevel].bitrate, minAutoLevel, nextLoadLevel, 0, bufferStarvationDelay, 1, 1);
        if (lowestSwitchLevel === -1) {
         lowestSwitchLevel = minAutoLevel;
        }
        this.hls.nextLoadLevel = this.hls.nextAutoLevel = lowestSwitchLevel;
        this.resetEstimator(this.hls.levels[lowestSwitchLevel].bitrate);
       }
      }
     };
     if (fragBlockingSwitch || fragLoadedDelay > fragLevelNextLoadedDelay * 2) {
      abortAndSwitch();
     } else {
      this.timer = self.setInterval(abortAndSwitch, fragLevelNextLoadedDelay * 1000);
     }
     hls.trigger(Events.FRAG_LOAD_EMERGENCY_ABORTED, {
      frag,
      part,
      stats,
     });
    };
    this.hls = _hls;
    this.bwEstimator = this.initEstimator();
    this.registerListeners();
   }
   resetEstimator(abrEwmaDefaultEstimate) {
    if (abrEwmaDefaultEstimate) {
     this.log(`setting initial bwe to ${abrEwmaDefaultEstimate}`);
     this.hls.config.abrEwmaDefaultEstimate = abrEwmaDefaultEstimate;
    }
    this.firstSelection = -1;
    this.bwEstimator = this.initEstimator();
   }
   initEstimator() {
    const config = this.hls.config;
    return new EwmaBandWidthEstimator(config.abrEwmaSlowVoD, config.abrEwmaFastVoD, config.abrEwmaDefaultEstimate);
   }
   registerListeners() {
    const { hls } = this;
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);
    hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);
    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);
    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
    hls.on(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);
    hls.on(Events.ERROR, this.onError, this);
   }
   unregisterListeners() {
    const { hls } = this;
    if (!hls) {
     return;
    }
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);
    hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);
    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);
    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
    hls.off(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);
    hls.off(Events.ERROR, this.onError, this);
   }
   destroy() {
    this.unregisterListeners();
    this.clearTimer();
    // @ts-ignore
    this.hls = this._abandonRulesCheck = this.supportedCache = null;
    this.fragCurrent = this.partCurrent = null;
   }
   onManifestLoading(event, data) {
    this.lastLoadedFragLevel = -1;
    this.firstSelection = -1;
    this.lastLevelLoadSec = 0;
    this.supportedCache = {};
    this.fragCurrent = this.partCurrent = null;
    this.onLevelsUpdated();
    this.clearTimer();
   }
   onLevelsUpdated() {
    if (this.lastLoadedFragLevel > -1 && this.fragCurrent) {
     this.lastLoadedFragLevel = this.fragCurrent.level;
    }
    this._nextAutoLevel = -1;
    this.onMaxAutoLevelUpdated();
    this.codecTiers = null;
    this.audioTracksByGroup = null;
   }
   onMaxAutoLevelUpdated() {
    this.firstSelection = -1;
    this.nextAutoLevelKey = '';
   }
   onFragLoading(event, data) {
    const frag = data.frag;
    if (this.ignoreFragment(frag)) {
     return;
    }
    if (!frag.bitrateTest) {
     var _data$part;
     this.fragCurrent = frag;
     this.partCurrent = (_data$part = data.part) != null ? _data$part : null;
    }
    this.clearTimer();
    this.timer = self.setInterval(this._abandonRulesCheck, 100);
   }
   onLevelSwitching(event, data) {
    this.clearTimer();
   }
   onError(event, data) {
    if (data.fatal) {
     return;
    }
    switch (data.details) {
     case ErrorDetails.BUFFER_ADD_CODEC_ERROR:
     case ErrorDetails.BUFFER_APPEND_ERROR:
      // Reset last loaded level so that a new selection can be made after calling recoverMediaError
      this.lastLoadedFragLevel = -1;
      this.firstSelection = -1;
      break;
     case ErrorDetails.FRAG_LOAD_TIMEOUT: {
      const frag = data.frag;
      const { fragCurrent, partCurrent: part } = this;
      if (frag && fragCurrent && frag.sn === fragCurrent.sn && frag.level === fragCurrent.level) {
       const now = performance.now();
       const stats = part ? part.stats : frag.stats;
       const timeLoading = now - stats.loading.start;
       const ttfb = stats.loading.first ? stats.loading.first - stats.loading.start : -1;
       const loadedFirstByte = stats.loaded && ttfb > -1;
       if (loadedFirstByte) {
        const ttfbEstimate = this.bwEstimator.getEstimateTTFB();
        this.bwEstimator.sample(timeLoading - Math.min(ttfbEstimate, ttfb), stats.loaded);
       } else {
        this.bwEstimator.sampleTTFB(timeLoading);
       }
      }
      break;
     }
    }
   }
   getTimeToLoadFrag(timeToFirstByteSec, bandwidth, fragSizeBits, isSwitch) {
    const fragLoadSec = timeToFirstByteSec + fragSizeBits / bandwidth;
    const playlistLoadSec = isSwitch ? timeToFirstByteSec + this.lastLevelLoadSec : 0;
    return fragLoadSec + playlistLoadSec;
   }
   onLevelLoaded(event, data) {
    const config = this.hls.config;
    const { loading } = data.stats;
    const timeLoadingMs = loading.end - loading.first;
    if (isFiniteNumber(timeLoadingMs)) {
     this.lastLevelLoadSec = timeLoadingMs / 1000;
    }
    if (data.details.live) {
     this.bwEstimator.update(config.abrEwmaSlowLive, config.abrEwmaFastLive);
    } else {
     this.bwEstimator.update(config.abrEwmaSlowVoD, config.abrEwmaFastVoD);
    }
    if (this.timer > -1) {
     this._abandonRulesCheck(data.levelInfo);
    }
   }
   onFragLoaded(event, { frag, part }) {
    const stats = part ? part.stats : frag.stats;
    if (frag.type === PlaylistLevelType.MAIN) {
     this.bwEstimator.sampleTTFB(stats.loading.first - stats.loading.start);
    }
    if (this.ignoreFragment(frag)) {
     return;
    }
    // stop monitoring bw once frag loaded
    this.clearTimer();
    // reset forced auto level value so that next level will be selected
    if (frag.level === this._nextAutoLevel) {
     this._nextAutoLevel = -1;
    }
    this.firstSelection = -1;

    // compute level average bitrate
    if (this.hls.config.abrMaxWithRealBitrate) {
     const duration = part ? part.duration : frag.duration;
     const level = this.hls.levels[frag.level];
     const loadedBytes = (level.loaded ? level.loaded.bytes : 0) + stats.loaded;
     const loadedDuration = (level.loaded ? level.loaded.duration : 0) + duration;
     level.loaded = {
      bytes: loadedBytes,
      duration: loadedDuration,
     };
     level.realBitrate = Math.round((8 * loadedBytes) / loadedDuration);
    }
    if (frag.bitrateTest) {
     const fragBufferedData = {
      stats,
      frag,
      part,
      id: frag.type,
     };
     this.onFragBuffered(Events.FRAG_BUFFERED, fragBufferedData);
     frag.bitrateTest = false;
    } else {
     // store level id after successful fragment load for playback
     this.lastLoadedFragLevel = frag.level;
    }
   }
   onFragBuffered(event, data) {
    const { frag, part } = data;
    const stats = part != null && part.stats.loaded ? part.stats : frag.stats;
    if (stats.aborted) {
     return;
    }
    if (this.ignoreFragment(frag)) {
     return;
    }
    // Use the difference between parsing and request instead of buffering and request to compute fragLoadingProcessing;
    // rationale is that buffer appending only happens once media is attached. This can happen when config.startFragPrefetch
    // is used. If we used buffering in that case, our BW estimate sample will be very large.
    const processingMs = stats.parsing.end - stats.loading.start - Math.min(stats.loading.first - stats.loading.start, this.bwEstimator.getEstimateTTFB());
    this.bwEstimator.sample(processingMs, stats.loaded);
    stats.bwEstimate = this.getBwEstimate();
    if (frag.bitrateTest) {
     this.bitrateTestDelay = processingMs / 1000;
    } else {
     this.bitrateTestDelay = 0;
    }
   }
   ignoreFragment(frag) {
    // Only count non-alt-audio frags which were actually buffered in our BW calculations
    return frag.type !== PlaylistLevelType.MAIN || frag.sn === 'initSegment';
   }
   clearTimer() {
    if (this.timer > -1) {
     self.clearInterval(this.timer);
     this.timer = -1;
    }
   }
   get firstAutoLevel() {
    const { maxAutoLevel, minAutoLevel } = this.hls;
    const bwEstimate = this.getBwEstimate();
    const maxStartDelay = this.hls.config.maxStarvationDelay;
    const abrAutoLevel = this.findBestLevel(bwEstimate, minAutoLevel, maxAutoLevel, 0, maxStartDelay, 1, 1);
    if (abrAutoLevel > -1) {
     return abrAutoLevel;
    }
    const firstLevel = this.hls.firstLevel;
    const clamped = Math.min(Math.max(firstLevel, minAutoLevel), maxAutoLevel);
    this.warn(`Could not find best starting auto level. Defaulting to first in playlist ${firstLevel} clamped to ${clamped}`);
    return clamped;
   }
   get forcedAutoLevel() {
    if (this.nextAutoLevelKey) {
     return -1;
    }
    return this._nextAutoLevel;
   }

   // return next auto level
   get nextAutoLevel() {
    const forcedAutoLevel = this.forcedAutoLevel;
    const bwEstimator = this.bwEstimator;
    const useEstimate = bwEstimator.canEstimate();
    const loadedFirstFrag = this.lastLoadedFragLevel > -1;
    // in case next auto level has been forced, and bw not available or not reliable, return forced value
    if (forcedAutoLevel !== -1 && (!useEstimate || !loadedFirstFrag || this.nextAutoLevelKey === this.getAutoLevelKey())) {
     return forcedAutoLevel;
    }

    // compute next level using ABR logic
    const nextABRAutoLevel = useEstimate && loadedFirstFrag ? this.getNextABRAutoLevel() : this.firstAutoLevel;

    // use forced auto level while it hasn't errored more than ABR selection
    if (forcedAutoLevel !== -1) {
     const levels = this.hls.levels;
     if (levels.length > Math.max(forcedAutoLevel, nextABRAutoLevel) && levels[forcedAutoLevel].loadError <= levels[nextABRAutoLevel].loadError) {
      return forcedAutoLevel;
     }
    }

    // save result until state has changed
    this._nextAutoLevel = nextABRAutoLevel;
    this.nextAutoLevelKey = this.getAutoLevelKey();
    return nextABRAutoLevel;
   }
   getAutoLevelKey() {
    return `${this.getBwEstimate()}_${this.getStarvationDelay().toFixed(2)}`;
   }
   getNextABRAutoLevel() {
    const { fragCurrent, partCurrent, hls } = this;
    if (hls.levels.length <= 1) {
     return hls.loadLevel;
    }
    const { maxAutoLevel, config, minAutoLevel } = hls;
    const currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;
    const avgbw = this.getBwEstimate();
    // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.
    const bufferStarvationDelay = this.getStarvationDelay();
    let bwFactor = config.abrBandWidthFactor;
    let bwUpFactor = config.abrBandWidthUpFactor;

    // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all
    if (bufferStarvationDelay) {
     const _bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, 0, bwFactor, bwUpFactor);
     if (_bestLevel >= 0) {
      this.rebufferNotice = -1;
      return _bestLevel;
     }
    }
    // not possible to get rid of rebuffering... try to find level that will guarantee less than maxStarvationDelay of rebuffering
    let maxStarvationDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxStarvationDelay) : config.maxStarvationDelay;
    if (!bufferStarvationDelay) {
     // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test
     const bitrateTestDelay = this.bitrateTestDelay;
     if (bitrateTestDelay) {
      // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value
      // max video loading delay used in  automatic start level selection :
      // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +
      // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )
      // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration
      const maxLoadingDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxLoadingDelay) : config.maxLoadingDelay;
      maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;
      this.info(`bitrate test took ${Math.round(1000 * bitrateTestDelay)}ms, set first fragment max fetchDuration to ${Math.round(1000 * maxStarvationDelay)} ms`);
      // don't use conservative factor on bitrate test
      bwFactor = bwUpFactor = 1;
     }
    }
    const bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, maxStarvationDelay, bwFactor, bwUpFactor);
    if (this.rebufferNotice !== bestLevel) {
     this.rebufferNotice = bestLevel;
     this.info(`${bufferStarvationDelay ? 'rebuffering expected' : 'buffer is empty'}, optimal quality level ${bestLevel}`);
    }
    if (bestLevel > -1) {
     return bestLevel;
    }
    // If no matching level found, see if min auto level would be a better option
    const minLevel = hls.levels[minAutoLevel];
    const autoLevel = hls.loadLevelObj;
    if (autoLevel && (minLevel == null ? void 0 : minLevel.bitrate) < autoLevel.bitrate) {
     return minAutoLevel;
    }
    // or if bitrate is not lower, continue to use loadLevel
    return hls.loadLevel;
   }
   getStarvationDelay() {
    const hls = this.hls;
    const media = hls.media;
    if (!media) {
     return Infinity;
    }
    // playbackRate is the absolute value of the playback rate; if media.playbackRate is 0, we use 1 to load as
    // if we're playing back at the normal rate.
    const playbackRate = media && media.playbackRate !== 0 ? Math.abs(media.playbackRate) : 1.0;
    const bufferInfo = hls.mainForwardBufferInfo;
    return (bufferInfo ? bufferInfo.len : 0) / playbackRate;
   }
   getBwEstimate() {
    return this.bwEstimator.canEstimate() ? this.bwEstimator.getEstimate() : this.hls.config.abrEwmaDefaultEstimate;
   }
   findBestLevel(currentBw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, maxStarvationDelay, bwFactor, bwUpFactor) {
    var _this$hls$latestLevel;
    const maxFetchDuration = bufferStarvationDelay + maxStarvationDelay;
    const lastLoadedFragLevel = this.lastLoadedFragLevel;
    const selectionBaseLevel = lastLoadedFragLevel === -1 ? this.hls.firstLevel : lastLoadedFragLevel;
    const { fragCurrent, partCurrent } = this;
    const { levels, allAudioTracks, loadLevel, config } = this.hls;
    if (levels.length === 1) {
     return 0;
    }
    const level = levels[selectionBaseLevel];
    const live = !!((_this$hls$latestLevel = this.hls.latestLevelDetails) != null && _this$hls$latestLevel.live);
    const firstSelection = loadLevel === -1 || lastLoadedFragLevel === -1;
    let currentCodecSet;
    let currentVideoRange = 'SDR';
    let currentFrameRate = (level == null ? void 0 : level.frameRate) || 0;
    const { audioPreference, videoPreference } = config;
    const audioTracksByGroup = this.audioTracksByGroup || (this.audioTracksByGroup = getAudioTracksByGroup(allAudioTracks));
    let minStartIndex = -1;
    if (firstSelection) {
     if (this.firstSelection !== -1) {
      return this.firstSelection;
     }
     const codecTiers = this.codecTiers || (this.codecTiers = getCodecTiers(levels, audioTracksByGroup, minAutoLevel, maxAutoLevel));
     const startTier = getStartCodecTier(codecTiers, currentVideoRange, currentBw, audioPreference, videoPreference);
     const { codecSet, videoRanges, minFramerate, minBitrate, minIndex, preferHDR } = startTier;
     minStartIndex = minIndex;
     currentCodecSet = codecSet;
     currentVideoRange = preferHDR ? videoRanges[videoRanges.length - 1] : videoRanges[0];
     currentFrameRate = minFramerate;
     currentBw = Math.max(currentBw, minBitrate);
     this.log(`picked start tier ${stringify(startTier)}`);
    } else {
     currentCodecSet = level == null ? void 0 : level.codecSet;
     currentVideoRange = level == null ? void 0 : level.videoRange;
    }
    const currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;
    const ttfbEstimateSec = this.bwEstimator.getEstimateTTFB() / 1000;
    const levelsSkipped = [];
    for (let i = maxAutoLevel; i >= minAutoLevel; i--) {
     var _levelInfo$supportedR;
     const levelInfo = levels[i];
     const upSwitch = i > selectionBaseLevel;
     if (!levelInfo) {
      continue;
     }
     if (config.useMediaCapabilities && !levelInfo.supportedResult && !levelInfo.supportedPromise) {
      const mediaCapabilities = navigator.mediaCapabilities;
      if (typeof (mediaCapabilities == null ? void 0 : mediaCapabilities.decodingInfo) === 'function' && requiresMediaCapabilitiesDecodingInfo(levelInfo, audioTracksByGroup, currentVideoRange, currentFrameRate, currentBw, audioPreference)) {
       levelInfo.supportedPromise = getMediaDecodingInfoPromise(levelInfo, audioTracksByGroup, mediaCapabilities, this.supportedCache);
       levelInfo.supportedPromise.then((decodingInfo) => {
        if (!this.hls) {
         return;
        }
        levelInfo.supportedResult = decodingInfo;
        const levels = this.hls.levels;
        const index = levels.indexOf(levelInfo);
        if (decodingInfo.error) {
         this.warn(`MediaCapabilities decodingInfo error: "${decodingInfo.error}" for level ${index} ${stringify(decodingInfo)}`);
        } else if (!decodingInfo.supported) {
         this.warn(`Unsupported MediaCapabilities decodingInfo result for level ${index} ${stringify(decodingInfo)}`);
         if (index > -1 && levels.length > 1) {
          this.log(`Removing unsupported level ${index}`);
          this.hls.removeLevel(index);
          if (this.hls.loadLevel === -1) {
           this.hls.nextLoadLevel = 0;
          }
         }
        } else if (decodingInfo.decodingInfoResults.some((info) => info.smooth === false || info.powerEfficient === false)) {
         this.log(`MediaCapabilities decodingInfo for level ${index} not smooth or powerEfficient: ${stringify(decodingInfo)}`);
        }
       });
      } else {
       levelInfo.supportedResult = SUPPORTED_INFO_DEFAULT;
      }
     }

     // skip candidates which change codec-family or video-range,
     // and which decrease or increase frame-rate for up and down-switch respectfully
     if ((currentCodecSet && levelInfo.codecSet !== currentCodecSet) || (currentVideoRange && levelInfo.videoRange !== currentVideoRange) || (upSwitch && currentFrameRate > levelInfo.frameRate) || (!upSwitch && currentFrameRate > 0 && currentFrameRate < levelInfo.frameRate) || ((_levelInfo$supportedR = levelInfo.supportedResult) != null && (_levelInfo$supportedR = _levelInfo$supportedR.decodingInfoResults) != null && _levelInfo$supportedR.some((info) => info.smooth === false))) {
      if (!firstSelection || i !== minStartIndex) {
       levelsSkipped.push(i);
       continue;
      }
     }
     const levelDetails = levelInfo.details;
     const avgDuration = (partCurrent ? (levelDetails == null ? void 0 : levelDetails.partTarget) : levelDetails == null ? void 0 : levelDetails.averagetargetduration) || currentFragDuration;
     let adjustedbw;
     // follow algorithm captured from stagefright :
     // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp
     // Pick the highest bandwidth stream below or equal to estimated bandwidth.
     // consider only 80% of the available bandwidth, but if we are switching up,
     // be even more conservative (70%) to avoid overestimating and immediately
     // switching back.
     if (!upSwitch) {
      adjustedbw = bwFactor * currentBw;
     } else {
      adjustedbw = bwUpFactor * currentBw;
     }

     // Use average bitrate when starvation delay (buffer length) is gt or eq two segment durations and rebuffering is not expected (maxStarvationDelay > 0)
     const bitrate = currentFragDuration && bufferStarvationDelay >= currentFragDuration * 2 && maxStarvationDelay === 0 ? levelInfo.averageBitrate : levelInfo.maxBitrate;
     const fetchDuration = this.getTimeToLoadFrag(ttfbEstimateSec, adjustedbw, bitrate * avgDuration, levelDetails === undefined);
     const canSwitchWithinTolerance =
      // if adjusted bw is greater than level bitrate AND
      adjustedbw >= bitrate &&
      // no level change, or new level has no error history
      (i === lastLoadedFragLevel || (levelInfo.loadError === 0 && levelInfo.fragmentError === 0)) &&
      // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches
      // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...
      // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that findBestLevel will return -1
      (fetchDuration <= ttfbEstimateSec || !isFiniteNumber(fetchDuration) || (live && !this.bitrateTestDelay) || fetchDuration < maxFetchDuration);
     if (canSwitchWithinTolerance) {
      const forcedAutoLevel = this.forcedAutoLevel;
      if (i !== loadLevel && (forcedAutoLevel === -1 || forcedAutoLevel !== loadLevel)) {
       if (levelsSkipped.length) {
        this.trace(`Skipped level(s) ${levelsSkipped.join(',')} of ${maxAutoLevel} max with CODECS and VIDEO-RANGE:"${levels[levelsSkipped[0]].codecs}" ${levels[levelsSkipped[0]].videoRange}; not compatible with "${currentCodecSet}" ${currentVideoRange}`);
       }
       this.info(`switch candidate:${selectionBaseLevel}->${i} adjustedbw(${Math.round(adjustedbw)})-bitrate=${Math.round(adjustedbw - bitrate)} ttfb:${ttfbEstimateSec.toFixed(1)} avgDuration:${avgDuration.toFixed(1)} maxFetchDuration:${maxFetchDuration.toFixed(1)} fetchDuration:${fetchDuration.toFixed(1)} firstSelection:${firstSelection} codecSet:${levelInfo.codecSet} videoRange:${levelInfo.videoRange} hls.loadLevel:${loadLevel}`);
      }
      if (firstSelection) {
       this.firstSelection = i;
      }
      // as we are looping from highest to lowest, this will return the best achievable quality level
      return i;
     }
    }
    // not enough time budget even with quality level 0 ... rebuffering might happen
    return -1;
   }
   set nextAutoLevel(nextLevel) {
    const value = this.deriveNextAutoLevel(nextLevel);
    if (this._nextAutoLevel !== value) {
     this.nextAutoLevelKey = '';
     this._nextAutoLevel = value;
    }
   }
   deriveNextAutoLevel(nextLevel) {
    const { maxAutoLevel, minAutoLevel } = this.hls;
    return Math.min(Math.max(nextLevel, minAutoLevel), maxAutoLevel);
   }
  }

  const BinarySearch = {
   /**
    * Searches for an item in an array which matches a certain condition.
    * This requires the condition to only match one item in the array,
    * and for the array to be ordered.
    *
    * @param list The array to search.
    * @param comparisonFn
    *      Called and provided a candidate item as the first argument.
    *      Should return:
    *          > -1 if the item should be located at a lower index than the provided item.
    *          > 1 if the item should be located at a higher index than the provided item.
    *          > 0 if the item is the item you're looking for.
    *
    * @returns the object if found, otherwise returns null
    */
   search: function (list, comparisonFn) {
    let minIndex = 0;
    let maxIndex = list.length - 1;
    let currentIndex = null;
    let currentElement = null;
    while (minIndex <= maxIndex) {
     currentIndex = ((minIndex + maxIndex) / 2) | 0;
     currentElement = list[currentIndex];
     const comparisonResult = comparisonFn(currentElement);
     if (comparisonResult > 0) {
      minIndex = currentIndex + 1;
     } else if (comparisonResult < 0) {
      maxIndex = currentIndex - 1;
     } else {
      return currentElement;
     }
    }
    return null;
   },
  };

  /**
   * Returns first fragment whose endPdt value exceeds the given PDT, or null.
   * @param fragments - The array of candidate fragments
   * @param PDTValue - The PDT value which must be exceeded
   * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous
   */
  function findFragmentByPDT(fragments, PDTValue, maxFragLookUpTolerance) {
   if (PDTValue === null || !Array.isArray(fragments) || !fragments.length || !isFiniteNumber(PDTValue)) {
    return null;
   }

   // if less than start
   const startPDT = fragments[0].programDateTime;
   if (PDTValue < (startPDT || 0)) {
    return null;
   }
   const endPDT = fragments[fragments.length - 1].endProgramDateTime;
   if (PDTValue >= (endPDT || 0)) {
    return null;
   }
   for (let seg = 0; seg < fragments.length; ++seg) {
    const frag = fragments[seg];
    if (pdtWithinToleranceTest(PDTValue, maxFragLookUpTolerance, frag)) {
     return frag;
    }
   }
   return null;
  }

  /**
   * Finds a fragment based on the SN of the previous fragment; or based on the needs of the current buffer.
   * This method compensates for small buffer gaps by applying a tolerance to the start of any candidate fragment, thus
   * breaking any traps which would cause the same fragment to be continuously selected within a small range.
   * @param fragPrevious - The last frag successfully appended
   * @param fragments - The array of candidate fragments
   * @param bufferEnd - The end of the contiguous buffered range the playhead is currently within
   * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous
   * @returns a matching fragment or null
   */
  function findFragmentByPTS(fragPrevious, fragments, bufferEnd = 0, maxFragLookUpTolerance = 0, nextFragLookupTolerance = 0.005) {
   let fragNext = null;
   if (fragPrevious) {
    fragNext = fragments[1 + fragPrevious.sn - fragments[0].sn] || null;
    // check for buffer-end rounding error
    const bufferEdgeError = fragPrevious.endDTS - bufferEnd;
    if (bufferEdgeError > 0 && bufferEdgeError < 0.0000015) {
     bufferEnd += 0.0000015;
    }
    if (fragNext && fragPrevious.level !== fragNext.level && fragNext.end <= fragPrevious.end) {
     fragNext = fragments[2 + fragPrevious.sn - fragments[0].sn] || null;
    }
   } else if (bufferEnd === 0 && fragments[0].start === 0) {
    fragNext = fragments[0];
   }
   // Prefer the next fragment if it's within tolerance
   if (fragNext && (((!fragPrevious || fragPrevious.level === fragNext.level) && fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, fragNext) === 0) || fragmentWithinFastStartSwitch(fragNext, fragPrevious, Math.min(nextFragLookupTolerance, maxFragLookUpTolerance)))) {
    return fragNext;
   }
   // We might be seeking past the tolerance so find the best match
   const foundFragment = BinarySearch.search(fragments, fragmentWithinToleranceTest.bind(null, bufferEnd, maxFragLookUpTolerance));
   if (foundFragment && (foundFragment !== fragPrevious || !fragNext)) {
    return foundFragment;
   }
   // If no match was found return the next fragment after fragPrevious, or null
   return fragNext;
  }
  function fragmentWithinFastStartSwitch(fragNext, fragPrevious, nextFragLookupTolerance) {
   if (fragPrevious && fragPrevious.start === 0 && fragPrevious.level < fragNext.level && (fragPrevious.endPTS || 0) > 0) {
    const firstDuration = fragPrevious.tagList.reduce((duration, tag) => {
     if (tag[0] === 'INF') {
      duration += parseFloat(tag[1]);
     }
     return duration;
    }, nextFragLookupTolerance);
    return fragNext.start <= firstDuration;
   }
   return false;
  }

  /**
   * The test function used by the findFragmentBySn's BinarySearch to look for the best match to the current buffer conditions.
   * @param candidate - The fragment to test
   * @param bufferEnd - The end of the current buffered range the playhead is currently within
   * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous
   * @returns 0 if it matches, 1 if too low, -1 if too high
   */
  function fragmentWithinToleranceTest(bufferEnd = 0, maxFragLookUpTolerance = 0, candidate) {
   // eagerly accept an accurate match (no tolerance)
   if (candidate.start <= bufferEnd && candidate.start + candidate.duration > bufferEnd) {
    return 0;
   }
   // offset should be within fragment boundary - config.maxFragLookUpTolerance
   // this is to cope with situations like
   // bufferEnd = 9.991
   // frag[] : [0,10]
   // frag[1] : [10,20]
   // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here
   //              frag start               frag start+duration
   //                  |-----------------------------|
   //              <--->                         <--->
   //  ...--------><-----------------------------><---------....
   // previous frag         matching fragment         next frag
   //  return -1             return 0                 return 1
   // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);
   // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments
   const candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0));
   if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) {
    return 1;
   } else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) {
    // if maxFragLookUpTolerance will have negative value then don't return -1 for first element
    return -1;
   }
   return 0;
  }

  /**
   * The test function used by the findFragmentByPdt's BinarySearch to look for the best match to the current buffer conditions.
   * This function tests the candidate's program date time values, as represented in Unix time
   * @param candidate - The fragment to test
   * @param pdtBufferEnd - The Unix time representing the end of the current buffered range
   * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous
   * @returns true if contiguous, false otherwise
   */
  function pdtWithinToleranceTest(pdtBufferEnd, maxFragLookUpTolerance, candidate) {
   const candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0)) * 1000;

   // endProgramDateTime can be null, default to zero
   const endProgramDateTime = candidate.endProgramDateTime || 0;
   return endProgramDateTime - candidateLookupTolerance > pdtBufferEnd;
  }
  function findNearestWithCC(details, cc, pos) {
   if (details) {
    if (details.startCC <= cc && details.endCC >= cc) {
     let fragments = details.fragments;
     const { fragmentHint } = details;
     if (fragmentHint) {
      fragments = fragments.concat(fragmentHint);
     }
     let closest;
     BinarySearch.search(fragments, (candidate) => {
      if (candidate.cc < cc) {
       return 1;
      }
      if (candidate.cc > cc) {
       return -1;
      }
      closest = candidate;
      if (candidate.end <= pos) {
       return 1;
      }
      if (candidate.start > pos) {
       return -1;
      }
      return 0;
     });
     return closest || null;
    }
   }
   return null;
  }

  function isTimeoutError(error) {
   switch (error.details) {
    case ErrorDetails.FRAG_LOAD_TIMEOUT:
    case ErrorDetails.KEY_LOAD_TIMEOUT:
    case ErrorDetails.LEVEL_LOAD_TIMEOUT:
    case ErrorDetails.MANIFEST_LOAD_TIMEOUT:
     return true;
   }
   return false;
  }
  function getRetryConfig(loadPolicy, error) {
   const isTimeout = isTimeoutError(error);
   return loadPolicy.default[`${isTimeout ? 'timeout' : 'error'}Retry`];
  }
  function getRetryDelay(retryConfig, retryCount) {
   // exponential backoff capped to max retry delay
   const backoffFactor = retryConfig.backoff === 'linear' ? 1 : Math.pow(2, retryCount);
   return Math.min(backoffFactor * retryConfig.retryDelayMs, retryConfig.maxRetryDelayMs);
  }
  function getLoaderConfigWithoutReties(loderConfig) {
   return _objectSpread2(_objectSpread2({}, loderConfig), {
    errorRetry: null,
    timeoutRetry: null,
   });
  }
  function shouldRetry(retryConfig, retryCount, isTimeout, loaderResponse) {
   if (!retryConfig) {
    return false;
   }
   const httpStatus = loaderResponse == null ? void 0 : loaderResponse.code;
   const retry = retryCount < retryConfig.maxNumRetry && (retryForHttpStatus(httpStatus) || !!isTimeout);
   return retryConfig.shouldRetry ? retryConfig.shouldRetry(retryConfig, retryCount, isTimeout, loaderResponse, retry) : retry;
  }
  function retryForHttpStatus(httpStatus) {
   // Do not retry on status 4xx, status 0 (CORS error), or undefined (decrypt/gap/parse error)
   return (httpStatus === 0 && navigator.onLine === false) || (!!httpStatus && (httpStatus < 400 || httpStatus > 499));
  }

  var NetworkErrorAction = {
   DoNothing: 0,
   SendEndCallback: 1,
   SendAlternateToPenaltyBox: 2,
   RemoveAlternatePermanently: 3,
   InsertDiscontinuity: 4,
   RetryRequest: 5,
  };
  var ErrorActionFlags = {
   None: 0,
   MoveAllAlternatesMatchingHost: 1,
   MoveAllAlternatesMatchingHDCP: 2,
   SwitchToSDR: 4,
  };
  class ErrorController extends Logger {
   constructor(hls) {
    super('error-controller', hls.logger);
    this.hls = void 0;
    this.playlistError = 0;
    this.penalizedRenditions = {};
    this.hls = hls;
    this.registerListeners();
   }
   registerListeners() {
    const hls = this.hls;
    hls.on(Events.ERROR, this.onError, this);
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
   }
   unregisterListeners() {
    const hls = this.hls;
    if (!hls) {
     return;
    }
    hls.off(Events.ERROR, this.onError, this);
    hls.off(Events.ERROR, this.onErrorOut, this);
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
   }
   destroy() {
    this.unregisterListeners();
    // @ts-ignore
    this.hls = null;
    this.penalizedRenditions = {};
   }
   startLoad(startPosition) {}
   stopLoad() {
    this.playlistError = 0;
   }
   getVariantLevelIndex(frag) {
    return (frag == null ? void 0 : frag.type) === PlaylistLevelType.MAIN ? frag.level : this.hls.loadLevel;
   }
   onManifestLoading() {
    this.playlistError = 0;
    this.penalizedRenditions = {};
   }
   onLevelUpdated() {
    this.playlistError = 0;
   }
   onError(event, data) {
    var _data$frag;
    if (data.fatal) {
     return;
    }
    const hls = this.hls;
    const context = data.context;
    switch (data.details) {
     case ErrorDetails.FRAG_LOAD_ERROR:
     case ErrorDetails.FRAG_LOAD_TIMEOUT:
     case ErrorDetails.KEY_LOAD_ERROR:
     case ErrorDetails.KEY_LOAD_TIMEOUT:
      data.errorAction = this.getFragRetryOrSwitchAction(data);
      return;
     case ErrorDetails.FRAG_PARSING_ERROR:
      // ignore empty segment errors marked as gap
      if ((_data$frag = data.frag) != null && _data$frag.gap) {
       data.errorAction = createDoNothingErrorAction();
       return;
      }
     // falls through
     case ErrorDetails.FRAG_GAP:
     case ErrorDetails.FRAG_DECRYPT_ERROR: {
      // Switch level if possible, otherwise allow retry count to reach max error retries
      data.errorAction = this.getFragRetryOrSwitchAction(data);
      data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;
      return;
     }
     case ErrorDetails.LEVEL_EMPTY_ERROR:
     case ErrorDetails.LEVEL_PARSING_ERROR:
      {
       var _data$context;
       // Only retry when empty and live
       const levelIndex = data.parent === PlaylistLevelType.MAIN ? data.level : hls.loadLevel;
       if (data.details === ErrorDetails.LEVEL_EMPTY_ERROR && !!((_data$context = data.context) != null && (_data$context = _data$context.levelDetails) != null && _data$context.live)) {
        data.errorAction = this.getPlaylistRetryOrSwitchAction(data, levelIndex);
       } else {
        // Escalate to fatal if not retrying or switching
        data.levelRetry = false;
        data.errorAction = this.getLevelSwitchAction(data, levelIndex);
       }
      }
      return;
     case ErrorDetails.LEVEL_LOAD_ERROR:
     case ErrorDetails.LEVEL_LOAD_TIMEOUT:
      if (typeof (context == null ? void 0 : context.level) === 'number') {
       data.errorAction = this.getPlaylistRetryOrSwitchAction(data, context.level);
      }
      return;
     case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:
     case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:
     case ErrorDetails.SUBTITLE_LOAD_ERROR:
     case ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT:
      if (context) {
       const level = hls.loadLevelObj;
       if (level && ((context.type === PlaylistContextType.AUDIO_TRACK && level.hasAudioGroup(context.groupId)) || (context.type === PlaylistContextType.SUBTITLE_TRACK && level.hasSubtitleGroup(context.groupId)))) {
        // Perform Pathway switch or Redundant failover if possible for fastest recovery
        // otherwise allow playlist retry count to reach max error retries
        data.errorAction = this.getPlaylistRetryOrSwitchAction(data, hls.loadLevel);
        data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;
        data.errorAction.flags = ErrorActionFlags.MoveAllAlternatesMatchingHost;
        return;
       }
      }
      return;
     case ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED:
      {
       const level = hls.loadLevelObj;
       const restrictedHdcpLevel = level == null ? void 0 : level.attrs['HDCP-LEVEL'];
       if (restrictedHdcpLevel) {
        data.errorAction = {
         action: NetworkErrorAction.SendAlternateToPenaltyBox,
         flags: ErrorActionFlags.MoveAllAlternatesMatchingHDCP,
         hdcpLevel: restrictedHdcpLevel,
        };
       } else {
        this.keySystemError(data);
       }
      }
      return;
     case ErrorDetails.BUFFER_ADD_CODEC_ERROR:
     case ErrorDetails.REMUX_ALLOC_ERROR:
     case ErrorDetails.BUFFER_APPEND_ERROR:
      // Buffer-controller can set errorAction when append errors can be ignored or resolved locally
      if (!data.errorAction) {
       var _data$level;
       data.errorAction = this.getLevelSwitchAction(data, (_data$level = data.level) != null ? _data$level : hls.loadLevel);
      }
      return;
     case ErrorDetails.INTERNAL_EXCEPTION:
     case ErrorDetails.BUFFER_APPENDING_ERROR:
     case ErrorDetails.BUFFER_FULL_ERROR:
     case ErrorDetails.LEVEL_SWITCH_ERROR:
     case ErrorDetails.BUFFER_STALLED_ERROR:
     case ErrorDetails.BUFFER_SEEK_OVER_HOLE:
     case ErrorDetails.BUFFER_NUDGE_ON_STALL:
      data.errorAction = createDoNothingErrorAction();
      return;
    }
    if (data.type === ErrorTypes.KEY_SYSTEM_ERROR) {
     this.keySystemError(data);
    }
   }
   keySystemError(data) {
    const levelIndex = this.getVariantLevelIndex(data.frag);
    // Do not retry level. Escalate to fatal if switching levels fails.
    data.levelRetry = false;
    data.errorAction = this.getLevelSwitchAction(data, levelIndex);
   }
   getPlaylistRetryOrSwitchAction(data, levelIndex) {
    const hls = this.hls;
    const retryConfig = getRetryConfig(hls.config.playlistLoadPolicy, data);
    const retryCount = this.playlistError++;
    const retry = shouldRetry(retryConfig, retryCount, isTimeoutError(data), data.response);
    if (retry) {
     return {
      action: NetworkErrorAction.RetryRequest,
      flags: ErrorActionFlags.None,
      retryConfig,
      retryCount,
     };
    }
    const errorAction = this.getLevelSwitchAction(data, levelIndex);
    if (retryConfig) {
     errorAction.retryConfig = retryConfig;
     errorAction.retryCount = retryCount;
    }
    return errorAction;
   }
   getFragRetryOrSwitchAction(data) {
    const hls = this.hls;
    // Share fragment error count accross media options (main, audio, subs)
    // This allows for level based rendition switching when media option assets fail
    const variantLevelIndex = this.getVariantLevelIndex(data.frag);
    const level = hls.levels[variantLevelIndex];
    const { fragLoadPolicy, keyLoadPolicy } = hls.config;
    const retryConfig = getRetryConfig(data.details.startsWith('key') ? keyLoadPolicy : fragLoadPolicy, data);
    const fragmentErrors = hls.levels.reduce((acc, level) => acc + level.fragmentError, 0);
    // Switch levels when out of retried or level index out of bounds
    if (level) {
     if (data.details !== ErrorDetails.FRAG_GAP) {
      level.fragmentError++;
     }
     const retry = shouldRetry(retryConfig, fragmentErrors, isTimeoutError(data), data.response);
     if (retry) {
      return {
       action: NetworkErrorAction.RetryRequest,
       flags: ErrorActionFlags.None,
       retryConfig,
       retryCount: fragmentErrors,
      };
     }
    }
    // Reach max retry count, or Missing level reference
    // Switch to valid index
    const errorAction = this.getLevelSwitchAction(data, variantLevelIndex);
    // Add retry details to allow skipping of FRAG_PARSING_ERROR
    if (retryConfig) {
     errorAction.retryConfig = retryConfig;
     errorAction.retryCount = fragmentErrors;
    }
    return errorAction;
   }
   getLevelSwitchAction(data, levelIndex) {
    const hls = this.hls;
    if (levelIndex === null || levelIndex === undefined) {
     levelIndex = hls.loadLevel;
    }
    const level = this.hls.levels[levelIndex];
    if (level) {
     var _data$frag2, _data$context2;
     const errorDetails = data.details;
     level.loadError++;
     if (errorDetails === ErrorDetails.BUFFER_APPEND_ERROR) {
      level.fragmentError++;
     }
     // Search for next level to retry
     let nextLevel = -1;
     const { levels, loadLevel, minAutoLevel, maxAutoLevel } = hls;
     if (!hls.autoLevelEnabled && !hls.config.preserveManualLevelOnError) {
      hls.loadLevel = -1;
     }
     const fragErrorType = (_data$frag2 = data.frag) == null ? void 0 : _data$frag2.type;
     // Find alternate audio codec if available on audio codec error
     const isAudioCodecError = (fragErrorType === PlaylistLevelType.AUDIO && errorDetails === ErrorDetails.FRAG_PARSING_ERROR) || (data.sourceBufferName === 'audio' && (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR || errorDetails === ErrorDetails.BUFFER_APPEND_ERROR));
     const findAudioCodecAlternate = isAudioCodecError && levels.some(({ audioCodec }) => level.audioCodec !== audioCodec);
     // Find alternate video codec if available on video codec error
     const isVideoCodecError = data.sourceBufferName === 'video' && (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR || errorDetails === ErrorDetails.BUFFER_APPEND_ERROR);
     const findVideoCodecAlternate = isVideoCodecError && levels.some(({ codecSet, audioCodec }) => level.codecSet !== codecSet && level.audioCodec === audioCodec);
     const { type: playlistErrorType, groupId: playlistErrorGroupId } = (_data$context2 = data.context) != null ? _data$context2 : {};
     for (let i = levels.length; i--; ) {
      const candidate = (i + loadLevel) % levels.length;
      if (candidate !== loadLevel && candidate >= minAutoLevel && candidate <= maxAutoLevel && levels[candidate].loadError === 0) {
       var _level$audioGroups, _level$subtitleGroups;
       const levelCandidate = levels[candidate];
       // Skip level switch if GAP tag is found in next level at same position
       if (errorDetails === ErrorDetails.FRAG_GAP && fragErrorType === PlaylistLevelType.MAIN && data.frag) {
        const levelDetails = levels[candidate].details;
        if (levelDetails) {
         const fragCandidate = findFragmentByPTS(data.frag, levelDetails.fragments, data.frag.start);
         if (fragCandidate != null && fragCandidate.gap) {
          continue;
         }
        }
       } else if ((playlistErrorType === PlaylistContextType.AUDIO_TRACK && levelCandidate.hasAudioGroup(playlistErrorGroupId)) || (playlistErrorType === PlaylistContextType.SUBTITLE_TRACK && levelCandidate.hasSubtitleGroup(playlistErrorGroupId))) {
        // For audio/subs playlist errors find another group ID or fallthrough to redundant fail-over
        continue;
       } else if ((fragErrorType === PlaylistLevelType.AUDIO && (_level$audioGroups = level.audioGroups) != null && _level$audioGroups.some((groupId) => levelCandidate.hasAudioGroup(groupId))) || (fragErrorType === PlaylistLevelType.SUBTITLE && (_level$subtitleGroups = level.subtitleGroups) != null && _level$subtitleGroups.some((groupId) => levelCandidate.hasSubtitleGroup(groupId))) || (findAudioCodecAlternate && level.audioCodec === levelCandidate.audioCodec) || (findVideoCodecAlternate && level.codecSet === levelCandidate.codecSet) || (!findAudioCodecAlternate && level.codecSet !== levelCandidate.codecSet)) {
        // For video/audio/subs frag errors find another group ID or fallthrough to redundant fail-over
        continue;
       }
       nextLevel = candidate;
       break;
      }
     }
     if (nextLevel > -1 && hls.loadLevel !== nextLevel) {
      data.levelRetry = true;
      this.playlistError = 0;
      return {
       action: NetworkErrorAction.SendAlternateToPenaltyBox,
       flags: ErrorActionFlags.None,
       nextAutoLevel: nextLevel,
      };
     }
    }
    // No levels to switch / Manual level selection / Level not found
    // Resolve with Pathway switch, Redundant fail-over, or stay on lowest Level
    return {
     action: NetworkErrorAction.SendAlternateToPenaltyBox,
     flags: ErrorActionFlags.MoveAllAlternatesMatchingHost,
    };
   }
   onErrorOut(event, data) {
    var _data$errorAction;
    switch ((_data$errorAction = data.errorAction) == null ? void 0 : _data$errorAction.action) {
     case NetworkErrorAction.DoNothing:
      break;
     case NetworkErrorAction.SendAlternateToPenaltyBox:
      this.sendAlternateToPenaltyBox(data);
      if (!data.errorAction.resolved && data.details !== ErrorDetails.FRAG_GAP) {
       data.fatal = true;
      } else if (/MediaSource readyState: ended/.test(data.error.message)) {
       this.warn(`MediaSource ended after "${data.sourceBufferName}" sourceBuffer append error. Attempting to recover from media error.`);
       this.hls.recoverMediaError();
      }
      break;
     case NetworkErrorAction.RetryRequest:
      // handled by stream and playlist/level controllers
      break;
    }
    if (data.fatal) {
     this.hls.stopLoad();
     return;
    }
   }
   sendAlternateToPenaltyBox(data) {
    const hls = this.hls;
    const errorAction = data.errorAction;
    if (!errorAction) {
     return;
    }
    const { flags, hdcpLevel, nextAutoLevel } = errorAction;
    switch (flags) {
     case ErrorActionFlags.None:
      this.switchLevel(data, nextAutoLevel);
      break;
     case ErrorActionFlags.MoveAllAlternatesMatchingHDCP:
      if (hdcpLevel) {
       hls.maxHdcpLevel = HdcpLevels[HdcpLevels.indexOf(hdcpLevel) - 1];
       errorAction.resolved = true;
      }
      this.warn(`Restricting playback to HDCP-LEVEL of "${hls.maxHdcpLevel}" or lower`);
      break;
    }
    // If not resolved by previous actions try to switch to next level
    if (!errorAction.resolved) {
     this.switchLevel(data, nextAutoLevel);
    }
   }
   switchLevel(data, levelIndex) {
    if (levelIndex !== undefined && data.errorAction) {
     this.warn(`switching to level ${levelIndex} after ${data.details}`);
     this.hls.nextAutoLevel = levelIndex;
     data.errorAction.resolved = true;
     // Stream controller is responsible for this but won't switch on false start
     this.hls.nextLoadLevel = this.hls.nextAutoLevel;
     if (data.details === ErrorDetails.BUFFER_ADD_CODEC_ERROR && data.mimeType && data.sourceBufferName !== 'audiovideo') {
      const codec = getCodecsForMimeType(data.mimeType);
      const levels = this.hls.levels;
      for (let i = levels.length; i--; ) {
       if (levels[i][`${data.sourceBufferName}Codec`] === codec) {
        this.hls.removeLevel(i);
       }
      }
     }
    }
   }
  }
  function createDoNothingErrorAction(resolved) {
   const errorAction = {
    action: NetworkErrorAction.DoNothing,
    flags: ErrorActionFlags.None,
   };
   if (resolved) {
    errorAction.resolved = true;
   }
   return errorAction;
  }

  var FragmentState = {
   NOT_LOADED: 'NOT_LOADED',
   APPENDING: 'APPENDING',
   PARTIAL: 'PARTIAL',
   OK: 'OK',
  };
  class FragmentTracker {
   constructor(hls) {
    this.activePartLists = Object.create(null);
    this.endListFragments = Object.create(null);
    this.fragments = Object.create(null);
    this.timeRanges = Object.create(null);
    this.bufferPadding = 0.2;
    this.hls = void 0;
    this.hasGaps = false;
    this.hls = hls;
    this._registerListeners();
   }
   _registerListeners() {
    const { hls } = this;
    if (hls) {
     hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
     hls.on(Events.BUFFER_APPENDED, this.onBufferAppended, this);
     hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);
     hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);
    }
   }
   _unregisterListeners() {
    const { hls } = this;
    if (hls) {
     hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
     hls.off(Events.BUFFER_APPENDED, this.onBufferAppended, this);
     hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);
     hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);
    }
   }
   destroy() {
    this._unregisterListeners();
    // @ts-ignore
    this.hls =
     // @ts-ignore
     this.fragments =
     // @ts-ignore
     this.activePartLists =
     // @ts-ignore
     this.endListFragments =
     this.timeRanges =
      null;
   }

   /**
    * Return a Fragment or Part with an appended range that matches the position and levelType
    * Otherwise, return null
    */
   getAppendedFrag(position, levelType) {
    const activeParts = this.activePartLists[levelType];
    if (activeParts) {
     for (let i = activeParts.length; i--; ) {
      const activePart = activeParts[i];
      if (!activePart) {
       break;
      }
      if (activePart.start <= position && position <= activePart.end && activePart.loaded) {
       return activePart;
      }
     }
    }
    return this.getBufferedFrag(position, levelType);
   }

   /**
    * Return a buffered Fragment that matches the position and levelType.
    * A buffered Fragment is one whose loading, parsing and appending is done (completed or "partial" meaning aborted).
    * If not found any Fragment, return null
    */
   getBufferedFrag(position, levelType) {
    return this.getFragAtPos(position, levelType, true);
   }
   getFragAtPos(position, levelType, buffered) {
    const { fragments } = this;
    const keys = Object.keys(fragments);
    for (let i = keys.length; i--; ) {
     const fragmentEntity = fragments[keys[i]];
     if ((fragmentEntity == null ? void 0 : fragmentEntity.body.type) === levelType && (!buffered || fragmentEntity.buffered)) {
      const frag = fragmentEntity.body;
      if (frag.start <= position && position <= frag.end) {
       return frag;
      }
     }
    }
    return null;
   }

   /**
    * Partial fragments effected by coded frame eviction will be removed
    * The browser will unload parts of the buffer to free up memory for new buffer data
    * Fragments will need to be reloaded when the buffer is freed up, removing partial fragments will allow them to reload(since there might be parts that are still playable)
    */
   detectEvictedFragments(elementaryStream, timeRange, playlistType, appendedPart, removeAppending) {
    if (this.timeRanges) {
     this.timeRanges[elementaryStream] = timeRange;
    }
    // Check if any flagged fragments have been unloaded
    // excluding anything newer than appendedPartSn
    const appendedPartSn = (appendedPart == null ? void 0 : appendedPart.fragment.sn) || -1;
    Object.keys(this.fragments).forEach((key) => {
     const fragmentEntity = this.fragments[key];
     if (!fragmentEntity) {
      return;
     }
     if (appendedPartSn >= fragmentEntity.body.sn) {
      return;
     }
     if (!fragmentEntity.buffered && (!fragmentEntity.loaded || removeAppending)) {
      if (fragmentEntity.body.type === playlistType) {
       this.removeFragment(fragmentEntity.body);
      }
      return;
     }
     const esData = fragmentEntity.range[elementaryStream];
     if (!esData) {
      return;
     }
     if (esData.time.length === 0) {
      this.removeFragment(fragmentEntity.body);
      return;
     }
     esData.time.some((time) => {
      const isNotBuffered = !this.isTimeBuffered(time.startPTS, time.endPTS, timeRange);
      if (isNotBuffered) {
       // Unregister partial fragment as it needs to load again to be reused
       this.removeFragment(fragmentEntity.body);
      }
      return isNotBuffered;
     });
    });
   }

   /**
    * Checks if the fragment passed in is loaded in the buffer properly
    * Partially loaded fragments will be registered as a partial fragment
    */
   detectPartialFragments(data) {
    const timeRanges = this.timeRanges;
    if (!timeRanges || data.frag.sn === 'initSegment') {
     return;
    }
    const frag = data.frag;
    const fragKey = getFragmentKey(frag);
    const fragmentEntity = this.fragments[fragKey];
    if (!fragmentEntity || (fragmentEntity.buffered && frag.gap)) {
     return;
    }
    const isFragHint = !frag.relurl;
    Object.keys(timeRanges).forEach((elementaryStream) => {
     const streamInfo = frag.elementaryStreams[elementaryStream];
     if (!streamInfo) {
      return;
     }
     const timeRange = timeRanges[elementaryStream];
     const partial = isFragHint || streamInfo.partial === true;
     fragmentEntity.range[elementaryStream] = this.getBufferedTimes(frag, data.part, partial, timeRange);
    });
    fragmentEntity.loaded = null;
    if (Object.keys(fragmentEntity.range).length) {
     fragmentEntity.buffered = true;
     const endList = (fragmentEntity.body.endList = frag.endList || fragmentEntity.body.endList);
     if (endList) {
      this.endListFragments[fragmentEntity.body.type] = fragmentEntity;
     }
     if (!isPartial(fragmentEntity)) {
      // Remove older fragment parts from lookup after frag is tracked as buffered
      this.removeParts(frag.sn - 1, frag.type);
     }
    } else {
     // remove fragment if nothing was appended
     this.removeFragment(fragmentEntity.body);
    }
   }
   removeParts(snToKeep, levelType) {
    const activeParts = this.activePartLists[levelType];
    if (!activeParts) {
     return;
    }
    this.activePartLists[levelType] = filterParts(activeParts, (part) => part.fragment.sn >= snToKeep);
   }
   fragBuffered(frag, force) {
    const fragKey = getFragmentKey(frag);
    let fragmentEntity = this.fragments[fragKey];
    if (!fragmentEntity && force) {
     fragmentEntity = this.fragments[fragKey] = {
      body: frag,
      appendedPTS: null,
      loaded: null,
      buffered: false,
      range: Object.create(null),
     };
     if (frag.gap) {
      this.hasGaps = true;
     }
    }
    if (fragmentEntity) {
     fragmentEntity.loaded = null;
     fragmentEntity.buffered = true;
    }
   }
   getBufferedTimes(fragment, part, partial, timeRange) {
    const buffered = {
     time: [],
     partial,
    };
    const startPTS = fragment.start;
    const endPTS = fragment.end;
    const minEndPTS = fragment.minEndPTS || endPTS;
    const maxStartPTS = fragment.maxStartPTS || startPTS;
    for (let i = 0; i < timeRange.length; i++) {
     const startTime = timeRange.start(i) - this.bufferPadding;
     const endTime = timeRange.end(i) + this.bufferPadding;
     if (maxStartPTS >= startTime && minEndPTS <= endTime) {
      // Fragment is entirely contained in buffer
      // No need to check the other timeRange times since it's completely playable
      buffered.time.push({
       startPTS: Math.max(startPTS, timeRange.start(i)),
       endPTS: Math.min(endPTS, timeRange.end(i)),
      });
      break;
     } else if (startPTS < endTime && endPTS > startTime) {
      const start = Math.max(startPTS, timeRange.start(i));
      const end = Math.min(endPTS, timeRange.end(i));
      if (end > start) {
       buffered.partial = true;
       // Check for intersection with buffer
       // Get playable sections of the fragment
       buffered.time.push({
        startPTS: start,
        endPTS: end,
       });
      }
     } else if (endPTS <= startTime) {
      // No need to check the rest of the timeRange as it is in order
      break;
     }
    }
    return buffered;
   }

   /**
    * Gets the partial fragment for a certain time
    */
   getPartialFragment(time) {
    let bestFragment = null;
    let timePadding;
    let startTime;
    let endTime;
    let bestOverlap = 0;
    const { bufferPadding, fragments } = this;
    Object.keys(fragments).forEach((key) => {
     const fragmentEntity = fragments[key];
     if (!fragmentEntity) {
      return;
     }
     if (isPartial(fragmentEntity)) {
      startTime = fragmentEntity.body.start - bufferPadding;
      endTime = fragmentEntity.body.end + bufferPadding;
      if (time >= startTime && time <= endTime) {
       // Use the fragment that has the most padding from start and end time
       timePadding = Math.min(time - startTime, endTime - time);
       if (bestOverlap <= timePadding) {
        bestFragment = fragmentEntity.body;
        bestOverlap = timePadding;
       }
      }
     }
    });
    return bestFragment;
   }
   isEndListAppended(type) {
    const lastFragmentEntity = this.endListFragments[type];
    return lastFragmentEntity !== undefined && (lastFragmentEntity.buffered || isPartial(lastFragmentEntity));
   }
   getState(fragment) {
    const fragKey = getFragmentKey(fragment);
    const fragmentEntity = this.fragments[fragKey];
    if (fragmentEntity) {
     if (!fragmentEntity.buffered) {
      return FragmentState.APPENDING;
     } else if (isPartial(fragmentEntity)) {
      return FragmentState.PARTIAL;
     } else {
      return FragmentState.OK;
     }
    }
    return FragmentState.NOT_LOADED;
   }
   isTimeBuffered(startPTS, endPTS, timeRange) {
    let startTime;
    let endTime;
    for (let i = 0; i < timeRange.length; i++) {
     startTime = timeRange.start(i) - this.bufferPadding;
     endTime = timeRange.end(i) + this.bufferPadding;
     if (startPTS >= startTime && endPTS <= endTime) {
      return true;
     }
     if (endPTS <= startTime) {
      // No need to check the rest of the timeRange as it is in order
      return false;
     }
    }
    return false;
   }
   onManifestLoading() {
    this.removeAllFragments();
   }
   onFragLoaded(event, data) {
    // don't track initsegment (for which sn is not a number)
    // don't track frags used for bitrateTest, they're irrelevant.
    if (data.frag.sn === 'initSegment' || data.frag.bitrateTest) {
     return;
    }
    const frag = data.frag;
    // Fragment entity `loaded` FragLoadedData is null when loading parts
    const loaded = data.part ? null : data;
    const fragKey = getFragmentKey(frag);
    this.fragments[fragKey] = {
     body: frag,
     appendedPTS: null,
     loaded,
     buffered: false,
     range: Object.create(null),
    };
   }
   onBufferAppended(event, data) {
    const { frag, part, timeRanges, type } = data;
    if (frag.sn === 'initSegment') {
     return;
    }
    const playlistType = frag.type;
    if (part) {
     let activeParts = this.activePartLists[playlistType];
     if (!activeParts) {
      this.activePartLists[playlistType] = activeParts = [];
     }
     activeParts.push(part);
    }
    // Store the latest timeRanges loaded in the buffer
    this.timeRanges = timeRanges;
    const timeRange = timeRanges[type];
    this.detectEvictedFragments(type, timeRange, playlistType, part);
   }
   onFragBuffered(event, data) {
    this.detectPartialFragments(data);
   }
   hasFragment(fragment) {
    const fragKey = getFragmentKey(fragment);
    return !!this.fragments[fragKey];
   }
   hasFragments(type) {
    const { fragments } = this;
    const keys = Object.keys(fragments);
    if (!type) {
     return keys.length > 0;
    }
    for (let i = keys.length; i--; ) {
     const fragmentEntity = fragments[keys[i]];
     if ((fragmentEntity == null ? void 0 : fragmentEntity.body.type) === type) {
      return true;
     }
    }
    return false;
   }
   hasParts(type) {
    var _this$activePartLists;
    return !!((_this$activePartLists = this.activePartLists[type]) != null && _this$activePartLists.length);
   }
   removeFragmentsInRange(start, end, playlistType, withGapOnly, unbufferedOnly) {
    if (withGapOnly && !this.hasGaps) {
     return;
    }
    Object.keys(this.fragments).forEach((key) => {
     const fragmentEntity = this.fragments[key];
     if (!fragmentEntity) {
      return;
     }
     const frag = fragmentEntity.body;
     if (frag.type !== playlistType || (withGapOnly && !frag.gap)) {
      return;
     }
     if (frag.start < end && frag.end > start && (fragmentEntity.buffered || unbufferedOnly)) {
      this.removeFragment(frag);
     }
    });
   }
   removeFragment(fragment) {
    const fragKey = getFragmentKey(fragment);
    fragment.clearElementaryStreamInfo();
    const activeParts = this.activePartLists[fragment.type];
    if (activeParts) {
     const snToRemove = fragment.sn;
     this.activePartLists[fragment.type] = filterParts(activeParts, (part) => part.fragment.sn !== snToRemove);
    }
    delete this.fragments[fragKey];
    if (fragment.endList) {
     delete this.endListFragments[fragment.type];
    }
   }
   removeAllFragments() {
    var _this$hls;
    this.fragments = Object.create(null);
    this.endListFragments = Object.create(null);
    this.activePartLists = Object.create(null);
    this.hasGaps = false;
    const partlist = (_this$hls = this.hls) == null || (_this$hls = _this$hls.latestLevelDetails) == null ? void 0 : _this$hls.partList;
    if (partlist) {
     partlist.forEach((part) => part.clearElementaryStreamInfo());
    }
   }
  }
  function isPartial(fragmentEntity) {
   var _fragmentEntity$range, _fragmentEntity$range2, _fragmentEntity$range3;
   return fragmentEntity.buffered && !!(fragmentEntity.body.gap || ((_fragmentEntity$range = fragmentEntity.range.video) != null && _fragmentEntity$range.partial) || ((_fragmentEntity$range2 = fragmentEntity.range.audio) != null && _fragmentEntity$range2.partial) || ((_fragmentEntity$range3 = fragmentEntity.range.audiovideo) != null && _fragmentEntity$range3.partial));
  }
  function getFragmentKey(fragment) {
   return `${fragment.type}_${fragment.level}_${fragment.sn}`;
  }
  function filterParts(partList, predicate) {
   return partList.filter((part) => {
    const keep = predicate(part);
    if (!keep) {
     part.clearElementaryStreamInfo();
    }
    return keep;
   });
  }

  var DecrypterAesMode = {
   cbc: 0,
   ctr: 1,
  };

  class AESCrypto {
   constructor(subtle, iv, aesMode) {
    this.subtle = void 0;
    this.aesIV = void 0;
    this.aesMode = void 0;
    this.subtle = subtle;
    this.aesIV = iv;
    this.aesMode = aesMode;
   }
   decrypt(data, key) {
    switch (this.aesMode) {
     case DecrypterAesMode.cbc:
      return this.subtle.decrypt(
       {
        name: 'AES-CBC',
        iv: this.aesIV,
       },
       key,
       data,
      );
     case DecrypterAesMode.ctr:
      return this.subtle.decrypt(
       {
        name: 'AES-CTR',
        counter: this.aesIV,
        length: 64,
       },
       //64 : NIST SP800-38A standard suggests that the counter should occupy half of the counter block
       key,
       data,
      );
     default:
      throw new Error(`[AESCrypto] invalid aes mode ${this.aesMode}`);
    }
   }
  }

  // PKCS7
  function removePadding(array) {
   const outputBytes = array.byteLength;
   const paddingBytes = outputBytes && new DataView(array.buffer).getUint8(outputBytes - 1);
   if (paddingBytes) {
    return array.slice(0, outputBytes - paddingBytes);
   }
   return array;
  }
  class AESDecryptor {
   constructor() {
    this.rcon = [0x0, 0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];
    this.subMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];
    this.invSubMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];
    this.sBox = new Uint32Array(256);
    this.invSBox = new Uint32Array(256);
    this.key = new Uint32Array(0);
    this.ksRows = 0;
    this.keySize = 0;
    this.keySchedule = void 0;
    this.invKeySchedule = void 0;
    this.initTable();
   }

   // Using view.getUint32() also swaps the byte order.
   uint8ArrayToUint32Array_(arrayBuffer) {
    const view = new DataView(arrayBuffer);
    const newArray = new Uint32Array(4);
    for (let i = 0; i < 4; i++) {
     newArray[i] = view.getUint32(i * 4);
    }
    return newArray;
   }
   initTable() {
    const sBox = this.sBox;
    const invSBox = this.invSBox;
    const subMix = this.subMix;
    const subMix0 = subMix[0];
    const subMix1 = subMix[1];
    const subMix2 = subMix[2];
    const subMix3 = subMix[3];
    const invSubMix = this.invSubMix;
    const invSubMix0 = invSubMix[0];
    const invSubMix1 = invSubMix[1];
    const invSubMix2 = invSubMix[2];
    const invSubMix3 = invSubMix[3];
    const d = new Uint32Array(256);
    let x = 0;
    let xi = 0;
    let i = 0;
    for (i = 0; i < 256; i++) {
     if (i < 128) {
      d[i] = i << 1;
     } else {
      d[i] = (i << 1) ^ 0x11b;
     }
    }
    for (i = 0; i < 256; i++) {
     let sx = xi ^ (xi << 1) ^ (xi << 2) ^ (xi << 3) ^ (xi << 4);
     sx = (sx >>> 8) ^ (sx & 0xff) ^ 0x63;
     sBox[x] = sx;
     invSBox[sx] = x;

     // Compute multiplication
     const x2 = d[x];
     const x4 = d[x2];
     const x8 = d[x4];

     // Compute sub/invSub bytes, mix columns tables
     let t = (d[sx] * 0x101) ^ (sx * 0x1010100);
     subMix0[x] = (t << 24) | (t >>> 8);
     subMix1[x] = (t << 16) | (t >>> 16);
     subMix2[x] = (t << 8) | (t >>> 24);
     subMix3[x] = t;

     // Compute inv sub bytes, inv mix columns tables
     t = (x8 * 0x1010101) ^ (x4 * 0x10001) ^ (x2 * 0x101) ^ (x * 0x1010100);
     invSubMix0[sx] = (t << 24) | (t >>> 8);
     invSubMix1[sx] = (t << 16) | (t >>> 16);
     invSubMix2[sx] = (t << 8) | (t >>> 24);
     invSubMix3[sx] = t;

     // Compute next counter
     if (!x) {
      x = xi = 1;
     } else {
      x = x2 ^ d[d[d[x8 ^ x2]]];
      xi ^= d[d[xi]];
     }
    }
   }
   expandKey(keyBuffer) {
    // convert keyBuffer to Uint32Array
    const key = this.uint8ArrayToUint32Array_(keyBuffer);
    let sameKey = true;
    let offset = 0;
    while (offset < key.length && sameKey) {
     sameKey = key[offset] === this.key[offset];
     offset++;
    }
    if (sameKey) {
     return;
    }
    this.key = key;
    const keySize = (this.keySize = key.length);
    if (keySize !== 4 && keySize !== 6 && keySize !== 8) {
     throw new Error('Invalid aes key size=' + keySize);
    }
    const ksRows = (this.ksRows = (keySize + 6 + 1) * 4);
    let ksRow;
    let invKsRow;
    const keySchedule = (this.keySchedule = new Uint32Array(ksRows));
    const invKeySchedule = (this.invKeySchedule = new Uint32Array(ksRows));
    const sbox = this.sBox;
    const rcon = this.rcon;
    const invSubMix = this.invSubMix;
    const invSubMix0 = invSubMix[0];
    const invSubMix1 = invSubMix[1];
    const invSubMix2 = invSubMix[2];
    const invSubMix3 = invSubMix[3];
    let prev;
    let t;
    for (ksRow = 0; ksRow < ksRows; ksRow++) {
     if (ksRow < keySize) {
      prev = keySchedule[ksRow] = key[ksRow];
      continue;
     }
     t = prev;
     if (ksRow % keySize === 0) {
      // Rot word
      t = (t << 8) | (t >>> 24);

      // Sub word
      t = (sbox[t >>> 24] << 24) | (sbox[(t >>> 16) & 0xff] << 16) | (sbox[(t >>> 8) & 0xff] << 8) | sbox[t & 0xff];

      // Mix Rcon
      t ^= rcon[(ksRow / keySize) | 0] << 24;
     } else if (keySize > 6 && ksRow % keySize === 4) {
      // Sub word
      t = (sbox[t >>> 24] << 24) | (sbox[(t >>> 16) & 0xff] << 16) | (sbox[(t >>> 8) & 0xff] << 8) | sbox[t & 0xff];
     }
     keySchedule[ksRow] = prev = (keySchedule[ksRow - keySize] ^ t) >>> 0;
    }
    for (invKsRow = 0; invKsRow < ksRows; invKsRow++) {
     ksRow = ksRows - invKsRow;
     if (invKsRow & 3) {
      t = keySchedule[ksRow];
     } else {
      t = keySchedule[ksRow - 4];
     }
     if (invKsRow < 4 || ksRow <= 4) {
      invKeySchedule[invKsRow] = t;
     } else {
      invKeySchedule[invKsRow] = invSubMix0[sbox[t >>> 24]] ^ invSubMix1[sbox[(t >>> 16) & 0xff]] ^ invSubMix2[sbox[(t >>> 8) & 0xff]] ^ invSubMix3[sbox[t & 0xff]];
     }
     invKeySchedule[invKsRow] = invKeySchedule[invKsRow] >>> 0;
    }
   }

   // Adding this as a method greatly improves performance.
   networkToHostOrderSwap(word) {
    return (word << 24) | ((word & 0xff00) << 8) | ((word & 0xff0000) >> 8) | (word >>> 24);
   }
   decrypt(inputArrayBuffer, offset, aesIV) {
    const nRounds = this.keySize + 6;
    const invKeySchedule = this.invKeySchedule;
    const invSBOX = this.invSBox;
    const invSubMix = this.invSubMix;
    const invSubMix0 = invSubMix[0];
    const invSubMix1 = invSubMix[1];
    const invSubMix2 = invSubMix[2];
    const invSubMix3 = invSubMix[3];
    const initVector = this.uint8ArrayToUint32Array_(aesIV);
    let initVector0 = initVector[0];
    let initVector1 = initVector[1];
    let initVector2 = initVector[2];
    let initVector3 = initVector[3];
    const inputInt32 = new Int32Array(inputArrayBuffer);
    const outputInt32 = new Int32Array(inputInt32.length);
    let t0, t1, t2, t3;
    let s0, s1, s2, s3;
    let inputWords0, inputWords1, inputWords2, inputWords3;
    let ksRow, i;
    const swapWord = this.networkToHostOrderSwap;
    while (offset < inputInt32.length) {
     inputWords0 = swapWord(inputInt32[offset]);
     inputWords1 = swapWord(inputInt32[offset + 1]);
     inputWords2 = swapWord(inputInt32[offset + 2]);
     inputWords3 = swapWord(inputInt32[offset + 3]);
     s0 = inputWords0 ^ invKeySchedule[0];
     s1 = inputWords3 ^ invKeySchedule[1];
     s2 = inputWords2 ^ invKeySchedule[2];
     s3 = inputWords1 ^ invKeySchedule[3];
     ksRow = 4;

     // Iterate through the rounds of decryption
     for (i = 1; i < nRounds; i++) {
      t0 = invSubMix0[s0 >>> 24] ^ invSubMix1[(s1 >> 16) & 0xff] ^ invSubMix2[(s2 >> 8) & 0xff] ^ invSubMix3[s3 & 0xff] ^ invKeySchedule[ksRow];
      t1 = invSubMix0[s1 >>> 24] ^ invSubMix1[(s2 >> 16) & 0xff] ^ invSubMix2[(s3 >> 8) & 0xff] ^ invSubMix3[s0 & 0xff] ^ invKeySchedule[ksRow + 1];
      t2 = invSubMix0[s2 >>> 24] ^ invSubMix1[(s3 >> 16) & 0xff] ^ invSubMix2[(s0 >> 8) & 0xff] ^ invSubMix3[s1 & 0xff] ^ invKeySchedule[ksRow + 2];
      t3 = invSubMix0[s3 >>> 24] ^ invSubMix1[(s0 >> 16) & 0xff] ^ invSubMix2[(s1 >> 8) & 0xff] ^ invSubMix3[s2 & 0xff] ^ invKeySchedule[ksRow + 3];
      // Update state
      s0 = t0;
      s1 = t1;
      s2 = t2;
      s3 = t3;
      ksRow = ksRow + 4;
     }

     // Shift rows, sub bytes, add round key
     t0 = (invSBOX[s0 >>> 24] << 24) ^ (invSBOX[(s1 >> 16) & 0xff] << 16) ^ (invSBOX[(s2 >> 8) & 0xff] << 8) ^ invSBOX[s3 & 0xff] ^ invKeySchedule[ksRow];
     t1 = (invSBOX[s1 >>> 24] << 24) ^ (invSBOX[(s2 >> 16) & 0xff] << 16) ^ (invSBOX[(s3 >> 8) & 0xff] << 8) ^ invSBOX[s0 & 0xff] ^ invKeySchedule[ksRow + 1];
     t2 = (invSBOX[s2 >>> 24] << 24) ^ (invSBOX[(s3 >> 16) & 0xff] << 16) ^ (invSBOX[(s0 >> 8) & 0xff] << 8) ^ invSBOX[s1 & 0xff] ^ invKeySchedule[ksRow + 2];
     t3 = (invSBOX[s3 >>> 24] << 24) ^ (invSBOX[(s0 >> 16) & 0xff] << 16) ^ (invSBOX[(s1 >> 8) & 0xff] << 8) ^ invSBOX[s2 & 0xff] ^ invKeySchedule[ksRow + 3];

     // Write
     outputInt32[offset] = swapWord(t0 ^ initVector0);
     outputInt32[offset + 1] = swapWord(t3 ^ initVector1);
     outputInt32[offset + 2] = swapWord(t2 ^ initVector2);
     outputInt32[offset + 3] = swapWord(t1 ^ initVector3);

     // reset initVector to last 4 unsigned int
     initVector0 = inputWords0;
     initVector1 = inputWords1;
     initVector2 = inputWords2;
     initVector3 = inputWords3;
     offset = offset + 4;
    }
    return outputInt32.buffer;
   }
  }

  class FastAESKey {
   constructor(subtle, key, aesMode) {
    this.subtle = void 0;
    this.key = void 0;
    this.aesMode = void 0;
    this.subtle = subtle;
    this.key = key;
    this.aesMode = aesMode;
   }
   expandKey() {
    const subtleAlgoName = getSubtleAlgoName(this.aesMode);
    return this.subtle.importKey(
     'raw',
     this.key,
     {
      name: subtleAlgoName,
     },
     false,
     ['encrypt', 'decrypt'],
    );
   }
  }
  function getSubtleAlgoName(aesMode) {
   switch (aesMode) {
    case DecrypterAesMode.cbc:
     return 'AES-CBC';
    case DecrypterAesMode.ctr:
     return 'AES-CTR';
    default:
     throw new Error(`[FastAESKey] invalid aes mode ${aesMode}`);
   }
  }

  const CHUNK_SIZE = 16; // 16 bytes, 128 bits

  class Decrypter {
   constructor(config, { removePKCS7Padding = true } = {}) {
    this.logEnabled = true;
    this.removePKCS7Padding = void 0;
    this.subtle = null;
    this.softwareDecrypter = null;
    this.key = null;
    this.fastAesKey = null;
    this.remainderData = null;
    this.currentIV = null;
    this.currentResult = null;
    this.useSoftware = void 0;
    this.enableSoftwareAES = void 0;
    this.enableSoftwareAES = config.enableSoftwareAES;
    this.removePKCS7Padding = removePKCS7Padding;
    // built in decryptor expects PKCS7 padding
    if (removePKCS7Padding) {
     try {
      const browserCrypto = self.crypto;
      if (browserCrypto) {
       this.subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;
      }
     } catch (e) {
      /* no-op */
     }
    }
    this.useSoftware = !this.subtle;
   }
   destroy() {
    this.subtle = null;
    this.softwareDecrypter = null;
    this.key = null;
    this.fastAesKey = null;
    this.remainderData = null;
    this.currentIV = null;
    this.currentResult = null;
   }
   isSync() {
    return this.useSoftware;
   }
   flush() {
    const { currentResult, remainderData } = this;
    if (!currentResult || remainderData) {
     this.reset();
     return null;
    }
    const data = new Uint8Array(currentResult);
    this.reset();
    if (this.removePKCS7Padding) {
     return removePadding(data);
    }
    return data;
   }
   reset() {
    this.currentResult = null;
    this.currentIV = null;
    this.remainderData = null;
    if (this.softwareDecrypter) {
     this.softwareDecrypter = null;
    }
   }
   decrypt(data, key, iv, aesMode) {
    if (this.useSoftware) {
     return new Promise((resolve, reject) => {
      const dataView = ArrayBuffer.isView(data) ? data : new Uint8Array(data);
      this.softwareDecrypt(dataView, key, iv, aesMode);
      const decryptResult = this.flush();
      if (decryptResult) {
       resolve(decryptResult.buffer);
      } else {
       reject(new Error('[softwareDecrypt] Failed to decrypt data'));
      }
     });
    }
    return this.webCryptoDecrypt(new Uint8Array(data), key, iv, aesMode);
   }

   // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached
   // data is handled in the flush() call
   softwareDecrypt(data, key, iv, aesMode) {
    const { currentIV, currentResult, remainderData } = this;
    if (aesMode !== DecrypterAesMode.cbc || key.byteLength !== 16) {
     logger.warn('SoftwareDecrypt: can only handle AES-128-CBC');
     return null;
    }
    this.logOnce('JS AES decrypt');
    // The output is staggered during progressive parsing - the current result is cached, and emitted on the next call
    // This is done in order to strip PKCS7 padding, which is found at the end of each segment. We only know we've reached
    // the end on flush(), but by that time we have already received all bytes for the segment.
    // Progressive decryption does not work with WebCrypto

    if (remainderData) {
     data = appendUint8Array(remainderData, data);
     this.remainderData = null;
    }

    // Byte length must be a multiple of 16 (AES-128 = 128 bit blocks = 16 bytes)
    const currentChunk = this.getValidChunk(data);
    if (!currentChunk.length) {
     return null;
    }
    if (currentIV) {
     iv = currentIV;
    }
    let softwareDecrypter = this.softwareDecrypter;
    if (!softwareDecrypter) {
     softwareDecrypter = this.softwareDecrypter = new AESDecryptor();
    }
    softwareDecrypter.expandKey(key);
    const result = currentResult;
    this.currentResult = softwareDecrypter.decrypt(currentChunk.buffer, 0, iv);
    this.currentIV = currentChunk.slice(-16).buffer;
    if (!result) {
     return null;
    }
    return result;
   }
   webCryptoDecrypt(data, key, iv, aesMode) {
    if (this.key !== key || !this.fastAesKey) {
     if (!this.subtle) {
      return Promise.resolve(this.onWebCryptoError(data, key, iv, aesMode));
     }
     this.key = key;
     this.fastAesKey = new FastAESKey(this.subtle, key, aesMode);
    }
    return this.fastAesKey
     .expandKey()
     .then((aesKey) => {
      // decrypt using web crypto
      if (!this.subtle) {
       return Promise.reject(new Error('web crypto not initialized'));
      }
      this.logOnce('WebCrypto AES decrypt');
      const crypto = new AESCrypto(this.subtle, new Uint8Array(iv), aesMode);
      return crypto.decrypt(data.buffer, aesKey);
     })
     .catch((err) => {
      logger.warn(`[decrypter]: WebCrypto Error, disable WebCrypto API, ${err.name}: ${err.message}`);
      return this.onWebCryptoError(data, key, iv, aesMode);
     });
   }
   onWebCryptoError(data, key, iv, aesMode) {
    const enableSoftwareAES = this.enableSoftwareAES;
    if (enableSoftwareAES) {
     this.useSoftware = true;
     this.logEnabled = true;
     this.softwareDecrypt(data, key, iv, aesMode);
     const decryptResult = this.flush();
     if (decryptResult) {
      return decryptResult.buffer;
     }
    }
    throw new Error('WebCrypto' + (enableSoftwareAES ? ' and softwareDecrypt' : '') + ': failed to decrypt data');
   }
   getValidChunk(data) {
    let currentChunk = data;
    const splitPoint = data.length - (data.length % CHUNK_SIZE);
    if (splitPoint !== data.length) {
     currentChunk = data.slice(0, splitPoint);
     this.remainderData = data.slice(splitPoint);
    }
    return currentChunk;
   }
   logOnce(msg) {
    if (!this.logEnabled) {
     return;
    }
    logger.log(`[decrypter]: ${msg}`);
    this.logEnabled = false;
   }
  }

  const MIN_CHUNK_SIZE = Math.pow(2, 17); // 128kb

  class FragmentLoader {
   constructor(config) {
    this.config = void 0;
    this.loader = null;
    this.partLoadTimeout = -1;
    this.config = config;
   }
   destroy() {
    if (this.loader) {
     this.loader.destroy();
     this.loader = null;
    }
   }
   abort() {
    if (this.loader) {
     // Abort the loader for current fragment. Only one may load at any given time
     this.loader.abort();
    }
   }
   load(frag, onProgress) {
    const url = frag.url;
    if (!url) {
     return Promise.reject(
      new LoadError({
       type: ErrorTypes.NETWORK_ERROR,
       details: ErrorDetails.FRAG_LOAD_ERROR,
       fatal: false,
       frag,
       error: new Error(`Fragment does not have a ${url ? 'part list' : 'url'}`),
       networkDetails: null,
      }),
     );
    }
    this.abort();
    const config = this.config;
    const FragmentILoader = config.fLoader;
    const DefaultILoader = config.loader;
    return new Promise((resolve, reject) => {
     if (this.loader) {
      this.loader.destroy();
     }
     if (frag.gap) {
      if (frag.tagList.some((tags) => tags[0] === 'GAP')) {
       reject(createGapLoadError(frag));
       return;
      } else {
       // Reset temporary treatment as GAP tag
       frag.gap = false;
      }
     }
     const loader = (this.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config));
     const loaderContext = createLoaderContext(frag);
     frag.loader = loader;
     const loadPolicy = getLoaderConfigWithoutReties(config.fragLoadPolicy.default);
     const loaderConfig = {
      loadPolicy,
      timeout: loadPolicy.maxLoadTimeMs,
      maxRetry: 0,
      retryDelay: 0,
      maxRetryDelay: 0,
      highWaterMark: frag.sn === 'initSegment' ? Infinity : MIN_CHUNK_SIZE,
     };
     // Assign frag stats to the loader's stats reference
     frag.stats = loader.stats;
     const callbacks = {
      onSuccess: (response, stats, context, networkDetails) => {
       this.resetLoader(frag, loader);
       let payload = response.data;
       if (context.resetIV && frag.decryptdata) {
        frag.decryptdata.iv = new Uint8Array(payload.slice(0, 16));
        payload = payload.slice(16);
       }
       resolve({
        frag,
        part: null,
        payload,
        networkDetails,
       });
      },
      onError: (response, context, networkDetails, stats) => {
       this.resetLoader(frag, loader);
       reject(
        new LoadError({
         type: ErrorTypes.NETWORK_ERROR,
         details: ErrorDetails.FRAG_LOAD_ERROR,
         fatal: false,
         frag,
         response: _objectSpread2(
          {
           url,
           data: undefined,
          },
          response,
         ),
         error: new Error(`HTTP Error ${response.code} ${response.text}`),
         networkDetails,
         stats,
        }),
       );
      },
      onAbort: (stats, context, networkDetails) => {
       this.resetLoader(frag, loader);
       reject(
        new LoadError({
         type: ErrorTypes.NETWORK_ERROR,
         details: ErrorDetails.INTERNAL_ABORTED,
         fatal: false,
         frag,
         error: new Error('Aborted'),
         networkDetails,
         stats,
        }),
       );
      },
      onTimeout: (stats, context, networkDetails) => {
       this.resetLoader(frag, loader);
       reject(
        new LoadError({
         type: ErrorTypes.NETWORK_ERROR,
         details: ErrorDetails.FRAG_LOAD_TIMEOUT,
         fatal: false,
         frag,
         error: new Error(`Timeout after ${loaderConfig.timeout}ms`),
         networkDetails,
         stats,
        }),
       );
      },
     };
     if (onProgress) {
      callbacks.onProgress = (stats, context, data, networkDetails) =>
       onProgress({
        frag,
        part: null,
        payload: data,
        networkDetails,
       });
     }
     loader.load(loaderContext, loaderConfig, callbacks);
    });
   }
   loadPart(frag, part, onProgress) {
    this.abort();
    const config = this.config;
    const FragmentILoader = config.fLoader;
    const DefaultILoader = config.loader;
    return new Promise((resolve, reject) => {
     if (this.loader) {
      this.loader.destroy();
     }
     if (frag.gap || part.gap) {
      reject(createGapLoadError(frag, part));
      return;
     }
     const loader = (this.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config));
     const loaderContext = createLoaderContext(frag, part);
     frag.loader = loader;
     // Should we define another load policy for parts?
     const loadPolicy = getLoaderConfigWithoutReties(config.fragLoadPolicy.default);
     const loaderConfig = {
      loadPolicy,
      timeout: loadPolicy.maxLoadTimeMs,
      maxRetry: 0,
      retryDelay: 0,
      maxRetryDelay: 0,
      highWaterMark: MIN_CHUNK_SIZE,
     };
     // Assign part stats to the loader's stats reference
     part.stats = loader.stats;
     loader.load(loaderContext, loaderConfig, {
      onSuccess: (response, stats, context, networkDetails) => {
       this.resetLoader(frag, loader);
       this.updateStatsFromPart(frag, part);
       const partLoadedData = {
        frag,
        part,
        payload: response.data,
        networkDetails,
       };
       onProgress(partLoadedData);
       resolve(partLoadedData);
      },
      onError: (response, context, networkDetails, stats) => {
       this.resetLoader(frag, loader);
       reject(
        new LoadError({
         type: ErrorTypes.NETWORK_ERROR,
         details: ErrorDetails.FRAG_LOAD_ERROR,
         fatal: false,
         frag,
         part,
         response: _objectSpread2(
          {
           url: loaderContext.url,
           data: undefined,
          },
          response,
         ),
         error: new Error(`HTTP Error ${response.code} ${response.text}`),
         networkDetails,
         stats,
        }),
       );
      },
      onAbort: (stats, context, networkDetails) => {
       frag.stats.aborted = part.stats.aborted;
       this.resetLoader(frag, loader);
       reject(
        new LoadError({
         type: ErrorTypes.NETWORK_ERROR,
         details: ErrorDetails.INTERNAL_ABORTED,
         fatal: false,
         frag,
         part,
         error: new Error('Aborted'),
         networkDetails,
         stats,
        }),
       );
      },
      onTimeout: (stats, context, networkDetails) => {
       this.resetLoader(frag, loader);
       reject(
        new LoadError({
         type: ErrorTypes.NETWORK_ERROR,
         details: ErrorDetails.FRAG_LOAD_TIMEOUT,
         fatal: false,
         frag,
         part,
         error: new Error(`Timeout after ${loaderConfig.timeout}ms`),
         networkDetails,
         stats,
        }),
       );
      },
     });
    });
   }
   updateStatsFromPart(frag, part) {
    const fragStats = frag.stats;
    const partStats = part.stats;
    const partTotal = partStats.total;
    fragStats.loaded += partStats.loaded;
    if (partTotal) {
     const estTotalParts = Math.round(frag.duration / part.duration);
     const estLoadedParts = Math.min(Math.round(fragStats.loaded / partTotal), estTotalParts);
     const estRemainingParts = estTotalParts - estLoadedParts;
     const estRemainingBytes = estRemainingParts * Math.round(fragStats.loaded / estLoadedParts);
     fragStats.total = fragStats.loaded + estRemainingBytes;
    } else {
     fragStats.total = Math.max(fragStats.loaded, fragStats.total);
    }
    const fragLoading = fragStats.loading;
    const partLoading = partStats.loading;
    if (fragLoading.start) {
     // add to fragment loader latency
     fragLoading.first += partLoading.first - partLoading.start;
    } else {
     fragLoading.start = partLoading.start;
     fragLoading.first = partLoading.first;
    }
    fragLoading.end = partLoading.end;
   }
   resetLoader(frag, loader) {
    frag.loader = null;
    if (this.loader === loader) {
     self.clearTimeout(this.partLoadTimeout);
     this.loader = null;
    }
    loader.destroy();
   }
  }
  function createLoaderContext(frag, part = null) {
   const segment = part || frag;
   const loaderContext = {
    frag,
    part,
    responseType: 'arraybuffer',
    url: segment.url,
    headers: {},
    rangeStart: 0,
    rangeEnd: 0,
   };
   const start = segment.byteRangeStartOffset;
   const end = segment.byteRangeEndOffset;
   if (isFiniteNumber(start) && isFiniteNumber(end)) {
    var _frag$decryptdata;
    let byteRangeStart = start;
    let byteRangeEnd = end;
    if (frag.sn === 'initSegment' && isMethodFullSegmentAesCbc((_frag$decryptdata = frag.decryptdata) == null ? void 0 : _frag$decryptdata.method)) {
     // MAP segment encrypted with method 'AES-128' or 'AES-256' (cbc), when served with HTTP Range,
     // has the unencrypted size specified in the range.
     // Ref: https://tools.ietf.org/html/draft-pantos-hls-rfc8216bis-08#section-6.3.6
     const fragmentLen = end - start;
     if (fragmentLen % 16) {
      byteRangeEnd = end + (16 - (fragmentLen % 16));
     }
     if (start !== 0) {
      loaderContext.resetIV = true;
      byteRangeStart = start - 16;
     }
    }
    loaderContext.rangeStart = byteRangeStart;
    loaderContext.rangeEnd = byteRangeEnd;
   }
   return loaderContext;
  }
  function createGapLoadError(frag, part) {
   const error = new Error(`GAP ${frag.gap ? 'tag' : 'attribute'} found`);
   const errorData = {
    type: ErrorTypes.MEDIA_ERROR,
    details: ErrorDetails.FRAG_GAP,
    fatal: false,
    frag,
    error,
    networkDetails: null,
   };
   if (part) {
    errorData.part = part;
   }
   (part ? part : frag).stats.aborted = true;
   return new LoadError(errorData);
  }
  function isMethodFullSegmentAesCbc(method) {
   return method === 'AES-128' || method === 'AES-256';
  }
  class LoadError extends Error {
   constructor(data) {
    super(data.error.message);
    this.data = void 0;
    this.data = data;
   }
  }

  /**
   * @ignore
   * Sub-class specialization of EventHandler base class.
   *
   * TaskLoop allows to schedule a task function being called (optionnaly repeatedly) on the main loop,
   * scheduled asynchroneously, avoiding recursive calls in the same tick.
   *
   * The task itself is implemented in `doTick`. It can be requested and called for single execution
   * using the `tick` method.
   *
   * It will be assured that the task execution method (`tick`) only gets called once per main loop "tick",
   * no matter how often it gets requested for execution. Execution in further ticks will be scheduled accordingly.
   *
   * If further execution requests have already been scheduled on the next tick, it can be checked with `hasNextTick`,
   * and cancelled with `clearNextTick`.
   *
   * The task can be scheduled as an interval repeatedly with a period as parameter (see `setInterval`, `clearInterval`).
   *
   * Sub-classes need to implement the `doTick` method which will effectively have the task execution routine.
   *
   * Further explanations:
   *
   * The baseclass has a `tick` method that will schedule the doTick call. It may be called synchroneously
   * only for a stack-depth of one. On re-entrant calls, sub-sequent calls are scheduled for next main loop ticks.
   *
   * When the task execution (`tick` method) is called in re-entrant way this is detected and
   * we are limiting the task execution per call stack to exactly one, but scheduling/post-poning further
   * task processing on the next main loop iteration (also known as "next tick" in the Node/JS runtime lingo).
   */
  class TaskLoop extends Logger {
   constructor(label, logger) {
    super(label, logger);
    this._boundTick = void 0;
    this._tickTimer = null;
    this._tickInterval = null;
    this._tickCallCount = 0;
    this._boundTick = this.tick.bind(this);
   }
   destroy() {
    this.onHandlerDestroying();
    this.onHandlerDestroyed();
   }
   onHandlerDestroying() {
    // clear all timers before unregistering from event bus
    this.clearNextTick();
    this.clearInterval();
   }
   onHandlerDestroyed() {}
   hasInterval() {
    return !!this._tickInterval;
   }
   hasNextTick() {
    return !!this._tickTimer;
   }

   /**
    * @param millis - Interval time (ms)
    * @eturns True when interval has been scheduled, false when already scheduled (no effect)
    */
   setInterval(millis) {
    if (!this._tickInterval) {
     this._tickCallCount = 0;
     this._tickInterval = self.setInterval(this._boundTick, millis);
     return true;
    }
    return false;
   }

   /**
    * @returns True when interval was cleared, false when none was set (no effect)
    */
   clearInterval() {
    if (this._tickInterval) {
     self.clearInterval(this._tickInterval);
     this._tickInterval = null;
     return true;
    }
    return false;
   }

   /**
    * @returns True when timeout was cleared, false when none was set (no effect)
    */
   clearNextTick() {
    if (this._tickTimer) {
     self.clearTimeout(this._tickTimer);
     this._tickTimer = null;
     return true;
    }
    return false;
   }

   /**
    * Will call the subclass doTick implementation in this main loop tick
    * or in the next one (via setTimeout(,0)) in case it has already been called
    * in this tick (in case this is a re-entrant call).
    */
   tick() {
    this._tickCallCount++;
    if (this._tickCallCount === 1) {
     this.doTick();
     // re-entrant call to tick from previous doTick call stack
     // -> schedule a call on the next main loop iteration to process this task processing request
     if (this._tickCallCount > 1) {
      // make sure only one timer exists at any time at max
      this.tickImmediate();
     }
     this._tickCallCount = 0;
    }
   }
   tickImmediate() {
    this.clearNextTick();
    this._tickTimer = self.setTimeout(this._boundTick, 0);
   }

   /**
    * For subclass to implement task logic
    * @abstract
    */
   doTick() {}
  }

  class ChunkMetadata {
   constructor(level, sn, id, size = 0, part = -1, partial = false) {
    this.level = void 0;
    this.sn = void 0;
    this.part = void 0;
    this.id = void 0;
    this.size = void 0;
    this.partial = void 0;
    this.transmuxing = getNewPerformanceTiming();
    this.buffering = {
     audio: getNewPerformanceTiming(),
     video: getNewPerformanceTiming(),
     audiovideo: getNewPerformanceTiming(),
    };
    this.level = level;
    this.sn = sn;
    this.id = id;
    this.size = size;
    this.part = part;
    this.partial = partial;
   }
  }
  function getNewPerformanceTiming() {
   return {
    start: 0,
    executeStart: 0,
    executeEnd: 0,
    end: 0,
   };
  }

  /**
   * Provides methods dealing with buffer length retrieval for example.
   *
   * In general, a helper around HTML5 MediaElement TimeRanges gathered from `buffered` property.
   *
   * Also @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/buffered
   */

  const noopBuffered = {
   length: 0,
   start: () => 0,
   end: () => 0,
  };
  class BufferHelper {
   /**
    * Return true if `media`'s buffered include `position`
    */
   static isBuffered(media, position) {
    if (media) {
     const buffered = BufferHelper.getBuffered(media);
     for (let i = buffered.length; i--; ) {
      if (position >= buffered.start(i) && position <= buffered.end(i)) {
       return true;
      }
     }
    }
    return false;
   }
   static bufferedRanges(media) {
    if (media) {
     const timeRanges = BufferHelper.getBuffered(media);
     return BufferHelper.timeRangesToArray(timeRanges);
    }
    return [];
   }
   static timeRangesToArray(timeRanges) {
    const buffered = [];
    for (let i = 0; i < timeRanges.length; i++) {
     buffered.push({
      start: timeRanges.start(i),
      end: timeRanges.end(i),
     });
    }
    return buffered;
   }
   static bufferInfo(media, pos, maxHoleDuration) {
    if (media) {
     const buffered = BufferHelper.bufferedRanges(media);
     if (buffered.length) {
      return BufferHelper.bufferedInfo(buffered, pos, maxHoleDuration);
     }
    }
    return {
     len: 0,
     start: pos,
     end: pos,
     bufferedIndex: -1,
    };
   }
   static bufferedInfo(buffered, pos, maxHoleDuration) {
    pos = Math.max(0, pos);
    // sort on buffer.start/smaller end (IE does not always return sorted buffered range)
    if (buffered.length > 1) {
     buffered.sort((a, b) => a.start - b.start || b.end - a.end);
    }
    let bufferedIndex = -1;
    let buffered2 = [];
    if (maxHoleDuration) {
     // there might be some small holes between buffer time range
     // consider that holes smaller than maxHoleDuration are irrelevant and build another
     // buffer time range representations that discards those holes
     for (let i = 0; i < buffered.length; i++) {
      if (pos >= buffered[i].start && pos <= buffered[i].end) {
       bufferedIndex = i;
      }
      const buf2len = buffered2.length;
      if (buf2len) {
       const buf2end = buffered2[buf2len - 1].end;
       // if small hole (value between 0 or maxHoleDuration ) or overlapping (negative)
       if (buffered[i].start - buf2end < maxHoleDuration) {
        // merge overlapping time ranges
        // update lastRange.end only if smaller than item.end
        // e.g.  [ 1, 15] with  [ 2,8] => [ 1,15] (no need to modify lastRange.end)
        // whereas [ 1, 8] with  [ 2,15] => [ 1,15] ( lastRange should switch from [1,8] to [1,15])
        if (buffered[i].end > buf2end) {
         buffered2[buf2len - 1].end = buffered[i].end;
        }
       } else {
        // big hole
        buffered2.push(buffered[i]);
       }
      } else {
       // first value
       buffered2.push(buffered[i]);
      }
     }
    } else {
     buffered2 = buffered;
    }
    let bufferLen = 0;
    let nextStart;

    // bufferStart and bufferEnd are buffer boundaries around current playback position (pos)
    let bufferStart = pos;
    let bufferEnd = pos;
    for (let i = 0; i < buffered2.length; i++) {
     const start = buffered2[i].start;
     const end = buffered2[i].end;
     // logger.log('buf start/end:' + buffered.start(i) + '/' + buffered.end(i));
     if (bufferedIndex === -1 && pos >= start && pos <= end) {
      bufferedIndex = i;
     }
     if (pos + maxHoleDuration >= start && pos < end) {
      // play position is inside this buffer TimeRange, retrieve end of buffer position and buffer length
      bufferStart = start;
      bufferEnd = end;
      bufferLen = bufferEnd - pos;
     } else if (pos + maxHoleDuration < start) {
      nextStart = start;
      break;
     }
    }
    return {
     len: bufferLen,
     start: bufferStart || 0,
     end: bufferEnd || 0,
     nextStart,
     buffered,
     bufferedIndex,
    };
   }

   /**
    * Safe method to get buffered property.
    * SourceBuffer.buffered may throw if SourceBuffer is removed from it's MediaSource
    */
   static getBuffered(media) {
    try {
     return media.buffered || noopBuffered;
    } catch (e) {
     logger.log('failed to get media.buffered', e);
     return noopBuffered;
    }
   }
  }

  const VARIABLE_REPLACEMENT_REGEX = /\{\$([a-zA-Z0-9-_]+)\}/g;
  function hasVariableReferences(str) {
   return VARIABLE_REPLACEMENT_REGEX.test(str);
  }
  function substituteVariables(parsed, value) {
   if (parsed.variableList !== null || parsed.hasVariableRefs) {
    const variableList = parsed.variableList;
    return value.replace(VARIABLE_REPLACEMENT_REGEX, (variableReference) => {
     const variableName = variableReference.substring(2, variableReference.length - 1);
     const variableValue = variableList == null ? void 0 : variableList[variableName];
     if (variableValue === undefined) {
      parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`Missing preceding EXT-X-DEFINE tag for Variable Reference: "${variableName}"`));
      return variableReference;
     }
     return variableValue;
    });
   }
   return value;
  }
  function addVariableDefinition(parsed, attr, parentUrl) {
   let variableList = parsed.variableList;
   if (!variableList) {
    parsed.variableList = variableList = {};
   }
   let NAME;
   let VALUE;
   if ('QUERYPARAM' in attr) {
    NAME = attr.QUERYPARAM;
    try {
     const searchParams = new self.URL(parentUrl).searchParams;
     if (searchParams.has(NAME)) {
      VALUE = searchParams.get(NAME);
     } else {
      throw new Error(`"${NAME}" does not match any query parameter in URI: "${parentUrl}"`);
     }
    } catch (error) {
     parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE QUERYPARAM: ${error.message}`));
    }
   } else {
    NAME = attr.NAME;
    VALUE = attr.VALUE;
   }
   if (NAME in variableList) {
    parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE duplicate Variable Name declarations: "${NAME}"`));
   } else {
    variableList[NAME] = VALUE || '';
   }
  }
  function importVariableDefinition(parsed, attr, sourceVariableList) {
   const IMPORT = attr.IMPORT;
   if (sourceVariableList && IMPORT in sourceVariableList) {
    let variableList = parsed.variableList;
    if (!variableList) {
     parsed.variableList = variableList = {};
    }
    variableList[IMPORT] = sourceVariableList[IMPORT];
   } else {
    parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE IMPORT attribute not found in Multivariant Playlist: "${IMPORT}"`));
   }
  }

  const DECIMAL_RESOLUTION_REGEX = /^(\d+)x(\d+)$/;
  const ATTR_LIST_REGEX = /(.+?)=(".*?"|.*?)(?:,|$)/g;

  // adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js
  class AttrList {
   constructor(attrs, parsed) {
    if (typeof attrs === 'string') {
     attrs = AttrList.parseAttrList(attrs, parsed);
    }
    _extends(this, attrs);
   }
   get clientAttrs() {
    return Object.keys(this).filter((attr) => attr.substring(0, 2) === 'X-');
   }
   decimalInteger(attrName) {
    const intValue = parseInt(this[attrName], 10);
    if (intValue > Number.MAX_SAFE_INTEGER) {
     return Infinity;
    }
    return intValue;
   }
   hexadecimalInteger(attrName) {
    if (this[attrName]) {
     let stringValue = (this[attrName] || '0x').slice(2);
     stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;
     const value = new Uint8Array(stringValue.length / 2);
     for (let i = 0; i < stringValue.length / 2; i++) {
      value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);
     }
     return value;
    }
    return null;
   }
   hexadecimalIntegerAsNumber(attrName) {
    const intValue = parseInt(this[attrName], 16);
    if (intValue > Number.MAX_SAFE_INTEGER) {
     return Infinity;
    }
    return intValue;
   }
   decimalFloatingPoint(attrName) {
    return parseFloat(this[attrName]);
   }
   optionalFloat(attrName, defaultValue) {
    const value = this[attrName];
    return value ? parseFloat(value) : defaultValue;
   }
   enumeratedString(attrName) {
    return this[attrName];
   }
   enumeratedStringList(attrName, dict) {
    const attrValue = this[attrName];
    return (attrValue ? attrValue.split(/[ ,]+/) : []).reduce((result, identifier) => {
     result[identifier.toLowerCase()] = true;
     return result;
    }, dict);
   }
   bool(attrName) {
    return this[attrName] === 'YES';
   }
   decimalResolution(attrName) {
    const res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);
    if (res === null) {
     return undefined;
    }
    return {
     width: parseInt(res[1], 10),
     height: parseInt(res[2], 10),
    };
   }
   static parseAttrList(input, parsed) {
    let match;
    const attrs = {};
    const quote = '"';
    ATTR_LIST_REGEX.lastIndex = 0;
    while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {
     const name = match[1].trim();
     let value = match[2];
     const quotedString = value.indexOf(quote) === 0 && value.lastIndexOf(quote) === value.length - 1;
     let hexadecimalSequence = false;
     if (quotedString) {
      value = value.slice(1, -1);
     } else {
      switch (name) {
       case 'IV':
       case 'SCTE35-CMD':
       case 'SCTE35-IN':
       case 'SCTE35-OUT':
        hexadecimalSequence = true;
      }
     }
     if (parsed && (quotedString || hexadecimalSequence)) {
      {
       value = substituteVariables(parsed, value);
      }
     } else if (!hexadecimalSequence && !quotedString) {
      switch (name) {
       case 'CLOSED-CAPTIONS':
        if (value === 'NONE') {
         break;
        }
       // falls through
       case 'ALLOWED-CPC':
       case 'CLASS':
       case 'ASSOC-LANGUAGE':
       case 'AUDIO':
       case 'BYTERANGE':
       case 'CHANNELS':
       case 'CHARACTERISTICS':
       case 'CODECS':
       case 'DATA-ID':
       case 'END-DATE':
       case 'GROUP-ID':
       case 'ID':
       case 'IMPORT':
       case 'INSTREAM-ID':
       case 'KEYFORMAT':
       case 'KEYFORMATVERSIONS':
       case 'LANGUAGE':
       case 'NAME':
       case 'PATHWAY-ID':
       case 'QUERYPARAM':
       case 'RECENTLY-REMOVED-DATERANGES':
       case 'SERVER-URI':
       case 'STABLE-RENDITION-ID':
       case 'STABLE-VARIANT-ID':
       case 'START-DATE':
       case 'SUBTITLES':
       case 'SUPPLEMENTAL-CODECS':
       case 'URI':
       case 'VALUE':
       case 'VIDEO':
       case 'X-ASSET-LIST':
       case 'X-ASSET-URI':
        // Since we are not checking tag:attribute combination, just warn rather than ignoring attribute
        logger.warn(`${input}: attribute ${name} is missing quotes`);
       // continue;
      }
     }
     attrs[name] = value;
    }
    return attrs;
   }
  }

  // Avoid exporting const enum so that these values can be inlined

  const CLASS_INTERSTITIAL = 'com.apple.hls.interstitial';
  function isDateRangeCueAttribute(attrName) {
   return attrName !== 'ID' && attrName !== 'CLASS' && attrName !== 'CUE' && attrName !== 'START-DATE' && attrName !== 'DURATION' && attrName !== 'END-DATE' && attrName !== 'END-ON-NEXT';
  }
  function isSCTE35Attribute(attrName) {
   return attrName === 'SCTE35-OUT' || attrName === 'SCTE35-IN' || attrName === 'SCTE35-CMD';
  }
  class DateRange {
   constructor(dateRangeAttr, dateRangeWithSameId, tagCount = 0) {
    var _dateRangeWithSameId$;
    this.attr = void 0;
    this.tagAnchor = void 0;
    this.tagOrder = void 0;
    this._startDate = void 0;
    this._endDate = void 0;
    this._dateAtEnd = void 0;
    this._cue = void 0;
    this._badValueForSameId = void 0;
    this.tagAnchor = (dateRangeWithSameId == null ? void 0 : dateRangeWithSameId.tagAnchor) || null;
    this.tagOrder = (_dateRangeWithSameId$ = dateRangeWithSameId == null ? void 0 : dateRangeWithSameId.tagOrder) != null ? _dateRangeWithSameId$ : tagCount;
    if (dateRangeWithSameId) {
     const previousAttr = dateRangeWithSameId.attr;
     for (const key in previousAttr) {
      if (Object.prototype.hasOwnProperty.call(dateRangeAttr, key) && dateRangeAttr[key] !== previousAttr[key]) {
       logger.warn(`DATERANGE tag attribute: "${key}" does not match for tags with ID: "${dateRangeAttr.ID}"`);
       this._badValueForSameId = key;
       break;
      }
     }
     // Merge DateRange tags with the same ID
     dateRangeAttr = _extends(new AttrList({}), previousAttr, dateRangeAttr);
    }
    this.attr = dateRangeAttr;
    if (dateRangeWithSameId) {
     this._startDate = dateRangeWithSameId._startDate;
     this._cue = dateRangeWithSameId._cue;
     this._endDate = dateRangeWithSameId._endDate;
     this._dateAtEnd = dateRangeWithSameId._dateAtEnd;
    } else {
     this._startDate = new Date(dateRangeAttr['START-DATE']);
    }
    if ('END-DATE' in this.attr) {
     const endDate = (dateRangeWithSameId == null ? void 0 : dateRangeWithSameId.endDate) || new Date(this.attr['END-DATE']);
     if (isFiniteNumber(endDate.getTime())) {
      this._endDate = endDate;
     }
    }
   }
   get id() {
    return this.attr.ID;
   }
   get class() {
    return this.attr.CLASS;
   }
   get cue() {
    const _cue = this._cue;
    if (_cue === undefined) {
     return (this._cue = this.attr.enumeratedStringList(this.attr.CUE ? 'CUE' : 'X-CUE', {
      pre: false,
      post: false,
      once: false,
     }));
    }
    return _cue;
   }
   get startTime() {
    const { tagAnchor } = this;
    // eslint-disable-next-line @typescript-eslint/prefer-optional-chain
    if (tagAnchor === null || tagAnchor.programDateTime === null) {
     logger.warn(`Expected tagAnchor Fragment with PDT set for DateRange "${this.id}": ${tagAnchor}`);
     return NaN;
    }
    return tagAnchor.start + (this.startDate.getTime() - tagAnchor.programDateTime) / 1000;
   }
   get startDate() {
    return this._startDate;
   }
   get endDate() {
    const dateAtEnd = this._endDate || this._dateAtEnd;
    if (dateAtEnd) {
     return dateAtEnd;
    }
    const duration = this.duration;
    if (duration !== null) {
     return (this._dateAtEnd = new Date(this._startDate.getTime() + duration * 1000));
    }
    return null;
   }
   get duration() {
    if ('DURATION' in this.attr) {
     const duration = this.attr.decimalFloatingPoint('DURATION');
     if (isFiniteNumber(duration)) {
      return duration;
     }
    } else if (this._endDate) {
     return (this._endDate.getTime() - this._startDate.getTime()) / 1000;
    }
    return null;
   }
   get plannedDuration() {
    if ('PLANNED-DURATION' in this.attr) {
     return this.attr.decimalFloatingPoint('PLANNED-DURATION');
    }
    return null;
   }
   get endOnNext() {
    return this.attr.bool('END-ON-NEXT');
   }
   get isInterstitial() {
    return this.class === CLASS_INTERSTITIAL;
   }
   get isValid() {
    return !!this.id && !this._badValueForSameId && isFiniteNumber(this.startDate.getTime()) && (this.duration === null || this.duration >= 0) && (!this.endOnNext || !!this.class) && (!this.attr.CUE || (!this.cue.pre && !this.cue.post) || this.cue.pre !== this.cue.post) && (!this.isInterstitial || 'X-ASSET-URI' in this.attr || 'X-ASSET-LIST' in this.attr);
   }
  }

  const DEFAULT_TARGET_DURATION = 10;

  /**
   * Object representing parsed data from an HLS Media Playlist. Found in {@link hls.js#Level.details}.
   */
  class LevelDetails {
   constructor(baseUrl) {
    this.PTSKnown = false;
    this.alignedSliding = false;
    this.averagetargetduration = void 0;
    this.endCC = 0;
    this.endSN = 0;
    this.fragments = void 0;
    this.fragmentHint = void 0;
    this.partList = null;
    this.dateRanges = void 0;
    this.dateRangeTagCount = 0;
    this.live = true;
    this.requestScheduled = -1;
    this.ageHeader = 0;
    this.advancedDateTime = void 0;
    this.updated = true;
    this.advanced = true;
    this.misses = 0;
    this.startCC = 0;
    this.startSN = 0;
    this.startTimeOffset = null;
    this.targetduration = 0;
    this.totalduration = 0;
    this.type = null;
    this.url = void 0;
    this.m3u8 = '';
    this.version = null;
    this.canBlockReload = false;
    this.canSkipUntil = 0;
    this.canSkipDateRanges = false;
    this.skippedSegments = 0;
    this.recentlyRemovedDateranges = void 0;
    this.partHoldBack = 0;
    this.holdBack = 0;
    this.partTarget = 0;
    this.preloadHint = void 0;
    this.renditionReports = void 0;
    this.tuneInGoal = 0;
    this.deltaUpdateFailed = void 0;
    this.driftStartTime = 0;
    this.driftEndTime = 0;
    this.driftStart = 0;
    this.driftEnd = 0;
    this.encryptedFragments = void 0;
    this.playlistParsingError = null;
    this.variableList = null;
    this.hasVariableRefs = false;
    this.appliedTimelineOffset = void 0;
    this.fragments = [];
    this.encryptedFragments = [];
    this.dateRanges = {};
    this.url = baseUrl;
   }
   reloaded(previous) {
    if (!previous) {
     this.advanced = true;
     this.updated = true;
     return;
    }
    const partSnDiff = this.lastPartSn - previous.lastPartSn;
    const partIndexDiff = this.lastPartIndex - previous.lastPartIndex;
    this.updated = this.endSN !== previous.endSN || !!partIndexDiff || !!partSnDiff || !this.live;
    this.advanced = this.endSN > previous.endSN || partSnDiff > 0 || (partSnDiff === 0 && partIndexDiff > 0);
    if (this.updated || this.advanced) {
     this.misses = Math.floor(previous.misses * 0.6);
    } else {
     this.misses = previous.misses + 1;
    }
   }
   get hasProgramDateTime() {
    if (this.fragments.length) {
     return isFiniteNumber(this.fragments[this.fragments.length - 1].programDateTime);
    }
    return false;
   }
   get levelTargetDuration() {
    return this.averagetargetduration || this.targetduration || DEFAULT_TARGET_DURATION;
   }
   get drift() {
    const runTime = this.driftEndTime - this.driftStartTime;
    if (runTime > 0) {
     const runDuration = this.driftEnd - this.driftStart;
     return (runDuration * 1000) / runTime;
    }
    return 1;
   }
   get edge() {
    return this.partEnd || this.fragmentEnd;
   }
   get partEnd() {
    var _this$partList;
    if ((_this$partList = this.partList) != null && _this$partList.length) {
     return this.partList[this.partList.length - 1].end;
    }
    return this.fragmentEnd;
   }
   get fragmentEnd() {
    if (this.fragments.length) {
     return this.fragments[this.fragments.length - 1].end;
    }
    return 0;
   }
   get fragmentStart() {
    if (this.fragments.length) {
     return this.fragments[0].start;
    }
    return 0;
   }
   get age() {
    if (this.advancedDateTime) {
     return Math.max(Date.now() - this.advancedDateTime, 0) / 1000;
    }
    return 0;
   }
   get lastPartIndex() {
    var _this$partList2;
    if ((_this$partList2 = this.partList) != null && _this$partList2.length) {
     return this.partList[this.partList.length - 1].index;
    }
    return -1;
   }
   get maxPartIndex() {
    const partList = this.partList;
    if (partList) {
     const lastIndex = this.lastPartIndex;
     if (lastIndex !== -1) {
      for (let i = partList.length; i--; ) {
       if (partList[i].index > lastIndex) {
        return partList[i].index;
       }
      }
      return lastIndex;
     }
    }
    return 0;
   }
   get lastPartSn() {
    var _this$partList3;
    if ((_this$partList3 = this.partList) != null && _this$partList3.length) {
     return this.partList[this.partList.length - 1].fragment.sn;
    }
    return this.endSN;
   }
   get expired() {
    if (this.live && this.age && this.misses < 3) {
     const playlistWindowDuration = this.partEnd - this.fragmentStart;
     return this.age > Math.max(playlistWindowDuration, this.totalduration) + this.levelTargetDuration;
    }
    return false;
   }
  }

  function isFullSegmentEncryption(method) {
   return method === 'AES-128' || method === 'AES-256' || method === 'AES-256-CTR';
  }
  function getAesModeFromFullSegmentMethod(method) {
   switch (method) {
    case 'AES-128':
    case 'AES-256':
     return DecrypterAesMode.cbc;
    case 'AES-256-CTR':
     return DecrypterAesMode.ctr;
    default:
     throw new Error(`invalid full segment method ${method}`);
   }
  }

  function base64Decode(base64encodedStr) {
   return Uint8Array.from(atob(base64encodedStr), (c) => c.charCodeAt(0));
  }

  // breaking up those two types in order to clarify what is happening in the decoding path.

  // http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197
  // http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt
  /* utf.js - UTF-8 <=> UTF-16 convertion
   *
   * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>
   * Version: 1.0
   * LastModified: Dec 25 1999
   * This library is free.  You can redistribute it and/or modify it.
   */

  function strToUtf8array(str) {
   return Uint8Array.from(unescape(encodeURIComponent(str)), (c) => c.charCodeAt(0));
  }

  function getKeyIdBytes(str) {
   const keyIdbytes = strToUtf8array(str).subarray(0, 16);
   const paddedkeyIdbytes = new Uint8Array(16);
   paddedkeyIdbytes.set(keyIdbytes, 16 - keyIdbytes.length);
   return paddedkeyIdbytes;
  }
  function changeEndianness(keyId) {
   const swap = function swap(array, from, to) {
    const cur = array[from];
    array[from] = array[to];
    array[to] = cur;
   };
   swap(keyId, 0, 3);
   swap(keyId, 1, 2);
   swap(keyId, 4, 5);
   swap(keyId, 6, 7);
  }
  function convertDataUriToArrayBytes(uri) {
   // data:[<media type][;attribute=value][;base64],<data>
   const colonsplit = uri.split(':');
   let keydata = null;
   if (colonsplit[0] === 'data' && colonsplit.length === 2) {
    const semicolonsplit = colonsplit[1].split(';');
    const commasplit = semicolonsplit[semicolonsplit.length - 1].split(',');
    if (commasplit.length === 2) {
     const isbase64 = commasplit[0] === 'base64';
     const data = commasplit[1];
     if (isbase64) {
      semicolonsplit.splice(-1, 1); // remove from processing
      keydata = base64Decode(data);
     } else {
      keydata = getKeyIdBytes(data);
     }
    }
   }
   return keydata;
  }

  /** returns `undefined` is `self` is missing, e.g. in node */
  const optionalSelf = typeof self !== 'undefined' ? self : undefined;

  /**
   * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess
   */
  var KeySystems = {
   CLEARKEY: 'org.w3.clearkey',
   FAIRPLAY: 'com.apple.fps',
   PLAYREADY: 'com.microsoft.playready',
   WIDEVINE: 'com.widevine.alpha',
  };

  // Playlist #EXT-X-KEY KEYFORMAT values
  var KeySystemFormats = {
   CLEARKEY: 'org.w3.clearkey',
   FAIRPLAY: 'com.apple.streamingkeydelivery',
   PLAYREADY: 'com.microsoft.playready',
   WIDEVINE: 'urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed',
  };
  function keySystemFormatToKeySystemDomain(format) {
   switch (format) {
    case KeySystemFormats.FAIRPLAY:
     return KeySystems.FAIRPLAY;
    case KeySystemFormats.PLAYREADY:
     return KeySystems.PLAYREADY;
    case KeySystemFormats.WIDEVINE:
     return KeySystems.WIDEVINE;
    case KeySystemFormats.CLEARKEY:
     return KeySystems.CLEARKEY;
   }
  }
  function keySystemDomainToKeySystemFormat(keySystem) {
   switch (keySystem) {
    case KeySystems.FAIRPLAY:
     return KeySystemFormats.FAIRPLAY;
    case KeySystems.PLAYREADY:
     return KeySystemFormats.PLAYREADY;
    case KeySystems.WIDEVINE:
     return KeySystemFormats.WIDEVINE;
    case KeySystems.CLEARKEY:
     return KeySystemFormats.CLEARKEY;
   }
  }
  function getKeySystemsForConfig(config) {
   const { drmSystems, widevineLicenseUrl } = config;
   const keySystemsToAttempt = drmSystems ? [KeySystems.FAIRPLAY, KeySystems.WIDEVINE, KeySystems.PLAYREADY, KeySystems.CLEARKEY].filter((keySystem) => !!drmSystems[keySystem]) : [];
   if (!keySystemsToAttempt[KeySystems.WIDEVINE] && widevineLicenseUrl) {
    keySystemsToAttempt.push(KeySystems.WIDEVINE);
   }
   return keySystemsToAttempt;
  }
  const requestMediaKeySystemAccess = (function (_optionalSelf$navigat) {
   if (optionalSelf != null && (_optionalSelf$navigat = optionalSelf.navigator) != null && _optionalSelf$navigat.requestMediaKeySystemAccess) {
    return self.navigator.requestMediaKeySystemAccess.bind(self.navigator);
   } else {
    return null;
   }
  })();

  /**
   * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration
   */
  function getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, drmSystemOptions) {
   let initDataTypes;
   switch (keySystem) {
    case KeySystems.FAIRPLAY:
     initDataTypes = ['cenc', 'sinf'];
     break;
    case KeySystems.WIDEVINE:
    case KeySystems.PLAYREADY:
     initDataTypes = ['cenc'];
     break;
    case KeySystems.CLEARKEY:
     initDataTypes = ['cenc', 'keyids'];
     break;
    default:
     throw new Error(`Unknown key-system: ${keySystem}`);
   }
   return createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions);
  }
  function createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions) {
   const baseConfig = {
    initDataTypes: initDataTypes,
    persistentState: drmSystemOptions.persistentState || 'optional',
    distinctiveIdentifier: drmSystemOptions.distinctiveIdentifier || 'optional',
    sessionTypes: drmSystemOptions.sessionTypes || [drmSystemOptions.sessionType || 'temporary'],
    audioCapabilities: audioCodecs.map((codec) => ({
     contentType: `audio/mp4; codecs=${codec}`,
     robustness: drmSystemOptions.audioRobustness || '',
     encryptionScheme: drmSystemOptions.audioEncryptionScheme || null,
    })),
    videoCapabilities: videoCodecs.map((codec) => ({
     contentType: `video/mp4; codecs=${codec}`,
     robustness: drmSystemOptions.videoRobustness || '',
     encryptionScheme: drmSystemOptions.videoEncryptionScheme || null,
    })),
   };
   return [baseConfig];
  }
  function isPersistentSessionType(drmSystemOptions) {
   var _drmSystemOptions$ses;
   return drmSystemOptions.sessionType === 'persistent-license' || !!((_drmSystemOptions$ses = drmSystemOptions.sessionTypes) != null && _drmSystemOptions$ses.some((type) => type === 'persistent-license'));
  }
  function parsePlayReadyWRM(keyBytes) {
   const keyBytesUtf16 = new Uint16Array(keyBytes.buffer, keyBytes.byteOffset, keyBytes.byteLength / 2);
   const keyByteStr = String.fromCharCode.apply(null, Array.from(keyBytesUtf16));

   // Parse Playready WRMHeader XML
   const xmlKeyBytes = keyByteStr.substring(keyByteStr.indexOf('<'), keyByteStr.length);
   const parser = new DOMParser();
   const xmlDoc = parser.parseFromString(xmlKeyBytes, 'text/xml');
   const keyData = xmlDoc.getElementsByTagName('KID')[0];
   if (keyData) {
    const keyId = keyData.childNodes[0] ? keyData.childNodes[0].nodeValue : keyData.getAttribute('VALUE');
    if (keyId) {
     const keyIdArray = base64Decode(keyId).subarray(0, 16);
     // KID value in PRO is a base64-encoded little endian GUID interpretation of UUID
     // KID value in tenc is a big endian UUID GUID interpretation of UUID
     changeEndianness(keyIdArray);
     return keyIdArray;
    }
   }
   return null;
  }

  let keyUriToKeyIdMap = {};
  class LevelKey {
   static clearKeyUriToKeyIdMap() {
    keyUriToKeyIdMap = {};
   }
   constructor(method, uri, format, formatversions = [1], iv = null, keyId) {
    this.uri = void 0;
    this.method = void 0;
    this.keyFormat = void 0;
    this.keyFormatVersions = void 0;
    this.encrypted = void 0;
    this.isCommonEncryption = void 0;
    this.iv = null;
    this.key = null;
    this.keyId = null;
    this.pssh = null;
    this.method = method;
    this.uri = uri;
    this.keyFormat = format;
    this.keyFormatVersions = formatversions;
    this.iv = iv;
    this.encrypted = method ? method !== 'NONE' : false;
    this.isCommonEncryption = this.encrypted && !isFullSegmentEncryption(method);
    if (keyId != null && keyId.startsWith('0x')) {
     this.keyId = new Uint8Array(hexToArrayBuffer(keyId));
    }
   }
   matches(key) {
    var _key$iv, _this$iv;
    return key.uri === this.uri && key.method === this.method && key.encrypted === this.encrypted && key.keyFormat === this.keyFormat && key.keyFormatVersions.join(',') === this.keyFormatVersions.join(',') && ((_key$iv = key.iv) == null ? void 0 : _key$iv.join(',')) === ((_this$iv = this.iv) == null ? void 0 : _this$iv.join(','));
   }
   isSupported() {
    // If it's Segment encryption or No encryption, just select that key system
    if (this.method) {
     if (isFullSegmentEncryption(this.method) || this.method === 'NONE') {
      return true;
     }
     if (this.keyFormat === 'identity') {
      // Maintain support for clear SAMPLE-AES with MPEG-3 TS
      return this.method === 'SAMPLE-AES';
     } else {
      switch (this.keyFormat) {
       case KeySystemFormats.FAIRPLAY:
       case KeySystemFormats.WIDEVINE:
       case KeySystemFormats.PLAYREADY:
       case KeySystemFormats.CLEARKEY:
        return ['ISO-23001-7', 'SAMPLE-AES', 'SAMPLE-AES-CENC', 'SAMPLE-AES-CTR'].indexOf(this.method) !== -1;
      }
     }
    }
    return false;
   }
   getDecryptData(sn) {
    if (!this.encrypted || !this.uri) {
     return null;
    }
    if (isFullSegmentEncryption(this.method) && this.uri && !this.iv) {
     if (typeof sn !== 'number') {
      // We are fetching decryption data for a initialization segment
      // If the segment was encrypted with AES-128/256
      // It must have an IV defined. We cannot substitute the Segment Number in.
      logger.warn(`missing IV for initialization segment with method="${this.method}" - compliance issue`);

      // Explicitly set sn to resulting value from implicit conversions 'initSegment' values for IV generation.
      sn = 0;
     }
     const iv = createInitializationVector(sn);
     const decryptdata = new LevelKey(this.method, this.uri, 'identity', this.keyFormatVersions, iv);
     return decryptdata;
    }
    if (this.pssh && this.keyId) {
     return this;
    }

    // Initialize keyId if possible
    const keyBytes = convertDataUriToArrayBytes(this.uri);
    if (keyBytes) {
     switch (this.keyFormat) {
      case KeySystemFormats.WIDEVINE:
       // Setting `pssh` on this LevelKey/DecryptData allows HLS.js to generate a session using
       // the playlist-key before the "encrypted" event. (Comment out to only use "encrypted" path.)
       this.pssh = keyBytes;
       // In case of Widevine, if KEYID is not in the playlist, assume only two fields in the pssh KEY tag URI.
       if (!this.keyId && keyBytes.length >= 22) {
        const offset = keyBytes.length - 22;
        this.keyId = keyBytes.subarray(offset, offset + 16);
       }
       break;
      case KeySystemFormats.PLAYREADY: {
       const PlayReadyKeySystemUUID = new Uint8Array([0x9a, 0x04, 0xf0, 0x79, 0x98, 0x40, 0x42, 0x86, 0xab, 0x92, 0xe6, 0x5b, 0xe0, 0x88, 0x5f, 0x95]);

       // Setting `pssh` on this LevelKey/DecryptData allows HLS.js to generate a session using
       // the playlist-key before the "encrypted" event. (Comment out to only use "encrypted" path.)
       this.pssh = mp4pssh(PlayReadyKeySystemUUID, null, keyBytes);
       this.keyId = parsePlayReadyWRM(keyBytes);
       break;
      }
      default: {
       let keydata = keyBytes.subarray(0, 16);
       if (keydata.length !== 16) {
        const padded = new Uint8Array(16);
        padded.set(keydata, 16 - keydata.length);
        keydata = padded;
       }
       this.keyId = keydata;
       break;
      }
     }
    }

    // Default behavior: assign a new keyId for each uri
    if (!this.keyId || this.keyId.byteLength !== 16) {
     let keyId = keyUriToKeyIdMap[this.uri];
     if (!keyId) {
      const val = Object.keys(keyUriToKeyIdMap).length % Number.MAX_SAFE_INTEGER;
      keyId = new Uint8Array(16);
      const dv = new DataView(keyId.buffer, 12, 4); // Just set the last 4 bytes
      dv.setUint32(0, val);
      keyUriToKeyIdMap[this.uri] = keyId;
     }
     this.keyId = keyId;
    }
    return this;
   }
  }
  function createInitializationVector(segmentNumber) {
   const uint8View = new Uint8Array(16);
   for (let i = 12; i < 16; i++) {
    uint8View[i] = (segmentNumber >> (8 * (15 - i))) & 0xff;
   }
   return uint8View;
  }

  const MASTER_PLAYLIST_REGEX = /#EXT-X-STREAM-INF:([^\r\n]*)(?:[\r\n](?:#[^\r\n]*)?)*([^\r\n]+)|#EXT-X-(SESSION-DATA|SESSION-KEY|DEFINE|CONTENT-STEERING|START):([^\r\n]*)[\r\n]+/g;
  const MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;
  const IS_MEDIA_PLAYLIST = /^#EXT(?:INF|-X-TARGETDURATION):/m; // Handle empty Media Playlist (first EXTINF not signaled, but TARGETDURATION present)

  const LEVEL_PLAYLIST_REGEX_FAST = new RegExp(
   [
    /#EXTINF:\s*(\d*(?:\.\d+)?)(?:,(.*)\s+)?/.source,
    // duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title
    /(?!#) *(\S[^\r\n]*)/.source,
    // segment URI, group 3 => the URI (note newline is not eaten)
    /#.*/.source, // All other non-segment oriented tags will match with all groups empty
   ].join('|'),
   'g',
  );
  const LEVEL_PLAYLIST_REGEX_SLOW = new RegExp([/#EXT-X-(PROGRAM-DATE-TIME|BYTERANGE|DATERANGE|DEFINE|KEY|MAP|PART|PART-INF|PLAYLIST-TYPE|PRELOAD-HINT|RENDITION-REPORT|SERVER-CONTROL|SKIP|START):(.+)/.source, /#EXT-X-(BITRATE|DISCONTINUITY-SEQUENCE|MEDIA-SEQUENCE|TARGETDURATION|VERSION): *(\d+)/.source, /#EXT-X-(DISCONTINUITY|ENDLIST|GAP|INDEPENDENT-SEGMENTS)/.source, /(#)([^:]*):(.*)/.source, /(#)(.*)(?:.*)\r?\n?/.source].join('|'));
  class M3U8Parser {
   static findGroup(groups, mediaGroupId) {
    for (let i = 0; i < groups.length; i++) {
     const group = groups[i];
     if (group.id === mediaGroupId) {
      return group;
     }
    }
   }
   static resolve(url, baseUrl) {
    return urlToolkitExports.buildAbsoluteURL(baseUrl, url, {
     alwaysNormalize: true,
    });
   }
   static isMediaPlaylist(str) {
    return IS_MEDIA_PLAYLIST.test(str);
   }
   static parseMasterPlaylist(string, baseurl) {
    const hasVariableRefs = hasVariableReferences(string);
    const parsed = {
     contentSteering: null,
     levels: [],
     playlistParsingError: null,
     sessionData: null,
     sessionKeys: null,
     startTimeOffset: null,
     variableList: null,
     hasVariableRefs,
    };
    const levelsWithKnownCodecs = [];
    MASTER_PLAYLIST_REGEX.lastIndex = 0;
    let result;
    while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {
     if (result[1]) {
      var _level$unknownCodecs;
      // '#EXT-X-STREAM-INF' is found, parse level tag  in group 1
      const attrs = new AttrList(result[1], parsed);
      const uri = substituteVariables(parsed, result[2]);
      const level = {
       attrs,
       bitrate: attrs.decimalInteger('BANDWIDTH') || attrs.decimalInteger('AVERAGE-BANDWIDTH'),
       name: attrs.NAME,
       url: M3U8Parser.resolve(uri, baseurl),
      };
      const resolution = attrs.decimalResolution('RESOLUTION');
      if (resolution) {
       level.width = resolution.width;
       level.height = resolution.height;
      }
      setCodecs(attrs.CODECS, level);
      const supplementalCodecs = attrs['SUPPLEMENTAL-CODECS'];
      if (supplementalCodecs) {
       level.supplemental = {};
       setCodecs(supplementalCodecs, level.supplemental);
      }
      if (!((_level$unknownCodecs = level.unknownCodecs) != null && _level$unknownCodecs.length)) {
       levelsWithKnownCodecs.push(level);
      }
      parsed.levels.push(level);
     } else if (result[3]) {
      const tag = result[3];
      const attributes = result[4];
      switch (tag) {
       case 'SESSION-DATA': {
        // #EXT-X-SESSION-DATA
        const sessionAttrs = new AttrList(attributes, parsed);
        const dataId = sessionAttrs['DATA-ID'];
        if (dataId) {
         if (parsed.sessionData === null) {
          parsed.sessionData = {};
         }
         parsed.sessionData[dataId] = sessionAttrs;
        }
        break;
       }
       case 'SESSION-KEY': {
        // #EXT-X-SESSION-KEY
        const sessionKey = parseKey(attributes, baseurl, parsed);
        if (sessionKey.encrypted && sessionKey.isSupported()) {
         if (parsed.sessionKeys === null) {
          parsed.sessionKeys = [];
         }
         parsed.sessionKeys.push(sessionKey);
        } else {
         logger.warn(`[Keys] Ignoring invalid EXT-X-SESSION-KEY tag: "${attributes}"`);
        }
        break;
       }
       case 'DEFINE': {
        // #EXT-X-DEFINE
        {
         const variableAttributes = new AttrList(attributes, parsed);
         addVariableDefinition(parsed, variableAttributes, baseurl);
        }
        break;
       }
       case 'CONTENT-STEERING': {
        // #EXT-X-CONTENT-STEERING
        const contentSteeringAttributes = new AttrList(attributes, parsed);
        parsed.contentSteering = {
         uri: M3U8Parser.resolve(contentSteeringAttributes['SERVER-URI'], baseurl),
         pathwayId: contentSteeringAttributes['PATHWAY-ID'] || '.',
        };
        break;
       }
       case 'START': {
        // #EXT-X-START
        parsed.startTimeOffset = parseStartTimeOffset(attributes);
        break;
       }
      }
     }
    }
    // Filter out levels with unknown codecs if it does not remove all levels
    const stripUnknownCodecLevels = levelsWithKnownCodecs.length > 0 && levelsWithKnownCodecs.length < parsed.levels.length;
    parsed.levels = stripUnknownCodecLevels ? levelsWithKnownCodecs : parsed.levels;
    if (parsed.levels.length === 0) {
     parsed.playlistParsingError = new Error('no levels found in manifest');
    }
    return parsed;
   }
   static parseMasterPlaylistMedia(string, baseurl, parsed) {
    let result;
    const results = {};
    const levels = parsed.levels;
    const groupsByType = {
     AUDIO: levels.map((level) => ({
      id: level.attrs.AUDIO,
      audioCodec: level.audioCodec,
     })),
     SUBTITLES: levels.map((level) => ({
      id: level.attrs.SUBTITLES,
      textCodec: level.textCodec,
     })),
     'CLOSED-CAPTIONS': [],
    };
    let id = 0;
    MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;
    while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {
     const attrs = new AttrList(result[1], parsed);
     const type = attrs.TYPE;
     if (type) {
      const groups = groupsByType[type];
      const medias = results[type] || [];
      results[type] = medias;
      const lang = attrs.LANGUAGE;
      const assocLang = attrs['ASSOC-LANGUAGE'];
      const channels = attrs.CHANNELS;
      const characteristics = attrs.CHARACTERISTICS;
      const instreamId = attrs['INSTREAM-ID'];
      const media = {
       attrs,
       bitrate: 0,
       id: id++,
       groupId: attrs['GROUP-ID'] || '',
       name: attrs.NAME || lang || '',
       type,
       default: attrs.bool('DEFAULT'),
       autoselect: attrs.bool('AUTOSELECT'),
       forced: attrs.bool('FORCED'),
       lang,
       url: attrs.URI ? M3U8Parser.resolve(attrs.URI, baseurl) : '',
      };
      if (assocLang) {
       media.assocLang = assocLang;
      }
      if (channels) {
       media.channels = channels;
      }
      if (characteristics) {
       media.characteristics = characteristics;
      }
      if (instreamId) {
       media.instreamId = instreamId;
      }
      if (groups != null && groups.length) {
       // If there are audio or text groups signalled in the manifest, let's look for a matching codec string for this track
       // If we don't find the track signalled, lets use the first audio groups codec we have
       // Acting as a best guess
       const groupCodec = M3U8Parser.findGroup(groups, media.groupId) || groups[0];
       assignCodec(media, groupCodec, 'audioCodec');
       assignCodec(media, groupCodec, 'textCodec');
      }
      medias.push(media);
     }
    }
    return results;
   }
   static parseLevelPlaylist(string, baseurl, id, type, levelUrlId, multivariantVariableList) {
    var _LEVEL_PLAYLIST_REGEX;
    const base = {
     url: baseurl,
    };
    const level = new LevelDetails(baseurl);
    const fragments = level.fragments;
    const programDateTimes = [];
    // The most recent init segment seen (applies to all subsequent segments)
    let currentInitSegment = null;
    let currentSN = 0;
    let currentPart = 0;
    let totalduration = 0;
    let discontinuityCounter = 0;
    let currentBitrate = 0;
    let prevFrag = null;
    let frag = new Fragment(type, base);
    let result;
    let i;
    let levelkeys;
    let firstPdtIndex = -1;
    let createNextFrag = false;
    let nextByteRange = null;
    let serverControlAttrs;
    LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;
    level.m3u8 = string;
    level.hasVariableRefs = hasVariableReferences(string);
    if (((_LEVEL_PLAYLIST_REGEX = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) == null ? void 0 : _LEVEL_PLAYLIST_REGEX[0]) !== '#EXTM3U') {
     level.playlistParsingError = new Error('Missing format identifier #EXTM3U');
     return level;
    }
    while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {
     if (createNextFrag) {
      createNextFrag = false;
      frag = new Fragment(type, base);
      // setup the next fragment for part loading
      frag.playlistOffset = totalduration;
      frag.setStart(totalduration);
      frag.sn = currentSN;
      frag.cc = discontinuityCounter;
      if (currentBitrate) {
       frag.bitrate = currentBitrate;
      }
      frag.level = id;
      if (currentInitSegment) {
       frag.initSegment = currentInitSegment;
       if (currentInitSegment.rawProgramDateTime) {
        frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;
        currentInitSegment.rawProgramDateTime = null;
       }
       if (nextByteRange) {
        frag.setByteRange(nextByteRange);
        nextByteRange = null;
       }
      }
     }
     const duration = result[1];
     if (duration) {
      // INF
      frag.duration = parseFloat(duration);
      // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
      const title = (' ' + result[2]).slice(1);
      frag.title = title || null;
      frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);
     } else if (result[3]) {
      // url
      if (isFiniteNumber(frag.duration)) {
       frag.playlistOffset = totalduration;
       frag.setStart(totalduration);
       if (levelkeys) {
        setFragLevelKeys(frag, levelkeys, level);
       }
       frag.sn = currentSN;
       frag.level = id;
       frag.cc = discontinuityCounter;
       fragments.push(frag);
       // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
       const uri = (' ' + result[3]).slice(1);
       frag.relurl = substituteVariables(level, uri);
       assignProgramDateTime(frag, prevFrag, programDateTimes);
       prevFrag = frag;
       totalduration += frag.duration;
       currentSN++;
       currentPart = 0;
       createNextFrag = true;
      }
     } else {
      result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);
      if (!result) {
       logger.warn('No matches on slow regex match for level playlist!');
       continue;
      }
      for (i = 1; i < result.length; i++) {
       if (result[i] !== undefined) {
        break;
       }
      }

      // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
      const tag = (' ' + result[i]).slice(1);
      const value1 = (' ' + result[i + 1]).slice(1);
      const value2 = result[i + 2] ? (' ' + result[i + 2]).slice(1) : null;
      switch (tag) {
       case 'BYTERANGE':
        if (prevFrag) {
         frag.setByteRange(value1, prevFrag);
        } else {
         frag.setByteRange(value1);
        }
        break;
       case 'PROGRAM-DATE-TIME':
        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
        frag.rawProgramDateTime = value1;
        frag.tagList.push(['PROGRAM-DATE-TIME', value1]);
        if (firstPdtIndex === -1) {
         firstPdtIndex = fragments.length;
        }
        break;
       case 'PLAYLIST-TYPE':
        if (level.type) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        }
        level.type = value1.toUpperCase();
        break;
       case 'MEDIA-SEQUENCE':
        if (level.startSN !== 0) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        } else if (fragments.length > 0) {
         assignMustAppearBeforeSegmentsError(level, tag, result);
        }
        currentSN = level.startSN = parseInt(value1);
        break;
       case 'SKIP': {
        if (level.skippedSegments) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        }
        const skipAttrs = new AttrList(value1, level);
        const skippedSegments = skipAttrs.decimalInteger('SKIPPED-SEGMENTS');
        if (isFiniteNumber(skippedSegments)) {
         level.skippedSegments += skippedSegments;
         // This will result in fragments[] containing undefined values, which we will fill in with `mergeDetails`
         for (let _i = skippedSegments; _i--; ) {
          fragments.push(null);
         }
         currentSN += skippedSegments;
        }
        const recentlyRemovedDateranges = skipAttrs.enumeratedString('RECENTLY-REMOVED-DATERANGES');
        if (recentlyRemovedDateranges) {
         level.recentlyRemovedDateranges = (level.recentlyRemovedDateranges || []).concat(recentlyRemovedDateranges.split('\t'));
        }
        break;
       }
       case 'TARGETDURATION':
        if (level.targetduration !== 0) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        }
        level.targetduration = Math.max(parseInt(value1), 1);
        break;
       case 'VERSION':
        if (level.version !== null) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        }
        level.version = parseInt(value1);
        break;
       case 'INDEPENDENT-SEGMENTS':
        break;
       case 'ENDLIST':
        if (!level.live) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        }
        level.live = false;
        break;
       case '#':
        if (value1 || value2) {
         frag.tagList.push(value2 ? [value1, value2] : [value1]);
        }
        break;
       case 'DISCONTINUITY':
        discontinuityCounter++;
        frag.tagList.push(['DIS']);
        break;
       case 'GAP':
        frag.gap = true;
        frag.tagList.push([tag]);
        break;
       case 'BITRATE':
        frag.tagList.push([tag, value1]);
        currentBitrate = parseInt(value1) * 1000;
        if (isFiniteNumber(currentBitrate)) {
         frag.bitrate = currentBitrate;
        } else {
         currentBitrate = 0;
        }
        break;
       case 'DATERANGE': {
        const dateRangeAttr = new AttrList(value1, level);
        const dateRange = new DateRange(dateRangeAttr, level.dateRanges[dateRangeAttr.ID], level.dateRangeTagCount);
        level.dateRangeTagCount++;
        if (dateRange.isValid || level.skippedSegments) {
         level.dateRanges[dateRange.id] = dateRange;
        } else {
         logger.warn(`Ignoring invalid DATERANGE tag: "${value1}"`);
        }
        // Add to fragment tag list for backwards compatibility (< v1.2.0)
        frag.tagList.push(['EXT-X-DATERANGE', value1]);
        break;
       }
       case 'DEFINE': {
        {
         const variableAttributes = new AttrList(value1, level);
         if ('IMPORT' in variableAttributes) {
          importVariableDefinition(level, variableAttributes, multivariantVariableList);
         } else {
          addVariableDefinition(level, variableAttributes, baseurl);
         }
        }
        break;
       }
       case 'DISCONTINUITY-SEQUENCE':
        if (level.startCC !== 0) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        } else if (fragments.length > 0) {
         assignMustAppearBeforeSegmentsError(level, tag, result);
        }
        level.startCC = discontinuityCounter = parseInt(value1);
        break;
       case 'KEY': {
        const levelKey = parseKey(value1, baseurl, level);
        if (levelKey.isSupported()) {
         if (levelKey.method === 'NONE') {
          levelkeys = undefined;
          break;
         }
         if (!levelkeys) {
          levelkeys = {};
         }
         const currentKey = levelkeys[levelKey.keyFormat];
         // Ignore duplicate playlist KEY tags
         if (!(currentKey != null && currentKey.matches(levelKey))) {
          if (currentKey) {
           levelkeys = _extends({}, levelkeys);
          }
          levelkeys[levelKey.keyFormat] = levelKey;
         }
        } else {
         logger.warn(`[Keys] Ignoring invalid EXT-X-KEY tag: "${value1}"`);
        }
        break;
       }
       case 'START':
        level.startTimeOffset = parseStartTimeOffset(value1);
        break;
       case 'MAP': {
        const mapAttrs = new AttrList(value1, level);
        if (frag.duration) {
         // Initial segment tag is after segment duration tag.
         //   #EXTINF: 6.0
         //   #EXT-X-MAP:URI="init.mp4
         const init = new Fragment(type, base);
         setInitSegment(init, mapAttrs, id, levelkeys);
         currentInitSegment = init;
         frag.initSegment = currentInitSegment;
         if (currentInitSegment.rawProgramDateTime && !frag.rawProgramDateTime) {
          frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;
         }
        } else {
         // Initial segment tag is before segment duration tag
         // Handle case where EXT-X-MAP is declared after EXT-X-BYTERANGE
         const end = frag.byteRangeEndOffset;
         if (end) {
          const start = frag.byteRangeStartOffset;
          nextByteRange = `${end - start}@${start}`;
         } else {
          nextByteRange = null;
         }
         setInitSegment(frag, mapAttrs, id, levelkeys);
         currentInitSegment = frag;
         createNextFrag = true;
        }
        currentInitSegment.cc = discontinuityCounter;
        break;
       }
       case 'SERVER-CONTROL': {
        if (serverControlAttrs) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        }
        serverControlAttrs = new AttrList(value1);
        level.canBlockReload = serverControlAttrs.bool('CAN-BLOCK-RELOAD');
        level.canSkipUntil = serverControlAttrs.optionalFloat('CAN-SKIP-UNTIL', 0);
        level.canSkipDateRanges = level.canSkipUntil > 0 && serverControlAttrs.bool('CAN-SKIP-DATERANGES');
        level.partHoldBack = serverControlAttrs.optionalFloat('PART-HOLD-BACK', 0);
        level.holdBack = serverControlAttrs.optionalFloat('HOLD-BACK', 0);
        break;
       }
       case 'PART-INF': {
        if (level.partTarget) {
         assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);
        }
        const partInfAttrs = new AttrList(value1);
        level.partTarget = partInfAttrs.decimalFloatingPoint('PART-TARGET');
        break;
       }
       case 'PART': {
        let partList = level.partList;
        if (!partList) {
         partList = level.partList = [];
        }
        const previousFragmentPart = currentPart > 0 ? partList[partList.length - 1] : undefined;
        const index = currentPart++;
        const partAttrs = new AttrList(value1, level);
        const part = new Part(partAttrs, frag, base, index, previousFragmentPart);
        partList.push(part);
        frag.duration += part.duration;
        break;
       }
       case 'PRELOAD-HINT': {
        const preloadHintAttrs = new AttrList(value1, level);
        level.preloadHint = preloadHintAttrs;
        break;
       }
       case 'RENDITION-REPORT': {
        const renditionReportAttrs = new AttrList(value1, level);
        level.renditionReports = level.renditionReports || [];
        level.renditionReports.push(renditionReportAttrs);
        break;
       }
       default:
        logger.warn(`line parsed but not handled: ${result}`);
        break;
      }
     }
    }
    if (prevFrag && !prevFrag.relurl) {
     fragments.pop();
     totalduration -= prevFrag.duration;
     if (level.partList) {
      level.fragmentHint = prevFrag;
     }
    } else if (level.partList) {
     assignProgramDateTime(frag, prevFrag, programDateTimes);
     frag.cc = discontinuityCounter;
     level.fragmentHint = frag;
     if (levelkeys) {
      setFragLevelKeys(frag, levelkeys, level);
     }
    }
    if (!level.targetduration) {
     level.playlistParsingError = new Error(`#EXT-X-TARGETDURATION is required`);
    }
    const fragmentLength = fragments.length;
    const firstFragment = fragments[0];
    const lastFragment = fragments[fragmentLength - 1];
    totalduration += level.skippedSegments * level.targetduration;
    if (totalduration > 0 && fragmentLength && lastFragment) {
     level.averagetargetduration = totalduration / fragmentLength;
     const lastSn = lastFragment.sn;
     level.endSN = lastSn !== 'initSegment' ? lastSn : 0;
     if (!level.live) {
      lastFragment.endList = true;
     }
     /**
      * Backfill any missing PDT values
      * "If the first EXT-X-PROGRAM-DATE-TIME tag in a Playlist appears after
      * one or more Media Segment URIs, the client SHOULD extrapolate
      * backward from that tag (using EXTINF durations and/or media
      * timestamps) to associate dates with those segments."
      * We have already extrapolated forward, but all fragments up to the first instance of PDT do not have their PDTs
      * computed.
      */
     if (firstPdtIndex > 0) {
      backfillProgramDateTimes(fragments, firstPdtIndex);
      if (firstFragment) {
       programDateTimes.unshift(firstFragment);
      }
     }
    }
    if (level.fragmentHint) {
     totalduration += level.fragmentHint.duration;
    }
    level.totalduration = totalduration;
    if (programDateTimes.length && level.dateRangeTagCount && firstFragment) {
     mapDateRanges(programDateTimes, level);
    }
    level.endCC = discontinuityCounter;
    return level;
   }
  }
  function mapDateRanges(programDateTimes, details) {
   // Make sure DateRanges are mapped to a ProgramDateTime tag that applies a date to a segment that overlaps with its start date
   let programDateTimeCount = programDateTimes.length;
   if (!programDateTimeCount) {
    if (details.hasProgramDateTime) {
     const lastFragment = details.fragments[details.fragments.length - 1];
     programDateTimes.push(lastFragment);
     programDateTimeCount++;
    } else {
     // no segments with EXT-X-PROGRAM-DATE-TIME references in playlist history
     return;
    }
   }
   const lastProgramDateTime = programDateTimes[programDateTimeCount - 1];
   const playlistEnd = details.live ? Infinity : details.totalduration;
   const dateRangeIds = Object.keys(details.dateRanges);
   for (let i = dateRangeIds.length; i--; ) {
    const dateRange = details.dateRanges[dateRangeIds[i]];
    const startDateTime = dateRange.startDate.getTime();
    dateRange.tagAnchor = lastProgramDateTime.ref;
    for (let j = programDateTimeCount; j--; ) {
     var _programDateTimes$j;
     if (((_programDateTimes$j = programDateTimes[j]) == null ? void 0 : _programDateTimes$j.sn) < details.startSN) {
      break;
     }
     const fragIndex = findFragmentWithStartDate(details, startDateTime, programDateTimes, j, playlistEnd);
     if (fragIndex !== -1) {
      dateRange.tagAnchor = details.fragments[fragIndex].ref;
      break;
     }
    }
   }
  }
  function findFragmentWithStartDate(details, startDateTime, programDateTimes, index, endTime) {
   const pdtFragment = programDateTimes[index];
   if (pdtFragment) {
    // find matching range between PDT tags
    const pdtStart = pdtFragment.programDateTime;
    if (startDateTime >= pdtStart || index === 0) {
     var _programDateTimes;
     const durationBetweenPdt = (((_programDateTimes = programDateTimes[index + 1]) == null ? void 0 : _programDateTimes.start) || endTime) - pdtFragment.start;
     if (startDateTime <= pdtStart + durationBetweenPdt * 1000) {
      // map to fragment with date-time range
      const startIndex = programDateTimes[index].sn - details.startSN;
      if (startIndex < 0) {
       return -1;
      }
      const fragments = details.fragments;
      if (fragments.length > programDateTimes.length) {
       const endSegment = programDateTimes[index + 1] || fragments[fragments.length - 1];
       const endIndex = endSegment.sn - details.startSN;
       for (let i = endIndex; i > startIndex; i--) {
        const fragStartDateTime = fragments[i].programDateTime;
        if (startDateTime >= fragStartDateTime && startDateTime < fragStartDateTime + fragments[i].duration * 1000) {
         return i;
        }
       }
      }
      return startIndex;
     }
    }
   }
   return -1;
  }
  function parseKey(keyTagAttributes, baseurl, parsed) {
   var _keyAttrs$METHOD, _keyAttrs$KEYFORMAT;
   // https://tools.ietf.org/html/rfc8216#section-4.3.2.4
   const keyAttrs = new AttrList(keyTagAttributes, parsed);
   const decryptmethod = (_keyAttrs$METHOD = keyAttrs.METHOD) != null ? _keyAttrs$METHOD : '';
   const decrypturi = keyAttrs.URI;
   const decryptiv = keyAttrs.hexadecimalInteger('IV');
   const decryptkeyformatversions = keyAttrs.KEYFORMATVERSIONS;
   // From RFC: This attribute is OPTIONAL; its absence indicates an implicit value of "identity".
   const decryptkeyformat = (_keyAttrs$KEYFORMAT = keyAttrs.KEYFORMAT) != null ? _keyAttrs$KEYFORMAT : 'identity';
   if (decrypturi && keyAttrs.IV && !decryptiv) {
    logger.error(`Invalid IV: ${keyAttrs.IV}`);
   }
   // If decrypturi is a URI with a scheme, then baseurl will be ignored
   // No uri is allowed when METHOD is NONE
   const resolvedUri = decrypturi ? M3U8Parser.resolve(decrypturi, baseurl) : '';
   const keyFormatVersions = (decryptkeyformatversions ? decryptkeyformatversions : '1').split('/').map(Number).filter(Number.isFinite);
   return new LevelKey(decryptmethod, resolvedUri, decryptkeyformat, keyFormatVersions, decryptiv, keyAttrs.KEYID);
  }
  function parseStartTimeOffset(startAttributes) {
   const startAttrs = new AttrList(startAttributes);
   const startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET');
   if (isFiniteNumber(startTimeOffset)) {
    return startTimeOffset;
   }
   return null;
  }
  function setCodecs(codecsAttributeValue, level) {
   let codecs = (codecsAttributeValue || '').split(/[ ,]+/).filter((c) => c);
   ['video', 'audio', 'text'].forEach((type) => {
    const filtered = codecs.filter((codec) => isCodecType(codec, type));
    if (filtered.length) {
     // Comma separated list of all codecs for type
     level[`${type}Codec`] = filtered.map((c) => c.split('/')[0]).join(',');
     // Remove known codecs so that only unknownCodecs are left after iterating through each type
     codecs = codecs.filter((codec) => filtered.indexOf(codec) === -1);
    }
   });
   level.unknownCodecs = codecs;
  }
  function assignCodec(media, groupItem, codecProperty) {
   const codecValue = groupItem[codecProperty];
   if (codecValue) {
    media[codecProperty] = codecValue;
   }
  }
  function backfillProgramDateTimes(fragments, firstPdtIndex) {
   let fragPrev = fragments[firstPdtIndex];
   for (let i = firstPdtIndex; i--; ) {
    const frag = fragments[i];
    // Exit on delta-playlist skipped segments
    if (!frag) {
     return;
    }
    frag.programDateTime = fragPrev.programDateTime - frag.duration * 1000;
    fragPrev = frag;
   }
  }
  function assignProgramDateTime(frag, prevFrag, programDateTimes) {
   if (frag.rawProgramDateTime) {
    programDateTimes.push(frag);
   } else if (prevFrag != null && prevFrag.programDateTime) {
    frag.programDateTime = prevFrag.endProgramDateTime;
   }
  }
  function setInitSegment(frag, mapAttrs, id, levelkeys) {
   frag.relurl = mapAttrs.URI;
   if (mapAttrs.BYTERANGE) {
    frag.setByteRange(mapAttrs.BYTERANGE);
   }
   frag.level = id;
   frag.sn = 'initSegment';
   if (levelkeys) {
    frag.levelkeys = levelkeys;
   }
   frag.initSegment = null;
  }
  function setFragLevelKeys(frag, levelkeys, level) {
   frag.levelkeys = levelkeys;
   const { encryptedFragments } = level;
   if ((!encryptedFragments.length || encryptedFragments[encryptedFragments.length - 1].levelkeys !== levelkeys) && Object.keys(levelkeys).some((format) => levelkeys[format].isCommonEncryption)) {
    encryptedFragments.push(frag);
   }
  }
  function assignMultipleMediaPlaylistTagOccuranceError(level, tag, result) {
   level.playlistParsingError = new Error(`#EXT-X-${tag} must not appear more than once (${result[0]})`);
  }
  function assignMustAppearBeforeSegmentsError(level, tag, result) {
   level.playlistParsingError = new Error(`#EXT-X-${tag} must appear before the first Media Segment (${result[0]})`);
  }

  function updateFromToPTS(fragFrom, fragTo) {
   const fragToPTS = fragTo.startPTS;
   // if we know startPTS[toIdx]
   if (isFiniteNumber(fragToPTS)) {
    // update fragment duration.
    // it helps to fix drifts between playlist reported duration and fragment real duration
    let duration = 0;
    let frag;
    if (fragTo.sn > fragFrom.sn) {
     duration = fragToPTS - fragFrom.start;
     frag = fragFrom;
    } else {
     duration = fragFrom.start - fragToPTS;
     frag = fragTo;
    }
    if (frag.duration !== duration) {
     frag.setDuration(duration);
    }
    // we dont know startPTS[toIdx]
   } else if (fragTo.sn > fragFrom.sn) {
    const contiguous = fragFrom.cc === fragTo.cc;
    // TODO: With part-loading end/durations we need to confirm the whole fragment is loaded before using (or setting) minEndPTS
    if (contiguous && fragFrom.minEndPTS) {
     fragTo.setStart(fragFrom.start + (fragFrom.minEndPTS - fragFrom.start));
    } else {
     fragTo.setStart(fragFrom.start + fragFrom.duration);
    }
   } else {
    fragTo.setStart(Math.max(fragFrom.start - fragTo.duration, 0));
   }
  }
  function updateFragPTSDTS(details, frag, startPTS, endPTS, startDTS, endDTS, logger) {
   const parsedMediaDuration = endPTS - startPTS;
   if (parsedMediaDuration <= 0) {
    logger.warn('Fragment should have a positive duration', frag);
    endPTS = startPTS + frag.duration;
    endDTS = startDTS + frag.duration;
   }
   let maxStartPTS = startPTS;
   let minEndPTS = endPTS;
   const fragStartPts = frag.startPTS;
   const fragEndPts = frag.endPTS;
   if (isFiniteNumber(fragStartPts)) {
    // delta PTS between audio and video
    const deltaPTS = Math.abs(fragStartPts - startPTS);
    if (details && deltaPTS > details.totalduration) {
     logger.warn(`media timestamps and playlist times differ by ${deltaPTS}s for level ${frag.level} ${details.url}`);
    } else if (!isFiniteNumber(frag.deltaPTS)) {
     frag.deltaPTS = deltaPTS;
    } else {
     frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS);
    }
    maxStartPTS = Math.max(startPTS, fragStartPts);
    startPTS = Math.min(startPTS, fragStartPts);
    startDTS = frag.startDTS !== undefined ? Math.min(startDTS, frag.startDTS) : startDTS;
    minEndPTS = Math.min(endPTS, fragEndPts);
    endPTS = Math.max(endPTS, fragEndPts);
    endDTS = frag.endDTS !== undefined ? Math.max(endDTS, frag.endDTS) : endDTS;
   }
   const drift = startPTS - frag.start;
   if (frag.start !== 0) {
    frag.setStart(startPTS);
   }
   frag.setDuration(endPTS - frag.start);
   frag.startPTS = startPTS;
   frag.maxStartPTS = maxStartPTS;
   frag.startDTS = startDTS;
   frag.endPTS = endPTS;
   frag.minEndPTS = minEndPTS;
   frag.endDTS = endDTS;
   const sn = frag.sn;
   // exit if sn out of range
   if (!details || sn < details.startSN || sn > details.endSN) {
    return 0;
   }
   let i;
   const fragIdx = sn - details.startSN;
   const fragments = details.fragments;
   // update frag reference in fragments array
   // rationale is that fragments array might not contain this frag object.
   // this will happen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()
   // if we don't update frag, we won't be able to propagate PTS info on the playlist
   // resulting in invalid sliding computation
   fragments[fragIdx] = frag;
   // adjust fragment PTS/duration from seqnum-1 to frag 0
   for (i = fragIdx; i > 0; i--) {
    updateFromToPTS(fragments[i], fragments[i - 1]);
   }

   // adjust fragment PTS/duration from seqnum to last frag
   for (i = fragIdx; i < fragments.length - 1; i++) {
    updateFromToPTS(fragments[i], fragments[i + 1]);
   }
   if (details.fragmentHint) {
    updateFromToPTS(fragments[fragments.length - 1], details.fragmentHint);
   }
   details.PTSKnown = details.alignedSliding = true;
   return drift;
  }
  function mergeDetails(oldDetails, newDetails, logger) {
   if (oldDetails === newDetails) {
    return;
   }
   // Track the last initSegment processed. Initialize it to the last one on the timeline.
   let currentInitSegment = null;
   const oldFragments = oldDetails.fragments;
   for (let i = oldFragments.length - 1; i >= 0; i--) {
    const oldInit = oldFragments[i].initSegment;
    if (oldInit) {
     currentInitSegment = oldInit;
     break;
    }
   }
   if (oldDetails.fragmentHint) {
    // prevent PTS and duration from being adjusted on the next hint
    delete oldDetails.fragmentHint.endPTS;
   }
   // check if old/new playlists have fragments in common
   // loop through overlapping SN and update startPTS, cc, and duration if any found
   let PTSFrag;
   mapFragmentIntersection(oldDetails, newDetails, (oldFrag, newFrag, newFragIndex, newFragments) => {
    if ((!newDetails.startCC || newDetails.skippedSegments) && newFrag.cc !== oldFrag.cc) {
     const ccOffset = oldFrag.cc - newFrag.cc;
     for (let i = newFragIndex; i < newFragments.length; i++) {
      newFragments[i].cc += ccOffset;
     }
     newDetails.endCC = newFragments[newFragments.length - 1].cc;
    }
    if (isFiniteNumber(oldFrag.startPTS) && isFiniteNumber(oldFrag.endPTS)) {
     newFrag.setStart((newFrag.startPTS = oldFrag.startPTS));
     newFrag.startDTS = oldFrag.startDTS;
     newFrag.maxStartPTS = oldFrag.maxStartPTS;
     newFrag.endPTS = oldFrag.endPTS;
     newFrag.endDTS = oldFrag.endDTS;
     newFrag.minEndPTS = oldFrag.minEndPTS;
     newFrag.setDuration(oldFrag.endPTS - oldFrag.startPTS);
     if (newFrag.duration) {
      PTSFrag = newFrag;
     }

     // PTS is known when any segment has startPTS and endPTS
     newDetails.PTSKnown = newDetails.alignedSliding = true;
    }
    if (oldFrag.hasStreams) {
     newFrag.elementaryStreams = oldFrag.elementaryStreams;
    }
    newFrag.loader = oldFrag.loader;
    if (oldFrag.hasStats) {
     newFrag.stats = oldFrag.stats;
    }
    if (oldFrag.initSegment) {
     newFrag.initSegment = oldFrag.initSegment;
     currentInitSegment = oldFrag.initSegment;
    }
   });
   const newFragments = newDetails.fragments;
   const fragmentsToCheck = newDetails.fragmentHint ? newFragments.concat(newDetails.fragmentHint) : newFragments;
   if (currentInitSegment) {
    fragmentsToCheck.forEach((frag) => {
     var _currentInitSegment;
     if (frag && (!frag.initSegment || frag.initSegment.relurl === ((_currentInitSegment = currentInitSegment) == null ? void 0 : _currentInitSegment.relurl))) {
      frag.initSegment = currentInitSegment;
     }
    });
   }
   if (newDetails.skippedSegments) {
    newDetails.deltaUpdateFailed = newFragments.some((frag) => !frag);
    if (newDetails.deltaUpdateFailed) {
     logger.warn('[level-helper] Previous playlist missing segments skipped in delta playlist');
     for (let i = newDetails.skippedSegments; i--; ) {
      newFragments.shift();
     }
     newDetails.startSN = newFragments[0].sn;
    } else {
     if (newDetails.canSkipDateRanges) {
      newDetails.dateRanges = mergeDateRanges(oldDetails.dateRanges, newDetails, logger);
     }
     const programDateTimes = oldDetails.fragments.filter((frag) => frag.rawProgramDateTime);
     if (oldDetails.hasProgramDateTime && !newDetails.hasProgramDateTime) {
      for (let i = 1; i < fragmentsToCheck.length; i++) {
       if (fragmentsToCheck[i].programDateTime === null) {
        assignProgramDateTime(fragmentsToCheck[i], fragmentsToCheck[i - 1], programDateTimes);
       }
      }
     }
     mapDateRanges(programDateTimes, newDetails);
    }
    newDetails.endCC = newFragments[newFragments.length - 1].cc;
   }
   if (!newDetails.startCC) {
    var _fragPriorToNewStart$;
    const fragPriorToNewStart = getFragmentWithSN(oldDetails, newDetails.startSN - 1);
    newDetails.startCC = (_fragPriorToNewStart$ = fragPriorToNewStart == null ? void 0 : fragPriorToNewStart.cc) != null ? _fragPriorToNewStart$ : newFragments[0].cc;
   }

   // Merge parts
   mapPartIntersection(oldDetails.partList, newDetails.partList, (oldPart, newPart) => {
    newPart.elementaryStreams = oldPart.elementaryStreams;
    newPart.stats = oldPart.stats;
   });

   // if at least one fragment contains PTS info, recompute PTS information for all fragments
   if (PTSFrag) {
    updateFragPTSDTS(newDetails, PTSFrag, PTSFrag.startPTS, PTSFrag.endPTS, PTSFrag.startDTS, PTSFrag.endDTS, logger);
   } else {
    // ensure that delta is within oldFragments range
    // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])
    // in that case we also need to adjust start offset of all fragments
    adjustSliding(oldDetails, newDetails);
   }
   if (newFragments.length) {
    newDetails.totalduration = newDetails.edge - newFragments[0].start;
   }
   newDetails.driftStartTime = oldDetails.driftStartTime;
   newDetails.driftStart = oldDetails.driftStart;
   const advancedDateTime = newDetails.advancedDateTime;
   if (newDetails.advanced && advancedDateTime) {
    const edge = newDetails.edge;
    if (!newDetails.driftStart) {
     newDetails.driftStartTime = advancedDateTime;
     newDetails.driftStart = edge;
    }
    newDetails.driftEndTime = advancedDateTime;
    newDetails.driftEnd = edge;
   } else {
    newDetails.driftEndTime = oldDetails.driftEndTime;
    newDetails.driftEnd = oldDetails.driftEnd;
    newDetails.advancedDateTime = oldDetails.advancedDateTime;
   }
   if (newDetails.requestScheduled === -1) {
    newDetails.requestScheduled = oldDetails.requestScheduled;
   }
  }
  function mergeDateRanges(oldDateRanges, newDetails, logger) {
   const { dateRanges: deltaDateRanges, recentlyRemovedDateranges } = newDetails;
   const dateRanges = _extends({}, oldDateRanges);
   if (recentlyRemovedDateranges) {
    recentlyRemovedDateranges.forEach((id) => {
     delete dateRanges[id];
    });
   }
   const mergeIds = Object.keys(dateRanges);
   const mergeCount = mergeIds.length;
   if (!mergeCount) {
    return deltaDateRanges;
   }
   Object.keys(deltaDateRanges).forEach((id) => {
    const mergedDateRange = dateRanges[id];
    const dateRange = new DateRange(deltaDateRanges[id].attr, mergedDateRange);
    if (dateRange.isValid) {
     dateRanges[id] = dateRange;
     if (!mergedDateRange) {
      dateRange.tagOrder += mergeCount;
     }
    } else {
     logger.warn(`Ignoring invalid Playlist Delta Update DATERANGE tag: "${stringify(deltaDateRanges[id].attr)}"`);
    }
   });
   return dateRanges;
  }
  function mapPartIntersection(oldParts, newParts, intersectionFn) {
   if (oldParts && newParts) {
    let delta = 0;
    for (let i = 0, len = oldParts.length; i <= len; i++) {
     const oldPart = oldParts[i];
     const newPart = newParts[i + delta];
     if (oldPart && newPart && oldPart.index === newPart.index && oldPart.fragment.sn === newPart.fragment.sn) {
      intersectionFn(oldPart, newPart);
     } else {
      delta--;
     }
    }
   }
  }
  function mapFragmentIntersection(oldDetails, newDetails, intersectionFn) {
   const skippedSegments = newDetails.skippedSegments;
   const start = Math.max(oldDetails.startSN, newDetails.startSN) - newDetails.startSN;
   const end = (oldDetails.fragmentHint ? 1 : 0) + (skippedSegments ? newDetails.endSN : Math.min(oldDetails.endSN, newDetails.endSN)) - newDetails.startSN;
   const delta = newDetails.startSN - oldDetails.startSN;
   const newFrags = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;
   const oldFrags = oldDetails.fragmentHint ? oldDetails.fragments.concat(oldDetails.fragmentHint) : oldDetails.fragments;
   for (let i = start; i <= end; i++) {
    const oldFrag = oldFrags[delta + i];
    let newFrag = newFrags[i];
    if (skippedSegments && !newFrag && oldFrag) {
     // Fill in skipped segments in delta playlist
     newFrag = newDetails.fragments[i] = oldFrag;
    }
    if (oldFrag && newFrag) {
     intersectionFn(oldFrag, newFrag, i, newFrags);
     const uriBefore = oldFrag.relurl;
     const uriAfter = newFrag.relurl;
     if (uriBefore && notEqualAfterStrippingQueries(uriBefore, uriAfter)) {
      newDetails.playlistParsingError = getSequenceError(`media sequence mismatch ${newFrag.sn}:`, oldDetails, newDetails, oldFrag, newFrag);
      return;
     } else if (oldFrag.cc !== newFrag.cc) {
      newDetails.playlistParsingError = getSequenceError(`discontinuity sequence mismatch (${oldFrag.cc}!=${newFrag.cc})`, oldDetails, newDetails, oldFrag, newFrag);
      return;
     }
    }
   }
  }
  function getSequenceError(message, oldDetails, newDetails, oldFrag, newFrag) {
   return new Error(`${message} ${newFrag.url}
Playlist starting @${oldDetails.startSN}
${oldDetails.m3u8}

Playlist starting @${newDetails.startSN}
${newDetails.m3u8}`);
  }
  function adjustSliding(oldDetails, newDetails, matchingStableVariantOrRendition = true) {
   const delta = newDetails.startSN + newDetails.skippedSegments - oldDetails.startSN;
   const oldFragments = oldDetails.fragments;
   const advancedOrStable = delta >= 0;
   let sliding = 0;
   if (advancedOrStable && delta < oldFragments.length) {
    sliding = oldFragments[delta].start;
   } else if (advancedOrStable && newDetails.startSN === oldDetails.endSN + 1) {
    sliding = oldDetails.fragmentEnd;
   } else if (advancedOrStable && matchingStableVariantOrRendition) {
    // align with expected position (updated playlist start sequence is past end sequence of last update)
    sliding = oldDetails.fragmentStart + delta * newDetails.levelTargetDuration;
   } else if (!newDetails.skippedSegments && newDetails.fragmentStart === 0) {
    // align new start with old (playlist switch has a sequence with no overlap and should not be used for alignment)
    sliding = oldDetails.fragmentStart;
   } else {
    // new details already has a sliding offset or has skipped segments
    return;
   }
   addSliding(newDetails, sliding);
  }
  function addSliding(details, sliding) {
   if (sliding) {
    const fragments = details.fragments;
    for (let i = details.skippedSegments; i < fragments.length; i++) {
     fragments[i].addStart(sliding);
    }
    if (details.fragmentHint) {
     details.fragmentHint.addStart(sliding);
    }
   }
  }
  function computeReloadInterval(newDetails, distanceToLiveEdgeMs = Infinity) {
   let reloadInterval = 1000 * newDetails.targetduration;
   if (newDetails.updated) {
    // Use last segment duration when shorter than target duration and near live edge
    const fragments = newDetails.fragments;
    const liveEdgeMaxTargetDurations = 4;
    if (fragments.length && reloadInterval * liveEdgeMaxTargetDurations > distanceToLiveEdgeMs) {
     const lastSegmentDuration = fragments[fragments.length - 1].duration * 1000;
     if (lastSegmentDuration < reloadInterval) {
      reloadInterval = lastSegmentDuration;
     }
    }
   } else {
    // estimate = 'miss half average';
    // follow HLS Spec, If the client reloads a Playlist file and finds that it has not
    // changed then it MUST wait for a period of one-half the target
    // duration before retrying.
    reloadInterval /= 2;
   }
   return Math.round(reloadInterval);
  }
  function getFragmentWithSN(details, sn, fragCurrent) {
   if (!details) {
    return null;
   }
   let fragment = details.fragments[sn - details.startSN];
   if (fragment) {
    return fragment;
   }
   fragment = details.fragmentHint;
   if (fragment && fragment.sn === sn) {
    return fragment;
   }
   if (sn < details.startSN && fragCurrent && fragCurrent.sn === sn) {
    return fragCurrent;
   }
   return null;
  }
  function getPartWith(details, sn, partIndex) {
   if (!details) {
    return null;
   }
   return findPart(details.partList, sn, partIndex);
  }
  function findPart(partList, sn, partIndex) {
   if (partList) {
    for (let i = partList.length; i--; ) {
     const part = partList[i];
     if (part.index === partIndex && part.fragment.sn === sn) {
      return part;
     }
    }
   }
   return null;
  }
  function reassignFragmentLevelIndexes(levels) {
   levels.forEach((level, index) => {
    var _level$details;
    (_level$details = level.details) == null ||
     _level$details.fragments.forEach((fragment) => {
      fragment.level = index;
      if (fragment.initSegment) {
       fragment.initSegment.level = index;
      }
     });
   });
  }
  function notEqualAfterStrippingQueries(uriBefore, uriAfter) {
   if (uriBefore !== uriAfter && uriAfter) {
    return stripQuery(uriBefore) !== stripQuery(uriAfter);
   }
   return false;
  }
  function stripQuery(uri) {
   return uri.replace(/\?[^?]*$/, '');
  }

  function findFirstFragWithCC(fragments, cc) {
   for (let i = 0, len = fragments.length; i < len; i++) {
    var _fragments$i;
    if (((_fragments$i = fragments[i]) == null ? void 0 : _fragments$i.cc) === cc) {
     return fragments[i];
    }
   }
   return null;
  }
  function shouldAlignOnDiscontinuities(refDetails, details) {
   if (refDetails) {
    if (details.startCC < refDetails.endCC && details.endCC > refDetails.startCC) {
     return true;
    }
   }
   return false;
  }
  function adjustFragmentStart(frag, sliding) {
   const start = frag.start + sliding;
   frag.startPTS = start;
   frag.setStart(start);
   frag.endPTS = start + frag.duration;
  }
  function adjustSlidingStart(sliding, details) {
   // Update segments
   const fragments = details.fragments;
   for (let i = 0, len = fragments.length; i < len; i++) {
    adjustFragmentStart(fragments[i], sliding);
   }
   // Update LL-HLS parts at the end of the playlist
   if (details.fragmentHint) {
    adjustFragmentStart(details.fragmentHint, sliding);
   }
   details.alignedSliding = true;
  }

  /**
   * Using the parameters of the last level, this function computes PTS' of the new fragments so that they form a
   * contiguous stream with the last fragments.
   * The PTS of a fragment lets Hls.js know where it fits into a stream - by knowing every PTS, we know which fragment to
   * download at any given time. PTS is normally computed when the fragment is demuxed, so taking this step saves us time
   * and an extra download.
   * @param lastLevel
   * @param details
   */
  function alignStream(switchDetails, details) {
   if (!switchDetails) {
    return;
   }
   alignDiscontinuities(details, switchDetails);
   if (!details.alignedSliding) {
    // If the PTS wasn't figured out via discontinuity sequence that means there was no CC increase within the level.
    // Aligning via Program Date Time should therefore be reliable, since PDT should be the same within the same
    // discontinuity sequence.
    alignMediaPlaylistByPDT(details, switchDetails);
   }
   if (!details.alignedSliding && !details.skippedSegments) {
    // Try to align on sn so that we pick a better start fragment.
    // Do not perform this on playlists with delta updates as this is only to align levels on switch
    // and adjustSliding only adjusts fragments after skippedSegments.
    adjustSliding(switchDetails, details, false);
   }
  }

  /**
   * Ajust the start of fragments in `details` by the difference in time between fragments of the latest
   * shared discontinuity sequence change.
   * @param lastLevel - The details of the last loaded level
   * @param details - The details of the new level
   */
  function alignDiscontinuities(details, refDetails) {
   if (!shouldAlignOnDiscontinuities(refDetails, details)) {
    return;
   }
   const targetCC = Math.min(refDetails.endCC, details.endCC);
   const refFrag = findFirstFragWithCC(refDetails.fragments, targetCC);
   const frag = findFirstFragWithCC(details.fragments, targetCC);
   if (!refFrag || !frag) {
    return;
   }
   logger.log(`Aligning playlist at start of dicontinuity sequence ${targetCC}`);
   const delta = refFrag.start - frag.start;
   adjustSlidingStart(delta, details);
  }

  /**
   * Ensures appropriate time-alignment between renditions based on PDT.
   * This function assumes the timelines represented in `refDetails` are accurate, including the PDTs
   * for the last discontinuity sequence number shared by both playlists when present,
   * and uses the "wallclock"/PDT timeline as a cross-reference to `details`, adjusting the presentation
   * times/timelines of `details` accordingly.
   * Given the asynchronous nature of fetches and initial loads of live `main` and audio/subtitle tracks,
   * the primary purpose of this function is to ensure the "local timelines" of audio/subtitle tracks
   * are aligned to the main/video timeline, using PDT as the cross-reference/"anchor" that should
   * be consistent across playlists, per the HLS spec.
   * @param details - The details of the rendition you'd like to time-align (e.g. an audio rendition).
   * @param refDetails - The details of the reference rendition with start and PDT times for alignment.
   */
  function alignMediaPlaylistByPDT(details, refDetails) {
   if (!details.hasProgramDateTime || !refDetails.hasProgramDateTime) {
    return;
   }
   const fragments = details.fragments;
   const refFragments = refDetails.fragments;
   if (!fragments.length || !refFragments.length) {
    return;
   }

   // Calculate a delta to apply to all fragments according to the delta in PDT times and start times
   // of a fragment in the reference details, and a fragment in the target details of the same discontinuity.
   // If a fragment of the same discontinuity was not found use the middle fragment of both.
   let refFrag;
   let frag;
   const targetCC = Math.min(refDetails.endCC, details.endCC);
   if (refDetails.startCC < targetCC && details.startCC < targetCC) {
    refFrag = findFirstFragWithCC(refFragments, targetCC);
    frag = findFirstFragWithCC(fragments, targetCC);
   }
   if (!refFrag || !frag) {
    refFrag = refFragments[Math.floor(refFragments.length / 2)];
    frag = findFirstFragWithCC(fragments, refFrag.cc) || fragments[Math.floor(fragments.length / 2)];
   }
   const refPDT = refFrag.programDateTime;
   const targetPDT = frag.programDateTime;
   if (!refPDT || !targetPDT) {
    return;
   }
   const delta = (targetPDT - refPDT) / 1000 - (frag.start - refFrag.start);
   adjustSlidingStart(delta, details);
  }

  /**
   *  TimeRanges to string helper
   */

  const TimeRanges = {
   toString: function (r) {
    let log = '';
    const len = r.length;
    for (let i = 0; i < len; i++) {
     log += `[${r.start(i).toFixed(3)}-${r.end(i).toFixed(3)}]`;
    }
    return log;
   },
  };

  const State = {
   STOPPED: 'STOPPED',
   IDLE: 'IDLE',
   KEY_LOADING: 'KEY_LOADING',
   FRAG_LOADING: 'FRAG_LOADING',
   FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',
   WAITING_TRACK: 'WAITING_TRACK',
   PARSING: 'PARSING',
   PARSED: 'PARSED',
   ENDED: 'ENDED',
   ERROR: 'ERROR',
   WAITING_INIT_PTS: 'WAITING_INIT_PTS',
   WAITING_LEVEL: 'WAITING_LEVEL',
  };
  class BaseStreamController extends TaskLoop {
   constructor(hls, fragmentTracker, keyLoader, logPrefix, playlistType) {
    super(logPrefix, hls.logger);
    this.hls = void 0;
    this.fragPrevious = null;
    this.fragCurrent = null;
    this.fragmentTracker = void 0;
    this.transmuxer = null;
    this._state = State.STOPPED;
    this.playlistType = void 0;
    this.media = null;
    this.mediaBuffer = null;
    this.config = void 0;
    this.bitrateTest = false;
    this.lastCurrentTime = 0;
    this.nextLoadPosition = 0;
    this.startPosition = 0;
    this.startTimeOffset = null;
    this.retryDate = 0;
    this.levels = null;
    this.fragmentLoader = void 0;
    this.keyLoader = void 0;
    this.levelLastLoaded = null;
    this.startFragRequested = false;
    this.decrypter = void 0;
    this.initPTS = [];
    this.buffering = true;
    this.loadingParts = false;
    this.loopSn = void 0;
    this.onMediaSeeking = () => {
     const { config, fragCurrent, media, mediaBuffer, state } = this;
     const currentTime = media ? media.currentTime : 0;
     const bufferInfo = BufferHelper.bufferInfo(mediaBuffer ? mediaBuffer : media, currentTime, config.maxBufferHole);
     const noFowardBuffer = !bufferInfo.len;
     this.log(`Media seeking to ${isFiniteNumber(currentTime) ? currentTime.toFixed(3) : currentTime}, state: ${state}, ${noFowardBuffer ? 'out of' : 'in'} buffer`);
     if (this.state === State.ENDED) {
      this.resetLoadingState();
     } else if (fragCurrent) {
      // Seeking while frag load is in progress
      const tolerance = config.maxFragLookUpTolerance;
      const fragStartOffset = fragCurrent.start - tolerance;
      const fragEndOffset = fragCurrent.start + fragCurrent.duration + tolerance;
      // if seeking out of buffered range or into new one
      if (noFowardBuffer || fragEndOffset < bufferInfo.start || fragStartOffset > bufferInfo.end) {
       const pastFragment = currentTime > fragEndOffset;
       // if the seek position is outside the current fragment range
       if (currentTime < fragStartOffset || pastFragment) {
        if (pastFragment && fragCurrent.loader) {
         this.log(`Cancelling fragment load for seek (sn: ${fragCurrent.sn})`);
         fragCurrent.abortRequests();
         this.resetLoadingState();
        }
        this.fragPrevious = null;
       }
      }
     }
     if (media) {
      // Remove gap fragments
      this.fragmentTracker.removeFragmentsInRange(currentTime, Infinity, this.playlistType, true);

      // Don't set lastCurrentTime with backward seeks (allows for frag selection with strict tolerances)
      const lastCurrentTime = this.lastCurrentTime;
      if (currentTime > lastCurrentTime) {
       this.lastCurrentTime = currentTime;
      }
      if (!this.loadingParts) {
       const bufferEnd = Math.max(bufferInfo.end, currentTime);
       const shouldLoadParts = this.shouldLoadParts(this.getLevelDetails(), bufferEnd);
       if (shouldLoadParts) {
        this.log(`LL-Part loading ON after seeking to ${currentTime.toFixed(2)} with buffer @${bufferEnd.toFixed(2)}`);
        this.loadingParts = shouldLoadParts;
       }
      }
     }

     // in case seeking occurs although no media buffered, adjust startPosition and nextLoadPosition to seek target
     if (!this.hls.hasEnoughToStart) {
      this.log(`Setting ${noFowardBuffer ? 'startPosition' : 'nextLoadPosition'} to ${currentTime} for seek without enough to start`);
      this.nextLoadPosition = currentTime;
      if (noFowardBuffer) {
       this.startPosition = currentTime;
      }
     }

     // Async tick to speed up processing
     this.tickImmediate();
    };
    this.onMediaEnded = () => {
     // reset startPosition and lastCurrentTime to restart playback @ stream beginning
     this.log(`setting startPosition to 0 because media ended`);
     this.startPosition = this.lastCurrentTime = 0;
    };
    this.playlistType = playlistType;
    this.hls = hls;
    this.fragmentLoader = new FragmentLoader(hls.config);
    this.keyLoader = keyLoader;
    this.fragmentTracker = fragmentTracker;
    this.config = hls.config;
    this.decrypter = new Decrypter(hls.config);
   }
   registerListeners() {
    const { hls } = this;
    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    hls.on(Events.ERROR, this.onError, this);
   }
   unregisterListeners() {
    const { hls } = this;
    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    hls.off(Events.ERROR, this.onError, this);
   }
   doTick() {
    this.onTickEnd();
   }
   onTickEnd() {}
   startLoad(startPosition) {}
   stopLoad() {
    if (this.state === State.STOPPED) {
     return;
    }
    this.fragmentLoader.abort();
    this.keyLoader.abort(this.playlistType);
    const frag = this.fragCurrent;
    if (frag != null && frag.loader) {
     frag.abortRequests();
     this.fragmentTracker.removeFragment(frag);
    }
    this.resetTransmuxer();
    this.fragCurrent = null;
    this.fragPrevious = null;
    this.clearInterval();
    this.clearNextTick();
    this.state = State.STOPPED;
   }
   get startPositionValue() {
    const { nextLoadPosition, startPosition } = this;
    if (startPosition === -1 && nextLoadPosition) {
     return nextLoadPosition;
    }
    return startPosition;
   }
   get bufferingEnabled() {
    return this.buffering;
   }
   pauseBuffering() {
    this.buffering = false;
   }
   resumeBuffering() {
    this.buffering = true;
   }
   get inFlightFrag() {
    return {
     frag: this.fragCurrent,
     state: this.state,
    };
   }
   _streamEnded(bufferInfo, levelDetails) {
    // Stream is never "ended" when playlist is live or media is detached
    if (levelDetails.live || !this.media) {
     return false;
    }
    // Stream is not "ended" when nothing is buffered past the start
    const bufferEnd = bufferInfo.end || 0;
    const timelineStart = this.config.timelineOffset || 0;
    if (bufferEnd <= timelineStart) {
     return false;
    }
    // Stream is not "ended" when there is a second buffered range starting before the end of the playlist
    const bufferedRanges = bufferInfo.buffered;
    if (this.config.maxBufferHole && bufferedRanges && bufferedRanges.length > 1) {
     // make sure bufferInfo accounts for any gaps
     bufferInfo = BufferHelper.bufferedInfo(bufferedRanges, bufferInfo.start, 0);
    }
    const nextStart = bufferInfo.nextStart;
    const hasSecondBufferedRange = nextStart && nextStart > timelineStart && nextStart < levelDetails.edge;
    if (hasSecondBufferedRange) {
     return false;
    }
    // Playhead is in unbuffered region. Marking EoS now could result in Safari failing to dispatch "ended" event following seek on start.
    if (this.media.currentTime < bufferInfo.start) {
     return false;
    }
    const partList = levelDetails.partList;
    // Since the last part isn't guaranteed to correspond to the last playlist segment for Low-Latency HLS,
    // check instead if the last part is buffered.
    if (partList != null && partList.length) {
     const lastPart = partList[partList.length - 1];

     // Checking the midpoint of the part for potential margin of error and related issues.
     // NOTE: Technically I believe parts could yield content that is < the computed duration (including potential a duration of 0)
     // and still be spec-compliant, so there may still be edge cases here. Likewise, there could be issues in end of stream
     // part mismatches for independent audio and video playlists/segments.
     const lastPartBuffered = BufferHelper.isBuffered(this.media, lastPart.start + lastPart.duration / 2);
     return lastPartBuffered;
    }
    const playlistType = levelDetails.fragments[levelDetails.fragments.length - 1].type;
    return this.fragmentTracker.isEndListAppended(playlistType);
   }
   getLevelDetails() {
    if (this.levels && this.levelLastLoaded !== null) {
     return this.levelLastLoaded.details;
    }
   }
   get timelineOffset() {
    const configuredTimelineOffset = this.config.timelineOffset;
    if (configuredTimelineOffset) {
     var _this$getLevelDetails;
     return ((_this$getLevelDetails = this.getLevelDetails()) == null ? void 0 : _this$getLevelDetails.appliedTimelineOffset) || configuredTimelineOffset;
    }
    return 0;
   }
   onMediaAttached(event, data) {
    const media = (this.media = this.mediaBuffer = data.media);
    media.removeEventListener('seeking', this.onMediaSeeking);
    media.removeEventListener('ended', this.onMediaEnded);
    media.addEventListener('seeking', this.onMediaSeeking);
    media.addEventListener('ended', this.onMediaEnded);
    const config = this.config;
    if (this.levels && config.autoStartLoad && this.state === State.STOPPED) {
     this.startLoad(config.startPosition);
    }
   }
   onMediaDetaching(event, data) {
    const transferringMedia = !!data.transferMedia;
    const media = this.media;
    if (media === null) {
     return;
    }
    if (media.ended) {
     this.log('MSE detaching and video ended, reset startPosition');
     this.startPosition = this.lastCurrentTime = 0;
    }

    // remove video listeners
    media.removeEventListener('seeking', this.onMediaSeeking);
    media.removeEventListener('ended', this.onMediaEnded);
    if (this.keyLoader && !transferringMedia) {
     this.keyLoader.detach();
    }
    this.media = this.mediaBuffer = null;
    this.loopSn = undefined;
    if (transferringMedia) {
     this.resetLoadingState();
     this.resetTransmuxer();
     return;
    }
    this.loadingParts = false;
    this.fragmentTracker.removeAllFragments();
    this.stopLoad();
   }
   onManifestLoading() {
    this.initPTS = [];
    this.levels = this.levelLastLoaded = this.fragCurrent = null;
    this.lastCurrentTime = this.startPosition = 0;
    this.startFragRequested = false;
   }
   onError(event, data) {}
   onManifestLoaded(event, data) {
    this.startTimeOffset = data.startTimeOffset;
   }
   onHandlerDestroying() {
    this.stopLoad();
    if (this.transmuxer) {
     this.transmuxer.destroy();
     this.transmuxer = null;
    }
    super.onHandlerDestroying();
    // @ts-ignore
    this.hls = this.onMediaSeeking = this.onMediaEnded = null;
   }
   onHandlerDestroyed() {
    this.state = State.STOPPED;
    if (this.fragmentLoader) {
     this.fragmentLoader.destroy();
    }
    if (this.keyLoader) {
     this.keyLoader.destroy();
    }
    if (this.decrypter) {
     this.decrypter.destroy();
    }
    this.hls = this.log = this.warn = this.decrypter = this.keyLoader = this.fragmentLoader = this.fragmentTracker = null;
    super.onHandlerDestroyed();
   }
   loadFragment(frag, level, targetBufferTime) {
    this.startFragRequested = true;
    this._loadFragForPlayback(frag, level, targetBufferTime);
   }
   _loadFragForPlayback(fragment, level, targetBufferTime) {
    const progressCallback = (data) => {
     const frag = data.frag;
     if (this.fragContextChanged(frag)) {
      this.warn(`${frag.type} sn: ${frag.sn}${data.part ? ' part: ' + data.part.index : ''} of ${this.fragInfo(frag, false, data.part)}) was dropped during download.`);
      this.fragmentTracker.removeFragment(frag);
      return;
     }
     frag.stats.chunkCount++;
     this._handleFragmentLoadProgress(data);
    };
    this._doFragLoad(fragment, level, targetBufferTime, progressCallback)
     .then((data) => {
      if (!data) {
       // if we're here we probably needed to backtrack or are waiting for more parts
       return;
      }
      const state = this.state;
      const frag = data.frag;
      if (this.fragContextChanged(frag)) {
       if (state === State.FRAG_LOADING || (!this.fragCurrent && state === State.PARSING)) {
        this.fragmentTracker.removeFragment(frag);
        this.state = State.IDLE;
       }
       return;
      }
      if ('payload' in data) {
       this.log(`Loaded ${frag.type} sn: ${frag.sn} of ${this.playlistLabel()} ${frag.level}`);
       this.hls.trigger(Events.FRAG_LOADED, data);
      }

      // Pass through the whole payload; controllers not implementing progressive loading receive data from this callback
      this._handleFragmentLoadComplete(data);
     })
     .catch((reason) => {
      if (this.state === State.STOPPED || this.state === State.ERROR) {
       return;
      }
      this.warn(`Frag error: ${(reason == null ? void 0 : reason.message) || reason}`);
      this.resetFragmentLoading(fragment);
     });
   }
   clearTrackerIfNeeded(frag) {
    var _this$mediaBuffer;
    const { fragmentTracker } = this;
    const fragState = fragmentTracker.getState(frag);
    if (fragState === FragmentState.APPENDING) {
     // Lower the max buffer length and try again
     const playlistType = frag.type;
     const bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, playlistType);
     const minForwardBufferLength = Math.max(frag.duration, bufferedInfo ? bufferedInfo.len : this.config.maxBufferLength);
     // If backtracking, always remove from the tracker without reducing max buffer length
     const backtrackFragment = this.backtrackFragment;
     const backtracked = backtrackFragment ? frag.sn - backtrackFragment.sn : 0;
     if (backtracked === 1 || this.reduceMaxBufferLength(minForwardBufferLength, frag.duration)) {
      fragmentTracker.removeFragment(frag);
     }
    } else if (((_this$mediaBuffer = this.mediaBuffer) == null ? void 0 : _this$mediaBuffer.buffered.length) === 0) {
     // Stop gap for bad tracker / buffer flush behavior
     fragmentTracker.removeAllFragments();
    } else if (fragmentTracker.hasParts(frag.type)) {
     // In low latency mode, remove fragments for which only some parts were buffered
     fragmentTracker.detectPartialFragments({
      frag,
      part: null,
      stats: frag.stats,
      id: frag.type,
     });
     if (fragmentTracker.getState(frag) === FragmentState.PARTIAL) {
      fragmentTracker.removeFragment(frag);
     }
    }
   }
   checkLiveUpdate(details) {
    if (details.updated && !details.live) {
     // Live stream ended, update fragment tracker
     const lastFragment = details.fragments[details.fragments.length - 1];
     this.fragmentTracker.detectPartialFragments({
      frag: lastFragment,
      part: null,
      stats: lastFragment.stats,
      id: lastFragment.type,
     });
    }
    if (!details.fragments[0]) {
     details.deltaUpdateFailed = true;
    }
   }
   waitForLive(levelInfo) {
    const details = levelInfo.details;
    return (details == null ? void 0 : details.live) && details.type !== 'EVENT' && (this.levelLastLoaded !== levelInfo || details.expired);
   }
   flushMainBuffer(startOffset, endOffset, type = null) {
    if (!(startOffset - endOffset)) {
     return;
    }
    // When alternate audio is playing, the audio-stream-controller is responsible for the audio buffer. Otherwise,
    // passing a null type flushes both buffers
    const flushScope = {
     startOffset,
     endOffset,
     type,
    };
    this.hls.trigger(Events.BUFFER_FLUSHING, flushScope);
   }
   _loadInitSegment(fragment, level) {
    this._doFragLoad(fragment, level)
     .then((data) => {
      const frag = data == null ? void 0 : data.frag;
      if (!frag || this.fragContextChanged(frag) || !this.levels) {
       throw new Error('init load aborted');
      }
      return data;
     })
     .then((data) => {
      const { hls } = this;
      const { frag, payload } = data;
      const decryptData = frag.decryptdata;

      // check to see if the payload needs to be decrypted
      if (payload && payload.byteLength > 0 && decryptData != null && decryptData.key && decryptData.iv && isFullSegmentEncryption(decryptData.method)) {
       const startTime = self.performance.now();
       // decrypt init segment data
       return this.decrypter
        .decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer, getAesModeFromFullSegmentMethod(decryptData.method))
        .catch((err) => {
         hls.trigger(Events.ERROR, {
          type: ErrorTypes.MEDIA_ERROR,
          details: ErrorDetails.FRAG_DECRYPT_ERROR,
          fatal: false,
          error: err,
          reason: err.message,
          frag,
         });
         throw err;
        })
        .then((decryptedData) => {
         const endTime = self.performance.now();
         hls.trigger(Events.FRAG_DECRYPTED, {
          frag,
          payload: decryptedData,
          stats: {
           tstart: startTime,
           tdecrypt: endTime,
          },
         });
         data.payload = decryptedData;
         return this.completeInitSegmentLoad(data);
        });
      }
      return this.completeInitSegmentLoad(data);
     })
     .catch((reason) => {
      if (this.state === State.STOPPED || this.state === State.ERROR) {
       return;
      }
      this.warn(reason);
      this.resetFragmentLoading(fragment);
     });
   }
   completeInitSegmentLoad(data) {
    const { levels } = this;
    if (!levels) {
     throw new Error('init load aborted, missing levels');
    }
    const stats = data.frag.stats;
    if (this.state !== State.STOPPED) {
     this.state = State.IDLE;
    }
    data.frag.data = new Uint8Array(data.payload);
    stats.parsing.start = stats.buffering.start = self.performance.now();
    stats.parsing.end = stats.buffering.end = self.performance.now();
    this.tick();
   }
   unhandledEncryptionError(initSegment, frag) {
    var _tracks$audio, _tracks$video;
    const tracks = initSegment.tracks;
    if (tracks && !frag.encrypted && (((_tracks$audio = tracks.audio) != null && _tracks$audio.encrypted) || ((_tracks$video = tracks.video) != null && _tracks$video.encrypted)) && (!this.config.emeEnabled || !this.keyLoader.emeController)) {
     const media = this.media;
     const error = new Error(`Encrypted track with no key in ${this.fragInfo(frag)} (media ${media ? 'attached mediaKeys: ' + media.mediaKeys : 'detached'})`);
     this.warn(error.message);
     // Ignore if media is detached or mediaKeys are set
     if (!media || media.mediaKeys) {
      return false;
     }
     this.hls.trigger(Events.ERROR, {
      type: ErrorTypes.KEY_SYSTEM_ERROR,
      details: ErrorDetails.KEY_SYSTEM_NO_KEYS,
      fatal: false,
      error,
      frag,
     });
     this.resetTransmuxer();
     return true;
    }
    return false;
   }
   fragContextChanged(frag) {
    const { fragCurrent } = this;
    return !frag || !fragCurrent || frag.sn !== fragCurrent.sn || frag.level !== fragCurrent.level;
   }
   fragBufferedComplete(frag, part) {
    const media = this.mediaBuffer ? this.mediaBuffer : this.media;
    this.log(`Buffered ${frag.type} sn: ${frag.sn}${part ? ' part: ' + part.index : ''} of ${this.fragInfo(frag, false, part)} > buffer:${media ? TimeRanges.toString(BufferHelper.getBuffered(media)) : '(detached)'})`);
    if (isMediaFragment(frag)) {
     var _this$levels;
     if (frag.type !== PlaylistLevelType.SUBTITLE) {
      const el = frag.elementaryStreams;
      if (!Object.keys(el).some((type) => !!el[type])) {
       // empty segment
       this.state = State.IDLE;
       return;
      }
     }
     const level = (_this$levels = this.levels) == null ? void 0 : _this$levels[frag.level];
     if (level != null && level.fragmentError) {
      this.log(`Resetting level fragment error count of ${level.fragmentError} on frag buffered`);
      level.fragmentError = 0;
     }
    }
    this.state = State.IDLE;
   }
   _handleFragmentLoadComplete(fragLoadedEndData) {
    const { transmuxer } = this;
    if (!transmuxer) {
     return;
    }
    const { frag, part, partsLoaded } = fragLoadedEndData;
    // If we did not load parts, or loaded all parts, we have complete (not partial) fragment data
    const complete = !partsLoaded || partsLoaded.length === 0 || partsLoaded.some((fragLoaded) => !fragLoaded);
    const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount + 1, 0, part ? part.index : -1, !complete);
    transmuxer.flush(chunkMeta);
   }
   _handleFragmentLoadProgress(frag) {}
   _doFragLoad(frag, level, targetBufferTime = null, progressCallback) {
    var _frag$decryptdata;
    this.fragCurrent = frag;
    const details = level.details;
    if (!this.levels || !details) {
     throw new Error(`frag load aborted, missing level${details ? '' : ' detail'}s`);
    }
    let keyLoadingPromise = null;
    if (frag.encrypted && !((_frag$decryptdata = frag.decryptdata) != null && _frag$decryptdata.key)) {
     this.log(`Loading key for ${frag.sn} of [${details.startSN}-${details.endSN}], ${this.playlistLabel()} ${frag.level}`);
     this.state = State.KEY_LOADING;
     this.fragCurrent = frag;
     keyLoadingPromise = this.keyLoader.load(frag).then((keyLoadedData) => {
      if (!this.fragContextChanged(keyLoadedData.frag)) {
       this.hls.trigger(Events.KEY_LOADED, keyLoadedData);
       if (this.state === State.KEY_LOADING) {
        this.state = State.IDLE;
       }
       return keyLoadedData;
      }
     });
     this.hls.trigger(Events.KEY_LOADING, {
      frag,
     });
     if (this.fragCurrent === null) {
      keyLoadingPromise = Promise.reject(new Error(`frag load aborted, context changed in KEY_LOADING`));
     }
    } else if (!frag.encrypted) {
     keyLoadingPromise = this.keyLoader.loadClear(frag, details.encryptedFragments, this.startFragRequested);
     if (keyLoadingPromise) {
      this.log(`[eme] blocking frag load until media-keys acquired`);
     }
    }
    const fragPrevious = this.fragPrevious;
    if (isMediaFragment(frag) && (!fragPrevious || frag.sn !== fragPrevious.sn)) {
     const shouldLoadParts = this.shouldLoadParts(level.details, frag.end);
     if (shouldLoadParts !== this.loadingParts) {
      this.log(`LL-Part loading ${shouldLoadParts ? 'ON' : 'OFF'} loading sn ${fragPrevious == null ? void 0 : fragPrevious.sn}->${frag.sn}`);
      this.loadingParts = shouldLoadParts;
     }
    }
    targetBufferTime = Math.max(frag.start, targetBufferTime || 0);
    if (this.loadingParts && isMediaFragment(frag)) {
     const partList = details.partList;
     if (partList && progressCallback) {
      if (targetBufferTime > details.fragmentEnd && details.fragmentHint) {
       frag = details.fragmentHint;
      }
      const partIndex = this.getNextPart(partList, frag, targetBufferTime);
      if (partIndex > -1) {
       const part = partList[partIndex];
       frag = this.fragCurrent = part.fragment;
       this.log(`Loading ${frag.type} sn: ${frag.sn} part: ${part.index} (${partIndex}/${partList.length - 1}) of ${this.fragInfo(frag, false, part)}) cc: ${frag.cc} [${details.startSN}-${details.endSN}], target: ${parseFloat(targetBufferTime.toFixed(3))}`);
       this.nextLoadPosition = part.start + part.duration;
       this.state = State.FRAG_LOADING;
       let _result;
       if (keyLoadingPromise) {
        _result = keyLoadingPromise
         .then((keyLoadedData) => {
          if (!keyLoadedData || this.fragContextChanged(keyLoadedData.frag)) {
           return null;
          }
          return this.doFragPartsLoad(frag, part, level, progressCallback);
         })
         .catch((error) => this.handleFragLoadError(error));
       } else {
        _result = this.doFragPartsLoad(frag, part, level, progressCallback).catch((error) => this.handleFragLoadError(error));
       }
       this.hls.trigger(Events.FRAG_LOADING, {
        frag,
        part,
        targetBufferTime,
       });
       if (this.fragCurrent === null) {
        return Promise.reject(new Error(`frag load aborted, context changed in FRAG_LOADING parts`));
       }
       return _result;
      } else if (!frag.url || this.loadedEndOfParts(partList, targetBufferTime)) {
       // Fragment hint has no parts
       return Promise.resolve(null);
      }
     }
    }
    if (isMediaFragment(frag) && this.loadingParts) {
     var _details$partList;
     this.log(`LL-Part loading OFF after next part miss @${targetBufferTime.toFixed(2)} Check buffer at sn: ${frag.sn} loaded parts: ${(_details$partList = details.partList) == null ? void 0 : _details$partList.filter((p) => p.loaded).map((p) => `[${p.start}-${p.end}]`)}`);
     this.loadingParts = false;
    } else if (!frag.url) {
     // Selected fragment hint for part but not loading parts
     return Promise.resolve(null);
    }
    this.log(`Loading ${frag.type} sn: ${frag.sn} of ${this.fragInfo(frag, false)}) cc: ${frag.cc} ${'[' + details.startSN + '-' + details.endSN + ']'}, target: ${parseFloat(targetBufferTime.toFixed(3))}`);
    // Don't update nextLoadPosition for fragments which are not buffered
    if (isFiniteNumber(frag.sn) && !this.bitrateTest) {
     this.nextLoadPosition = frag.start + frag.duration;
    }
    this.state = State.FRAG_LOADING;

    // Load key before streaming fragment data
    const dataOnProgress = this.config.progressive;
    let result;
    if (dataOnProgress && keyLoadingPromise) {
     result = keyLoadingPromise
      .then((keyLoadedData) => {
       if (!keyLoadedData || this.fragContextChanged(keyLoadedData.frag)) {
        return null;
       }
       return this.fragmentLoader.load(frag, progressCallback);
      })
      .catch((error) => this.handleFragLoadError(error));
    } else {
     // load unencrypted fragment data with progress event,
     // or handle fragment result after key and fragment are finished loading
     result = Promise.all([this.fragmentLoader.load(frag, dataOnProgress ? progressCallback : undefined), keyLoadingPromise])
      .then(([fragLoadedData]) => {
       if (!dataOnProgress && progressCallback) {
        progressCallback(fragLoadedData);
       }
       return fragLoadedData;
      })
      .catch((error) => this.handleFragLoadError(error));
    }
    this.hls.trigger(Events.FRAG_LOADING, {
     frag,
     targetBufferTime,
    });
    if (this.fragCurrent === null) {
     return Promise.reject(new Error(`frag load aborted, context changed in FRAG_LOADING`));
    }
    return result;
   }
   doFragPartsLoad(frag, fromPart, level, progressCallback) {
    return new Promise((resolve, reject) => {
     var _level$details;
     const partsLoaded = [];
     const initialPartList = (_level$details = level.details) == null ? void 0 : _level$details.partList;
     const loadPart = (part) => {
      this.fragmentLoader
       .loadPart(frag, part, progressCallback)
       .then((partLoadedData) => {
        partsLoaded[part.index] = partLoadedData;
        const loadedPart = partLoadedData.part;
        this.hls.trigger(Events.FRAG_LOADED, partLoadedData);
        const nextPart = getPartWith(level.details, frag.sn, part.index + 1) || findPart(initialPartList, frag.sn, part.index + 1);
        if (nextPart) {
         loadPart(nextPart);
        } else {
         return resolve({
          frag,
          part: loadedPart,
          partsLoaded,
         });
        }
       })
       .catch(reject);
     };
     loadPart(fromPart);
    });
   }
   handleFragLoadError(error) {
    if ('data' in error) {
     const data = error.data;
     if (data && data.details === ErrorDetails.INTERNAL_ABORTED) {
      this.handleFragLoadAborted(data.frag, data.part);
     } else {
      this.hls.trigger(Events.ERROR, data);
     }
    } else {
     this.hls.trigger(Events.ERROR, {
      type: ErrorTypes.OTHER_ERROR,
      details: ErrorDetails.INTERNAL_EXCEPTION,
      err: error,
      error,
      fatal: true,
     });
    }
    return null;
   }
   _handleTransmuxerFlush(chunkMeta) {
    const context = this.getCurrentContext(chunkMeta);
    if (!context || this.state !== State.PARSING) {
     if (!this.fragCurrent && this.state !== State.STOPPED && this.state !== State.ERROR) {
      this.state = State.IDLE;
     }
     return;
    }
    const { frag, part, level } = context;
    const now = self.performance.now();
    frag.stats.parsing.end = now;
    if (part) {
     part.stats.parsing.end = now;
    }
    // See if part loading should be disabled/enabled based on buffer and playback position.
    const levelDetails = this.getLevelDetails();
    const loadingPartsAtEdge = levelDetails && frag.sn > levelDetails.endSN;
    const shouldLoadParts = loadingPartsAtEdge || this.shouldLoadParts(levelDetails, frag.end);
    if (shouldLoadParts !== this.loadingParts) {
     this.log(`LL-Part loading ${shouldLoadParts ? 'ON' : 'OFF'} after parsing segment ending @${frag.end.toFixed(2)}`);
     this.loadingParts = shouldLoadParts;
    }
    this.updateLevelTiming(frag, part, level, chunkMeta.partial);
   }
   shouldLoadParts(details, bufferEnd) {
    if (this.config.lowLatencyMode) {
     if (!details) {
      return this.loadingParts;
     }
     if (details.partList) {
      var _details$fragmentHint;
      // Buffer must be ahead of first part + duration of parts after last segment
      // and playback must be at or past segment adjacent to part list
      const firstPart = details.partList[0];
      // Loading of VTT subtitle parts is not implemented in subtitle-stream-controller (#7460)
      if (firstPart.fragment.type === PlaylistLevelType.SUBTITLE) {
       return false;
      }
      const safePartStart = firstPart.end + (((_details$fragmentHint = details.fragmentHint) == null ? void 0 : _details$fragmentHint.duration) || 0);
      if (bufferEnd >= safePartStart) {
       var _this$media;
       const playhead = this.hls.hasEnoughToStart ? ((_this$media = this.media) == null ? void 0 : _this$media.currentTime) || this.lastCurrentTime : this.getLoadPosition();
       if (playhead > firstPart.start - firstPart.fragment.duration) {
        return true;
       }
      }
     }
    }
    return false;
   }
   getCurrentContext(chunkMeta) {
    const { levels, fragCurrent } = this;
    const { level: levelIndex, sn, part: partIndex } = chunkMeta;
    if (!(levels != null && levels[levelIndex])) {
     this.warn(`Levels object was unset while buffering fragment ${sn} of ${this.playlistLabel()} ${levelIndex}. The current chunk will not be buffered.`);
     return null;
    }
    const level = levels[levelIndex];
    const levelDetails = level.details;
    const part = partIndex > -1 ? getPartWith(levelDetails, sn, partIndex) : null;
    const frag = part ? part.fragment : getFragmentWithSN(levelDetails, sn, fragCurrent);
    if (!frag) {
     return null;
    }
    if (fragCurrent && fragCurrent !== frag) {
     frag.stats = fragCurrent.stats;
    }
    return {
     frag,
     part,
     level,
    };
   }
   bufferFragmentData(data, frag, part, chunkMeta, noBacktracking) {
    if (this.state !== State.PARSING) {
     return;
    }
    const { data1, data2 } = data;
    let buffer = data1;
    if (data2) {
     // Combine the moof + mdat so that we buffer with a single append
     buffer = appendUint8Array(data1, data2);
    }
    if (!buffer.length) {
     return;
    }
    const offsetTimestamp = this.initPTS[frag.cc];
    const offset = offsetTimestamp ? -offsetTimestamp.baseTime / offsetTimestamp.timescale : undefined;
    const segment = {
     type: data.type,
     frag,
     part,
     chunkMeta,
     offset,
     parent: frag.type,
     data: buffer,
    };
    this.hls.trigger(Events.BUFFER_APPENDING, segment);
    if (data.dropped && data.independent && !part) {
     if (noBacktracking) {
      return;
     }
     // Clear buffer so that we reload previous segments sequentially if required
     this.flushBufferGap(frag);
    }
   }
   flushBufferGap(frag) {
    const media = this.media;
    if (!media) {
     return;
    }
    // If currentTime is not buffered, clear the back buffer so that we can backtrack as much as needed
    if (!BufferHelper.isBuffered(media, media.currentTime)) {
     this.flushMainBuffer(0, frag.start);
     return;
    }
    // Remove back-buffer without interrupting playback to allow back tracking
    const currentTime = media.currentTime;
    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);
    const fragDuration = frag.duration;
    const segmentFraction = Math.min(this.config.maxFragLookUpTolerance * 2, fragDuration * 0.25);
    const start = Math.max(Math.min(frag.start - segmentFraction, bufferInfo.end - segmentFraction), currentTime + segmentFraction);
    if (frag.start - start > segmentFraction) {
     this.flushMainBuffer(start, frag.start);
    }
   }
   getFwdBufferInfo(bufferable, type) {
    var _this$media2;
    const pos = this.getLoadPosition();
    if (!isFiniteNumber(pos)) {
     return null;
    }
    const backwardSeek = this.lastCurrentTime > pos;
    const maxBufferHole = backwardSeek || ((_this$media2 = this.media) != null && _this$media2.paused) ? 0 : this.config.maxBufferHole;
    return this.getFwdBufferInfoAtPos(bufferable, pos, type, maxBufferHole);
   }
   getFwdBufferInfoAtPos(bufferable, pos, type, maxBufferHole) {
    const bufferInfo = BufferHelper.bufferInfo(bufferable, pos, maxBufferHole);
    // Workaround flaw in getting forward buffer when maxBufferHole is smaller than gap at current pos
    if (bufferInfo.len === 0 && bufferInfo.nextStart !== undefined) {
     const bufferedFragAtPos = this.fragmentTracker.getBufferedFrag(pos, type);
     if (bufferedFragAtPos && (bufferInfo.nextStart <= bufferedFragAtPos.end || bufferedFragAtPos.gap)) {
      const gapDuration = Math.max(Math.min(bufferInfo.nextStart, bufferedFragAtPos.end) - pos, maxBufferHole);
      return BufferHelper.bufferInfo(bufferable, pos, gapDuration);
     }
    }
    return bufferInfo;
   }
   getMaxBufferLength(levelBitrate) {
    const { config } = this;
    let maxBufLen;
    if (levelBitrate) {
     maxBufLen = Math.max((8 * config.maxBufferSize) / levelBitrate, config.maxBufferLength);
    } else {
     maxBufLen = config.maxBufferLength;
    }
    return Math.min(maxBufLen, config.maxMaxBufferLength);
   }
   reduceMaxBufferLength(threshold, fragDuration) {
    const config = this.config;
    const minLength = Math.max(Math.min(threshold - fragDuration, config.maxBufferLength), fragDuration);
    const reducedLength = Math.max(threshold - fragDuration * 3, config.maxMaxBufferLength / 2, minLength);
    if (reducedLength >= minLength) {
     // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...
     config.maxMaxBufferLength = reducedLength;
     this.warn(`Reduce max buffer length to ${reducedLength}s`);
     return true;
    }
    return false;
   }
   getAppendedFrag(position, playlistType = PlaylistLevelType.MAIN) {
    const fragOrPart = this.fragmentTracker ? this.fragmentTracker.getAppendedFrag(position, playlistType) : null;
    if (fragOrPart && 'fragment' in fragOrPart) {
     return fragOrPart.fragment;
    }
    return fragOrPart;
   }
   getNextFragment(pos, levelDetails) {
    const fragments = levelDetails.fragments;
    const fragLen = fragments.length;
    if (!fragLen) {
     return null;
    }

    // find fragment index, contiguous with end of buffer position
    const { config } = this;
    const start = fragments[0].start;
    const canLoadParts = config.lowLatencyMode && !!levelDetails.partList;
    let frag = null;
    if (levelDetails.live) {
     const initialLiveManifestSize = config.initialLiveManifestSize;
     if (fragLen < initialLiveManifestSize) {
      this.warn(`Not enough fragments to start playback (have: ${fragLen}, need: ${initialLiveManifestSize})`);
      return null;
     }
     // The real fragment start times for a live stream are only known after the PTS range for that level is known.
     // In order to discover the range, we load the best matching fragment for that level and demux it.
     // Do not load using live logic if the starting frag is requested - we want to use getFragmentAtPosition() so that
     // we get the fragment matching that start time
     if ((!levelDetails.PTSKnown && !this.startFragRequested && this.startPosition === -1) || pos < start) {
      var _frag;
      if (canLoadParts && !this.loadingParts) {
       this.log(`LL-Part loading ON for initial live fragment`);
       this.loadingParts = true;
      }
      frag = this.getInitialLiveFragment(levelDetails);
      const mainStart = this.hls.startPosition;
      const liveSyncPosition = this.hls.liveSyncPosition;
      const startPosition = frag ? (mainStart !== -1 && mainStart >= start ? mainStart : liveSyncPosition) || frag.start : pos;
      this.log(`Setting startPosition to ${startPosition} to match start frag at live edge. mainStart: ${mainStart} liveSyncPosition: ${liveSyncPosition} frag.start: ${(_frag = frag) == null ? void 0 : _frag.start}`);
      this.startPosition = this.nextLoadPosition = startPosition;
     }
    } else if (pos <= start) {
     // VoD playlist: if loadPosition before start of playlist, load first fragment
     frag = fragments[0];
    }

    // If we haven't run into any special cases already, just load the fragment most closely matching the requested position
    if (!frag) {
     const end = this.loadingParts ? levelDetails.partEnd : levelDetails.fragmentEnd;
     frag = this.getFragmentAtPosition(pos, end, levelDetails);
    }
    let programFrag = this.filterReplacedPrimary(frag, levelDetails);
    if (!programFrag && frag) {
     const curSNIdx = frag.sn - levelDetails.startSN;
     programFrag = this.filterReplacedPrimary(fragments[curSNIdx + 1] || null, levelDetails);
    }
    return this.mapToInitFragWhenRequired(programFrag);
   }
   isLoopLoading(frag, targetBufferTime) {
    const trackerState = this.fragmentTracker.getState(frag);
    return (trackerState === FragmentState.OK || (trackerState === FragmentState.PARTIAL && !!frag.gap)) && this.nextLoadPosition > targetBufferTime;
   }
   getNextFragmentLoopLoading(frag, levelDetails, bufferInfo, playlistType, maxBufLen) {
    let nextFragment = null;
    if (frag.gap) {
     nextFragment = this.getNextFragment(this.nextLoadPosition, levelDetails);
     if (nextFragment && !nextFragment.gap && bufferInfo.nextStart) {
      // Media buffered after GAP tags should not make the next buffer timerange exceed forward buffer length
      const nextbufferInfo = this.getFwdBufferInfoAtPos(this.mediaBuffer ? this.mediaBuffer : this.media, bufferInfo.nextStart, playlistType, 0);
      if (nextbufferInfo !== null && bufferInfo.len + nextbufferInfo.len >= maxBufLen) {
       // Returning here might result in not finding an audio and video candiate to skip to
       const sn = nextFragment.sn;
       if (this.loopSn !== sn) {
        this.log(`buffer full after gaps in "${playlistType}" playlist starting at sn: ${sn}`);
        this.loopSn = sn;
       }
       return null;
      }
     }
    }
    this.loopSn = undefined;
    return nextFragment;
   }
   get primaryPrefetch() {
    if (interstitialsEnabled(this.config)) {
     var _this$hls$interstitia;
     const playingInterstitial = (_this$hls$interstitia = this.hls.interstitialsManager) == null || (_this$hls$interstitia = _this$hls$interstitia.playingItem) == null ? void 0 : _this$hls$interstitia.event;
     if (playingInterstitial) {
      return true;
     }
    }
    return false;
   }
   filterReplacedPrimary(frag, details) {
    if (!frag) {
     return frag;
    }
    if (interstitialsEnabled(this.config) && frag.type !== PlaylistLevelType.SUBTITLE) {
     // Do not load fragments outside the buffering schedule segment
     const interstitials = this.hls.interstitialsManager;
     const bufferingItem = interstitials == null ? void 0 : interstitials.bufferingItem;
     if (bufferingItem) {
      const bufferingInterstitial = bufferingItem.event;
      if (bufferingInterstitial) {
       // Do not stream fragments while buffering Interstitial Events (except for overlap at the start)
       if (bufferingInterstitial.appendInPlace || Math.abs(frag.start - bufferingItem.start) > 1 || bufferingItem.start === 0) {
        return null;
       }
      } else {
       // Limit fragment loading to media in schedule item
       if (frag.end <= bufferingItem.start && (details == null ? void 0 : details.live) === false) {
        // fragment ends by schedule item start
        // this.fragmentTracker.fragBuffered(frag, true);
        return null;
       }
       if (frag.start > bufferingItem.end && bufferingItem.nextEvent) {
        // fragment is past schedule item end
        // allow some overflow when not appending in place to prevent stalls
        if (bufferingItem.nextEvent.appendInPlace || frag.start - bufferingItem.end > 1) {
         return null;
        }
       }
      }
     }
     // Skip loading of fragments that overlap completely with appendInPlace interstitials
     const playerQueue = interstitials == null ? void 0 : interstitials.playerQueue;
     if (playerQueue) {
      for (let i = playerQueue.length; i--; ) {
       const interstitial = playerQueue[i].interstitial;
       if (interstitial.appendInPlace && frag.start >= interstitial.startTime && frag.end <= interstitial.resumeTime) {
        return null;
       }
      }
     }
    }
    return frag;
   }
   mapToInitFragWhenRequired(frag) {
    // If an initSegment is present, it must be buffered first
    if (frag != null && frag.initSegment && !frag.initSegment.data && !this.bitrateTest) {
     return frag.initSegment;
    }
    return frag;
   }
   getNextPart(partList, frag, targetBufferTime) {
    let nextPart = -1;
    let contiguous = false;
    let independentAttrOmitted = true;
    for (let i = 0, len = partList.length; i < len; i++) {
     const part = partList[i];
     independentAttrOmitted = independentAttrOmitted && !part.independent;
     if (nextPart > -1 && targetBufferTime < part.start) {
      break;
     }
     const loaded = part.loaded;
     if (loaded) {
      nextPart = -1;
     } else if (contiguous || ((part.independent || independentAttrOmitted) && part.fragment === frag)) {
      if (part.fragment !== frag) {
       this.warn(`Need buffer at ${targetBufferTime} but next unloaded part starts at ${part.start}`);
      }
      nextPart = i;
     }
     contiguous = loaded;
    }
    return nextPart;
   }
   loadedEndOfParts(partList, targetBufferTime) {
    let part;
    for (let i = partList.length; i--; ) {
     part = partList[i];
     if (!part.loaded) {
      return false;
     }
     if (targetBufferTime > part.start) {
      return true;
     }
    }
    return false;
   }

   /*
   This method is used find the best matching first fragment for a live playlist. This fragment is used to calculate the
   "sliding" of the playlist, which is its offset from the start of playback. After sliding we can compute the real
   start and end times for each fragment in the playlist (after which this method will not need to be called).
  */
   getInitialLiveFragment(levelDetails) {
    const fragments = levelDetails.fragments;
    const fragPrevious = this.fragPrevious;
    let frag = null;
    if (fragPrevious) {
     if (levelDetails.hasProgramDateTime) {
      // Prefer using PDT, because it can be accurate enough to choose the correct fragment without knowing the level sliding
      this.log(`Live playlist, switching playlist, load frag with same PDT: ${fragPrevious.programDateTime}`);
      frag = findFragmentByPDT(fragments, fragPrevious.endProgramDateTime, this.config.maxFragLookUpTolerance);
     }
     if (!frag) {
      // SN does not need to be accurate between renditions, but depending on the packaging it may be so.
      const targetSN = fragPrevious.sn + 1;
      if (targetSN >= levelDetails.startSN && targetSN <= levelDetails.endSN) {
       const fragNext = fragments[targetSN - levelDetails.startSN];
       // Ensure that we're staying within the continuity range, since PTS resets upon a new range
       if (fragPrevious.cc === fragNext.cc) {
        frag = fragNext;
        this.log(`Live playlist, switching playlist, load frag with next SN: ${frag.sn}`);
       }
      }
      // It's important to stay within the continuity range if available; otherwise the fragments in the playlist
      // will have the wrong start times
      if (!frag) {
       frag = findNearestWithCC(levelDetails, fragPrevious.cc, fragPrevious.end);
       if (frag) {
        this.log(`Live playlist, switching playlist, load frag with same CC: ${frag.sn}`);
       }
      }
     }
    } else {
     // Find a new start fragment when fragPrevious is null
     const liveStart = this.hls.liveSyncPosition;
     if (liveStart !== null) {
      frag = this.getFragmentAtPosition(liveStart, this.bitrateTest ? levelDetails.fragmentEnd : levelDetails.edge, levelDetails);
     }
    }
    return frag;
   }

   /*
  This method finds the best matching fragment given the provided position.
   */
   getFragmentAtPosition(bufferEnd, end, levelDetails) {
    const { config } = this;
    let { fragPrevious } = this;
    let { fragments, endSN } = levelDetails;
    const { fragmentHint } = levelDetails;
    const { maxFragLookUpTolerance } = config;
    const partList = levelDetails.partList;
    const loadingParts = !!(this.loadingParts && partList != null && partList.length && fragmentHint);
    if (loadingParts && !this.bitrateTest && partList[partList.length - 1].fragment.sn === fragmentHint.sn) {
     // Include incomplete fragment with parts at end
     fragments = fragments.concat(fragmentHint);
     endSN = fragmentHint.sn;
    }
    let frag;
    if (bufferEnd < end) {
     var _this$media3;
     const backwardSeek = bufferEnd < this.lastCurrentTime;
     const lookupTolerance = backwardSeek || bufferEnd > end - maxFragLookUpTolerance || ((_this$media3 = this.media) != null && _this$media3.paused) || !this.startFragRequested ? 0 : maxFragLookUpTolerance;
     // Remove the tolerance if it would put the bufferEnd past the actual end of stream
     // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)
     frag = findFragmentByPTS(fragPrevious, fragments, bufferEnd, lookupTolerance);
    } else {
     // reach end of playlist
     frag = fragments[fragments.length - 1];
    }
    if (frag) {
     const curSNIdx = frag.sn - levelDetails.startSN;
     // Move fragPrevious forward to support forcing the next fragment to load
     // when the buffer catches up to a previously buffered range.
     const fragState = this.fragmentTracker.getState(frag);
     if (fragState === FragmentState.OK || (fragState === FragmentState.PARTIAL && frag.gap)) {
      fragPrevious = frag;
     }
     if (fragPrevious && frag.sn === fragPrevious.sn && (!loadingParts || partList[0].fragment.sn > frag.sn || !levelDetails.live)) {
      // Force the next fragment to load if the previous one was already selected. This can occasionally happen with
      // non-uniform fragment durations
      const sameLevel = frag.level === fragPrevious.level;
      if (sameLevel) {
       const nextFrag = fragments[curSNIdx + 1];
       if (frag.sn < endSN && this.fragmentTracker.getState(nextFrag) !== FragmentState.OK) {
        frag = nextFrag;
       } else {
        frag = null;
       }
      }
     }
    }
    return frag;
   }
   alignPlaylists(details, previousDetails, switchDetails) {
    // TODO: If not for `shouldAlignOnDiscontinuities` requiring fragPrevious.cc,
    //  this could all go in level-helper mergeDetails()
    const length = details.fragments.length;
    if (!length) {
     this.warn(`No fragments in live playlist`);
     return 0;
    }
    const slidingStart = details.fragmentStart;
    const firstLevelLoad = !previousDetails;
    const aligned = details.alignedSliding && isFiniteNumber(slidingStart);
    if (firstLevelLoad || (!aligned && !slidingStart)) {
     alignStream(switchDetails, details);
     const alignedSlidingStart = details.fragmentStart;
     this.log(`Live playlist sliding: ${alignedSlidingStart.toFixed(2)} start-sn: ${previousDetails ? previousDetails.startSN : 'na'}->${details.startSN} fragments: ${length}`);
     return alignedSlidingStart;
    }
    return slidingStart;
   }
   waitForCdnTuneIn(details) {
    // Wait for Low-Latency CDN Tune-in to get an updated playlist
    const advancePartLimit = 3;
    return details.live && details.canBlockReload && details.partTarget && details.tuneInGoal > Math.max(details.partHoldBack, details.partTarget * advancePartLimit);
   }
   setStartPosition(details, sliding) {
    // compute start position if set to -1. use it straight away if value is defined
    let startPosition = this.startPosition;
    if (startPosition < sliding) {
     startPosition = -1;
    }
    const timelineOffset = this.timelineOffset;
    if (startPosition === -1) {
     // Use Playlist EXT-X-START:TIME-OFFSET when set
     // Prioritize Multivariant Playlist offset so that main, audio, and subtitle stream-controller start times match
     const offsetInMultivariantPlaylist = this.startTimeOffset !== null;
     const startTimeOffset = offsetInMultivariantPlaylist ? this.startTimeOffset : details.startTimeOffset;
     if (startTimeOffset !== null && isFiniteNumber(startTimeOffset)) {
      startPosition = sliding + startTimeOffset;
      if (startTimeOffset < 0) {
       startPosition += details.edge;
      }
      startPosition = Math.min(Math.max(sliding, startPosition), sliding + details.totalduration);
      this.log(`Setting startPosition to ${startPosition} for start time offset ${startTimeOffset} found in ${offsetInMultivariantPlaylist ? 'multivariant' : 'media'} playlist`);
      this.startPosition = startPosition;
     } else if (details.live) {
      // Leave this.startPosition at -1, so that we can use `getInitialLiveFragment` logic when startPosition has
      // not been specified via the config or an as an argument to startLoad (#3736).
      startPosition = this.hls.liveSyncPosition || sliding;
      this.log(`Setting startPosition to -1 to start at live edge ${startPosition}`);
      this.startPosition = -1;
     } else {
      this.log(`setting startPosition to 0 by default`);
      this.startPosition = startPosition = 0;
     }
     this.lastCurrentTime = startPosition + timelineOffset;
    }
    this.nextLoadPosition = startPosition + timelineOffset;
   }
   getLoadPosition() {
    var _this$hls;
    const { media } = this;
    // if we have not yet loaded any fragment, start loading from start position
    let pos = 0;
    if ((_this$hls = this.hls) != null && _this$hls.hasEnoughToStart && media) {
     pos = media.currentTime;
    } else if (this.nextLoadPosition >= 0) {
     pos = this.nextLoadPosition;
    }
    return pos;
   }
   handleFragLoadAborted(frag, part) {
    if (this.transmuxer && frag.type === this.playlistType && isMediaFragment(frag) && frag.stats.aborted) {
     this.log(`Fragment ${frag.sn}${part ? ' part ' + part.index : ''} of ${this.playlistLabel()} ${frag.level} was aborted`);
     this.resetFragmentLoading(frag);
    }
   }
   resetFragmentLoading(frag) {
    if (!this.fragCurrent || (!this.fragContextChanged(frag) && this.state !== State.FRAG_LOADING_WAITING_RETRY)) {
     this.state = State.IDLE;
    }
   }
   onFragmentOrKeyLoadError(filterType, data) {
    var _data$response;
    if (data.chunkMeta && !data.frag) {
     const context = this.getCurrentContext(data.chunkMeta);
     if (context) {
      data.frag = context.frag;
     }
    }
    const frag = data.frag;
    // Handle frag error related to caller's filterType
    if (!frag || frag.type !== filterType || !this.levels) {
     return;
    }
    if (this.fragContextChanged(frag)) {
     var _this$fragCurrent;
     this.warn(`Frag load error must match current frag to retry ${frag.url} > ${(_this$fragCurrent = this.fragCurrent) == null ? void 0 : _this$fragCurrent.url}`);
     return;
    }
    const gapTagEncountered = data.details === ErrorDetails.FRAG_GAP;
    if (gapTagEncountered) {
     this.fragmentTracker.fragBuffered(frag, true);
    }
    // keep retrying until the limit will be reached
    const errorAction = data.errorAction;
    const { action, flags, retryCount = 0, retryConfig } = errorAction || {};
    const couldRetry = !!errorAction && !!retryConfig;
    const retry = couldRetry && action === NetworkErrorAction.RetryRequest;
    const noAlternate = couldRetry && !errorAction.resolved && flags === ErrorActionFlags.MoveAllAlternatesMatchingHost;
    const httpStatus = ((_data$response = data.response) == null ? void 0 : _data$response.code) || 0;
    if (!retry && noAlternate && isMediaFragment(frag) && !frag.endList && httpStatus !== 0) {
     this.resetFragmentErrors(filterType);
     this.treatAsGap(frag);
     errorAction.resolved = true;
    } else if ((retry || noAlternate) && retryCount < retryConfig.maxNumRetry) {
     this.resetStartWhenNotLoaded(this.levelLastLoaded);
     const delay = getRetryDelay(retryConfig, retryCount);
     this.warn(`Fragment ${frag.sn} of ${filterType} ${frag.level} errored with ${data.details}, retrying loading ${retryCount + 1}/${retryConfig.maxNumRetry} in ${delay}ms`);
     errorAction.resolved = true;
     this.retryDate = self.performance.now() + delay;
     this.state = State.FRAG_LOADING_WAITING_RETRY;
    } else if (retryConfig && errorAction) {
     this.resetFragmentErrors(filterType);
     if (retryCount < retryConfig.maxNumRetry) {
      // Network retry is skipped when level switch is preferred
      if (!gapTagEncountered && action !== NetworkErrorAction.RemoveAlternatePermanently) {
       errorAction.resolved = true;
      }
     } else {
      this.warn(`${data.details} reached or exceeded max retry (${retryCount})`);
      return;
     }
    } else if (action === NetworkErrorAction.SendAlternateToPenaltyBox) {
     this.state = State.WAITING_LEVEL;
    } else {
     this.state = State.ERROR;
    }
    // Perform next async tick sooner to speed up error action resolution
    this.tickImmediate();
   }
   reduceLengthAndFlushBuffer(data) {
    // if in appending state
    if (this.state === State.PARSING || this.state === State.PARSED) {
     const frag = data.frag;
     const playlistType = data.parent;
     const bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, playlistType);
     // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end
     // reduce max buf len if current position is buffered
     const buffered = bufferedInfo && bufferedInfo.len > 0.5;
     if (buffered) {
      this.reduceMaxBufferLength(bufferedInfo.len, (frag == null ? void 0 : frag.duration) || 10);
     }
     const flushBuffer = !buffered;
     if (flushBuffer) {
      // current position is not buffered, but browser is still complaining about buffer full error
      // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708
      // in that case flush the whole audio buffer to recover
      this.warn(`Buffer full error while media.currentTime (${this.getLoadPosition()}) is not buffered, flush ${playlistType} buffer`);
     }
     if (frag) {
      this.fragmentTracker.removeFragment(frag);
      this.nextLoadPosition = frag.start;
     }
     this.resetLoadingState();
     return flushBuffer;
    }
    return false;
   }
   resetFragmentErrors(filterType) {
    if (filterType === PlaylistLevelType.AUDIO) {
     // Reset current fragment since audio track audio is essential and may not have a fail-over track
     this.fragCurrent = null;
    }
    // Fragment errors that result in a level switch or redundant fail-over
    // should reset the stream controller state to idle
    if (!this.hls.hasEnoughToStart) {
     this.startFragRequested = false;
    }
    if (this.state !== State.STOPPED) {
     this.state = State.IDLE;
    }
   }
   afterBufferFlushed(media, bufferType, playlistType) {
    if (!media) {
     return;
    }
    // After successful buffer flushing, filter flushed fragments from bufferedFrags use mediaBuffered instead of media
    // (so that we will check against video.buffered ranges in case of alt audio track)
    const bufferedTimeRanges = BufferHelper.getBuffered(media);
    this.fragmentTracker.detectEvictedFragments(bufferType, bufferedTimeRanges, playlistType);
    if (this.state === State.ENDED) {
     this.resetLoadingState();
    }
   }
   resetLoadingState() {
    this.log('Reset loading state');
    this.fragCurrent = null;
    this.fragPrevious = null;
    if (this.state !== State.STOPPED) {
     this.state = State.IDLE;
    }
   }
   resetStartWhenNotLoaded(level) {
    // if loadedmetadata is not set, it means that first frag request failed
    // in that case, reset startFragRequested flag
    if (!this.hls.hasEnoughToStart) {
     this.startFragRequested = false;
     const details = level ? level.details : null;
     if (details != null && details.live) {
      // Update the start position and return to IDLE to recover live start
      this.log(`resetting startPosition for live start`);
      this.startPosition = -1;
      this.setStartPosition(details, details.fragmentStart);
      this.resetLoadingState();
     } else {
      this.nextLoadPosition = this.startPosition;
     }
    }
   }
   resetWhenMissingContext(chunkMeta) {
    this.warn(`The loading context changed while buffering fragment ${chunkMeta.sn} of ${this.playlistLabel()} ${chunkMeta.level}. This chunk will not be buffered.`);
    this.removeUnbufferedFrags();
    this.resetStartWhenNotLoaded(this.levelLastLoaded);
    this.resetLoadingState();
   }
   removeUnbufferedFrags(start = 0) {
    this.fragmentTracker.removeFragmentsInRange(start, Infinity, this.playlistType, false, true);
   }
   updateLevelTiming(frag, part, level, partial) {
    const details = level.details;
    if (!details) {
     this.warn('level.details undefined');
     return;
    }
    const parsed = Object.keys(frag.elementaryStreams).reduce((result, type) => {
     const info = frag.elementaryStreams[type];
     if (info) {
      const parsedDuration = info.endPTS - info.startPTS;
      if (parsedDuration <= 0) {
       // Destroy the transmuxer after it's next time offset failed to advance because duration was <= 0.
       // The new transmuxer will be configured with a time offset matching the next fragment start,
       // preventing the timeline from shifting.
       this.warn(`Could not parse fragment ${frag.sn} ${type} duration reliably (${parsedDuration})`);
       return result || false;
      }
      const drift = partial ? 0 : updateFragPTSDTS(details, frag, info.startPTS, info.endPTS, info.startDTS, info.endDTS, this);
      this.hls.trigger(Events.LEVEL_PTS_UPDATED, {
       details,
       level,
       drift,
       type,
       frag,
       start: info.startPTS,
       end: info.endPTS,
      });
      return true;
     }
     return result;
    }, false);
    if (!parsed) {
     var _this$transmuxer;
     if (level.fragmentError === 0) {
      // Mark and track the odd empty segment as a gap to avoid reloading
      this.treatAsGap(frag, level);
     }
     if (((_this$transmuxer = this.transmuxer) == null ? void 0 : _this$transmuxer.error) === null) {
      const error = new Error(`Found no media in fragment ${frag.sn} of ${this.playlistLabel()} ${frag.level} resetting transmuxer to fallback to playlist timing`);
      this.warn(error.message);
      this.hls.trigger(Events.ERROR, {
       type: ErrorTypes.MEDIA_ERROR,
       details: ErrorDetails.FRAG_PARSING_ERROR,
       fatal: false,
       error,
       frag,
       reason: `Found no media in msn ${frag.sn} of ${this.playlistLabel()} "${level.url}"`,
      });
      if (!this.hls) {
       return;
      }
      this.resetTransmuxer();
     }
     // For this error fallthrough. Marking parsed will allow advancing to next fragment.
    }
    this.state = State.PARSED;
    this.log(`Parsed ${frag.type} sn: ${frag.sn}${part ? ' part: ' + part.index : ''} of ${this.fragInfo(frag, false, part)})`);
    this.hls.trigger(Events.FRAG_PARSED, {
     frag,
     part,
    });
   }
   playlistLabel() {
    return this.playlistType === PlaylistLevelType.MAIN ? 'level' : 'track';
   }
   fragInfo(frag, pts = true, part) {
    var _ref, _ref2;
    return `${this.playlistLabel()} ${frag.level} (${part ? 'part' : 'frag'}:[${((_ref = pts && !part ? frag.startPTS : (part || frag).start) != null ? _ref : NaN).toFixed(3)}-${((_ref2 = pts && !part ? frag.endPTS : (part || frag).end) != null ? _ref2 : NaN).toFixed(3)}]${part && frag.type === 'main' ? 'INDEPENDENT=' + (part.independent ? 'YES' : 'NO') : ''}`;
   }
   treatAsGap(frag, level) {
    if (level) {
     level.fragmentError++;
    }
    frag.gap = true;
    this.fragmentTracker.removeFragment(frag);
    this.fragmentTracker.fragBuffered(frag, true);
   }
   resetTransmuxer() {
    var _this$transmuxer2;
    (_this$transmuxer2 = this.transmuxer) == null || _this$transmuxer2.reset();
   }
   recoverWorkerError(data) {
    if (data.event === 'demuxerWorker') {
     this.fragmentTracker.removeAllFragments();
     if (this.transmuxer) {
      this.transmuxer.destroy();
      this.transmuxer = null;
     }
     this.resetStartWhenNotLoaded(this.levelLastLoaded);
     this.resetLoadingState();
    }
   }
   set state(nextState) {
    const previousState = this._state;
    if (previousState !== nextState) {
     this._state = nextState;
     this.log(`${previousState}->${nextState}`);
    }
   }
   get state() {
    return this._state;
   }
  }
  function interstitialsEnabled(config) {
   return !!config.interstitialsController && config.enableInterstitialPlayback !== false;
  }

  class ChunkCache {
   constructor() {
    this.chunks = [];
    this.dataLength = 0;
   }
   push(chunk) {
    this.chunks.push(chunk);
    this.dataLength += chunk.length;
   }
   flush() {
    const { chunks, dataLength } = this;
    let result;
    if (!chunks.length) {
     return new Uint8Array(0);
    } else if (chunks.length === 1) {
     result = chunks[0];
    } else {
     result = concatUint8Arrays(chunks, dataLength);
    }
    this.reset();
    return result;
   }
   reset() {
    this.chunks.length = 0;
    this.dataLength = 0;
   }
  }
  function concatUint8Arrays(chunks, dataLength) {
   const result = new Uint8Array(dataLength);
   let offset = 0;
   for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];
    result.set(chunk, offset);
    offset += chunk.length;
   }
   return result;
  }

  var eventemitter3 = { exports: {} };

  var hasRequiredEventemitter3;

  function requireEventemitter3() {
   if (hasRequiredEventemitter3) return eventemitter3.exports;
   hasRequiredEventemitter3 = 1;
   (function (module) {
    var has = Object.prototype.hasOwnProperty,
     prefix = '~';

    /**
     * Constructor to create a storage for our `EE` objects.
     * An `Events` instance is a plain object whose properties are event names.
     *
     * @constructor
     * @private
     */
    function Events() {}

    //
    // We try to not inherit from `Object.prototype`. In some engines creating an
    // instance in this way is faster than calling `Object.create(null)` directly.
    // If `Object.create(null)` is not supported we prefix the event names with a
    // character to make sure that the built-in object properties are not
    // overridden or used as an attack vector.
    //
    if (Object.create) {
     Events.prototype = Object.create(null);

     //
     // This hack is needed because the `__proto__` property is still inherited in
     // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.
     //
     if (!new Events().__proto__) prefix = false;
    }

    /**
     * Representation of a single event listener.
     *
     * @param {Function} fn The listener function.
     * @param {*} context The context to invoke the listener with.
     * @param {Boolean} [once=false] Specify if the listener is a one-time listener.
     * @constructor
     * @private
     */
    function EE(fn, context, once) {
     this.fn = fn;
     this.context = context;
     this.once = once || false;
    }

    /**
     * Add a listener for a given event.
     *
     * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
     * @param {(String|Symbol)} event The event name.
     * @param {Function} fn The listener function.
     * @param {*} context The context to invoke the listener with.
     * @param {Boolean} once Specify if the listener is a one-time listener.
     * @returns {EventEmitter}
     * @private
     */
    function addListener(emitter, event, fn, context, once) {
     if (typeof fn !== 'function') {
      throw new TypeError('The listener must be a function');
     }

     var listener = new EE(fn, context || emitter, once),
      evt = prefix ? prefix + event : event;

     if (!emitter._events[evt]) (emitter._events[evt] = listener), emitter._eventsCount++;
     else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);
     else emitter._events[evt] = [emitter._events[evt], listener];

     return emitter;
    }

    /**
     * Clear event by name.
     *
     * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
     * @param {(String|Symbol)} evt The Event name.
     * @private
     */
    function clearEvent(emitter, evt) {
     if (--emitter._eventsCount === 0) emitter._events = new Events();
     else delete emitter._events[evt];
    }

    /**
     * Minimal `EventEmitter` interface that is molded against the Node.js
     * `EventEmitter` interface.
     *
     * @constructor
     * @public
     */
    function EventEmitter() {
     this._events = new Events();
     this._eventsCount = 0;
    }

    /**
     * Return an array listing the events for which the emitter has registered
     * listeners.
     *
     * @returns {Array}
     * @public
     */
    EventEmitter.prototype.eventNames = function eventNames() {
     var names = [],
      events,
      name;

     if (this._eventsCount === 0) return names;

     for (name in (events = this._events)) {
      if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);
     }

     if (Object.getOwnPropertySymbols) {
      return names.concat(Object.getOwnPropertySymbols(events));
     }

     return names;
    };

    /**
     * Return the listeners registered for a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @returns {Array} The registered listeners.
     * @public
     */
    EventEmitter.prototype.listeners = function listeners(event) {
     var evt = prefix ? prefix + event : event,
      handlers = this._events[evt];

     if (!handlers) return [];
     if (handlers.fn) return [handlers.fn];

     for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {
      ee[i] = handlers[i].fn;
     }

     return ee;
    };

    /**
     * Return the number of listeners listening to a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @returns {Number} The number of listeners.
     * @public
     */
    EventEmitter.prototype.listenerCount = function listenerCount(event) {
     var evt = prefix ? prefix + event : event,
      listeners = this._events[evt];

     if (!listeners) return 0;
     if (listeners.fn) return 1;
     return listeners.length;
    };

    /**
     * Calls each of the listeners registered for a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @returns {Boolean} `true` if the event had listeners, else `false`.
     * @public
     */
    EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {
     var evt = prefix ? prefix + event : event;

     if (!this._events[evt]) return false;

     var listeners = this._events[evt],
      len = arguments.length,
      args,
      i;

     if (listeners.fn) {
      if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);

      switch (len) {
       case 1:
        return listeners.fn.call(listeners.context), true;
       case 2:
        return listeners.fn.call(listeners.context, a1), true;
       case 3:
        return listeners.fn.call(listeners.context, a1, a2), true;
       case 4:
        return listeners.fn.call(listeners.context, a1, a2, a3), true;
       case 5:
        return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;
       case 6:
        return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;
      }

      for (i = 1, args = new Array(len - 1); i < len; i++) {
       args[i - 1] = arguments[i];
      }

      listeners.fn.apply(listeners.context, args);
     } else {
      var length = listeners.length,
       j;

      for (i = 0; i < length; i++) {
       if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);

       switch (len) {
        case 1:
         listeners[i].fn.call(listeners[i].context);
         break;
        case 2:
         listeners[i].fn.call(listeners[i].context, a1);
         break;
        case 3:
         listeners[i].fn.call(listeners[i].context, a1, a2);
         break;
        case 4:
         listeners[i].fn.call(listeners[i].context, a1, a2, a3);
         break;
        default:
         if (!args)
          for (j = 1, args = new Array(len - 1); j < len; j++) {
           args[j - 1] = arguments[j];
          }

         listeners[i].fn.apply(listeners[i].context, args);
       }
      }
     }

     return true;
    };

    /**
     * Add a listener for a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @param {Function} fn The listener function.
     * @param {*} [context=this] The context to invoke the listener with.
     * @returns {EventEmitter} `this`.
     * @public
     */
    EventEmitter.prototype.on = function on(event, fn, context) {
     return addListener(this, event, fn, context, false);
    };

    /**
     * Add a one-time listener for a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @param {Function} fn The listener function.
     * @param {*} [context=this] The context to invoke the listener with.
     * @returns {EventEmitter} `this`.
     * @public
     */
    EventEmitter.prototype.once = function once(event, fn, context) {
     return addListener(this, event, fn, context, true);
    };

    /**
     * Remove the listeners of a given event.
     *
     * @param {(String|Symbol)} event The event name.
     * @param {Function} fn Only remove the listeners that match this function.
     * @param {*} context Only remove the listeners that have this context.
     * @param {Boolean} once Only remove one-time listeners.
     * @returns {EventEmitter} `this`.
     * @public
     */
    EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {
     var evt = prefix ? prefix + event : event;

     if (!this._events[evt]) return this;
     if (!fn) {
      clearEvent(this, evt);
      return this;
     }

     var listeners = this._events[evt];

     if (listeners.fn) {
      if (listeners.fn === fn && (!once || listeners.once) && (!context || listeners.context === context)) {
       clearEvent(this, evt);
      }
     } else {
      for (var i = 0, events = [], length = listeners.length; i < length; i++) {
       if (listeners[i].fn !== fn || (once && !listeners[i].once) || (context && listeners[i].context !== context)) {
        events.push(listeners[i]);
       }
      }

      //
      // Reset the array, or remove it completely if we have no more listeners.
      //
      if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;
      else clearEvent(this, evt);
     }

     return this;
    };

    /**
     * Remove all listeners, or those of the specified event.
     *
     * @param {(String|Symbol)} [event] The event name.
     * @returns {EventEmitter} `this`.
     * @public
     */
    EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {
     var evt;

     if (event) {
      evt = prefix ? prefix + event : event;
      if (this._events[evt]) clearEvent(this, evt);
     } else {
      this._events = new Events();
      this._eventsCount = 0;
     }

     return this;
    };

    //
    // Alias methods names because people roll like that.
    //
    EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
    EventEmitter.prototype.addListener = EventEmitter.prototype.on;

    //
    // Expose the prefix.
    //
    EventEmitter.prefixed = prefix;

    //
    // Allow `EventEmitter` to be imported as module namespace.
    //
    EventEmitter.EventEmitter = EventEmitter;

    //
    // Expose the module.
    //
    {
     module.exports = EventEmitter;
    }
   })(eventemitter3);
   return eventemitter3.exports;
  }

  var eventemitter3Exports = requireEventemitter3();
  var EventEmitter = /*@__PURE__*/ getDefaultExportFromCjs(eventemitter3Exports);

  const version = '1.6.10';

  // ensure the worker ends up in the bundle
  // If the worker should not be included this gets aliased to empty.js
  const workerStore = {};
  function hasUMDWorker() {
   return typeof __HLS_WORKER_BUNDLE__ === 'function';
  }
  function injectWorker() {
   const workerContext = workerStore[version];
   if (workerContext) {
    workerContext.clientCount++;
    return workerContext;
   }
   const blob = new self.Blob([`var exports={};var module={exports:exports};function define(f){f()};define.amd=true;(${__HLS_WORKER_BUNDLE__.toString()})(true);`], {
    type: 'text/javascript',
   });
   const objectURL = self.URL.createObjectURL(blob);
   const worker = new self.Worker(objectURL);
   const result = {
    worker,
    objectURL,
    clientCount: 1,
   };
   workerStore[version] = result;
   return result;
  }
  function loadWorker(path) {
   const workerContext = workerStore[path];
   if (workerContext) {
    workerContext.clientCount++;
    return workerContext;
   }
   const scriptURL = new self.URL(path, self.location.href).href;
   const worker = new self.Worker(scriptURL);
   const result = {
    worker,
    scriptURL,
    clientCount: 1,
   };
   workerStore[path] = result;
   return result;
  }
  function removeWorkerFromStore(path) {
   const workerContext = workerStore[path || version];
   if (workerContext) {
    const clientCount = workerContext.clientCount--;
    if (clientCount === 1) {
     const { worker, objectURL } = workerContext;
     delete workerStore[path || version];
     if (objectURL) {
      // revoke the Object URL that was used to create transmuxer worker, so as not to leak it
      self.URL.revokeObjectURL(objectURL);
     }
     worker.terminate();
    }
   }
  }

  /**
   * Returns true if an ID3 footer can be found at offset in data
   *
   * @param data - The data to search in
   * @param offset - The offset at which to start searching
   *
   * @returns `true` if an ID3 footer is found
   *
   * @internal
   *
   * @group ID3
   */
  function isId3Footer(data, offset) {
   /*
    * The footer is a copy of the header, but with a different identifier
    */
   if (offset + 10 <= data.length) {
    // look for '3DI' identifier
    if (data[offset] === 0x33 && data[offset + 1] === 0x44 && data[offset + 2] === 0x49) {
     // check version is within range
     if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {
      // check size is within range
      if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {
       return true;
      }
     }
    }
   }
   return false;
  }

  /**
   * Returns true if an ID3 header can be found at offset in data
   *
   * @param data - The data to search in
   * @param offset - The offset at which to start searching
   *
   * @returns `true` if an ID3 header is found
   *
   * @internal
   *
   * @group ID3
   */
  function isId3Header(data, offset) {
   /*
    * http://id3.org/id3v2.3.0
    * [0]     = 'I'
    * [1]     = 'D'
    * [2]     = '3'
    * [3,4]   = {Version}
    * [5]     = {Flags}
    * [6-9]   = {ID3 Size}
    *
    * An ID3v2 tag can be detected with the following pattern:
    *  $49 44 33 yy yy xx zz zz zz zz
    * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80
    */
   if (offset + 10 <= data.length) {
    // look for 'ID3' identifier
    if (data[offset] === 0x49 && data[offset + 1] === 0x44 && data[offset + 2] === 0x33) {
     // check version is within range
     if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {
      // check size is within range
      if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {
       return true;
      }
     }
    }
   }
   return false;
  }

  /**
   * Read ID3 size
   *
   * @param data - The data to read from
   * @param offset - The offset at which to start reading
   *
   * @returns The size
   *
   * @internal
   *
   * @group ID3
   */
  function readId3Size(data, offset) {
   let size = 0;
   size = (data[offset] & 0x7f) << 21;
   size |= (data[offset + 1] & 0x7f) << 14;
   size |= (data[offset + 2] & 0x7f) << 7;
   size |= data[offset + 3] & 0x7f;
   return size;
  }

  /**
   * Returns any adjacent ID3 tags found in data starting at offset, as one block of data
   *
   * @param data - The data to search in
   * @param offset - The offset at which to start searching
   *
   * @returns The block of data containing any ID3 tags found
   * or `undefined` if no header is found at the starting offset
   *
   * @internal
   *
   * @group ID3
   */
  function getId3Data(data, offset) {
   const front = offset;
   let length = 0;
   while (isId3Header(data, offset)) {
    // ID3 header is 10 bytes
    length += 10;
    const size = readId3Size(data, offset + 6);
    length += size;
    if (isId3Footer(data, offset + 10)) {
     // ID3 footer is 10 bytes
     length += 10;
    }
    offset += length;
   }
   if (length > 0) {
    return data.subarray(front, front + length);
   }
   return undefined;
  }

  function getAudioConfig(observer, data, offset, manifestCodec) {
   const adtsSamplingRates = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];
   const byte2 = data[offset + 2];
   const adtsSamplingIndex = (byte2 >> 2) & 0xf;
   if (adtsSamplingIndex > 12) {
    const error = new Error(`invalid ADTS sampling index:${adtsSamplingIndex}`);
    observer.emit(Events.ERROR, Events.ERROR, {
     type: ErrorTypes.MEDIA_ERROR,
     details: ErrorDetails.FRAG_PARSING_ERROR,
     fatal: true,
     error,
     reason: error.message,
    });
    return;
   }
   // MPEG-4 Audio Object Type (profile_ObjectType+1)
   const adtsObjectType = ((byte2 >> 6) & 0x3) + 1;
   const channelCount = ((data[offset + 3] >> 6) & 0x3) | ((byte2 & 1) << 2);
   const codec = 'mp4a.40.' + adtsObjectType;
   /* refer to http://wiki.multimedia.cx/index.php?title=MPEG-4_Audio#Audio_Specific_Config
      ISO/IEC 14496-3 - Table 1.13  Syntax of AudioSpecificConfig()
    Audio Profile / Audio Object Type
    0: Null
    1: AAC Main
    2: AAC LC (Low Complexity)
    3: AAC SSR (Scalable Sample Rate)
    4: AAC LTP (Long Term Prediction)
    5: SBR (Spectral Band Replication)
    6: AAC Scalable
   sampling freq
    0: 96000 Hz
    1: 88200 Hz
    2: 64000 Hz
    3: 48000 Hz
    4: 44100 Hz
    5: 32000 Hz
    6: 24000 Hz
    7: 22050 Hz
    8: 16000 Hz
    9: 12000 Hz
    10: 11025 Hz
    11: 8000 Hz
    12: 7350 Hz
    13: Reserved
    14: Reserved
    15: frequency is written explictly
    Channel Configurations
    These are the channel configurations:
    0: Defined in AOT Specifc Config
    1: 1 channel: front-center
    2: 2 channels: front-left, front-right
  */
   // audioObjectType = profile => profile, the MPEG-4 Audio Object Type minus 1
   const samplerate = adtsSamplingRates[adtsSamplingIndex];
   let aacSampleIndex = adtsSamplingIndex;
   if (adtsObjectType === 5 || adtsObjectType === 29) {
    // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies
    // there is a factor 2 between frame sample rate and output sample rate
    // multiply frequency by 2 (see table above, equivalent to substract 3)
    aacSampleIndex -= 3;
   }
   const config = [(adtsObjectType << 3) | ((aacSampleIndex & 0x0e) >> 1), ((aacSampleIndex & 0x01) << 7) | (channelCount << 3)];
   logger.log(`manifest codec:${manifestCodec}, parsed codec:${codec}, channels:${channelCount}, rate:${samplerate} (ADTS object type:${adtsObjectType} sampling index:${adtsSamplingIndex})`);
   return {
    config,
    samplerate,
    channelCount,
    codec,
    parsedCodec: codec,
    manifestCodec,
   };
  }
  function isHeaderPattern$1(data, offset) {
   return data[offset] === 0xff && (data[offset + 1] & 0xf6) === 0xf0;
  }
  function getHeaderLength(data, offset) {
   return data[offset + 1] & 0x01 ? 7 : 9;
  }
  function getFullFrameLength(data, offset) {
   return ((data[offset + 3] & 0x03) << 11) | (data[offset + 4] << 3) | ((data[offset + 5] & 0xe0) >>> 5);
  }
  function canGetFrameLength(data, offset) {
   return offset + 5 < data.length;
  }
  function isHeader$1(data, offset) {
   // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1
   // Layer bits (position 14 and 15) in header should be always 0 for ADTS
   // More info https://wiki.multimedia.cx/index.php?title=ADTS
   return offset + 1 < data.length && isHeaderPattern$1(data, offset);
  }
  function canParse$1(data, offset) {
   return canGetFrameLength(data, offset) && isHeaderPattern$1(data, offset) && getFullFrameLength(data, offset) <= data.length - offset;
  }
  function probe$1(data, offset) {
   // same as isHeader but we also check that ADTS frame follows last ADTS frame
   // or end of data is reached
   if (isHeader$1(data, offset)) {
    // ADTS header Length
    const headerLength = getHeaderLength(data, offset);
    if (offset + headerLength >= data.length) {
     return false;
    }
    // ADTS frame Length
    const frameLength = getFullFrameLength(data, offset);
    if (frameLength <= headerLength) {
     return false;
    }
    const newOffset = offset + frameLength;
    return newOffset === data.length || isHeader$1(data, newOffset);
   }
   return false;
  }
  function initTrackConfig(track, observer, data, offset, audioCodec) {
   if (!track.samplerate) {
    const config = getAudioConfig(observer, data, offset, audioCodec);
    if (!config) {
     return;
    }
    _extends(track, config);
   }
  }
  function getFrameDuration(samplerate) {
   return (1024 * 90000) / samplerate;
  }
  function parseFrameHeader(data, offset) {
   // The protection skip bit tells us if we have 2 bytes of CRC data at the end of the ADTS header
   const headerLength = getHeaderLength(data, offset);
   if (offset + headerLength <= data.length) {
    // retrieve frame size
    const frameLength = getFullFrameLength(data, offset) - headerLength;
    if (frameLength > 0) {
     // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}`);
     return {
      headerLength,
      frameLength,
     };
    }
   }
  }
  function appendFrame$2(track, data, offset, pts, frameIndex) {
   const frameDuration = getFrameDuration(track.samplerate);
   const stamp = pts + frameIndex * frameDuration;
   const header = parseFrameHeader(data, offset);
   let unit;
   if (header) {
    const { frameLength, headerLength } = header;
    const _length = headerLength + frameLength;
    const missing = Math.max(0, offset + _length - data.length);
    // logger.log(`AAC frame ${frameIndex}, pts:${stamp} length@offset/total: ${frameLength}@${offset+headerLength}/${data.byteLength} missing: ${missing}`);
    if (missing) {
     unit = new Uint8Array(_length - headerLength);
     unit.set(data.subarray(offset + headerLength, data.length), 0);
    } else {
     unit = data.subarray(offset + headerLength, offset + _length);
    }
    const _sample = {
     unit,
     pts: stamp,
    };
    if (!missing) {
     track.samples.push(_sample);
    }
    return {
     sample: _sample,
     length: _length,
     missing,
    };
   }
   // overflow incomplete header
   const length = data.length - offset;
   unit = new Uint8Array(length);
   unit.set(data.subarray(offset, data.length), 0);
   const sample = {
    unit,
    pts: stamp,
   };
   return {
    sample,
    length,
    missing: -1,
   };
  }

  /**
   * Checks if the given data contains an ID3 tag.
   *
   * @param data - The data to check
   * @param offset - The offset at which to start checking
   *
   * @returns `true` if an ID3 tag is found
   *
   * @group ID3
   *
   * @beta
   */
  function canParseId3(data, offset) {
   return isId3Header(data, offset) && readId3Size(data, offset + 6) + 10 <= data.length - offset;
  }

  function toArrayBuffer(view) {
   if (view instanceof ArrayBuffer) {
    return view;
   } else {
    if (view.byteOffset == 0 && view.byteLength == view.buffer.byteLength) {
     // This is a TypedArray over the whole buffer.
     return view.buffer;
    }
    // This is a 'view' on the buffer.  Create a new buffer that only contains
    // the data.  Note that since this isn't an ArrayBuffer, the 'new' call
    // will allocate a new buffer to hold the copy.
    return new Uint8Array(view).buffer;
   }
  }

  function toUint8(data, offset = 0, length = Infinity) {
   return view(data, offset, length, Uint8Array);
  }
  function view(data, offset, length, Type) {
   const buffer = unsafeGetArrayBuffer(data);
   let bytesPerElement = 1;
   if ('BYTES_PER_ELEMENT' in Type) {
    bytesPerElement = Type.BYTES_PER_ELEMENT;
   }
   // Absolute end of the |data| view within |buffer|.
   const dataOffset = isArrayBufferView(data) ? data.byteOffset : 0;
   const dataEnd = (dataOffset + data.byteLength) / bytesPerElement;
   // Absolute start of the result within |buffer|.
   const rawStart = (dataOffset + offset) / bytesPerElement;
   const start = Math.floor(Math.max(0, Math.min(rawStart, dataEnd)));
   // Absolute end of the result within |buffer|.
   const end = Math.floor(Math.min(start + Math.max(length, 0), dataEnd));
   return new Type(buffer, start, end - start);
  }
  function unsafeGetArrayBuffer(view) {
   if (view instanceof ArrayBuffer) {
    return view;
   } else {
    return view.buffer;
   }
  }
  function isArrayBufferView(obj) {
   return obj && obj.buffer instanceof ArrayBuffer && obj.byteLength !== undefined && obj.byteOffset !== undefined;
  }

  function decodeId3ImageFrame(frame) {
   const metadataFrame = {
    key: frame.type,
    description: '',
    data: '',
    mimeType: null,
    pictureType: null,
   };
   const utf8Encoding = 0x03;
   if (frame.size < 2) {
    return undefined;
   }
   if (frame.data[0] !== utf8Encoding) {
    console.log('Ignore frame with unrecognized character ' + 'encoding');
    return undefined;
   }
   const mimeTypeEndIndex = frame.data.subarray(1).indexOf(0);
   if (mimeTypeEndIndex === -1) {
    return undefined;
   }
   const mimeType = utf8ArrayToStr(toUint8(frame.data, 1, mimeTypeEndIndex));
   const pictureType = frame.data[2 + mimeTypeEndIndex];
   const descriptionEndIndex = frame.data.subarray(3 + mimeTypeEndIndex).indexOf(0);
   if (descriptionEndIndex === -1) {
    return undefined;
   }
   const description = utf8ArrayToStr(toUint8(frame.data, 3 + mimeTypeEndIndex, descriptionEndIndex));
   let data;
   if (mimeType === '-->') {
    data = utf8ArrayToStr(toUint8(frame.data, 4 + mimeTypeEndIndex + descriptionEndIndex));
   } else {
    data = toArrayBuffer(frame.data.subarray(4 + mimeTypeEndIndex + descriptionEndIndex));
   }
   metadataFrame.mimeType = mimeType;
   metadataFrame.pictureType = pictureType;
   metadataFrame.description = description;
   metadataFrame.data = data;
   return metadataFrame;
  }

  /**
   * Decode an ID3 PRIV frame.
   *
   * @param frame - the ID3 PRIV frame
   *
   * @returns The decoded ID3 PRIV frame
   *
   * @internal
   *
   * @group ID3
   */
  function decodeId3PrivFrame(frame) {
   /*
  Format: <text string>\0<binary data>
  */
   if (frame.size < 2) {
    return undefined;
   }
   const owner = utf8ArrayToStr(frame.data, true);
   const privateData = new Uint8Array(frame.data.subarray(owner.length + 1));
   return {
    key: frame.type,
    info: owner,
    data: privateData.buffer,
   };
  }

  /**
   * Decodes an ID3 text frame
   *
   * @param frame - the ID3 text frame
   *
   * @returns The decoded ID3 text frame
   *
   * @internal
   *
   * @group ID3
   */
  function decodeId3TextFrame(frame) {
   if (frame.size < 2) {
    return undefined;
   }
   if (frame.type === 'TXXX') {
    /*
    Format:
    [0]   = {Text Encoding}
    [1-?] = {Description}\0{Value}
    */
    let index = 1;
    const description = utf8ArrayToStr(frame.data.subarray(index), true);
    index += description.length + 1;
    const value = utf8ArrayToStr(frame.data.subarray(index));
    return {
     key: frame.type,
     info: description,
     data: value,
    };
   }
   /*
  Format:
  [0]   = {Text Encoding}
  [1-?] = {Value}
  */
   const text = utf8ArrayToStr(frame.data.subarray(1));
   return {
    key: frame.type,
    info: '',
    data: text,
   };
  }

  /**
   * Decode a URL frame
   *
   * @param frame - the ID3 URL frame
   *
   * @returns The decoded ID3 URL frame
   *
   * @internal
   *
   * @group ID3
   */
  function decodeId3UrlFrame(frame) {
   if (frame.type === 'WXXX') {
    /*
    Format:
    [0]   = {Text Encoding}
    [1-?] = {Description}\0{URL}
    */
    if (frame.size < 2) {
     return undefined;
    }
    let index = 1;
    const description = utf8ArrayToStr(frame.data.subarray(index), true);
    index += description.length + 1;
    const value = utf8ArrayToStr(frame.data.subarray(index));
    return {
     key: frame.type,
     info: description,
     data: value,
    };
   }
   /*
  Format:
  [0-?] = {URL}
  */
   const url = utf8ArrayToStr(frame.data);
   return {
    key: frame.type,
    info: '',
    data: url,
   };
  }

  /**
   * Decode an ID3 frame.
   *
   * @param frame - the ID3 frame
   *
   * @returns The decoded ID3 frame
   *
   * @internal
   *
   * @group ID3
   */
  function decodeId3Frame(frame) {
   if (frame.type === 'PRIV') {
    return decodeId3PrivFrame(frame);
   } else if (frame.type[0] === 'W') {
    return decodeId3UrlFrame(frame);
   } else if (frame.type === 'APIC') {
    return decodeId3ImageFrame(frame);
   }
   return decodeId3TextFrame(frame);
  }

  /**
   * Returns the data of an ID3 frame.
   *
   * @param data - The data to read from
   *
   * @returns The data of the ID3 frame
   *
   * @internal
   *
   * @group ID3
   */
  function getId3FrameData(data) {
   /*
  Frame ID       $xx xx xx xx (four characters)
  Size           $xx xx xx xx
  Flags          $xx xx
  */
   const type = String.fromCharCode(data[0], data[1], data[2], data[3]);
   const size = readId3Size(data, 4);
   // skip frame id, size, and flags
   const offset = 10;
   return {
    type,
    size,
    data: data.subarray(offset, offset + size),
   };
  }

  const HEADER_FOOTER_SIZE = 10;
  const FRAME_SIZE = 10;
  /**
   * Returns an array of ID3 frames found in all the ID3 tags in the id3Data
   *
   * @param id3Data - The ID3 data containing one or more ID3 tags
   *
   * @returns Array of ID3 frame objects
   *
   * @group ID3
   *
   * @beta
   */
  function getId3Frames(id3Data) {
   let offset = 0;
   const frames = [];
   while (isId3Header(id3Data, offset)) {
    const size = readId3Size(id3Data, offset + 6);
    if ((id3Data[offset + 5] >> 6) & 1) {
     // skip extended header
     offset += HEADER_FOOTER_SIZE;
    }
    // skip past ID3 header
    offset += HEADER_FOOTER_SIZE;
    const end = offset + size;
    // loop through frames in the ID3 tag
    while (offset + FRAME_SIZE < end) {
     const frameData = getId3FrameData(id3Data.subarray(offset));
     const frame = decodeId3Frame(frameData);
     if (frame) {
      frames.push(frame);
     }
     // skip frame header and frame data
     offset += frameData.size + HEADER_FOOTER_SIZE;
    }
    if (isId3Footer(id3Data, offset)) {
     offset += HEADER_FOOTER_SIZE;
    }
   }
   return frames;
  }

  /**
   * Returns true if the ID3 frame is an Elementary Stream timestamp frame
   *
   * @param frame - the ID3 frame
   *
   * @returns `true` if the ID3 frame is an Elementary Stream timestamp frame
   *
   * @internal
   *
   * @group ID3
   */
  function isId3TimestampFrame(frame) {
   return frame && frame.key === 'PRIV' && frame.info === 'com.apple.streaming.transportStreamTimestamp';
  }

  /**
   * Read a 33 bit timestamp from an ID3 frame.
   *
   * @param timeStampFrame - the ID3 frame
   *
   * @returns The timestamp
   *
   * @internal
   *
   * @group ID3
   */
  function readId3Timestamp(timeStampFrame) {
   if (timeStampFrame.data.byteLength === 8) {
    const data = new Uint8Array(timeStampFrame.data);
    // timestamp is 33 bit expressed as a big-endian eight-octet number,
    // with the upper 31 bits set to zero.
    const pts33Bit = data[3] & 0x1;
    let timestamp = (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];
    timestamp /= 45;
    if (pts33Bit) {
     timestamp += 47721858.84;
    } // 2^32 / 90
    return Math.round(timestamp);
   }
   return undefined;
  }

  /**
   * Searches for the Elementary Stream timestamp found in the ID3 data chunk
   *
   * @param data - Block of data containing one or more ID3 tags
   *
   * @returns The timestamp
   *
   * @group ID3
   *
   * @beta
   */
  function getId3Timestamp(data) {
   const frames = getId3Frames(data);
   for (let i = 0; i < frames.length; i++) {
    const frame = frames[i];
    if (isId3TimestampFrame(frame)) {
     return readId3Timestamp(frame);
    }
   }
   return undefined;
  }

  let MetadataSchema = /*#__PURE__*/ (function (MetadataSchema) {
   MetadataSchema['audioId3'] = 'org.id3';
   MetadataSchema['dateRange'] = 'com.apple.quicktime.HLS';
   MetadataSchema['emsg'] = 'https://aomedia.org/emsg/ID3';
   MetadataSchema['misbklv'] = 'urn:misb:KLV:bin:1910.1';
   return MetadataSchema;
  })({});

  function dummyTrack(type = '', inputTimeScale = 90000) {
   return {
    type,
    id: -1,
    pid: -1,
    inputTimeScale,
    sequenceNumber: -1,
    samples: [],
    dropped: 0,
   };
  }

  class BaseAudioDemuxer {
   constructor() {
    this._audioTrack = void 0;
    this._id3Track = void 0;
    this.frameIndex = 0;
    this.cachedData = null;
    this.basePTS = null;
    this.initPTS = null;
    this.lastPTS = null;
   }
   resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
    this._id3Track = {
     type: 'id3',
     id: 3,
     pid: -1,
     inputTimeScale: 90000,
     sequenceNumber: 0,
     samples: [],
     dropped: 0,
    };
   }
   resetTimeStamp(deaultTimestamp) {
    this.initPTS = deaultTimestamp;
    this.resetContiguity();
   }
   resetContiguity() {
    this.basePTS = null;
    this.lastPTS = null;
    this.frameIndex = 0;
   }
   canParse(data, offset) {
    return false;
   }
   appendFrame(track, data, offset) {}

   // feed incoming data to the front of the parsing pipeline
   demux(data, timeOffset) {
    if (this.cachedData) {
     data = appendUint8Array(this.cachedData, data);
     this.cachedData = null;
    }
    let id3Data = getId3Data(data, 0);
    let offset = id3Data ? id3Data.length : 0;
    let lastDataIndex;
    const track = this._audioTrack;
    const id3Track = this._id3Track;
    const timestamp = id3Data ? getId3Timestamp(id3Data) : undefined;
    const length = data.length;
    if (this.basePTS === null || (this.frameIndex === 0 && isFiniteNumber(timestamp))) {
     this.basePTS = initPTSFn(timestamp, timeOffset, this.initPTS);
     this.lastPTS = this.basePTS;
    }
    if (this.lastPTS === null) {
     this.lastPTS = this.basePTS;
    }

    // more expressive than alternative: id3Data?.length
    if (id3Data && id3Data.length > 0) {
     id3Track.samples.push({
      pts: this.lastPTS,
      dts: this.lastPTS,
      data: id3Data,
      type: MetadataSchema.audioId3,
      duration: Number.POSITIVE_INFINITY,
     });
    }
    while (offset < length) {
     if (this.canParse(data, offset)) {
      const frame = this.appendFrame(track, data, offset);
      if (frame) {
       this.frameIndex++;
       this.lastPTS = frame.sample.pts;
       offset += frame.length;
       lastDataIndex = offset;
      } else {
       offset = length;
      }
     } else if (canParseId3(data, offset)) {
      // after a canParse, a call to getId3Data *should* always returns some data
      id3Data = getId3Data(data, offset);
      id3Track.samples.push({
       pts: this.lastPTS,
       dts: this.lastPTS,
       data: id3Data,
       type: MetadataSchema.audioId3,
       duration: Number.POSITIVE_INFINITY,
      });
      offset += id3Data.length;
      lastDataIndex = offset;
     } else {
      offset++;
     }
     if (offset === length && lastDataIndex !== length) {
      const partialData = data.slice(lastDataIndex);
      if (this.cachedData) {
       this.cachedData = appendUint8Array(this.cachedData, partialData);
      } else {
       this.cachedData = partialData;
      }
     }
    }
    return {
     audioTrack: track,
     videoTrack: dummyTrack(),
     id3Track,
     textTrack: dummyTrack(),
    };
   }
   demuxSampleAes(data, keyData, timeOffset) {
    return Promise.reject(new Error(`[${this}] This demuxer does not support Sample-AES decryption`));
   }
   flush(timeOffset) {
    // Parse cache in case of remaining frames.
    const cachedData = this.cachedData;
    if (cachedData) {
     this.cachedData = null;
     this.demux(cachedData, 0);
    }
    return {
     audioTrack: this._audioTrack,
     videoTrack: dummyTrack(),
     id3Track: this._id3Track,
     textTrack: dummyTrack(),
    };
   }
   destroy() {
    this.cachedData = null;
    // @ts-ignore
    this._audioTrack = this._id3Track = undefined;
   }
  }

  /**
   * Initialize PTS
   * <p>
   *    use timestamp unless it is undefined, NaN or Infinity
   * </p>
   */
  const initPTSFn = (timestamp, timeOffset, initPTS) => {
   if (isFiniteNumber(timestamp)) {
    return timestamp * 90;
   }
   const init90kHz = initPTS ? (initPTS.baseTime * 90000) / initPTS.timescale : 0;
   return timeOffset * 90000 + init90kHz;
  };

  /**
   *  MPEG parser helper
   */

  let chromeVersion$1 = null;
  const BitratesMap = [32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160];
  const SamplingRateMap = [44100, 48000, 32000, 22050, 24000, 16000, 11025, 12000, 8000];
  const SamplesCoefficients = [
   // MPEG 2.5
   [
    0,
    // Reserved
    72,
    // Layer3
    144,
    // Layer2
    12, // Layer1
   ],
   // Reserved
   [
    0,
    // Reserved
    0,
    // Layer3
    0,
    // Layer2
    0, // Layer1
   ],
   // MPEG 2
   [
    0,
    // Reserved
    72,
    // Layer3
    144,
    // Layer2
    12, // Layer1
   ],
   // MPEG 1
   [
    0,
    // Reserved
    144,
    // Layer3
    144,
    // Layer2
    12, // Layer1
   ],
  ];
  const BytesInSlot = [
   0,
   // Reserved
   1,
   // Layer3
   1,
   // Layer2
   4, // Layer1
  ];
  function appendFrame$1(track, data, offset, pts, frameIndex) {
   // Using http://www.datavoyage.com/mpgscript/mpeghdr.htm as a reference
   if (offset + 24 > data.length) {
    return;
   }
   const header = parseHeader(data, offset);
   if (header && offset + header.frameLength <= data.length) {
    const frameDuration = (header.samplesPerFrame * 90000) / header.sampleRate;
    const stamp = pts + frameIndex * frameDuration;
    const sample = {
     unit: data.subarray(offset, offset + header.frameLength),
     pts: stamp,
     dts: stamp,
    };
    track.config = [];
    track.channelCount = header.channelCount;
    track.samplerate = header.sampleRate;
    track.samples.push(sample);
    return {
     sample,
     length: header.frameLength,
     missing: 0,
    };
   }
  }
  function parseHeader(data, offset) {
   const mpegVersion = (data[offset + 1] >> 3) & 3;
   const mpegLayer = (data[offset + 1] >> 1) & 3;
   const bitRateIndex = (data[offset + 2] >> 4) & 15;
   const sampleRateIndex = (data[offset + 2] >> 2) & 3;
   if (mpegVersion !== 1 && bitRateIndex !== 0 && bitRateIndex !== 15 && sampleRateIndex !== 3) {
    const paddingBit = (data[offset + 2] >> 1) & 1;
    const channelMode = data[offset + 3] >> 6;
    const columnInBitrates = mpegVersion === 3 ? 3 - mpegLayer : mpegLayer === 3 ? 3 : 4;
    const bitRate = BitratesMap[columnInBitrates * 14 + bitRateIndex - 1] * 1000;
    const columnInSampleRates = mpegVersion === 3 ? 0 : mpegVersion === 2 ? 1 : 2;
    const sampleRate = SamplingRateMap[columnInSampleRates * 3 + sampleRateIndex];
    const channelCount = channelMode === 3 ? 1 : 2; // If bits of channel mode are `11` then it is a single channel (Mono)
    const sampleCoefficient = SamplesCoefficients[mpegVersion][mpegLayer];
    const bytesInSlot = BytesInSlot[mpegLayer];
    const samplesPerFrame = sampleCoefficient * 8 * bytesInSlot;
    const frameLength = Math.floor((sampleCoefficient * bitRate) / sampleRate + paddingBit) * bytesInSlot;
    if (chromeVersion$1 === null) {
     const userAgent = navigator.userAgent || '';
     const result = userAgent.match(/Chrome\/(\d+)/i);
     chromeVersion$1 = result ? parseInt(result[1]) : 0;
    }
    const needChromeFix = !!chromeVersion$1 && chromeVersion$1 <= 87;
    if (needChromeFix && mpegLayer === 2 && bitRate >= 224000 && channelMode === 0) {
     // Work around bug in Chromium by setting channelMode to dual-channel (01) instead of stereo (00)
     data[offset + 3] = data[offset + 3] | 0x80;
    }
    return {
     sampleRate,
     channelCount,
     frameLength,
     samplesPerFrame,
    };
   }
  }
  function isHeaderPattern(data, offset) {
   return data[offset] === 0xff && (data[offset + 1] & 0xe0) === 0xe0 && (data[offset + 1] & 0x06) !== 0x00;
  }
  function isHeader(data, offset) {
   // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1
   // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)
   // More info http://www.mp3-tech.org/programmer/frame_header.html
   return offset + 1 < data.length && isHeaderPattern(data, offset);
  }
  function canParse(data, offset) {
   const headerSize = 4;
   return isHeaderPattern(data, offset) && headerSize <= data.length - offset;
  }
  function probe(data, offset) {
   // same as isHeader but we also check that MPEG frame follows last MPEG frame
   // or end of data is reached
   if (offset + 1 < data.length && isHeaderPattern(data, offset)) {
    // MPEG header Length
    const headerLength = 4;
    // MPEG frame Length
    const header = parseHeader(data, offset);
    let frameLength = headerLength;
    if (header != null && header.frameLength) {
     frameLength = header.frameLength;
    }
    const newOffset = offset + frameLength;
    return newOffset === data.length || isHeader(data, newOffset);
   }
   return false;
  }

  /**
   * AAC demuxer
   */
  class AACDemuxer extends BaseAudioDemuxer {
   constructor(observer, config) {
    super();
    this.observer = void 0;
    this.config = void 0;
    this.observer = observer;
    this.config = config;
   }
   resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);
    this._audioTrack = {
     container: 'audio/adts',
     type: 'audio',
     id: 2,
     pid: -1,
     sequenceNumber: 0,
     segmentCodec: 'aac',
     samples: [],
     manifestCodec: audioCodec,
     duration: trackDuration,
     inputTimeScale: 90000,
     dropped: 0,
    };
   }

   // Source for probe info - https://wiki.multimedia.cx/index.php?title=ADTS
   static probe(data, logger) {
    if (!data) {
     return false;
    }

    // Check for the ADTS sync word
    // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1
    // Layer bits (position 14 and 15) in header should be always 0 for ADTS
    // More info https://wiki.multimedia.cx/index.php?title=ADTS
    const id3Data = getId3Data(data, 0);
    let offset = (id3Data == null ? void 0 : id3Data.length) || 0;
    if (probe(data, offset)) {
     return false;
    }
    for (let length = data.length; offset < length; offset++) {
     if (probe$1(data, offset)) {
      logger.log('ADTS sync word found !');
      return true;
     }
    }
    return false;
   }
   canParse(data, offset) {
    return canParse$1(data, offset);
   }
   appendFrame(track, data, offset) {
    initTrackConfig(track, this.observer, data, offset, track.manifestCodec);
    const frame = appendFrame$2(track, data, offset, this.basePTS, this.frameIndex);
    if (frame && frame.missing === 0) {
     return frame;
    }
   }
  }

  const getAudioBSID = (data, offset) => {
   // check the bsid to confirm ac-3 | ec-3
   let bsid = 0;
   let numBits = 5;
   offset += numBits;
   const temp = new Uint32Array(1); // unsigned 32 bit for temporary storage
   const mask = new Uint32Array(1); // unsigned 32 bit mask value
   const byte = new Uint8Array(1); // unsigned 8 bit for temporary storage
   while (numBits > 0) {
    byte[0] = data[offset];
    // read remaining bits, upto 8 bits at a time
    const bits = Math.min(numBits, 8);
    const shift = 8 - bits;
    mask[0] = (0xff000000 >>> (24 + shift)) << shift;
    temp[0] = (byte[0] & mask[0]) >> shift;
    bsid = !bsid ? temp[0] : (bsid << bits) | temp[0];
    offset += 1;
    numBits -= bits;
   }
   return bsid;
  };

  class AC3Demuxer extends BaseAudioDemuxer {
   constructor(observer) {
    super();
    this.observer = void 0;
    this.observer = observer;
   }
   resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);
    this._audioTrack = {
     container: 'audio/ac-3',
     type: 'audio',
     id: 2,
     pid: -1,
     sequenceNumber: 0,
     segmentCodec: 'ac3',
     samples: [],
     manifestCodec: audioCodec,
     duration: trackDuration,
     inputTimeScale: 90000,
     dropped: 0,
    };
   }
   canParse(data, offset) {
    return offset + 64 < data.length;
   }
   appendFrame(track, data, offset) {
    const frameLength = appendFrame(track, data, offset, this.basePTS, this.frameIndex);
    if (frameLength !== -1) {
     const sample = track.samples[track.samples.length - 1];
     return {
      sample,
      length: frameLength,
      missing: 0,
     };
    }
   }
   static probe(data) {
    if (!data) {
     return false;
    }
    const id3Data = getId3Data(data, 0);
    if (!id3Data) {
     return false;
    }

    // look for the ac-3 sync bytes
    const offset = id3Data.length;
    if (
     data[offset] === 0x0b &&
     data[offset + 1] === 0x77 &&
     getId3Timestamp(id3Data) !== undefined &&
     // check the bsid to confirm ac-3
     getAudioBSID(data, offset) < 16
    ) {
     return true;
    }
    return false;
   }
  }
  function appendFrame(track, data, start, pts, frameIndex) {
   if (start + 8 > data.length) {
    return -1; // not enough bytes left
   }
   if (data[start] !== 0x0b || data[start + 1] !== 0x77) {
    return -1; // invalid magic
   }

   // get sample rate
   const samplingRateCode = data[start + 4] >> 6;
   if (samplingRateCode >= 3) {
    return -1; // invalid sampling rate
   }
   const samplingRateMap = [48000, 44100, 32000];
   const sampleRate = samplingRateMap[samplingRateCode];

   // get frame size
   const frameSizeCode = data[start + 4] & 0x3f;
   const frameSizeMap = [64, 69, 96, 64, 70, 96, 80, 87, 120, 80, 88, 120, 96, 104, 144, 96, 105, 144, 112, 121, 168, 112, 122, 168, 128, 139, 192, 128, 140, 192, 160, 174, 240, 160, 175, 240, 192, 208, 288, 192, 209, 288, 224, 243, 336, 224, 244, 336, 256, 278, 384, 256, 279, 384, 320, 348, 480, 320, 349, 480, 384, 417, 576, 384, 418, 576, 448, 487, 672, 448, 488, 672, 512, 557, 768, 512, 558, 768, 640, 696, 960, 640, 697, 960, 768, 835, 1152, 768, 836, 1152, 896, 975, 1344, 896, 976, 1344, 1024, 1114, 1536, 1024, 1115, 1536, 1152, 1253, 1728, 1152, 1254, 1728, 1280, 1393, 1920, 1280, 1394, 1920];
   const frameLength = frameSizeMap[frameSizeCode * 3 + samplingRateCode] * 2;
   if (start + frameLength > data.length) {
    return -1;
   }

   // get channel count
   const channelMode = data[start + 6] >> 5;
   let skipCount = 0;
   if (channelMode === 2) {
    skipCount += 2;
   } else {
    if (channelMode & 1 && channelMode !== 1) {
     skipCount += 2;
    }
    if (channelMode & 4) {
     skipCount += 2;
    }
   }
   const lfeon = (((data[start + 6] << 8) | data[start + 7]) >> (12 - skipCount)) & 1;
   const channelsMap = [2, 1, 2, 3, 3, 4, 4, 5];
   const channelCount = channelsMap[channelMode] + lfeon;

   // build dac3 box
   const bsid = data[start + 5] >> 3;
   const bsmod = data[start + 5] & 7;
   const config = new Uint8Array([(samplingRateCode << 6) | (bsid << 1) | (bsmod >> 2), ((bsmod & 3) << 6) | (channelMode << 3) | (lfeon << 2) | (frameSizeCode >> 4), (frameSizeCode << 4) & 0xe0]);
   const frameDuration = (1536 / sampleRate) * 90000;
   const stamp = pts + frameIndex * frameDuration;
   const unit = data.subarray(start, start + frameLength);
   track.config = config;
   track.channelCount = channelCount;
   track.samplerate = sampleRate;
   track.samples.push({
    unit,
    pts: stamp,
   });
   return frameLength;
  }

  /**
   * MP3 demuxer
   */
  class MP3Demuxer extends BaseAudioDemuxer {
   resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);
    this._audioTrack = {
     container: 'audio/mpeg',
     type: 'audio',
     id: 2,
     pid: -1,
     sequenceNumber: 0,
     segmentCodec: 'mp3',
     samples: [],
     manifestCodec: audioCodec,
     duration: trackDuration,
     inputTimeScale: 90000,
     dropped: 0,
    };
   }
   static probe(data) {
    if (!data) {
     return false;
    }

    // check if data contains ID3 timestamp and MPEG sync word
    // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1
    // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)
    // More info http://www.mp3-tech.org/programmer/frame_header.html
    const id3Data = getId3Data(data, 0);
    let offset = (id3Data == null ? void 0 : id3Data.length) || 0;

    // Check for ac-3|ec-3 sync bytes and return false if present
    if (
     id3Data &&
     data[offset] === 0x0b &&
     data[offset + 1] === 0x77 &&
     getId3Timestamp(id3Data) !== undefined &&
     // check the bsid to confirm ac-3 or ec-3 (not mp3)
     getAudioBSID(data, offset) <= 16
    ) {
     return false;
    }
    for (let length = data.length; offset < length; offset++) {
     if (probe(data, offset)) {
      logger.log('MPEG Audio sync word found !');
      return true;
     }
    }
    return false;
   }
   canParse(data, offset) {
    return canParse(data, offset);
   }
   appendFrame(track, data, offset) {
    if (this.basePTS === null) {
     return;
    }
    return appendFrame$1(track, data, offset, this.basePTS, this.frameIndex);
   }
  }

  const emsgSchemePattern = /\/emsg[-/]ID3/i;
  class MP4Demuxer {
   constructor(observer, config) {
    this.remainderData = null;
    this.timeOffset = 0;
    this.config = void 0;
    this.videoTrack = void 0;
    this.audioTrack = void 0;
    this.id3Track = void 0;
    this.txtTrack = void 0;
    this.config = config;
   }
   resetTimeStamp() {}
   resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
    const videoTrack = (this.videoTrack = dummyTrack('video', 1));
    const audioTrack = (this.audioTrack = dummyTrack('audio', 1));
    const captionTrack = (this.txtTrack = dummyTrack('text', 1));
    this.id3Track = dummyTrack('id3', 1);
    this.timeOffset = 0;
    if (!(initSegment != null && initSegment.byteLength)) {
     return;
    }
    const initData = parseInitSegment(initSegment);
    if (initData.video) {
     const { id, timescale, codec, supplemental } = initData.video;
     videoTrack.id = id;
     videoTrack.timescale = captionTrack.timescale = timescale;
     videoTrack.codec = codec;
     videoTrack.supplemental = supplemental;
    }
    if (initData.audio) {
     const { id, timescale, codec } = initData.audio;
     audioTrack.id = id;
     audioTrack.timescale = timescale;
     audioTrack.codec = codec;
    }
    captionTrack.id = RemuxerTrackIdConfig.text;
    videoTrack.sampleDuration = 0;
    videoTrack.duration = audioTrack.duration = trackDuration;
   }
   resetContiguity() {
    this.remainderData = null;
   }
   static probe(data) {
    return hasMoofData(data);
   }
   demux(data, timeOffset) {
    this.timeOffset = timeOffset;
    // Load all data into the avc track. The CMAF remuxer will look for the data in the samples object; the rest of the fields do not matter
    let videoSamples = data;
    const videoTrack = this.videoTrack;
    const textTrack = this.txtTrack;
    if (this.config.progressive) {
     // Split the bytestream into two ranges: one encompassing all data up until the start of the last moof, and everything else.
     // This is done to guarantee that we're sending valid data to MSE - when demuxing progressively, we have no guarantee
     // that the fetch loader gives us flush moof+mdat pairs. If we push jagged data to MSE, it will throw an exception.
     if (this.remainderData) {
      videoSamples = appendUint8Array(this.remainderData, data);
     }
     const segmentedData = segmentValidRange(videoSamples);
     this.remainderData = segmentedData.remainder;
     videoTrack.samples = segmentedData.valid || new Uint8Array();
    } else {
     videoTrack.samples = videoSamples;
    }
    const id3Track = this.extractID3Track(videoTrack, timeOffset);
    textTrack.samples = parseSamples(timeOffset, videoTrack);
    return {
     videoTrack,
     audioTrack: this.audioTrack,
     id3Track,
     textTrack: this.txtTrack,
    };
   }
   flush() {
    const timeOffset = this.timeOffset;
    const videoTrack = this.videoTrack;
    const textTrack = this.txtTrack;
    videoTrack.samples = this.remainderData || new Uint8Array();
    this.remainderData = null;
    const id3Track = this.extractID3Track(videoTrack, this.timeOffset);
    textTrack.samples = parseSamples(timeOffset, videoTrack);
    return {
     videoTrack,
     audioTrack: dummyTrack(),
     id3Track,
     textTrack: dummyTrack(),
    };
   }
   extractID3Track(videoTrack, timeOffset) {
    const id3Track = this.id3Track;
    if (videoTrack.samples.length) {
     const emsgs = findBox(videoTrack.samples, ['emsg']);
     if (emsgs) {
      emsgs.forEach((data) => {
       const emsgInfo = parseEmsg(data);
       if (emsgSchemePattern.test(emsgInfo.schemeIdUri)) {
        const pts = getEmsgStartTime(emsgInfo, timeOffset);
        let duration = emsgInfo.eventDuration === 0xffffffff ? Number.POSITIVE_INFINITY : emsgInfo.eventDuration / emsgInfo.timeScale;
        // Safari takes anything <= 0.001 seconds and maps it to Infinity
        if (duration <= 0.001) {
         duration = Number.POSITIVE_INFINITY;
        }
        const payload = emsgInfo.payload;
        id3Track.samples.push({
         data: payload,
         len: payload.byteLength,
         dts: pts,
         pts: pts,
         type: MetadataSchema.emsg,
         duration: duration,
        });
       } else if (this.config.enableEmsgKLVMetadata && emsgInfo.schemeIdUri.startsWith('urn:misb:KLV:bin:1910.1')) {
        const pts = getEmsgStartTime(emsgInfo, timeOffset);
        id3Track.samples.push({
         data: emsgInfo.payload,
         len: emsgInfo.payload.byteLength,
         dts: pts,
         pts: pts,
         type: MetadataSchema.misbklv,
         duration: Number.POSITIVE_INFINITY,
        });
       }
      });
     }
    }
    return id3Track;
   }
   demuxSampleAes(data, keyData, timeOffset) {
    return Promise.reject(new Error('The MP4 demuxer does not support SAMPLE-AES decryption'));
   }
   destroy() {
    // @ts-ignore
    this.config = null;
    this.remainderData = null;
    this.videoTrack = this.audioTrack = this.id3Track = this.txtTrack = undefined;
   }
  }
  function getEmsgStartTime(emsgInfo, timeOffset) {
   return isFiniteNumber(emsgInfo.presentationTime) ? emsgInfo.presentationTime / emsgInfo.timeScale : timeOffset + emsgInfo.presentationTimeDelta / emsgInfo.timeScale;
  }

  /**
   * SAMPLE-AES decrypter
   */

  class SampleAesDecrypter {
   constructor(observer, config, keyData) {
    this.keyData = void 0;
    this.decrypter = void 0;
    this.keyData = keyData;
    this.decrypter = new Decrypter(config, {
     removePKCS7Padding: false,
    });
   }
   decryptBuffer(encryptedData) {
    return this.decrypter.decrypt(encryptedData, this.keyData.key.buffer, this.keyData.iv.buffer, DecrypterAesMode.cbc);
   }

   // AAC - encrypt all full 16 bytes blocks starting from offset 16
   decryptAacSample(samples, sampleIndex, callback) {
    const curUnit = samples[sampleIndex].unit;
    if (curUnit.length <= 16) {
     // No encrypted portion in this sample (first 16 bytes is not
     // encrypted, see https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/HLS_Sample_Encryption/Encryption/Encryption.html),
     return;
    }
    const encryptedData = curUnit.subarray(16, curUnit.length - (curUnit.length % 16));
    const encryptedBuffer = encryptedData.buffer.slice(encryptedData.byteOffset, encryptedData.byteOffset + encryptedData.length);
    this.decryptBuffer(encryptedBuffer).then((decryptedBuffer) => {
     const decryptedData = new Uint8Array(decryptedBuffer);
     curUnit.set(decryptedData, 16);
     if (!this.decrypter.isSync()) {
      this.decryptAacSamples(samples, sampleIndex + 1, callback);
     }
    });
   }
   decryptAacSamples(samples, sampleIndex, callback) {
    for (; ; sampleIndex++) {
     if (sampleIndex >= samples.length) {
      callback();
      return;
     }
     if (samples[sampleIndex].unit.length < 32) {
      continue;
     }
     this.decryptAacSample(samples, sampleIndex, callback);
     if (!this.decrypter.isSync()) {
      return;
     }
    }
   }

   // AVC - encrypt one 16 bytes block out of ten, starting from offset 32
   getAvcEncryptedData(decodedData) {
    const encryptedDataLen = Math.floor((decodedData.length - 48) / 160) * 16 + 16;
    const encryptedData = new Int8Array(encryptedDataLen);
    let outputPos = 0;
    for (let inputPos = 32; inputPos < decodedData.length - 16; inputPos += 160, outputPos += 16) {
     encryptedData.set(decodedData.subarray(inputPos, inputPos + 16), outputPos);
    }
    return encryptedData;
   }
   getAvcDecryptedUnit(decodedData, decryptedData) {
    const uint8DecryptedData = new Uint8Array(decryptedData);
    let inputPos = 0;
    for (let outputPos = 32; outputPos < decodedData.length - 16; outputPos += 160, inputPos += 16) {
     decodedData.set(uint8DecryptedData.subarray(inputPos, inputPos + 16), outputPos);
    }
    return decodedData;
   }
   decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit) {
    const decodedData = discardEPB(curUnit.data);
    const encryptedData = this.getAvcEncryptedData(decodedData);
    this.decryptBuffer(encryptedData.buffer).then((decryptedBuffer) => {
     curUnit.data = this.getAvcDecryptedUnit(decodedData, decryptedBuffer);
     if (!this.decrypter.isSync()) {
      this.decryptAvcSamples(samples, sampleIndex, unitIndex + 1, callback);
     }
    });
   }
   decryptAvcSamples(samples, sampleIndex, unitIndex, callback) {
    if (samples instanceof Uint8Array) {
     throw new Error('Cannot decrypt samples of type Uint8Array');
    }
    for (; ; sampleIndex++, unitIndex = 0) {
     if (sampleIndex >= samples.length) {
      callback();
      return;
     }
     const curUnits = samples[sampleIndex].units;
     for (; ; unitIndex++) {
      if (unitIndex >= curUnits.length) {
       break;
      }
      const curUnit = curUnits[unitIndex];
      if (curUnit.data.length <= 48 || (curUnit.type !== 1 && curUnit.type !== 5)) {
       continue;
      }
      this.decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit);
      if (!this.decrypter.isSync()) {
       return;
      }
     }
    }
   }
  }

  class BaseVideoParser {
   constructor() {
    this.VideoSample = null;
   }
   createVideoSample(key, pts, dts) {
    return {
     key,
     frame: false,
     pts,
     dts,
     units: [],
     length: 0,
    };
   }
   getLastNalUnit(samples) {
    var _VideoSample;
    let VideoSample = this.VideoSample;
    let lastUnit;
    // try to fallback to previous sample if current one is empty
    if (!VideoSample || VideoSample.units.length === 0) {
     VideoSample = samples[samples.length - 1];
    }
    if ((_VideoSample = VideoSample) != null && _VideoSample.units) {
     const units = VideoSample.units;
     lastUnit = units[units.length - 1];
    }
    return lastUnit;
   }
   pushAccessUnit(VideoSample, videoTrack) {
    if (VideoSample.units.length && VideoSample.frame) {
     // if sample does not have PTS/DTS, patch with last sample PTS/DTS
     if (VideoSample.pts === undefined) {
      const samples = videoTrack.samples;
      const nbSamples = samples.length;
      if (nbSamples) {
       const lastSample = samples[nbSamples - 1];
       VideoSample.pts = lastSample.pts;
       VideoSample.dts = lastSample.dts;
      } else {
       // dropping samples, no timestamp found
       videoTrack.dropped++;
       return;
      }
     }
     videoTrack.samples.push(VideoSample);
    }
   }
   parseNALu(track, array, endOfSegment) {
    const len = array.byteLength;
    let state = track.naluState || 0;
    const lastState = state;
    const units = [];
    let i = 0;
    let value;
    let overflow;
    let unitType;
    let lastUnitStart = -1;
    let lastUnitType = 0;
    // logger.log('PES:' + Hex.hexDump(array));

    if (state === -1) {
     // special use case where we found 3 or 4-byte start codes exactly at the end of previous PES packet
     lastUnitStart = 0;
     // NALu type is value read from offset 0
     lastUnitType = this.getNALuType(array, 0);
     state = 0;
     i = 1;
    }
    while (i < len) {
     value = array[i++];
     // optimization. state 0 and 1 are the predominant case. let's handle them outside of the switch/case
     if (!state) {
      state = value ? 0 : 1;
      continue;
     }
     if (state === 1) {
      state = value ? 0 : 2;
      continue;
     }
     // here we have state either equal to 2 or 3
     if (!value) {
      state = 3;
     } else if (value === 1) {
      overflow = i - state - 1;
      if (lastUnitStart >= 0) {
       const unit = {
        data: array.subarray(lastUnitStart, overflow),
        type: lastUnitType,
       };
       // logger.log('pushing NALU, type/size:' + unit.type + '/' + unit.data.byteLength);
       units.push(unit);
      } else {
       // lastUnitStart is undefined => this is the first start code found in this PES packet
       // first check if start code delimiter is overlapping between 2 PES packets,
       // ie it started in last packet (lastState not zero)
       // and ended at the beginning of this PES packet (i <= 4 - lastState)
       const lastUnit = this.getLastNalUnit(track.samples);
       if (lastUnit) {
        if (lastState && i <= 4 - lastState) {
         // start delimiter overlapping between PES packets
         // strip start delimiter bytes from the end of last NAL unit
         // check if lastUnit had a state different from zero
         if (lastUnit.state) {
          // strip last bytes
          lastUnit.data = lastUnit.data.subarray(0, lastUnit.data.byteLength - lastState);
         }
        }
        // If NAL units are not starting right at the beginning of the PES packet, push preceding data into previous NAL unit.

        if (overflow > 0) {
         // logger.log('first NALU found with overflow:' + overflow);
         lastUnit.data = appendUint8Array(lastUnit.data, array.subarray(0, overflow));
         lastUnit.state = 0;
        }
       }
      }
      // check if we can read unit type
      if (i < len) {
       unitType = this.getNALuType(array, i);
       // logger.log('find NALU @ offset:' + i + ',type:' + unitType);
       lastUnitStart = i;
       lastUnitType = unitType;
       state = 0;
      } else {
       // not enough byte to read unit type. let's read it on next PES parsing
       state = -1;
      }
     } else {
      state = 0;
     }
    }
    if (lastUnitStart >= 0 && state >= 0) {
     const unit = {
      data: array.subarray(lastUnitStart, len),
      type: lastUnitType,
      state: state,
     };
     units.push(unit);
     // logger.log('pushing NALU, type/size/state:' + unit.type + '/' + unit.data.byteLength + '/' + state);
    }
    // no NALu found
    if (units.length === 0) {
     // append pes.data to previous NAL unit
     const lastUnit = this.getLastNalUnit(track.samples);
     if (lastUnit) {
      lastUnit.data = appendUint8Array(lastUnit.data, array);
     }
    }
    track.naluState = state;
    return units;
   }
  }

  /**
   * Parser for exponential Golomb codes, a variable-bitwidth number encoding scheme used by h264.
   */

  class ExpGolomb {
   constructor(data) {
    this.data = void 0;
    this.bytesAvailable = void 0;
    this.word = void 0;
    this.bitsAvailable = void 0;
    this.data = data;
    // the number of bytes left to examine in this.data
    this.bytesAvailable = data.byteLength;
    // the current word being examined
    this.word = 0; // :uint
    // the number of bits left to examine in the current word
    this.bitsAvailable = 0; // :uint
   }

   // ():void
   loadWord() {
    const data = this.data;
    const bytesAvailable = this.bytesAvailable;
    const position = data.byteLength - bytesAvailable;
    const workingBytes = new Uint8Array(4);
    const availableBytes = Math.min(4, bytesAvailable);
    if (availableBytes === 0) {
     throw new Error('no bytes available');
    }
    workingBytes.set(data.subarray(position, position + availableBytes));
    this.word = new DataView(workingBytes.buffer).getUint32(0);
    // track the amount of this.data that has been processed
    this.bitsAvailable = availableBytes * 8;
    this.bytesAvailable -= availableBytes;
   }

   // (count:int):void
   skipBits(count) {
    let skipBytes; // :int
    count = Math.min(count, this.bytesAvailable * 8 + this.bitsAvailable);
    if (this.bitsAvailable > count) {
     this.word <<= count;
     this.bitsAvailable -= count;
    } else {
     count -= this.bitsAvailable;
     skipBytes = count >> 3;
     count -= skipBytes << 3;
     this.bytesAvailable -= skipBytes;
     this.loadWord();
     this.word <<= count;
     this.bitsAvailable -= count;
    }
   }

   // (size:int):uint
   readBits(size) {
    let bits = Math.min(this.bitsAvailable, size); // :uint
    const valu = this.word >>> (32 - bits); // :uint
    if (size > 32) {
     logger.error('Cannot read more than 32 bits at a time');
    }
    this.bitsAvailable -= bits;
    if (this.bitsAvailable > 0) {
     this.word <<= bits;
    } else if (this.bytesAvailable > 0) {
     this.loadWord();
    } else {
     throw new Error('no bits available');
    }
    bits = size - bits;
    if (bits > 0 && this.bitsAvailable) {
     return (valu << bits) | this.readBits(bits);
    } else {
     return valu;
    }
   }

   // ():uint
   skipLZ() {
    let leadingZeroCount; // :uint
    for (leadingZeroCount = 0; leadingZeroCount < this.bitsAvailable; ++leadingZeroCount) {
     if ((this.word & (0x80000000 >>> leadingZeroCount)) !== 0) {
      // the first bit of working word is 1
      this.word <<= leadingZeroCount;
      this.bitsAvailable -= leadingZeroCount;
      return leadingZeroCount;
     }
    }
    // we exhausted word and still have not found a 1
    this.loadWord();
    return leadingZeroCount + this.skipLZ();
   }

   // ():void
   skipUEG() {
    this.skipBits(1 + this.skipLZ());
   }

   // ():void
   skipEG() {
    this.skipBits(1 + this.skipLZ());
   }

   // ():uint
   readUEG() {
    const clz = this.skipLZ(); // :uint
    return this.readBits(clz + 1) - 1;
   }

   // ():int
   readEG() {
    const valu = this.readUEG(); // :int
    if (0x01 & valu) {
     // the number is odd if the low order bit is set
     return (1 + valu) >>> 1; // add 1 to make it even, and divide by 2
    } else {
     return -1 * (valu >>> 1); // divide by two then make it negative
    }
   }

   // Some convenience functions
   // :Boolean
   readBoolean() {
    return this.readBits(1) === 1;
   }

   // ():int
   readUByte() {
    return this.readBits(8);
   }

   // ():int
   readUShort() {
    return this.readBits(16);
   }

   // ():int
   readUInt() {
    return this.readBits(32);
   }
  }

  class AvcVideoParser extends BaseVideoParser {
   parsePES(track, textTrack, pes, endOfSegment) {
    const units = this.parseNALu(track, pes.data, endOfSegment);
    let VideoSample = this.VideoSample;
    let push;
    let spsfound = false;
    // free pes.data to save up some memory
    pes.data = null;

    // if new NAL units found and last sample still there, let's push ...
    // this helps parsing streams with missing AUD (only do this if AUD never found)
    if (VideoSample && units.length && !track.audFound) {
     this.pushAccessUnit(VideoSample, track);
     VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);
    }
    units.forEach((unit) => {
     var _VideoSample2, _VideoSample3;
     switch (unit.type) {
      // NDR
      case 1: {
       let iskey = false;
       push = true;
       const data = unit.data;
       // only check slice type to detect KF in case SPS found in same packet (any keyframe is preceded by SPS ...)
       if (spsfound && data.length > 4) {
        // retrieve slice type by parsing beginning of NAL unit (follow H264 spec, slice_header definition) to detect keyframe embedded in NDR
        const sliceType = this.readSliceType(data);
        // 2 : I slice, 4 : SI slice, 7 : I slice, 9: SI slice
        // SI slice : A slice that is coded using intra prediction only and using quantisation of the prediction samples.
        // An SI slice can be coded such that its decoded samples can be constructed identically to an SP slice.
        // I slice: A slice that is not an SI slice that is decoded using intra prediction only.
        // if (sliceType === 2 || sliceType === 7) {
        if (sliceType === 2 || sliceType === 4 || sliceType === 7 || sliceType === 9) {
         iskey = true;
        }
       }
       if (iskey) {
        var _VideoSample;
        // if we have non-keyframe data already, that cannot belong to the same frame as a keyframe, so force a push
        if ((_VideoSample = VideoSample) != null && _VideoSample.frame && !VideoSample.key) {
         this.pushAccessUnit(VideoSample, track);
         VideoSample = this.VideoSample = null;
        }
       }
       if (!VideoSample) {
        VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);
       }
       VideoSample.frame = true;
       VideoSample.key = iskey;
       break;
       // IDR
      }
      case 5:
       push = true;
       // handle PES not starting with AUD
       // if we have frame data already, that cannot belong to the same frame, so force a push
       if ((_VideoSample2 = VideoSample) != null && _VideoSample2.frame && !VideoSample.key) {
        this.pushAccessUnit(VideoSample, track);
        VideoSample = this.VideoSample = null;
       }
       if (!VideoSample) {
        VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);
       }
       VideoSample.key = true;
       VideoSample.frame = true;
       break;
      // SEI
      case 6: {
       push = true;
       parseSEIMessageFromNALu(unit.data, 1, pes.pts, textTrack.samples);
       break;
       // SPS
      }
      case 7: {
       var _track$pixelRatio, _track$pixelRatio2;
       push = true;
       spsfound = true;
       const sps = unit.data;
       const config = this.readSPS(sps);
       if (!track.sps || track.width !== config.width || track.height !== config.height || ((_track$pixelRatio = track.pixelRatio) == null ? void 0 : _track$pixelRatio[0]) !== config.pixelRatio[0] || ((_track$pixelRatio2 = track.pixelRatio) == null ? void 0 : _track$pixelRatio2[1]) !== config.pixelRatio[1]) {
        track.width = config.width;
        track.height = config.height;
        track.pixelRatio = config.pixelRatio;
        track.sps = [sps];
        const codecarray = sps.subarray(1, 4);
        let codecstring = 'avc1.';
        for (let i = 0; i < 3; i++) {
         let h = codecarray[i].toString(16);
         if (h.length < 2) {
          h = '0' + h;
         }
         codecstring += h;
        }
        track.codec = codecstring;
       }
       break;
      }
      // PPS
      case 8:
       push = true;
       track.pps = [unit.data];
       break;
      // AUD
      case 9:
       push = true;
       track.audFound = true;
       if ((_VideoSample3 = VideoSample) != null && _VideoSample3.frame) {
        this.pushAccessUnit(VideoSample, track);
        VideoSample = null;
       }
       if (!VideoSample) {
        VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);
       }
       break;
      // Filler Data
      case 12:
       push = true;
       break;
      default:
       push = false;
       break;
     }
     if (VideoSample && push) {
      const units = VideoSample.units;
      units.push(unit);
     }
    });
    // if last PES packet, push samples
    if (endOfSegment && VideoSample) {
     this.pushAccessUnit(VideoSample, track);
     this.VideoSample = null;
    }
   }
   getNALuType(data, offset) {
    return data[offset] & 0x1f;
   }
   readSliceType(data) {
    const eg = new ExpGolomb(data);
    // skip NALu type
    eg.readUByte();
    // discard first_mb_in_slice
    eg.readUEG();
    // return slice_type
    return eg.readUEG();
   }

   /**
    * The scaling list is optionally transmitted as part of a sequence parameter
    * set and is not relevant to transmuxing.
    * @param count the number of entries in this scaling list
    * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1
    */
   skipScalingList(count, reader) {
    let lastScale = 8;
    let nextScale = 8;
    let deltaScale;
    for (let j = 0; j < count; j++) {
     if (nextScale !== 0) {
      deltaScale = reader.readEG();
      nextScale = (lastScale + deltaScale + 256) % 256;
     }
     lastScale = nextScale === 0 ? lastScale : nextScale;
    }
   }

   /**
    * Read a sequence parameter set and return some interesting video
    * properties. A sequence parameter set is the H264 metadata that
    * describes the properties of upcoming video frames.
    * @returns an object with configuration parsed from the
    * sequence parameter set, including the dimensions of the
    * associated video frames.
    */
   readSPS(sps) {
    const eg = new ExpGolomb(sps);
    let frameCropLeftOffset = 0;
    let frameCropRightOffset = 0;
    let frameCropTopOffset = 0;
    let frameCropBottomOffset = 0;
    let numRefFramesInPicOrderCntCycle;
    let scalingListCount;
    let i;
    const readUByte = eg.readUByte.bind(eg);
    const readBits = eg.readBits.bind(eg);
    const readUEG = eg.readUEG.bind(eg);
    const readBoolean = eg.readBoolean.bind(eg);
    const skipBits = eg.skipBits.bind(eg);
    const skipEG = eg.skipEG.bind(eg);
    const skipUEG = eg.skipUEG.bind(eg);
    const skipScalingList = this.skipScalingList.bind(this);
    readUByte();
    const profileIdc = readUByte(); // profile_idc
    readBits(5); // profileCompat constraint_set[0-4]_flag, u(5)
    skipBits(3); // reserved_zero_3bits u(3),
    readUByte(); // level_idc u(8)
    skipUEG(); // seq_parameter_set_id
    // some profiles have more optional data we don't need
    if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {
     const chromaFormatIdc = readUEG();
     if (chromaFormatIdc === 3) {
      skipBits(1);
     } // separate_colour_plane_flag

     skipUEG(); // bit_depth_luma_minus8
     skipUEG(); // bit_depth_chroma_minus8
     skipBits(1); // qpprime_y_zero_transform_bypass_flag
     if (readBoolean()) {
      // seq_scaling_matrix_present_flag
      scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;
      for (i = 0; i < scalingListCount; i++) {
       if (readBoolean()) {
        // seq_scaling_list_present_flag[ i ]
        if (i < 6) {
         skipScalingList(16, eg);
        } else {
         skipScalingList(64, eg);
        }
       }
      }
     }
    }
    skipUEG(); // log2_max_frame_num_minus4
    const picOrderCntType = readUEG();
    if (picOrderCntType === 0) {
     readUEG(); // log2_max_pic_order_cnt_lsb_minus4
    } else if (picOrderCntType === 1) {
     skipBits(1); // delta_pic_order_always_zero_flag
     skipEG(); // offset_for_non_ref_pic
     skipEG(); // offset_for_top_to_bottom_field
     numRefFramesInPicOrderCntCycle = readUEG();
     for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {
      skipEG();
     } // offset_for_ref_frame[ i ]
    }
    skipUEG(); // max_num_ref_frames
    skipBits(1); // gaps_in_frame_num_value_allowed_flag
    const picWidthInMbsMinus1 = readUEG();
    const picHeightInMapUnitsMinus1 = readUEG();
    const frameMbsOnlyFlag = readBits(1);
    if (frameMbsOnlyFlag === 0) {
     skipBits(1);
    } // mb_adaptive_frame_field_flag

    skipBits(1); // direct_8x8_inference_flag
    if (readBoolean()) {
     // frame_cropping_flag
     frameCropLeftOffset = readUEG();
     frameCropRightOffset = readUEG();
     frameCropTopOffset = readUEG();
     frameCropBottomOffset = readUEG();
    }
    let pixelRatio = [1, 1];
    if (readBoolean()) {
     // vui_parameters_present_flag
     if (readBoolean()) {
      // aspect_ratio_info_present_flag
      const aspectRatioIdc = readUByte();
      switch (aspectRatioIdc) {
       case 1:
        pixelRatio = [1, 1];
        break;
       case 2:
        pixelRatio = [12, 11];
        break;
       case 3:
        pixelRatio = [10, 11];
        break;
       case 4:
        pixelRatio = [16, 11];
        break;
       case 5:
        pixelRatio = [40, 33];
        break;
       case 6:
        pixelRatio = [24, 11];
        break;
       case 7:
        pixelRatio = [20, 11];
        break;
       case 8:
        pixelRatio = [32, 11];
        break;
       case 9:
        pixelRatio = [80, 33];
        break;
       case 10:
        pixelRatio = [18, 11];
        break;
       case 11:
        pixelRatio = [15, 11];
        break;
       case 12:
        pixelRatio = [64, 33];
        break;
       case 13:
        pixelRatio = [160, 99];
        break;
       case 14:
        pixelRatio = [4, 3];
        break;
       case 15:
        pixelRatio = [3, 2];
        break;
       case 16:
        pixelRatio = [2, 1];
        break;
       case 255: {
        pixelRatio = [(readUByte() << 8) | readUByte(), (readUByte() << 8) | readUByte()];
        break;
       }
      }
     }
    }
    return {
     width: Math.ceil((picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2),
     height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - (frameMbsOnlyFlag ? 2 : 4) * (frameCropTopOffset + frameCropBottomOffset),
     pixelRatio: pixelRatio,
    };
   }
  }

  class HevcVideoParser extends BaseVideoParser {
   constructor(...args) {
    super(...args);
    this.initVPS = null;
   }
   parsePES(track, textTrack, pes, endOfSegment) {
    const units = this.parseNALu(track, pes.data, endOfSegment);
    let VideoSample = this.VideoSample;
    let push;
    let spsfound = false;
    // free pes.data to save up some memory
    pes.data = null;

    // if new NAL units found and last sample still there, let's push ...
    // this helps parsing streams with missing AUD (only do this if AUD never found)
    if (VideoSample && units.length && !track.audFound) {
     this.pushAccessUnit(VideoSample, track);
     VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);
    }
    units.forEach((unit) => {
     var _VideoSample2, _VideoSample3;
     switch (unit.type) {
      // NON-IDR, NON RANDOM ACCESS SLICE
      case 0:
      case 1:
      case 2:
      case 3:
      case 4:
      case 5:
      case 6:
      case 7:
      case 8:
      case 9:
       if (!VideoSample) {
        VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);
       }
       VideoSample.frame = true;
       push = true;
       break;

      // CRA, BLA (random access picture)
      case 16:
      case 17:
      case 18:
      case 21:
       push = true;
       if (spsfound) {
        var _VideoSample;
        // handle PES not starting with AUD
        // if we have frame data already, that cannot belong to the same frame, so force a push
        if ((_VideoSample = VideoSample) != null && _VideoSample.frame && !VideoSample.key) {
         this.pushAccessUnit(VideoSample, track);
         VideoSample = this.VideoSample = null;
        }
       }
       if (!VideoSample) {
        VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);
       }
       VideoSample.key = true;
       VideoSample.frame = true;
       break;

      // IDR
      case 19:
      case 20:
       push = true;
       // handle PES not starting with AUD
       // if we have frame data already, that cannot belong to the same frame, so force a push
       if ((_VideoSample2 = VideoSample) != null && _VideoSample2.frame && !VideoSample.key) {
        this.pushAccessUnit(VideoSample, track);
        VideoSample = this.VideoSample = null;
       }
       if (!VideoSample) {
        VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);
       }
       VideoSample.key = true;
       VideoSample.frame = true;
       break;

      // SEI
      case 39:
       push = true;
       parseSEIMessageFromNALu(
        unit.data,
        2,
        // NALu header size
        pes.pts,
        textTrack.samples,
       );
       break;

      // VPS
      case 32:
       push = true;
       if (!track.vps) {
        if (typeof track.params !== 'object') {
         track.params = {};
        }
        track.params = _extends(track.params, this.readVPS(unit.data));
        this.initVPS = unit.data;
       }
       track.vps = [unit.data];
       break;

      // SPS
      case 33:
       push = true;
       spsfound = true;
       if (track.vps !== undefined && track.vps[0] !== this.initVPS && track.sps !== undefined && !this.matchSPS(track.sps[0], unit.data)) {
        this.initVPS = track.vps[0];
        track.sps = track.pps = undefined;
       }
       if (!track.sps) {
        const config = this.readSPS(unit.data);
        track.width = config.width;
        track.height = config.height;
        track.pixelRatio = config.pixelRatio;
        track.codec = config.codecString;
        track.sps = [];
        if (typeof track.params !== 'object') {
         track.params = {};
        }
        for (const prop in config.params) {
         track.params[prop] = config.params[prop];
        }
       }
       this.pushParameterSet(track.sps, unit.data, track.vps);
       if (!VideoSample) {
        VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);
       }
       VideoSample.key = true;
       break;

      // PPS
      case 34:
       push = true;
       if (typeof track.params === 'object') {
        if (!track.pps) {
         track.pps = [];
         const config = this.readPPS(unit.data);
         for (const prop in config) {
          track.params[prop] = config[prop];
         }
        }
        this.pushParameterSet(track.pps, unit.data, track.vps);
       }
       break;

      // ACCESS UNIT DELIMITER
      case 35:
       push = true;
       track.audFound = true;
       if ((_VideoSample3 = VideoSample) != null && _VideoSample3.frame) {
        this.pushAccessUnit(VideoSample, track);
        VideoSample = null;
       }
       if (!VideoSample) {
        VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);
       }
       break;
      default:
       push = false;
       break;
     }
     if (VideoSample && push) {
      const units = VideoSample.units;
      units.push(unit);
     }
    });
    // if last PES packet, push samples
    if (endOfSegment && VideoSample) {
     this.pushAccessUnit(VideoSample, track);
     this.VideoSample = null;
    }
   }
   pushParameterSet(parameterSets, data, vps) {
    if ((vps && vps[0] === this.initVPS) || (!vps && !parameterSets.length)) {
     parameterSets.push(data);
    }
   }
   getNALuType(data, offset) {
    return (data[offset] & 0x7e) >>> 1;
   }
   ebsp2rbsp(arr) {
    const dst = new Uint8Array(arr.byteLength);
    let dstIdx = 0;
    for (let i = 0; i < arr.byteLength; i++) {
     if (i >= 2) {
      // Unescape: Skip 0x03 after 00 00
      if (arr[i] === 0x03 && arr[i - 1] === 0x00 && arr[i - 2] === 0x00) {
       continue;
      }
     }
     dst[dstIdx] = arr[i];
     dstIdx++;
    }
    return new Uint8Array(dst.buffer, 0, dstIdx);
   }
   pushAccessUnit(VideoSample, videoTrack) {
    super.pushAccessUnit(VideoSample, videoTrack);
    if (this.initVPS) {
     this.initVPS = null; // null initVPS to prevent possible track's sps/pps growth until next VPS
    }
   }
   readVPS(vps) {
    const eg = new ExpGolomb(vps);
    // remove header
    eg.readUByte();
    eg.readUByte();
    eg.readBits(4); // video_parameter_set_id
    eg.skipBits(2);
    eg.readBits(6); // max_layers_minus1
    const max_sub_layers_minus1 = eg.readBits(3);
    const temporal_id_nesting_flag = eg.readBoolean();
    // ...vui fps can be here, but empty fps value is not critical for metadata

    return {
     numTemporalLayers: max_sub_layers_minus1 + 1,
     temporalIdNested: temporal_id_nesting_flag,
    };
   }
   readSPS(sps) {
    const eg = new ExpGolomb(this.ebsp2rbsp(sps));
    eg.readUByte();
    eg.readUByte();
    eg.readBits(4); //video_parameter_set_id
    const max_sub_layers_minus1 = eg.readBits(3);
    eg.readBoolean(); // temporal_id_nesting_flag

    // profile_tier_level
    const general_profile_space = eg.readBits(2);
    const general_tier_flag = eg.readBoolean();
    const general_profile_idc = eg.readBits(5);
    const general_profile_compatibility_flags_1 = eg.readUByte();
    const general_profile_compatibility_flags_2 = eg.readUByte();
    const general_profile_compatibility_flags_3 = eg.readUByte();
    const general_profile_compatibility_flags_4 = eg.readUByte();
    const general_constraint_indicator_flags_1 = eg.readUByte();
    const general_constraint_indicator_flags_2 = eg.readUByte();
    const general_constraint_indicator_flags_3 = eg.readUByte();
    const general_constraint_indicator_flags_4 = eg.readUByte();
    const general_constraint_indicator_flags_5 = eg.readUByte();
    const general_constraint_indicator_flags_6 = eg.readUByte();
    const general_level_idc = eg.readUByte();
    const sub_layer_profile_present_flags = [];
    const sub_layer_level_present_flags = [];
    for (let i = 0; i < max_sub_layers_minus1; i++) {
     sub_layer_profile_present_flags.push(eg.readBoolean());
     sub_layer_level_present_flags.push(eg.readBoolean());
    }
    if (max_sub_layers_minus1 > 0) {
     for (let i = max_sub_layers_minus1; i < 8; i++) {
      eg.readBits(2);
     }
    }
    for (let i = 0; i < max_sub_layers_minus1; i++) {
     if (sub_layer_profile_present_flags[i]) {
      eg.readUByte(); // sub_layer_profile_space, sub_layer_tier_flag, sub_layer_profile_idc
      eg.readUByte();
      eg.readUByte();
      eg.readUByte();
      eg.readUByte(); // sub_layer_profile_compatibility_flag
      eg.readUByte();
      eg.readUByte();
      eg.readUByte();
      eg.readUByte();
      eg.readUByte();
      eg.readUByte();
     }
     if (sub_layer_level_present_flags[i]) {
      eg.readUByte();
     }
    }
    eg.readUEG(); // seq_parameter_set_id
    const chroma_format_idc = eg.readUEG();
    if (chroma_format_idc == 3) {
     eg.skipBits(1); //separate_colour_plane_flag
    }
    const pic_width_in_luma_samples = eg.readUEG();
    const pic_height_in_luma_samples = eg.readUEG();
    const conformance_window_flag = eg.readBoolean();
    let pic_left_offset = 0,
     pic_right_offset = 0,
     pic_top_offset = 0,
     pic_bottom_offset = 0;
    if (conformance_window_flag) {
     pic_left_offset += eg.readUEG();
     pic_right_offset += eg.readUEG();
     pic_top_offset += eg.readUEG();
     pic_bottom_offset += eg.readUEG();
    }
    const bit_depth_luma_minus8 = eg.readUEG();
    const bit_depth_chroma_minus8 = eg.readUEG();
    const log2_max_pic_order_cnt_lsb_minus4 = eg.readUEG();
    const sub_layer_ordering_info_present_flag = eg.readBoolean();
    for (let i = sub_layer_ordering_info_present_flag ? 0 : max_sub_layers_minus1; i <= max_sub_layers_minus1; i++) {
     eg.skipUEG(); // max_dec_pic_buffering_minus1[i]
     eg.skipUEG(); // max_num_reorder_pics[i]
     eg.skipUEG(); // max_latency_increase_plus1[i]
    }
    eg.skipUEG(); // log2_min_luma_coding_block_size_minus3
    eg.skipUEG(); // log2_diff_max_min_luma_coding_block_size
    eg.skipUEG(); // log2_min_transform_block_size_minus2
    eg.skipUEG(); // log2_diff_max_min_transform_block_size
    eg.skipUEG(); // max_transform_hierarchy_depth_inter
    eg.skipUEG(); // max_transform_hierarchy_depth_intra
    const scaling_list_enabled_flag = eg.readBoolean();
    if (scaling_list_enabled_flag) {
     const sps_scaling_list_data_present_flag = eg.readBoolean();
     if (sps_scaling_list_data_present_flag) {
      for (let sizeId = 0; sizeId < 4; sizeId++) {
       for (let matrixId = 0; matrixId < (sizeId === 3 ? 2 : 6); matrixId++) {
        const scaling_list_pred_mode_flag = eg.readBoolean();
        if (!scaling_list_pred_mode_flag) {
         eg.readUEG(); // scaling_list_pred_matrix_id_delta
        } else {
         const coefNum = Math.min(64, 1 << (4 + (sizeId << 1)));
         if (sizeId > 1) {
          eg.readEG();
         }
         for (let i = 0; i < coefNum; i++) {
          eg.readEG();
         }
        }
       }
      }
     }
    }
    eg.readBoolean(); // amp_enabled_flag
    eg.readBoolean(); // sample_adaptive_offset_enabled_flag
    const pcm_enabled_flag = eg.readBoolean();
    if (pcm_enabled_flag) {
     eg.readUByte();
     eg.skipUEG();
     eg.skipUEG();
     eg.readBoolean();
    }
    const num_short_term_ref_pic_sets = eg.readUEG();
    let num_delta_pocs = 0;
    for (let i = 0; i < num_short_term_ref_pic_sets; i++) {
     let inter_ref_pic_set_prediction_flag = false;
     if (i !== 0) {
      inter_ref_pic_set_prediction_flag = eg.readBoolean();
     }
     if (inter_ref_pic_set_prediction_flag) {
      if (i === num_short_term_ref_pic_sets) {
       eg.readUEG();
      }
      eg.readBoolean();
      eg.readUEG();
      let next_num_delta_pocs = 0;
      for (let j = 0; j <= num_delta_pocs; j++) {
       const used_by_curr_pic_flag = eg.readBoolean();
       let use_delta_flag = false;
       if (!used_by_curr_pic_flag) {
        use_delta_flag = eg.readBoolean();
       }
       if (used_by_curr_pic_flag || use_delta_flag) {
        next_num_delta_pocs++;
       }
      }
      num_delta_pocs = next_num_delta_pocs;
     } else {
      const num_negative_pics = eg.readUEG();
      const num_positive_pics = eg.readUEG();
      num_delta_pocs = num_negative_pics + num_positive_pics;
      for (let j = 0; j < num_negative_pics; j++) {
       eg.readUEG();
       eg.readBoolean();
      }
      for (let j = 0; j < num_positive_pics; j++) {
       eg.readUEG();
       eg.readBoolean();
      }
     }
    }
    const long_term_ref_pics_present_flag = eg.readBoolean();
    if (long_term_ref_pics_present_flag) {
     const num_long_term_ref_pics_sps = eg.readUEG();
     for (let i = 0; i < num_long_term_ref_pics_sps; i++) {
      for (let j = 0; j < log2_max_pic_order_cnt_lsb_minus4 + 4; j++) {
       eg.readBits(1);
      }
      eg.readBits(1);
     }
    }
    let min_spatial_segmentation_idc = 0;
    let sar_width = 1,
     sar_height = 1;
    let fps_fixed = true,
     fps_den = 1,
     fps_num = 0;
    eg.readBoolean(); // sps_temporal_mvp_enabled_flag
    eg.readBoolean(); // strong_intra_smoothing_enabled_flag
    let default_display_window_flag = false;
    const vui_parameters_present_flag = eg.readBoolean();
    if (vui_parameters_present_flag) {
     const aspect_ratio_info_present_flag = eg.readBoolean();
     if (aspect_ratio_info_present_flag) {
      const aspect_ratio_idc = eg.readUByte();
      const sar_width_table = [1, 12, 10, 16, 40, 24, 20, 32, 80, 18, 15, 64, 160, 4, 3, 2];
      const sar_height_table = [1, 11, 11, 11, 33, 11, 11, 11, 33, 11, 11, 33, 99, 3, 2, 1];
      if (aspect_ratio_idc > 0 && aspect_ratio_idc < 16) {
       sar_width = sar_width_table[aspect_ratio_idc - 1];
       sar_height = sar_height_table[aspect_ratio_idc - 1];
      } else if (aspect_ratio_idc === 255) {
       sar_width = eg.readBits(16);
       sar_height = eg.readBits(16);
      }
     }
     const overscan_info_present_flag = eg.readBoolean();
     if (overscan_info_present_flag) {
      eg.readBoolean();
     }
     const video_signal_type_present_flag = eg.readBoolean();
     if (video_signal_type_present_flag) {
      eg.readBits(3);
      eg.readBoolean();
      const colour_description_present_flag = eg.readBoolean();
      if (colour_description_present_flag) {
       eg.readUByte();
       eg.readUByte();
       eg.readUByte();
      }
     }
     const chroma_loc_info_present_flag = eg.readBoolean();
     if (chroma_loc_info_present_flag) {
      eg.readUEG();
      eg.readUEG();
     }
     eg.readBoolean(); // neutral_chroma_indication_flag
     eg.readBoolean(); // field_seq_flag
     eg.readBoolean(); // frame_field_info_present_flag
     default_display_window_flag = eg.readBoolean();
     if (default_display_window_flag) {
      eg.skipUEG();
      eg.skipUEG();
      eg.skipUEG();
      eg.skipUEG();
     }
     const vui_timing_info_present_flag = eg.readBoolean();
     if (vui_timing_info_present_flag) {
      fps_den = eg.readBits(32);
      fps_num = eg.readBits(32);
      const vui_poc_proportional_to_timing_flag = eg.readBoolean();
      if (vui_poc_proportional_to_timing_flag) {
       eg.readUEG();
      }
      const vui_hrd_parameters_present_flag = eg.readBoolean();
      if (vui_hrd_parameters_present_flag) {
       //const commonInfPresentFlag = true;
       //if (commonInfPresentFlag) {
       const nal_hrd_parameters_present_flag = eg.readBoolean();
       const vcl_hrd_parameters_present_flag = eg.readBoolean();
       let sub_pic_hrd_params_present_flag = false;
       if (nal_hrd_parameters_present_flag || vcl_hrd_parameters_present_flag) {
        sub_pic_hrd_params_present_flag = eg.readBoolean();
        if (sub_pic_hrd_params_present_flag) {
         eg.readUByte();
         eg.readBits(5);
         eg.readBoolean();
         eg.readBits(5);
        }
        eg.readBits(4); // bit_rate_scale
        eg.readBits(4); // cpb_size_scale
        if (sub_pic_hrd_params_present_flag) {
         eg.readBits(4);
        }
        eg.readBits(5);
        eg.readBits(5);
        eg.readBits(5);
       }
       //}
       for (let i = 0; i <= max_sub_layers_minus1; i++) {
        fps_fixed = eg.readBoolean(); // fixed_pic_rate_general_flag
        const fixed_pic_rate_within_cvs_flag = fps_fixed || eg.readBoolean();
        let low_delay_hrd_flag = false;
        if (fixed_pic_rate_within_cvs_flag) {
         eg.readEG();
        } else {
         low_delay_hrd_flag = eg.readBoolean();
        }
        const cpb_cnt = low_delay_hrd_flag ? 1 : eg.readUEG() + 1;
        if (nal_hrd_parameters_present_flag) {
         for (let j = 0; j < cpb_cnt; j++) {
          eg.readUEG();
          eg.readUEG();
          if (sub_pic_hrd_params_present_flag) {
           eg.readUEG();
           eg.readUEG();
          }
          eg.skipBits(1);
         }
        }
        if (vcl_hrd_parameters_present_flag) {
         for (let j = 0; j < cpb_cnt; j++) {
          eg.readUEG();
          eg.readUEG();
          if (sub_pic_hrd_params_present_flag) {
           eg.readUEG();
           eg.readUEG();
          }
          eg.skipBits(1);
         }
        }
       }
      }
     }
     const bitstream_restriction_flag = eg.readBoolean();
     if (bitstream_restriction_flag) {
      eg.readBoolean(); // tiles_fixed_structure_flag
      eg.readBoolean(); // motion_vectors_over_pic_boundaries_flag
      eg.readBoolean(); // restricted_ref_pic_lists_flag
      min_spatial_segmentation_idc = eg.readUEG();
     }
    }
    let width = pic_width_in_luma_samples,
     height = pic_height_in_luma_samples;
    if (conformance_window_flag) {
     let chroma_scale_w = 1,
      chroma_scale_h = 1;
     if (chroma_format_idc === 1) {
      // YUV 420
      chroma_scale_w = chroma_scale_h = 2;
     } else if (chroma_format_idc == 2) {
      // YUV 422
      chroma_scale_w = 2;
     }
     width = pic_width_in_luma_samples - chroma_scale_w * pic_right_offset - chroma_scale_w * pic_left_offset;
     height = pic_height_in_luma_samples - chroma_scale_h * pic_bottom_offset - chroma_scale_h * pic_top_offset;
    }
    const profile_space_string = general_profile_space ? ['A', 'B', 'C'][general_profile_space] : '';
    const profile_compatibility_buf = (general_profile_compatibility_flags_1 << 24) | (general_profile_compatibility_flags_2 << 16) | (general_profile_compatibility_flags_3 << 8) | general_profile_compatibility_flags_4;
    let profile_compatibility_rev = 0;
    for (let i = 0; i < 32; i++) {
     profile_compatibility_rev = (profile_compatibility_rev | (((profile_compatibility_buf >> i) & 1) << (31 - i))) >>> 0; // reverse bit position (and cast as UInt32)
    }
    let profile_compatibility_flags_string = profile_compatibility_rev.toString(16);
    if (general_profile_idc === 1 && profile_compatibility_flags_string === '2') {
     profile_compatibility_flags_string = '6';
    }
    const tier_flag_string = general_tier_flag ? 'H' : 'L';
    return {
     codecString: `hvc1.${profile_space_string}${general_profile_idc}.${profile_compatibility_flags_string}.${tier_flag_string}${general_level_idc}.B0`,
     params: {
      general_tier_flag,
      general_profile_idc,
      general_profile_space,
      general_profile_compatibility_flags: [general_profile_compatibility_flags_1, general_profile_compatibility_flags_2, general_profile_compatibility_flags_3, general_profile_compatibility_flags_4],
      general_constraint_indicator_flags: [general_constraint_indicator_flags_1, general_constraint_indicator_flags_2, general_constraint_indicator_flags_3, general_constraint_indicator_flags_4, general_constraint_indicator_flags_5, general_constraint_indicator_flags_6],
      general_level_idc,
      bit_depth: bit_depth_luma_minus8 + 8,
      bit_depth_luma_minus8,
      bit_depth_chroma_minus8,
      min_spatial_segmentation_idc,
      chroma_format_idc: chroma_format_idc,
      frame_rate: {
       fixed: fps_fixed,
       fps: fps_num / fps_den,
      },
     },
     width,
     height,
     pixelRatio: [sar_width, sar_height],
    };
   }
   readPPS(pps) {
    const eg = new ExpGolomb(this.ebsp2rbsp(pps));
    eg.readUByte();
    eg.readUByte();
    eg.skipUEG(); // pic_parameter_set_id
    eg.skipUEG(); // seq_parameter_set_id
    eg.skipBits(2); // dependent_slice_segments_enabled_flag, output_flag_present_flag
    eg.skipBits(3); // num_extra_slice_header_bits
    eg.skipBits(2); // sign_data_hiding_enabled_flag, cabac_init_present_flag
    eg.skipUEG();
    eg.skipUEG();
    eg.skipEG(); // init_qp_minus26
    eg.skipBits(2); // constrained_intra_pred_flag, transform_skip_enabled_flag
    const cu_qp_delta_enabled_flag = eg.readBoolean();
    if (cu_qp_delta_enabled_flag) {
     eg.skipUEG();
    }
    eg.skipEG(); // cb_qp_offset
    eg.skipEG(); // cr_qp_offset
    eg.skipBits(4); // pps_slice_chroma_qp_offsets_present_flag, weighted_pred_flag, weighted_bipred_flag, transquant_bypass_enabled_flag
    const tiles_enabled_flag = eg.readBoolean();
    const entropy_coding_sync_enabled_flag = eg.readBoolean();
    let parallelismType = 1; // slice-based parallel decoding
    if (entropy_coding_sync_enabled_flag && tiles_enabled_flag) {
     parallelismType = 0; // mixed-type parallel decoding
    } else if (entropy_coding_sync_enabled_flag) {
     parallelismType = 3; // wavefront-based parallel decoding
    } else if (tiles_enabled_flag) {
     parallelismType = 2; // tile-based parallel decoding
    }
    return {
     parallelismType,
    };
   }
   matchSPS(sps1, sps2) {
    // compare without headers and VPS related params
    return String.fromCharCode.apply(null, sps1).substr(3) === String.fromCharCode.apply(null, sps2).substr(3);
   }
  }

  const PACKET_LENGTH = 188;
  class TSDemuxer {
   constructor(observer, config, typeSupported, logger) {
    this.logger = void 0;
    this.observer = void 0;
    this.config = void 0;
    this.typeSupported = void 0;
    this.sampleAes = null;
    this.pmtParsed = false;
    this.audioCodec = void 0;
    this.videoCodec = void 0;
    this._pmtId = -1;
    this._videoTrack = void 0;
    this._audioTrack = void 0;
    this._id3Track = void 0;
    this._txtTrack = void 0;
    this.aacOverFlow = null;
    this.remainderData = null;
    this.videoParser = void 0;
    this.observer = observer;
    this.config = config;
    this.typeSupported = typeSupported;
    this.logger = logger;
    this.videoParser = null;
   }
   static probe(data, logger) {
    const syncOffset = TSDemuxer.syncOffset(data);
    if (syncOffset > 0) {
     logger.warn(`MPEG2-TS detected but first sync word found @ offset ${syncOffset}`);
    }
    return syncOffset !== -1;
   }
   static syncOffset(data) {
    const length = data.length;
    let scanwindow = Math.min(PACKET_LENGTH * 5, length - PACKET_LENGTH) + 1;
    let i = 0;
    while (i < scanwindow) {
     // a TS init segment should contain at least 2 TS packets: PAT and PMT, each starting with 0x47
     let foundPat = false;
     let packetStart = -1;
     let tsPackets = 0;
     for (let j = i; j < length; j += PACKET_LENGTH) {
      if (data[j] === 0x47 && (length - j === PACKET_LENGTH || data[j + PACKET_LENGTH] === 0x47)) {
       tsPackets++;
       if (packetStart === -1) {
        packetStart = j;
        // First sync word found at offset, increase scan length (#5251)
        if (packetStart !== 0) {
         scanwindow = Math.min(packetStart + PACKET_LENGTH * 99, data.length - PACKET_LENGTH) + 1;
        }
       }
       if (!foundPat) {
        foundPat = parsePID(data, j) === 0;
       }
       // Sync word found at 0 with 3 packets, or found at offset least 2 packets up to scanwindow (#5501)
       if (foundPat && tsPackets > 1 && ((packetStart === 0 && tsPackets > 2) || j + PACKET_LENGTH > scanwindow)) {
        return packetStart;
       }
      } else if (tsPackets) {
       // Exit if sync word found, but does not contain contiguous packets
       return -1;
      } else {
       break;
      }
     }
     i++;
    }
    return -1;
   }

   /**
    * Creates a track model internal to demuxer used to drive remuxing input
    */
   static createTrack(type, duration) {
    return {
     container: type === 'video' || type === 'audio' ? 'video/mp2t' : undefined,
     type,
     id: RemuxerTrackIdConfig[type],
     pid: -1,
     inputTimeScale: 90000,
     sequenceNumber: 0,
     samples: [],
     dropped: 0,
     duration: type === 'audio' ? duration : undefined,
    };
   }

   /**
    * Initializes a new init segment on the demuxer/remuxer interface. Needed for discontinuities/track-switches (or at stream start)
    * Resets all internal track instances of the demuxer.
    */
   resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
    this.pmtParsed = false;
    this._pmtId = -1;
    this._videoTrack = TSDemuxer.createTrack('video');
    this._videoTrack.duration = trackDuration;
    this._audioTrack = TSDemuxer.createTrack('audio', trackDuration);
    this._id3Track = TSDemuxer.createTrack('id3');
    this._txtTrack = TSDemuxer.createTrack('text');
    this._audioTrack.segmentCodec = 'aac';

    // flush any partial content
    this.videoParser = null;
    this.aacOverFlow = null;
    this.remainderData = null;
    this.audioCodec = audioCodec;
    this.videoCodec = videoCodec;
   }
   resetTimeStamp() {}
   resetContiguity() {
    const { _audioTrack, _videoTrack, _id3Track } = this;
    if (_audioTrack) {
     _audioTrack.pesData = null;
    }
    if (_videoTrack) {
     _videoTrack.pesData = null;
    }
    if (_id3Track) {
     _id3Track.pesData = null;
    }
    this.aacOverFlow = null;
    this.remainderData = null;
   }
   demux(data, timeOffset, isSampleAes = false, flush = false) {
    if (!isSampleAes) {
     this.sampleAes = null;
    }
    let pes;
    const videoTrack = this._videoTrack;
    const audioTrack = this._audioTrack;
    const id3Track = this._id3Track;
    const textTrack = this._txtTrack;
    let videoPid = videoTrack.pid;
    let videoData = videoTrack.pesData;
    let audioPid = audioTrack.pid;
    let id3Pid = id3Track.pid;
    let audioData = audioTrack.pesData;
    let id3Data = id3Track.pesData;
    let unknownPID = null;
    let pmtParsed = this.pmtParsed;
    let pmtId = this._pmtId;
    let len = data.length;
    if (this.remainderData) {
     data = appendUint8Array(this.remainderData, data);
     len = data.length;
     this.remainderData = null;
    }
    if (len < PACKET_LENGTH && !flush) {
     this.remainderData = data;
     return {
      audioTrack,
      videoTrack,
      id3Track,
      textTrack,
     };
    }
    const syncOffset = Math.max(0, TSDemuxer.syncOffset(data));
    len -= (len - syncOffset) % PACKET_LENGTH;
    if (len < data.byteLength && !flush) {
     this.remainderData = new Uint8Array(data.buffer, len, data.buffer.byteLength - len);
    }

    // loop through TS packets
    let tsPacketErrors = 0;
    for (let start = syncOffset; start < len; start += PACKET_LENGTH) {
     if (data[start] === 0x47) {
      const stt = !!(data[start + 1] & 0x40);
      const pid = parsePID(data, start);
      const atf = (data[start + 3] & 0x30) >> 4;

      // if an adaption field is present, its length is specified by the fifth byte of the TS packet header.
      let offset;
      if (atf > 1) {
       offset = start + 5 + data[start + 4];
       // continue if there is only adaptation field
       if (offset === start + PACKET_LENGTH) {
        continue;
       }
      } else {
       offset = start + 4;
      }
      switch (pid) {
       case videoPid:
        if (stt) {
         if (videoData && (pes = parsePES(videoData, this.logger))) {
          this.readyVideoParser(videoTrack.segmentCodec);
          if (this.videoParser !== null) {
           this.videoParser.parsePES(videoTrack, textTrack, pes, false);
          }
         }
         videoData = {
          data: [],
          size: 0,
         };
        }
        if (videoData) {
         videoData.data.push(data.subarray(offset, start + PACKET_LENGTH));
         videoData.size += start + PACKET_LENGTH - offset;
        }
        break;
       case audioPid:
        if (stt) {
         if (audioData && (pes = parsePES(audioData, this.logger))) {
          switch (audioTrack.segmentCodec) {
           case 'aac':
            this.parseAACPES(audioTrack, pes);
            break;
           case 'mp3':
            this.parseMPEGPES(audioTrack, pes);
            break;
           case 'ac3':
            {
             this.parseAC3PES(audioTrack, pes);
            }
            break;
          }
         }
         audioData = {
          data: [],
          size: 0,
         };
        }
        if (audioData) {
         audioData.data.push(data.subarray(offset, start + PACKET_LENGTH));
         audioData.size += start + PACKET_LENGTH - offset;
        }
        break;
       case id3Pid:
        if (stt) {
         if (id3Data && (pes = parsePES(id3Data, this.logger))) {
          this.parseID3PES(id3Track, pes);
         }
         id3Data = {
          data: [],
          size: 0,
         };
        }
        if (id3Data) {
         id3Data.data.push(data.subarray(offset, start + PACKET_LENGTH));
         id3Data.size += start + PACKET_LENGTH - offset;
        }
        break;
       case 0:
        if (stt) {
         offset += data[offset] + 1;
        }
        pmtId = this._pmtId = parsePAT(data, offset);
        // this.logger.log('PMT PID:'  + this._pmtId);
        break;
       case pmtId: {
        if (stt) {
         offset += data[offset] + 1;
        }
        const parsedPIDs = parsePMT(data, offset, this.typeSupported, isSampleAes, this.observer, this.logger);

        // only update track id if track PID found while parsing PMT
        // this is to avoid resetting the PID to -1 in case
        // track PID transiently disappears from the stream
        // this could happen in case of transient missing audio samples for example
        // NOTE this is only the PID of the track as found in TS,
        // but we are not using this for MP4 track IDs.
        videoPid = parsedPIDs.videoPid;
        if (videoPid > 0) {
         videoTrack.pid = videoPid;
         videoTrack.segmentCodec = parsedPIDs.segmentVideoCodec;
        }
        audioPid = parsedPIDs.audioPid;
        if (audioPid > 0) {
         audioTrack.pid = audioPid;
         audioTrack.segmentCodec = parsedPIDs.segmentAudioCodec;
        }
        id3Pid = parsedPIDs.id3Pid;
        if (id3Pid > 0) {
         id3Track.pid = id3Pid;
        }
        if (unknownPID !== null && !pmtParsed) {
         this.logger.warn(`MPEG-TS PMT found at ${start} after unknown PID '${unknownPID}'. Backtracking to sync byte @${syncOffset} to parse all TS packets.`);
         unknownPID = null;
         // we set it to -188, the += 188 in the for loop will reset start to 0
         start = syncOffset - 188;
        }
        pmtParsed = this.pmtParsed = true;
        break;
       }
       case 0x11:
       case 0x1fff:
        break;
       default:
        unknownPID = pid;
        break;
      }
     } else {
      tsPacketErrors++;
     }
    }
    if (tsPacketErrors > 0) {
     emitParsingError(this.observer, new Error(`Found ${tsPacketErrors} TS packet/s that do not start with 0x47`), undefined, this.logger);
    }
    videoTrack.pesData = videoData;
    audioTrack.pesData = audioData;
    id3Track.pesData = id3Data;
    const demuxResult = {
     audioTrack,
     videoTrack,
     id3Track,
     textTrack,
    };
    if (flush) {
     this.extractRemainingSamples(demuxResult);
    }
    return demuxResult;
   }
   flush() {
    const { remainderData } = this;
    this.remainderData = null;
    let result;
    if (remainderData) {
     result = this.demux(remainderData, -1, false, true);
    } else {
     result = {
      videoTrack: this._videoTrack,
      audioTrack: this._audioTrack,
      id3Track: this._id3Track,
      textTrack: this._txtTrack,
     };
    }
    this.extractRemainingSamples(result);
    if (this.sampleAes) {
     return this.decrypt(result, this.sampleAes);
    }
    return result;
   }
   extractRemainingSamples(demuxResult) {
    const { audioTrack, videoTrack, id3Track, textTrack } = demuxResult;
    const videoData = videoTrack.pesData;
    const audioData = audioTrack.pesData;
    const id3Data = id3Track.pesData;
    // try to parse last PES packets
    let pes;
    if (videoData && (pes = parsePES(videoData, this.logger))) {
     this.readyVideoParser(videoTrack.segmentCodec);
     if (this.videoParser !== null) {
      this.videoParser.parsePES(videoTrack, textTrack, pes, true);
      videoTrack.pesData = null;
     }
    } else {
     // either avcData null or PES truncated, keep it for next frag parsing
     videoTrack.pesData = videoData;
    }
    if (audioData && (pes = parsePES(audioData, this.logger))) {
     switch (audioTrack.segmentCodec) {
      case 'aac':
       this.parseAACPES(audioTrack, pes);
       break;
      case 'mp3':
       this.parseMPEGPES(audioTrack, pes);
       break;
      case 'ac3':
       {
        this.parseAC3PES(audioTrack, pes);
       }
       break;
     }
     audioTrack.pesData = null;
    } else {
     if (audioData != null && audioData.size) {
      this.logger.log('last AAC PES packet truncated,might overlap between fragments');
     }

     // either audioData null or PES truncated, keep it for next frag parsing
     audioTrack.pesData = audioData;
    }
    if (id3Data && (pes = parsePES(id3Data, this.logger))) {
     this.parseID3PES(id3Track, pes);
     id3Track.pesData = null;
    } else {
     // either id3Data null or PES truncated, keep it for next frag parsing
     id3Track.pesData = id3Data;
    }
   }
   demuxSampleAes(data, keyData, timeOffset) {
    const demuxResult = this.demux(data, timeOffset, true, !this.config.progressive);
    const sampleAes = (this.sampleAes = new SampleAesDecrypter(this.observer, this.config, keyData));
    return this.decrypt(demuxResult, sampleAes);
   }
   readyVideoParser(codec) {
    if (this.videoParser === null) {
     if (codec === 'avc') {
      this.videoParser = new AvcVideoParser();
     } else if (codec === 'hevc') {
      this.videoParser = new HevcVideoParser();
     }
    }
   }
   decrypt(demuxResult, sampleAes) {
    return new Promise((resolve) => {
     const { audioTrack, videoTrack } = demuxResult;
     if (audioTrack.samples && audioTrack.segmentCodec === 'aac') {
      sampleAes.decryptAacSamples(audioTrack.samples, 0, () => {
       if (videoTrack.samples) {
        sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, () => {
         resolve(demuxResult);
        });
       } else {
        resolve(demuxResult);
       }
      });
     } else if (videoTrack.samples) {
      sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, () => {
       resolve(demuxResult);
      });
     }
    });
   }
   destroy() {
    if (this.observer) {
     this.observer.removeAllListeners();
    }
    // @ts-ignore
    this.config = this.logger = this.observer = null;
    this.aacOverFlow = this.videoParser = this.remainderData = this.sampleAes = null;
    this._videoTrack = this._audioTrack = this._id3Track = this._txtTrack = undefined;
   }
   parseAACPES(track, pes) {
    let startOffset = 0;
    const aacOverFlow = this.aacOverFlow;
    let data = pes.data;
    if (aacOverFlow) {
     this.aacOverFlow = null;
     const frameMissingBytes = aacOverFlow.missing;
     const sampleLength = aacOverFlow.sample.unit.byteLength;
     // logger.log(`AAC: append overflowing ${sampleLength} bytes to beginning of new PES`);
     if (frameMissingBytes === -1) {
      data = appendUint8Array(aacOverFlow.sample.unit, data);
     } else {
      const frameOverflowBytes = sampleLength - frameMissingBytes;
      aacOverFlow.sample.unit.set(data.subarray(0, frameMissingBytes), frameOverflowBytes);
      track.samples.push(aacOverFlow.sample);
      startOffset = aacOverFlow.missing;
     }
    }
    // look for ADTS header (0xFFFx)
    let offset;
    let len;
    for (offset = startOffset, len = data.length; offset < len - 1; offset++) {
     if (isHeader$1(data, offset)) {
      break;
     }
    }
    // if ADTS header does not start straight from the beginning of the PES payload, raise an error
    if (offset !== startOffset) {
     let reason;
     const recoverable = offset < len - 1;
     if (recoverable) {
      reason = `AAC PES did not start with ADTS header,offset:${offset}`;
     } else {
      reason = 'No ADTS header found in AAC PES';
     }
     emitParsingError(this.observer, new Error(reason), recoverable, this.logger);
     if (!recoverable) {
      return;
     }
    }
    initTrackConfig(track, this.observer, data, offset, this.audioCodec);
    let pts;
    if (pes.pts !== undefined) {
     pts = pes.pts;
    } else if (aacOverFlow) {
     // if last AAC frame is overflowing, we should ensure timestamps are contiguous:
     // first sample PTS should be equal to last sample PTS + frameDuration
     const frameDuration = getFrameDuration(track.samplerate);
     pts = aacOverFlow.sample.pts + frameDuration;
    } else {
     this.logger.warn('[tsdemuxer]: AAC PES unknown PTS');
     return;
    }

    // scan for aac samples
    let frameIndex = 0;
    let frame;
    while (offset < len) {
     frame = appendFrame$2(track, data, offset, pts, frameIndex);
     offset += frame.length;
     if (!frame.missing) {
      frameIndex++;
      for (; offset < len - 1; offset++) {
       if (isHeader$1(data, offset)) {
        break;
       }
      }
     } else {
      this.aacOverFlow = frame;
      break;
     }
    }
   }
   parseMPEGPES(track, pes) {
    const data = pes.data;
    const length = data.length;
    let frameIndex = 0;
    let offset = 0;
    const pts = pes.pts;
    if (pts === undefined) {
     this.logger.warn('[tsdemuxer]: MPEG PES unknown PTS');
     return;
    }
    while (offset < length) {
     if (isHeader(data, offset)) {
      const frame = appendFrame$1(track, data, offset, pts, frameIndex);
      if (frame) {
       offset += frame.length;
       frameIndex++;
      } else {
       // logger.log('Unable to parse Mpeg audio frame');
       break;
      }
     } else {
      // nothing found, keep looking
      offset++;
     }
    }
   }
   parseAC3PES(track, pes) {
    {
     const data = pes.data;
     const pts = pes.pts;
     if (pts === undefined) {
      this.logger.warn('[tsdemuxer]: AC3 PES unknown PTS');
      return;
     }
     const length = data.length;
     let frameIndex = 0;
     let offset = 0;
     let parsed;
     while (offset < length && (parsed = appendFrame(track, data, offset, pts, frameIndex++)) > 0) {
      offset += parsed;
     }
    }
   }
   parseID3PES(id3Track, pes) {
    if (pes.pts === undefined) {
     this.logger.warn('[tsdemuxer]: ID3 PES unknown PTS');
     return;
    }
    const id3Sample = _extends({}, pes, {
     type: this._videoTrack ? MetadataSchema.emsg : MetadataSchema.audioId3,
     duration: Number.POSITIVE_INFINITY,
    });
    id3Track.samples.push(id3Sample);
   }
  }
  function parsePID(data, offset) {
   // pid is a 13-bit field starting at the last bit of TS[1]
   return ((data[offset + 1] & 0x1f) << 8) + data[offset + 2];
  }
  function parsePAT(data, offset) {
   // skip the PSI header and parse the first PMT entry
   return ((data[offset + 10] & 0x1f) << 8) | data[offset + 11];
  }
  function parsePMT(data, offset, typeSupported, isSampleAes, observer, logger) {
   const result = {
    audioPid: -1,
    videoPid: -1,
    id3Pid: -1,
    segmentVideoCodec: 'avc',
    segmentAudioCodec: 'aac',
   };
   const sectionLength = ((data[offset + 1] & 0x0f) << 8) | data[offset + 2];
   const tableEnd = offset + 3 + sectionLength - 4;
   // to determine where the table is, we have to figure out how
   // long the program info descriptors are
   const programInfoLength = ((data[offset + 10] & 0x0f) << 8) | data[offset + 11];
   // advance the offset to the first entry in the mapping table
   offset += 12 + programInfoLength;
   while (offset < tableEnd) {
    const pid = parsePID(data, offset);
    const esInfoLength = ((data[offset + 3] & 0x0f) << 8) | data[offset + 4];
    switch (data[offset]) {
     case 0xcf:
      // SAMPLE-AES AAC
      if (!isSampleAes) {
       logEncryptedSamplesFoundInUnencryptedStream('ADTS AAC', logger);
       break;
      }
     /* falls through */
     case 0x0f:
      // ISO/IEC 13818-7 ADTS AAC (MPEG-2 lower bit-rate audio)
      // logger.log('AAC PID:'  + pid);
      if (result.audioPid === -1) {
       result.audioPid = pid;
      }
      break;

     // Packetized metadata (ID3)
     case 0x15:
      // logger.log('ID3 PID:'  + pid);
      if (result.id3Pid === -1) {
       result.id3Pid = pid;
      }
      break;
     case 0xdb:
      // SAMPLE-AES AVC
      if (!isSampleAes) {
       logEncryptedSamplesFoundInUnencryptedStream('H.264', logger);
       break;
      }
     /* falls through */
     case 0x1b:
      // ITU-T Rec. H.264 and ISO/IEC 14496-10 (lower bit-rate video)
      // logger.log('AVC PID:'  + pid);
      if (result.videoPid === -1) {
       result.videoPid = pid;
      }
      break;

     // ISO/IEC 11172-3 (MPEG-1 audio)
     // or ISO/IEC 13818-3 (MPEG-2 halved sample rate audio)
     case 0x03:
     case 0x04:
      // logger.log('MPEG PID:'  + pid);
      if (!typeSupported.mpeg && !typeSupported.mp3) {
       logger.log('MPEG audio found, not supported in this browser');
      } else if (result.audioPid === -1) {
       result.audioPid = pid;
       result.segmentAudioCodec = 'mp3';
      }
      break;
     case 0xc1:
      // SAMPLE-AES AC3
      if (!isSampleAes) {
       logEncryptedSamplesFoundInUnencryptedStream('AC-3', logger);
       break;
      }
     /* falls through */
     case 0x81:
      {
       if (!typeSupported.ac3) {
        logger.log('AC-3 audio found, not supported in this browser');
       } else if (result.audioPid === -1) {
        result.audioPid = pid;
        result.segmentAudioCodec = 'ac3';
       }
      }
      break;
     case 0x06:
      // stream_type 6 can mean a lot of different things in case of DVB.
      // We need to look at the descriptors. Right now, we're only interested
      // in AC-3 audio, so we do the descriptor parsing only when we don't have
      // an audio PID yet.
      if (result.audioPid === -1 && esInfoLength > 0) {
       let parsePos = offset + 5;
       let remaining = esInfoLength;
       while (remaining > 2) {
        const descriptorId = data[parsePos];
        switch (descriptorId) {
         case 0x6a:
          // DVB Descriptor for AC-3
          {
           if (typeSupported.ac3 !== true) {
            logger.log('AC-3 audio found, not supported in this browser for now');
           } else {
            result.audioPid = pid;
            result.segmentAudioCodec = 'ac3';
           }
          }
          break;
        }
        const descriptorLen = data[parsePos + 1] + 2;
        parsePos += descriptorLen;
        remaining -= descriptorLen;
       }
      }
      break;
     case 0xc2: // SAMPLE-AES EC3
     /* falls through */
     case 0x87:
      emitParsingError(observer, new Error('Unsupported EC-3 in M2TS found'), undefined, logger);
      return result;
     case 0x24:
      // ITU-T Rec. H.265 and ISO/IEC 23008-2 (HEVC)
      {
       if (result.videoPid === -1) {
        result.videoPid = pid;
        result.segmentVideoCodec = 'hevc';
        logger.log('HEVC in M2TS found');
       }
      }
      break;
    }
    // move to the next table entry
    // skip past the elementary stream descriptors, if present
    offset += esInfoLength + 5;
   }
   return result;
  }
  function emitParsingError(observer, error, levelRetry, logger) {
   logger.warn(`parsing error: ${error.message}`);
   observer.emit(Events.ERROR, Events.ERROR, {
    type: ErrorTypes.MEDIA_ERROR,
    details: ErrorDetails.FRAG_PARSING_ERROR,
    fatal: false,
    levelRetry,
    error,
    reason: error.message,
   });
  }
  function logEncryptedSamplesFoundInUnencryptedStream(type, logger) {
   logger.log(`${type} with AES-128-CBC encryption found in unencrypted stream`);
  }
  function parsePES(stream, logger) {
   let i = 0;
   let frag;
   let pesLen;
   let pesHdrLen;
   let pesPts;
   let pesDts;
   const data = stream.data;
   // safety check
   if (!stream || stream.size === 0) {
    return null;
   }

   // we might need up to 19 bytes to read PES header
   // if first chunk of data is less than 19 bytes, let's merge it with following ones until we get 19 bytes
   // usually only one merge is needed (and this is rare ...)
   while (data[0].length < 19 && data.length > 1) {
    data[0] = appendUint8Array(data[0], data[1]);
    data.splice(1, 1);
   }
   // retrieve PTS/DTS from first fragment
   frag = data[0];
   const pesPrefix = (frag[0] << 16) + (frag[1] << 8) + frag[2];
   if (pesPrefix === 1) {
    pesLen = (frag[4] << 8) + frag[5];
    // if PES parsed length is not zero and greater than total received length, stop parsing. PES might be truncated
    // minus 6 : PES header size
    if (pesLen && pesLen > stream.size - 6) {
     return null;
    }
    const pesFlags = frag[7];
    if (pesFlags & 0xc0) {
     /* PES header described here : http://dvd.sourceforge.net/dvdinfo/pes-hdr.html
          as PTS / DTS is 33 bit we cannot use bitwise operator in JS,
          as Bitwise operators treat their operands as a sequence of 32 bits */
     pesPts =
      (frag[9] & 0x0e) * 536870912 +
      // 1 << 29
      (frag[10] & 0xff) * 4194304 +
      // 1 << 22
      (frag[11] & 0xfe) * 16384 +
      // 1 << 14
      (frag[12] & 0xff) * 128 +
      // 1 << 7
      (frag[13] & 0xfe) / 2;
     if (pesFlags & 0x40) {
      pesDts =
       (frag[14] & 0x0e) * 536870912 +
       // 1 << 29
       (frag[15] & 0xff) * 4194304 +
       // 1 << 22
       (frag[16] & 0xfe) * 16384 +
       // 1 << 14
       (frag[17] & 0xff) * 128 +
       // 1 << 7
       (frag[18] & 0xfe) / 2;
      if (pesPts - pesDts > 60 * 90000) {
       logger.warn(`${Math.round((pesPts - pesDts) / 90000)}s delta between PTS and DTS, align them`);
       pesPts = pesDts;
      }
     } else {
      pesDts = pesPts;
     }
    }
    pesHdrLen = frag[8];
    // 9 bytes : 6 bytes for PES header + 3 bytes for PES extension
    let payloadStartOffset = pesHdrLen + 9;
    if (stream.size <= payloadStartOffset) {
     return null;
    }
    stream.size -= payloadStartOffset;
    // reassemble PES packet
    const pesData = new Uint8Array(stream.size);
    for (let j = 0, dataLen = data.length; j < dataLen; j++) {
     frag = data[j];
     let len = frag.byteLength;
     if (payloadStartOffset) {
      if (payloadStartOffset > len) {
       // trim full frag if PES header bigger than frag
       payloadStartOffset -= len;
       continue;
      } else {
       // trim partial frag if PES header smaller than frag
       frag = frag.subarray(payloadStartOffset);
       len -= payloadStartOffset;
       payloadStartOffset = 0;
      }
     }
     pesData.set(frag, i);
     i += len;
    }
    if (pesLen) {
     // payload size : remove PES header + PES extension
     pesLen -= pesHdrLen + 3;
    }
    return {
     data: pesData,
     pts: pesPts,
     dts: pesDts,
     len: pesLen,
    };
   }
   return null;
  }

  /**
   *  AAC helper
   */

  class AAC {
   static getSilentFrame(codec, channelCount) {
    switch (codec) {
     case 'mp4a.40.2':
      if (channelCount === 1) {
       return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);
      } else if (channelCount === 2) {
       return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);
      } else if (channelCount === 3) {
       return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);
      } else if (channelCount === 4) {
       return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);
      } else if (channelCount === 5) {
       return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);
      } else if (channelCount === 6) {
       return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);
      }
      break;
     // handle HE-AAC below (mp4a.40.5 / mp4a.40.29)
     default:
      if (channelCount === 1) {
       // ffmpeg -y -f lavfi -i "aevalsrc=0:d=0.05" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
       return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
      } else if (channelCount === 2) {
       // ffmpeg -y -f lavfi -i "aevalsrc=0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
       return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
      } else if (channelCount === 3) {
       // ffmpeg -y -f lavfi -i "aevalsrc=0|0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
       return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
      }
      break;
    }
    return undefined;
   }
  }

  /**
   * Generate MP4 Box
   */

  const UINT32_MAX = Math.pow(2, 32) - 1;
  class MP4 {
   static init() {
    MP4.types = {
     avc1: [],
     // codingname
     avcC: [],
     hvc1: [],
     hvcC: [],
     btrt: [],
     dinf: [],
     dref: [],
     esds: [],
     ftyp: [],
     hdlr: [],
     mdat: [],
     mdhd: [],
     mdia: [],
     mfhd: [],
     minf: [],
     moof: [],
     moov: [],
     mp4a: [],
     '.mp3': [],
     dac3: [],
     'ac-3': [],
     mvex: [],
     mvhd: [],
     pasp: [],
     sdtp: [],
     stbl: [],
     stco: [],
     stsc: [],
     stsd: [],
     stsz: [],
     stts: [],
     tfdt: [],
     tfhd: [],
     traf: [],
     trak: [],
     trun: [],
     trex: [],
     tkhd: [],
     vmhd: [],
     smhd: [],
    };
    let i;
    for (i in MP4.types) {
     if (MP4.types.hasOwnProperty(i)) {
      MP4.types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];
     }
    }
    const videoHdlr = new Uint8Array([
     0x00,
     // version 0
     0x00,
     0x00,
     0x00,
     // flags
     0x00,
     0x00,
     0x00,
     0x00,
     // pre_defined
     0x76,
     0x69,
     0x64,
     0x65,
     // handler_type: 'vide'
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x56,
     0x69,
     0x64,
     0x65,
     0x6f,
     0x48,
     0x61,
     0x6e,
     0x64,
     0x6c,
     0x65,
     0x72,
     0x00, // name: 'VideoHandler'
    ]);
    const audioHdlr = new Uint8Array([
     0x00,
     // version 0
     0x00,
     0x00,
     0x00,
     // flags
     0x00,
     0x00,
     0x00,
     0x00,
     // pre_defined
     0x73,
     0x6f,
     0x75,
     0x6e,
     // handler_type: 'soun'
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x53,
     0x6f,
     0x75,
     0x6e,
     0x64,
     0x48,
     0x61,
     0x6e,
     0x64,
     0x6c,
     0x65,
     0x72,
     0x00, // name: 'SoundHandler'
    ]);
    MP4.HDLR_TYPES = {
     video: videoHdlr,
     audio: audioHdlr,
    };
    const dref = new Uint8Array([
     0x00,
     // version 0
     0x00,
     0x00,
     0x00,
     // flags
     0x00,
     0x00,
     0x00,
     0x01,
     // entry_count
     0x00,
     0x00,
     0x00,
     0x0c,
     // entry_size
     0x75,
     0x72,
     0x6c,
     0x20,
     // 'url' type
     0x00,
     // version 0
     0x00,
     0x00,
     0x01, // entry_flags
    ]);
    const stco = new Uint8Array([
     0x00,
     // version
     0x00,
     0x00,
     0x00,
     // flags
     0x00,
     0x00,
     0x00,
     0x00, // entry_count
    ]);
    MP4.STTS = MP4.STSC = MP4.STCO = stco;
    MP4.STSZ = new Uint8Array([
     0x00,
     // version
     0x00,
     0x00,
     0x00,
     // flags
     0x00,
     0x00,
     0x00,
     0x00,
     // sample_size
     0x00,
     0x00,
     0x00,
     0x00, // sample_count
    ]);
    MP4.VMHD = new Uint8Array([
     0x00,
     // version
     0x00,
     0x00,
     0x01,
     // flags
     0x00,
     0x00,
     // graphicsmode
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00, // opcolor
    ]);
    MP4.SMHD = new Uint8Array([
     0x00,
     // version
     0x00,
     0x00,
     0x00,
     // flags
     0x00,
     0x00,
     // balance
     0x00,
     0x00, // reserved
    ]);
    MP4.STSD = new Uint8Array([
     0x00,
     // version 0
     0x00, 0x00, 0x00,
     // flags
     0x00, 0x00, 0x00, 0x01,
    ]); // entry_count

    const majorBrand = new Uint8Array([105, 115, 111, 109]); // isom
    const avc1Brand = new Uint8Array([97, 118, 99, 49]); // avc1
    const minorVersion = new Uint8Array([0, 0, 0, 1]);
    MP4.FTYP = MP4.box(MP4.types.ftyp, majorBrand, minorVersion, majorBrand, avc1Brand);
    MP4.DINF = MP4.box(MP4.types.dinf, MP4.box(MP4.types.dref, dref));
   }
   static box(type, ...payload) {
    let size = 8;
    let i = payload.length;
    const len = i;
    // calculate the total size we need to allocate
    while (i--) {
     size += payload[i].byteLength;
    }
    const result = new Uint8Array(size);
    result[0] = (size >> 24) & 0xff;
    result[1] = (size >> 16) & 0xff;
    result[2] = (size >> 8) & 0xff;
    result[3] = size & 0xff;
    result.set(type, 4);
    // copy the payload into the result
    for (i = 0, size = 8; i < len; i++) {
     // copy payload[i] array @ offset size
     result.set(payload[i], size);
     size += payload[i].byteLength;
    }
    return result;
   }
   static hdlr(type) {
    return MP4.box(MP4.types.hdlr, MP4.HDLR_TYPES[type]);
   }
   static mdat(data) {
    return MP4.box(MP4.types.mdat, data);
   }
   static mdhd(timescale, duration) {
    duration *= timescale;
    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
    return MP4.box(
     MP4.types.mdhd,
     new Uint8Array([
      0x01,
      // version 1
      0x00,
      0x00,
      0x00,
      // flags
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x02,
      // creation_time
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x03,
      // modification_time
      (timescale >> 24) & 0xff,
      (timescale >> 16) & 0xff,
      (timescale >> 8) & 0xff,
      timescale & 0xff,
      // timescale
      upperWordDuration >> 24,
      (upperWordDuration >> 16) & 0xff,
      (upperWordDuration >> 8) & 0xff,
      upperWordDuration & 0xff,
      lowerWordDuration >> 24,
      (lowerWordDuration >> 16) & 0xff,
      (lowerWordDuration >> 8) & 0xff,
      lowerWordDuration & 0xff,
      0x55,
      0xc4,
      // 'und' language (undetermined)
      0x00,
      0x00,
     ]),
    );
   }
   static mdia(track) {
    return MP4.box(MP4.types.mdia, MP4.mdhd(track.timescale || 0, track.duration || 0), MP4.hdlr(track.type), MP4.minf(track));
   }
   static mfhd(sequenceNumber) {
    return MP4.box(
     MP4.types.mfhd,
     new Uint8Array([
      0x00,
      0x00,
      0x00,
      0x00,
      // flags
      sequenceNumber >> 24,
      (sequenceNumber >> 16) & 0xff,
      (sequenceNumber >> 8) & 0xff,
      sequenceNumber & 0xff, // sequence_number
     ]),
    );
   }
   static minf(track) {
    if (track.type === 'audio') {
     return MP4.box(MP4.types.minf, MP4.box(MP4.types.smhd, MP4.SMHD), MP4.DINF, MP4.stbl(track));
    } else {
     return MP4.box(MP4.types.minf, MP4.box(MP4.types.vmhd, MP4.VMHD), MP4.DINF, MP4.stbl(track));
    }
   }
   static moof(sn, baseMediaDecodeTime, track) {
    return MP4.box(MP4.types.moof, MP4.mfhd(sn), MP4.traf(track, baseMediaDecodeTime));
   }
   static moov(tracks) {
    let i = tracks.length;
    const boxes = [];
    while (i--) {
     boxes[i] = MP4.trak(tracks[i]);
    }
    return MP4.box.apply(null, [MP4.types.moov, MP4.mvhd(tracks[0].timescale || 0, tracks[0].duration || 0)].concat(boxes).concat(MP4.mvex(tracks)));
   }
   static mvex(tracks) {
    let i = tracks.length;
    const boxes = [];
    while (i--) {
     boxes[i] = MP4.trex(tracks[i]);
    }
    return MP4.box.apply(null, [MP4.types.mvex, ...boxes]);
   }
   static mvhd(timescale, duration) {
    duration *= timescale;
    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
    const bytes = new Uint8Array([
     0x01,
     // version 1
     0x00,
     0x00,
     0x00,
     // flags
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x02,
     // creation_time
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x03,
     // modification_time
     (timescale >> 24) & 0xff,
     (timescale >> 16) & 0xff,
     (timescale >> 8) & 0xff,
     timescale & 0xff,
     // timescale
     upperWordDuration >> 24,
     (upperWordDuration >> 16) & 0xff,
     (upperWordDuration >> 8) & 0xff,
     upperWordDuration & 0xff,
     lowerWordDuration >> 24,
     (lowerWordDuration >> 16) & 0xff,
     (lowerWordDuration >> 8) & 0xff,
     lowerWordDuration & 0xff,
     0x00,
     0x01,
     0x00,
     0x00,
     // 1.0 rate
     0x01,
     0x00,
     // 1.0 volume
     0x00,
     0x00,
     // reserved
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     0x01,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x01,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x40,
     0x00,
     0x00,
     0x00,
     // transformation: unity matrix
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     // pre_defined
     0xff,
     0xff,
     0xff,
     0xff, // next_track_ID
    ]);
    return MP4.box(MP4.types.mvhd, bytes);
   }
   static sdtp(track) {
    const samples = track.samples || [];
    const bytes = new Uint8Array(4 + samples.length);
    let i;
    let flags;
    // leave the full box header (4 bytes) all zero
    // write the sample table
    for (i = 0; i < samples.length; i++) {
     flags = samples[i].flags;
     bytes[i + 4] = (flags.dependsOn << 4) | (flags.isDependedOn << 2) | flags.hasRedundancy;
    }
    return MP4.box(MP4.types.sdtp, bytes);
   }
   static stbl(track) {
    return MP4.box(MP4.types.stbl, MP4.stsd(track), MP4.box(MP4.types.stts, MP4.STTS), MP4.box(MP4.types.stsc, MP4.STSC), MP4.box(MP4.types.stsz, MP4.STSZ), MP4.box(MP4.types.stco, MP4.STCO));
   }
   static avc1(track) {
    let sps = [];
    let pps = [];
    let i;
    let data;
    let len;
    // assemble the SPSs

    for (i = 0; i < track.sps.length; i++) {
     data = track.sps[i];
     len = data.byteLength;
     sps.push((len >>> 8) & 0xff);
     sps.push(len & 0xff);

     // SPS
     sps = sps.concat(Array.prototype.slice.call(data));
    }

    // assemble the PPSs
    for (i = 0; i < track.pps.length; i++) {
     data = track.pps[i];
     len = data.byteLength;
     pps.push((len >>> 8) & 0xff);
     pps.push(len & 0xff);
     pps = pps.concat(Array.prototype.slice.call(data));
    }
    const avcc = MP4.box(
     MP4.types.avcC,
     new Uint8Array(
      [
       0x01,
       // version
       sps[3],
       // profile
       sps[4],
       // profile compat
       sps[5],
       // level
       0xfc | 3,
       // lengthSizeMinusOne, hard-coded to 4 bytes
       0xe0 | track.sps.length, // 3bit reserved (111) + numOfSequenceParameterSets
      ]
       .concat(sps)
       .concat([
        track.pps.length, // numOfPictureParameterSets
       ])
       .concat(pps),
     ),
    ); // "PPS"
    const width = track.width;
    const height = track.height;
    const hSpacing = track.pixelRatio[0];
    const vSpacing = track.pixelRatio[1];
    return MP4.box(
     MP4.types.avc1,
     new Uint8Array([
      0x00,
      0x00,
      0x00,
      // reserved
      0x00,
      0x00,
      0x00,
      // reserved
      0x00,
      0x01,
      // data_reference_index
      0x00,
      0x00,
      // pre_defined
      0x00,
      0x00,
      // reserved
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      // pre_defined
      (width >> 8) & 0xff,
      width & 0xff,
      // width
      (height >> 8) & 0xff,
      height & 0xff,
      // height
      0x00,
      0x48,
      0x00,
      0x00,
      // horizresolution
      0x00,
      0x48,
      0x00,
      0x00,
      // vertresolution
      0x00,
      0x00,
      0x00,
      0x00,
      // reserved
      0x00,
      0x01,
      // frame_count
      0x12,
      0x64,
      0x61,
      0x69,
      0x6c,
      // dailymotion/hls.js
      0x79,
      0x6d,
      0x6f,
      0x74,
      0x69,
      0x6f,
      0x6e,
      0x2f,
      0x68,
      0x6c,
      0x73,
      0x2e,
      0x6a,
      0x73,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      // compressorname
      0x00,
      0x18,
      // depth = 24
      0x11,
      0x11,
     ]),
     // pre_defined = -1
     avcc,
     MP4.box(
      MP4.types.btrt,
      new Uint8Array([
       0x00, 0x1c, 0x9c, 0x80,
       // bufferSizeDB
       0x00, 0x2d, 0xc6, 0xc0,
       // maxBitrate
       0x00, 0x2d, 0xc6, 0xc0,
      ]),
     ),
     // avgBitrate
     MP4.box(
      MP4.types.pasp,
      new Uint8Array([
       hSpacing >> 24,
       // hSpacing
       (hSpacing >> 16) & 0xff,
       (hSpacing >> 8) & 0xff,
       hSpacing & 0xff,
       vSpacing >> 24,
       // vSpacing
       (vSpacing >> 16) & 0xff,
       (vSpacing >> 8) & 0xff,
       vSpacing & 0xff,
      ]),
     ),
    );
   }
   static esds(track) {
    const config = track.config;
    return new Uint8Array([
     0x00,
     // version 0
     0x00,
     0x00,
     0x00,
     // flags

     0x03,
     // descriptor_type
     0x19,
     // length

     0x00,
     0x01,
     // es_id

     0x00,
     // stream_priority

     0x04,
     // descriptor_type
     0x11,
     // length
     0x40,
     // codec : mpeg4_audio
     0x15,
     // stream_type
     0x00,
     0x00,
     0x00,
     // buffer_size
     0x00,
     0x00,
     0x00,
     0x00,
     // maxBitrate
     0x00,
     0x00,
     0x00,
     0x00,
     // avgBitrate

     0x05,
     // descriptor_type
     0x02,
     // length
     ...config,
     0x06,
     0x01,
     0x02, // GASpecificConfig)); // length + audio config descriptor
    ]);
   }
   static audioStsd(track) {
    const samplerate = track.samplerate || 0;
    return new Uint8Array([
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     0x01,
     // data_reference_index
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved
     0x00,
     track.channelCount || 0,
     // channelcount
     0x00,
     0x10,
     // sampleSize:16bits
     0x00,
     0x00,
     0x00,
     0x00,
     // reserved2
     (samplerate >> 8) & 0xff,
     samplerate & 0xff,
     //
     0x00,
     0x00,
    ]);
   }
   static mp4a(track) {
    return MP4.box(MP4.types.mp4a, MP4.audioStsd(track), MP4.box(MP4.types.esds, MP4.esds(track)));
   }
   static mp3(track) {
    return MP4.box(MP4.types['.mp3'], MP4.audioStsd(track));
   }
   static ac3(track) {
    return MP4.box(MP4.types['ac-3'], MP4.audioStsd(track), MP4.box(MP4.types.dac3, track.config));
   }
   static stsd(track) {
    const { segmentCodec } = track;
    if (track.type === 'audio') {
     if (segmentCodec === 'aac') {
      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp4a(track));
     }
     if (segmentCodec === 'ac3' && track.config) {
      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.ac3(track));
     }
     if (segmentCodec === 'mp3' && track.codec === 'mp3') {
      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp3(track));
     }
    } else {
     if (track.pps && track.sps) {
      if (segmentCodec === 'avc') {
       return MP4.box(MP4.types.stsd, MP4.STSD, MP4.avc1(track));
      }
      if (segmentCodec === 'hevc' && track.vps) {
       return MP4.box(MP4.types.stsd, MP4.STSD, MP4.hvc1(track));
      }
     } else {
      throw new Error(`video track missing pps or sps`);
     }
    }
    throw new Error(`unsupported ${track.type} segment codec (${segmentCodec}/${track.codec})`);
   }
   static tkhd(track) {
    const id = track.id;
    const duration = (track.duration || 0) * (track.timescale || 0);
    const width = track.width || 0;
    const height = track.height || 0;
    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
    return MP4.box(
     MP4.types.tkhd,
     new Uint8Array([
      0x01,
      // version 1
      0x00,
      0x00,
      0x07,
      // flags
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x02,
      // creation_time
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x03,
      // modification_time
      (id >> 24) & 0xff,
      (id >> 16) & 0xff,
      (id >> 8) & 0xff,
      id & 0xff,
      // track_ID
      0x00,
      0x00,
      0x00,
      0x00,
      // reserved
      upperWordDuration >> 24,
      (upperWordDuration >> 16) & 0xff,
      (upperWordDuration >> 8) & 0xff,
      upperWordDuration & 0xff,
      lowerWordDuration >> 24,
      (lowerWordDuration >> 16) & 0xff,
      (lowerWordDuration >> 8) & 0xff,
      lowerWordDuration & 0xff,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      // reserved
      0x00,
      0x00,
      // layer
      0x00,
      0x00,
      // alternate_group
      0x00,
      0x00,
      // non-audio track volume
      0x00,
      0x00,
      // reserved
      0x00,
      0x01,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x01,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x40,
      0x00,
      0x00,
      0x00,
      // transformation: unity matrix
      (width >> 8) & 0xff,
      width & 0xff,
      0x00,
      0x00,
      // width
      (height >> 8) & 0xff,
      height & 0xff,
      0x00,
      0x00, // height
     ]),
    );
   }
   static traf(track, baseMediaDecodeTime) {
    const sampleDependencyTable = MP4.sdtp(track);
    const id = track.id;
    const upperWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));
    const lowerWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));
    return MP4.box(
     MP4.types.traf,
     MP4.box(
      MP4.types.tfhd,
      new Uint8Array([
       0x00,
       // version 0
       0x00,
       0x00,
       0x00,
       // flags
       id >> 24,
       (id >> 16) & 0xff,
       (id >> 8) & 0xff,
       id & 0xff, // track_ID
      ]),
     ),
     MP4.box(
      MP4.types.tfdt,
      new Uint8Array([
       0x01,
       // version 1
       0x00,
       0x00,
       0x00,
       // flags
       upperWordBaseMediaDecodeTime >> 24,
       (upperWordBaseMediaDecodeTime >> 16) & 0xff,
       (upperWordBaseMediaDecodeTime >> 8) & 0xff,
       upperWordBaseMediaDecodeTime & 0xff,
       lowerWordBaseMediaDecodeTime >> 24,
       (lowerWordBaseMediaDecodeTime >> 16) & 0xff,
       (lowerWordBaseMediaDecodeTime >> 8) & 0xff,
       lowerWordBaseMediaDecodeTime & 0xff,
      ]),
     ),
     MP4.trun(
      track,
      sampleDependencyTable.length +
       16 +
       // tfhd
       20 +
       // tfdt
       8 +
       // traf header
       16 +
       // mfhd
       8 +
       // moof header
       8,
     ),
     // mdat header
     sampleDependencyTable,
    );
   }

   /**
    * Generate a track box.
    * @param track a track definition
    */
   static trak(track) {
    track.duration = track.duration || 0xffffffff;
    return MP4.box(MP4.types.trak, MP4.tkhd(track), MP4.mdia(track));
   }
   static trex(track) {
    const id = track.id;
    return MP4.box(
     MP4.types.trex,
     new Uint8Array([
      0x00,
      // version 0
      0x00,
      0x00,
      0x00,
      // flags
      id >> 24,
      (id >> 16) & 0xff,
      (id >> 8) & 0xff,
      id & 0xff,
      // track_ID
      0x00,
      0x00,
      0x00,
      0x01,
      // default_sample_description_index
      0x00,
      0x00,
      0x00,
      0x00,
      // default_sample_duration
      0x00,
      0x00,
      0x00,
      0x00,
      // default_sample_size
      0x00,
      0x01,
      0x00,
      0x01, // default_sample_flags
     ]),
    );
   }
   static trun(track, offset) {
    const samples = track.samples || [];
    const len = samples.length;
    const arraylen = 12 + 16 * len;
    const array = new Uint8Array(arraylen);
    let i;
    let sample;
    let duration;
    let size;
    let flags;
    let cts;
    offset += 8 + arraylen;
    array.set(
     [
      track.type === 'video' ? 0x01 : 0x00,
      // version 1 for video with signed-int sample_composition_time_offset
      0x00,
      0x0f,
      0x01,
      // flags
      (len >>> 24) & 0xff,
      (len >>> 16) & 0xff,
      (len >>> 8) & 0xff,
      len & 0xff,
      // sample_count
      (offset >>> 24) & 0xff,
      (offset >>> 16) & 0xff,
      (offset >>> 8) & 0xff,
      offset & 0xff, // data_offset
     ],
     0,
    );
    for (i = 0; i < len; i++) {
     sample = samples[i];
     duration = sample.duration;
     size = sample.size;
     flags = sample.flags;
     cts = sample.cts;
     array.set(
      [
       (duration >>> 24) & 0xff,
       (duration >>> 16) & 0xff,
       (duration >>> 8) & 0xff,
       duration & 0xff,
       // sample_duration
       (size >>> 24) & 0xff,
       (size >>> 16) & 0xff,
       (size >>> 8) & 0xff,
       size & 0xff,
       // sample_size
       (flags.isLeading << 2) | flags.dependsOn,
       (flags.isDependedOn << 6) | (flags.hasRedundancy << 4) | (flags.paddingValue << 1) | flags.isNonSync,
       flags.degradPrio & (0xf0 << 8),
       flags.degradPrio & 0x0f,
       // sample_flags
       (cts >>> 24) & 0xff,
       (cts >>> 16) & 0xff,
       (cts >>> 8) & 0xff,
       cts & 0xff, // sample_composition_time_offset
      ],
      12 + 16 * i,
     );
    }
    return MP4.box(MP4.types.trun, array);
   }
   static initSegment(tracks) {
    if (!MP4.types) {
     MP4.init();
    }
    const movie = MP4.moov(tracks);
    const result = appendUint8Array(MP4.FTYP, movie);
    return result;
   }
   static hvc1(track) {
    const ps = track.params;
    const units = [track.vps, track.sps, track.pps];
    const NALuLengthSize = 4;
    const config = new Uint8Array([0x01, (ps.general_profile_space << 6) | (ps.general_tier_flag ? 32 : 0) | ps.general_profile_idc, ps.general_profile_compatibility_flags[0], ps.general_profile_compatibility_flags[1], ps.general_profile_compatibility_flags[2], ps.general_profile_compatibility_flags[3], ps.general_constraint_indicator_flags[0], ps.general_constraint_indicator_flags[1], ps.general_constraint_indicator_flags[2], ps.general_constraint_indicator_flags[3], ps.general_constraint_indicator_flags[4], ps.general_constraint_indicator_flags[5], ps.general_level_idc, 240 | (ps.min_spatial_segmentation_idc >> 8), 255 & ps.min_spatial_segmentation_idc, 252 | ps.parallelismType, 252 | ps.chroma_format_idc, 248 | ps.bit_depth_luma_minus8, 248 | ps.bit_depth_chroma_minus8, 0x00, parseInt(ps.frame_rate.fps), (NALuLengthSize - 1) | (ps.temporal_id_nested << 2) | (ps.num_temporal_layers << 3) | (ps.frame_rate.fixed ? 64 : 0), units.length]);

    // compute hvcC size in bytes
    let length = config.length;
    for (let i = 0; i < units.length; i += 1) {
     length += 3;
     for (let j = 0; j < units[i].length; j += 1) {
      length += 2 + units[i][j].length;
     }
    }
    const hvcC = new Uint8Array(length);
    hvcC.set(config, 0);
    length = config.length;
    // append parameter set units: one vps, one or more sps and pps
    const iMax = units.length - 1;
    for (let i = 0; i < units.length; i += 1) {
     hvcC.set(new Uint8Array([(32 + i) | (i === iMax ? 128 : 0), 0x00, units[i].length]), length);
     length += 3;
     for (let j = 0; j < units[i].length; j += 1) {
      hvcC.set(new Uint8Array([units[i][j].length >> 8, units[i][j].length & 255]), length);
      length += 2;
      hvcC.set(units[i][j], length);
      length += units[i][j].length;
     }
    }
    const hvcc = MP4.box(MP4.types.hvcC, hvcC);
    const width = track.width;
    const height = track.height;
    const hSpacing = track.pixelRatio[0];
    const vSpacing = track.pixelRatio[1];
    return MP4.box(
     MP4.types.hvc1,
     new Uint8Array([
      0x00,
      0x00,
      0x00,
      // reserved
      0x00,
      0x00,
      0x00,
      // reserved
      0x00,
      0x01,
      // data_reference_index
      0x00,
      0x00,
      // pre_defined
      0x00,
      0x00,
      // reserved
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      // pre_defined
      (width >> 8) & 0xff,
      width & 0xff,
      // width
      (height >> 8) & 0xff,
      height & 0xff,
      // height
      0x00,
      0x48,
      0x00,
      0x00,
      // horizresolution
      0x00,
      0x48,
      0x00,
      0x00,
      // vertresolution
      0x00,
      0x00,
      0x00,
      0x00,
      // reserved
      0x00,
      0x01,
      // frame_count
      0x12,
      0x64,
      0x61,
      0x69,
      0x6c,
      // dailymotion/hls.js
      0x79,
      0x6d,
      0x6f,
      0x74,
      0x69,
      0x6f,
      0x6e,
      0x2f,
      0x68,
      0x6c,
      0x73,
      0x2e,
      0x6a,
      0x73,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      0x00,
      // compressorname
      0x00,
      0x18,
      // depth = 24
      0x11,
      0x11,
     ]),
     // pre_defined = -1
     hvcc,
     MP4.box(
      MP4.types.btrt,
      new Uint8Array([
       0x00, 0x1c, 0x9c, 0x80,
       // bufferSizeDB
       0x00, 0x2d, 0xc6, 0xc0,
       // maxBitrate
       0x00, 0x2d, 0xc6, 0xc0,
      ]),
     ),
     // avgBitrate
     MP4.box(
      MP4.types.pasp,
      new Uint8Array([
       hSpacing >> 24,
       // hSpacing
       (hSpacing >> 16) & 0xff,
       (hSpacing >> 8) & 0xff,
       hSpacing & 0xff,
       vSpacing >> 24,
       // vSpacing
       (vSpacing >> 16) & 0xff,
       (vSpacing >> 8) & 0xff,
       vSpacing & 0xff,
      ]),
     ),
    );
   }
  }
  MP4.types = void 0;
  MP4.HDLR_TYPES = void 0;
  MP4.STTS = void 0;
  MP4.STSC = void 0;
  MP4.STCO = void 0;
  MP4.STSZ = void 0;
  MP4.VMHD = void 0;
  MP4.SMHD = void 0;
  MP4.STSD = void 0;
  MP4.FTYP = void 0;
  MP4.DINF = void 0;

  const MPEG_TS_CLOCK_FREQ_HZ = 90000;
  function toTimescaleFromBase(baseTime, destScale, srcBase = 1, round = false) {
   const result = baseTime * destScale * srcBase; // equivalent to `(value * scale) / (1 / base)`
   return round ? Math.round(result) : result;
  }
  function toTimescaleFromScale(baseTime, destScale, srcScale = 1, round = false) {
   return toTimescaleFromBase(baseTime, destScale, 1 / srcScale, round);
  }
  function toMsFromMpegTsClock(baseTime, round = false) {
   return toTimescaleFromBase(baseTime, 1000, 1 / MPEG_TS_CLOCK_FREQ_HZ, round);
  }
  function toMpegTsClockFromTimescale(baseTime, srcScale = 1) {
   return toTimescaleFromBase(baseTime, MPEG_TS_CLOCK_FREQ_HZ, 1 / srcScale);
  }

  const MAX_SILENT_FRAME_DURATION = 10 * 1000; // 10 seconds
  const AAC_SAMPLES_PER_FRAME = 1024;
  const MPEG_AUDIO_SAMPLE_PER_FRAME = 1152;
  const AC3_SAMPLES_PER_FRAME = 1536;
  let chromeVersion = null;
  let safariWebkitVersion = null;
  function createMp4Sample(isKeyframe, duration, size, cts) {
   return {
    duration,
    size,
    cts,
    flags: {
     isLeading: 0,
     isDependedOn: 0,
     hasRedundancy: 0,
     degradPrio: 0,
     dependsOn: isKeyframe ? 2 : 1,
     isNonSync: isKeyframe ? 0 : 1,
    },
   };
  }
  class MP4Remuxer extends Logger {
   constructor(observer, config, typeSupported, logger) {
    super('mp4-remuxer', logger);
    this.observer = void 0;
    this.config = void 0;
    this.typeSupported = void 0;
    this.ISGenerated = false;
    this._initPTS = null;
    this._initDTS = null;
    this.nextVideoTs = null;
    this.nextAudioTs = null;
    this.videoSampleDuration = null;
    this.isAudioContiguous = false;
    this.isVideoContiguous = false;
    this.videoTrackConfig = void 0;
    this.observer = observer;
    this.config = config;
    this.typeSupported = typeSupported;
    this.ISGenerated = false;
    if (chromeVersion === null) {
     const userAgent = navigator.userAgent || '';
     const result = userAgent.match(/Chrome\/(\d+)/i);
     chromeVersion = result ? parseInt(result[1]) : 0;
    }
    if (safariWebkitVersion === null) {
     const result = navigator.userAgent.match(/Safari\/(\d+)/i);
     safariWebkitVersion = result ? parseInt(result[1]) : 0;
    }
   }
   destroy() {
    // @ts-ignore
    this.config = this.videoTrackConfig = this._initPTS = this._initDTS = null;
   }
   resetTimeStamp(defaultTimeStamp) {
    this.log('initPTS & initDTS reset');
    this._initPTS = this._initDTS = defaultTimeStamp;
   }
   resetNextTimestamp() {
    this.log('reset next timestamp');
    this.isVideoContiguous = false;
    this.isAudioContiguous = false;
   }
   resetInitSegment() {
    this.log('ISGenerated flag reset');
    this.ISGenerated = false;
    this.videoTrackConfig = undefined;
   }
   getVideoStartPts(videoSamples) {
    // Get the minimum PTS value relative to the first sample's PTS, normalized for 33-bit wrapping
    let rolloverDetected = false;
    const firstPts = videoSamples[0].pts;
    const startPTS = videoSamples.reduce((minPTS, sample) => {
     let pts = sample.pts;
     let delta = pts - minPTS;
     if (delta < -4294967296) {
      // 2^32, see PTSNormalize for reasoning, but we're hitting a rollover here, and we don't want that to impact the timeOffset calculation
      rolloverDetected = true;
      pts = normalizePts(pts, firstPts);
      delta = pts - minPTS;
     }
     if (delta > 0) {
      return minPTS;
     }
     return pts;
    }, firstPts);
    if (rolloverDetected) {
     this.debug('PTS rollover detected');
    }
    return startPTS;
   }
   remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, flush, playlistType) {
    let video;
    let audio;
    let initSegment;
    let text;
    let id3;
    let independent;
    let audioTimeOffset = timeOffset;
    let videoTimeOffset = timeOffset;

    // If we're remuxing audio and video progressively, wait until we've received enough samples for each track before proceeding.
    // This is done to synchronize the audio and video streams. We know if the current segment will have samples if the "pid"
    // parameter is greater than -1. The pid is set when the PMT is parsed, which contains the tracks list.
    // However, if the initSegment has already been generated, or we've reached the end of a segment (flush),
    // then we can remux one track without waiting for the other.
    const hasAudio = audioTrack.pid > -1;
    const hasVideo = videoTrack.pid > -1;
    const length = videoTrack.samples.length;
    const enoughAudioSamples = audioTrack.samples.length > 0;
    const enoughVideoSamples = (flush && length > 0) || length > 1;
    const canRemuxAvc = ((!hasAudio || enoughAudioSamples) && (!hasVideo || enoughVideoSamples)) || this.ISGenerated || flush;
    if (canRemuxAvc) {
     if (this.ISGenerated) {
      var _videoTrack$pixelRati, _config$pixelRatio, _videoTrack$pixelRati2, _config$pixelRatio2;
      const config = this.videoTrackConfig;
      if ((config && (videoTrack.width !== config.width || videoTrack.height !== config.height || ((_videoTrack$pixelRati = videoTrack.pixelRatio) == null ? void 0 : _videoTrack$pixelRati[0]) !== ((_config$pixelRatio = config.pixelRatio) == null ? void 0 : _config$pixelRatio[0]) || ((_videoTrack$pixelRati2 = videoTrack.pixelRatio) == null ? void 0 : _videoTrack$pixelRati2[1]) !== ((_config$pixelRatio2 = config.pixelRatio) == null ? void 0 : _config$pixelRatio2[1]))) || (!config && enoughVideoSamples) || (this.nextAudioTs === null && enoughAudioSamples)) {
       this.resetInitSegment();
      }
     }
     if (!this.ISGenerated) {
      initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);
     }
     const isVideoContiguous = this.isVideoContiguous;
     let firstKeyFrameIndex = -1;
     let firstKeyFramePTS;
     if (enoughVideoSamples) {
      firstKeyFrameIndex = findKeyframeIndex(videoTrack.samples);
      if (!isVideoContiguous && this.config.forceKeyFrameOnDiscontinuity) {
       independent = true;
       if (firstKeyFrameIndex > 0) {
        this.warn(`Dropped ${firstKeyFrameIndex} out of ${length} video samples due to a missing keyframe`);
        const startPTS = this.getVideoStartPts(videoTrack.samples);
        videoTrack.samples = videoTrack.samples.slice(firstKeyFrameIndex);
        videoTrack.dropped += firstKeyFrameIndex;
        videoTimeOffset += (videoTrack.samples[0].pts - startPTS) / videoTrack.inputTimeScale;
        firstKeyFramePTS = videoTimeOffset;
       } else if (firstKeyFrameIndex === -1) {
        this.warn(`No keyframe found out of ${length} video samples`);
        independent = false;
       }
      }
     }
     if (this.ISGenerated) {
      if (enoughAudioSamples && enoughVideoSamples) {
       // timeOffset is expected to be the offset of the first timestamp of this fragment (first DTS)
       // if first audio DTS is not aligned with first video DTS then we need to take that into account
       // when providing timeOffset to remuxAudio / remuxVideo. if we don't do that, there might be a permanent / small
       // drift between audio and video streams
       const startPTS = this.getVideoStartPts(videoTrack.samples);
       const tsDelta = normalizePts(audioTrack.samples[0].pts, startPTS) - startPTS;
       const audiovideoTimestampDelta = tsDelta / videoTrack.inputTimeScale;
       audioTimeOffset += Math.max(0, audiovideoTimestampDelta);
       videoTimeOffset += Math.max(0, -audiovideoTimestampDelta);
      }

      // Purposefully remuxing audio before video, so that remuxVideo can use nextAudioPts, which is calculated in remuxAudio.
      if (enoughAudioSamples) {
       // if initSegment was generated without audio samples, regenerate it again
       if (!audioTrack.samplerate) {
        this.warn('regenerate InitSegment as audio detected');
        initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);
       }
       audio = this.remuxAudio(audioTrack, audioTimeOffset, this.isAudioContiguous, accurateTimeOffset, hasVideo || enoughVideoSamples || playlistType === PlaylistLevelType.AUDIO ? videoTimeOffset : undefined);
       if (enoughVideoSamples) {
        const audioTrackLength = audio ? audio.endPTS - audio.startPTS : 0;
        // if initSegment was generated without video samples, regenerate it again
        if (!videoTrack.inputTimeScale) {
         this.warn('regenerate InitSegment as video detected');
         initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);
        }
        video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, audioTrackLength);
       }
      } else if (enoughVideoSamples) {
       video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, 0);
      }
      if (video) {
       video.firstKeyFrame = firstKeyFrameIndex;
       video.independent = firstKeyFrameIndex !== -1;
       video.firstKeyFramePTS = firstKeyFramePTS;
      }
     }
    }

    // Allow ID3 and text to remux, even if more audio/video samples are required
    if (this.ISGenerated && this._initPTS && this._initDTS) {
     if (id3Track.samples.length) {
      id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, this._initPTS, this._initDTS);
     }
     if (textTrack.samples.length) {
      text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, this._initPTS);
     }
    }
    return {
     audio,
     video,
     initSegment,
     independent,
     text,
     id3,
    };
   }
   generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset) {
    const audioSamples = audioTrack.samples;
    const videoSamples = videoTrack.samples;
    const typeSupported = this.typeSupported;
    const tracks = {};
    const _initPTS = this._initPTS;
    let computePTSDTS = !_initPTS || accurateTimeOffset;
    let container = 'audio/mp4';
    let initPTS;
    let initDTS;
    let timescale;
    let trackId = -1;
    if (computePTSDTS) {
     initPTS = initDTS = Infinity;
    }
    if (audioTrack.config && audioSamples.length) {
     // let's use audio sampling rate as MP4 time scale.
     // rationale is that there is a integer nb of audio frames per audio sample (1024 for AAC)
     // using audio sampling rate here helps having an integer MP4 frame duration
     // this avoids potential rounding issue and AV sync issue
     audioTrack.timescale = audioTrack.samplerate;
     switch (audioTrack.segmentCodec) {
      case 'mp3':
       if (typeSupported.mpeg) {
        // Chrome and Safari
        container = 'audio/mpeg';
        audioTrack.codec = '';
       } else if (typeSupported.mp3) {
        // Firefox
        audioTrack.codec = 'mp3';
       }
       break;
      case 'ac3':
       audioTrack.codec = 'ac-3';
       break;
     }
     tracks.audio = {
      id: 'audio',
      container: container,
      codec: audioTrack.codec,
      initSegment: audioTrack.segmentCodec === 'mp3' && typeSupported.mpeg ? new Uint8Array(0) : MP4.initSegment([audioTrack]),
      metadata: {
       channelCount: audioTrack.channelCount,
      },
     };
     if (computePTSDTS) {
      trackId = audioTrack.id;
      timescale = audioTrack.inputTimeScale;
      if (!_initPTS || timescale !== _initPTS.timescale) {
       // remember first PTS of this demuxing context. for audio, PTS = DTS
       initPTS = initDTS = audioSamples[0].pts - Math.round(timescale * timeOffset);
      } else {
       computePTSDTS = false;
      }
     }
    }
    if (videoTrack.sps && videoTrack.pps && videoSamples.length) {
     // let's use input time scale as MP4 video timescale
     // we use input time scale straight away to avoid rounding issues on frame duration / cts computation
     videoTrack.timescale = videoTrack.inputTimeScale;
     tracks.video = {
      id: 'main',
      container: 'video/mp4',
      codec: videoTrack.codec,
      initSegment: MP4.initSegment([videoTrack]),
      metadata: {
       width: videoTrack.width,
       height: videoTrack.height,
      },
     };
     if (computePTSDTS) {
      trackId = videoTrack.id;
      timescale = videoTrack.inputTimeScale;
      if (!_initPTS || timescale !== _initPTS.timescale) {
       const startPTS = this.getVideoStartPts(videoSamples);
       const startOffset = Math.round(timescale * timeOffset);
       initDTS = Math.min(initDTS, normalizePts(videoSamples[0].dts, startPTS) - startOffset);
       initPTS = Math.min(initPTS, startPTS - startOffset);
      } else {
       computePTSDTS = false;
      }
     }
     this.videoTrackConfig = {
      width: videoTrack.width,
      height: videoTrack.height,
      pixelRatio: videoTrack.pixelRatio,
     };
    }
    if (Object.keys(tracks).length) {
     this.ISGenerated = true;
     if (computePTSDTS) {
      if (_initPTS) {
       this.warn(`Timestamps at playlist time: ${accurateTimeOffset ? '' : '~'}${timeOffset} ${initPTS / timescale} != initPTS: ${_initPTS.baseTime / _initPTS.timescale} (${_initPTS.baseTime}/${_initPTS.timescale}) trackId: ${_initPTS.trackId}`);
      }
      this.log(`Found initPTS at playlist time: ${timeOffset} offset: ${initPTS / timescale} (${initPTS}/${timescale}) trackId: ${trackId}`);
      this._initPTS = {
       baseTime: initPTS,
       timescale: timescale,
       trackId: trackId,
      };
      this._initDTS = {
       baseTime: initDTS,
       timescale: timescale,
       trackId: trackId,
      };
     } else {
      initPTS = timescale = undefined;
     }
     return {
      tracks,
      initPTS,
      timescale,
      trackId,
     };
    }
   }
   remuxVideo(track, timeOffset, contiguous, audioTrackLength) {
    const timeScale = track.inputTimeScale;
    const inputSamples = track.samples;
    const outputSamples = [];
    const nbSamples = inputSamples.length;
    const initPTS = this._initPTS;
    const initTime = (initPTS.baseTime * timeScale) / initPTS.timescale;
    let nextVideoTs = this.nextVideoTs;
    let offset = 8;
    let mp4SampleDuration = this.videoSampleDuration;
    let firstDTS;
    let lastDTS;
    let minPTS = Number.POSITIVE_INFINITY;
    let maxPTS = Number.NEGATIVE_INFINITY;
    let sortSamples = false;

    // if parsed fragment is contiguous with last one, let's use last DTS value as reference
    if (!contiguous || nextVideoTs === null) {
     const pts = initTime + timeOffset * timeScale;
     const cts = inputSamples[0].pts - normalizePts(inputSamples[0].dts, inputSamples[0].pts);
     if (chromeVersion && nextVideoTs !== null && Math.abs(pts - cts - (nextVideoTs + initTime)) < 15000) {
      // treat as contigous to adjust samples that would otherwise produce video buffer gaps in Chrome
      contiguous = true;
     } else {
      // if not contiguous, let's use target timeOffset
      nextVideoTs = pts - cts - initTime;
     }
    }

    // PTS is coded on 33bits, and can loop from -2^32 to 2^32
    // PTSNormalize will make PTS/DTS value monotonic, we use last known DTS value as reference value
    const nextVideoPts = nextVideoTs + initTime;
    for (let i = 0; i < nbSamples; i++) {
     const sample = inputSamples[i];
     sample.pts = normalizePts(sample.pts, nextVideoPts);
     sample.dts = normalizePts(sample.dts, nextVideoPts);
     if (sample.dts < inputSamples[i > 0 ? i - 1 : i].dts) {
      sortSamples = true;
     }
    }

    // sort video samples by DTS then PTS then demux id order
    if (sortSamples) {
     inputSamples.sort(function (a, b) {
      const deltadts = a.dts - b.dts;
      const deltapts = a.pts - b.pts;
      return deltadts || deltapts;
     });
    }

    // Get first/last DTS
    firstDTS = inputSamples[0].dts;
    lastDTS = inputSamples[inputSamples.length - 1].dts;

    // Sample duration (as expected by trun MP4 boxes), should be the delta between sample DTS
    // set this constant duration as being the avg delta between consecutive DTS.
    const inputDuration = lastDTS - firstDTS;
    const averageSampleDuration = inputDuration ? Math.round(inputDuration / (nbSamples - 1)) : mp4SampleDuration || track.inputTimeScale / 30;

    // if fragment are contiguous, detect hole/overlapping between fragments
    if (contiguous) {
     // check timestamp continuity across consecutive fragments (this is to remove inter-fragment gap/hole)
     const delta = firstDTS - nextVideoPts;
     const foundHole = delta > averageSampleDuration;
     const foundOverlap = delta < -1;
     if (foundHole || foundOverlap) {
      if (foundHole) {
       this.warn(`${(track.segmentCodec || '').toUpperCase()}: ${toMsFromMpegTsClock(delta, true)} ms (${delta}dts) hole between fragments detected at ${timeOffset.toFixed(3)}`);
      } else {
       this.warn(`${(track.segmentCodec || '').toUpperCase()}: ${toMsFromMpegTsClock(-delta, true)} ms (${delta}dts) overlapping between fragments detected at ${timeOffset.toFixed(3)}`);
      }
      if (!foundOverlap || nextVideoPts >= inputSamples[0].pts || chromeVersion) {
       firstDTS = nextVideoPts;
       const firstPTS = inputSamples[0].pts - delta;
       if (foundHole) {
        inputSamples[0].dts = firstDTS;
        inputSamples[0].pts = firstPTS;
       } else {
        let isPTSOrderRetained = true;
        for (let i = 0; i < inputSamples.length; i++) {
         if (inputSamples[i].dts > firstPTS && isPTSOrderRetained) {
          break;
         }
         const prevPTS = inputSamples[i].pts;
         inputSamples[i].dts -= delta;
         inputSamples[i].pts -= delta;

         // check to see if this sample's PTS order has changed
         // relative to the next one
         if (i < inputSamples.length - 1) {
          const nextSamplePTS = inputSamples[i + 1].pts;
          const currentSamplePTS = inputSamples[i].pts;
          const currentOrder = nextSamplePTS <= currentSamplePTS;
          const prevOrder = nextSamplePTS <= prevPTS;
          isPTSOrderRetained = currentOrder == prevOrder;
         }
        }
       }
       this.log(`Video: Initial PTS/DTS adjusted: ${toMsFromMpegTsClock(firstPTS, true)}/${toMsFromMpegTsClock(firstDTS, true)}, delta: ${toMsFromMpegTsClock(delta, true)} ms`);
      }
     }
    }
    firstDTS = Math.max(0, firstDTS);
    let nbNalu = 0;
    let naluLen = 0;
    let dtsStep = firstDTS;
    for (let i = 0; i < nbSamples; i++) {
     // compute total/avc sample length and nb of NAL units
     const sample = inputSamples[i];
     const units = sample.units;
     const nbUnits = units.length;
     let sampleLen = 0;
     for (let j = 0; j < nbUnits; j++) {
      sampleLen += units[j].data.length;
     }
     naluLen += sampleLen;
     nbNalu += nbUnits;
     sample.length = sampleLen;

     // ensure sample monotonic DTS
     if (sample.dts < dtsStep) {
      sample.dts = dtsStep;
      dtsStep += (averageSampleDuration / 4) | 0 || 1;
     } else {
      dtsStep = sample.dts;
     }
     minPTS = Math.min(sample.pts, minPTS);
     maxPTS = Math.max(sample.pts, maxPTS);
    }
    lastDTS = inputSamples[nbSamples - 1].dts;

    /* concatenate the video data and construct the mdat in place
      (need 8 more bytes to fill length and mpdat type) */
    const mdatSize = naluLen + 4 * nbNalu + 8;
    let mdat;
    try {
     mdat = new Uint8Array(mdatSize);
    } catch (err) {
     this.observer.emit(Events.ERROR, Events.ERROR, {
      type: ErrorTypes.MUX_ERROR,
      details: ErrorDetails.REMUX_ALLOC_ERROR,
      fatal: false,
      error: err,
      bytes: mdatSize,
      reason: `fail allocating video mdat ${mdatSize}`,
     });
     return;
    }
    const view = new DataView(mdat.buffer);
    view.setUint32(0, mdatSize);
    mdat.set(MP4.types.mdat, 4);
    let stretchedLastFrame = false;
    let minDtsDelta = Number.POSITIVE_INFINITY;
    let minPtsDelta = Number.POSITIVE_INFINITY;
    let maxDtsDelta = Number.NEGATIVE_INFINITY;
    let maxPtsDelta = Number.NEGATIVE_INFINITY;
    for (let i = 0; i < nbSamples; i++) {
     const VideoSample = inputSamples[i];
     const VideoSampleUnits = VideoSample.units;
     let mp4SampleLength = 0;
     // convert NALU bitstream to MP4 format (prepend NALU with size field)
     for (let j = 0, nbUnits = VideoSampleUnits.length; j < nbUnits; j++) {
      const unit = VideoSampleUnits[j];
      const unitData = unit.data;
      const unitDataLen = unit.data.byteLength;
      view.setUint32(offset, unitDataLen);
      offset += 4;
      mdat.set(unitData, offset);
      offset += unitDataLen;
      mp4SampleLength += 4 + unitDataLen;
     }

     // expected sample duration is the Decoding Timestamp diff of consecutive samples
     let ptsDelta;
     if (i < nbSamples - 1) {
      mp4SampleDuration = inputSamples[i + 1].dts - VideoSample.dts;
      ptsDelta = inputSamples[i + 1].pts - VideoSample.pts;
     } else {
      const config = this.config;
      const lastFrameDuration = i > 0 ? VideoSample.dts - inputSamples[i - 1].dts : averageSampleDuration;
      ptsDelta = i > 0 ? VideoSample.pts - inputSamples[i - 1].pts : averageSampleDuration;
      if (config.stretchShortVideoTrack && this.nextAudioTs !== null) {
       // In some cases, a segment's audio track duration may exceed the video track duration.
       // Since we've already remuxed audio, and we know how long the audio track is, we look to
       // see if the delta to the next segment is longer than maxBufferHole.
       // If so, playback would potentially get stuck, so we artificially inflate
       // the duration of the last frame to minimize any potential gap between segments.
       const gapTolerance = Math.floor(config.maxBufferHole * timeScale);
       const deltaToFrameEnd = (audioTrackLength ? minPTS + audioTrackLength * timeScale : this.nextAudioTs + initTime) - VideoSample.pts;
       if (deltaToFrameEnd > gapTolerance) {
        // We subtract lastFrameDuration from deltaToFrameEnd to try to prevent any video
        // frame overlap. maxBufferHole should be >> lastFrameDuration anyway.
        mp4SampleDuration = deltaToFrameEnd - lastFrameDuration;
        if (mp4SampleDuration < 0) {
         mp4SampleDuration = lastFrameDuration;
        } else {
         stretchedLastFrame = true;
        }
        this.log(`It is approximately ${deltaToFrameEnd / 90} ms to the next segment; using duration ${mp4SampleDuration / 90} ms for the last video frame.`);
       } else {
        mp4SampleDuration = lastFrameDuration;
       }
      } else {
       mp4SampleDuration = lastFrameDuration;
      }
     }
     const compositionTimeOffset = Math.round(VideoSample.pts - VideoSample.dts);
     minDtsDelta = Math.min(minDtsDelta, mp4SampleDuration);
     maxDtsDelta = Math.max(maxDtsDelta, mp4SampleDuration);
     minPtsDelta = Math.min(minPtsDelta, ptsDelta);
     maxPtsDelta = Math.max(maxPtsDelta, ptsDelta);
     outputSamples.push(createMp4Sample(VideoSample.key, mp4SampleDuration, mp4SampleLength, compositionTimeOffset));
    }
    if (outputSamples.length) {
     if (chromeVersion) {
      if (chromeVersion < 70) {
       // Chrome workaround, mark first sample as being a Random Access Point (keyframe) to avoid sourcebuffer append issue
       // https://code.google.com/p/chromium/issues/detail?id=229412
       const flags = outputSamples[0].flags;
       flags.dependsOn = 2;
       flags.isNonSync = 0;
      }
     } else if (safariWebkitVersion) {
      // Fix for "CNN special report, with CC" in test-streams (Safari browser only)
      // Ignore DTS when frame durations are irregular. Safari MSE does not handle this leading to gaps.
      if (maxPtsDelta - minPtsDelta < maxDtsDelta - minDtsDelta && averageSampleDuration / maxDtsDelta < 0.025 && outputSamples[0].cts === 0) {
       this.warn('Found irregular gaps in sample duration. Using PTS instead of DTS to determine MP4 sample duration.');
       let dts = firstDTS;
       for (let i = 0, len = outputSamples.length; i < len; i++) {
        const nextDts = dts + outputSamples[i].duration;
        const pts = dts + outputSamples[i].cts;
        if (i < len - 1) {
         const nextPts = nextDts + outputSamples[i + 1].cts;
         outputSamples[i].duration = nextPts - pts;
        } else {
         outputSamples[i].duration = i ? outputSamples[i - 1].duration : averageSampleDuration;
        }
        outputSamples[i].cts = 0;
        dts = nextDts;
       }
      }
     }
    }
    // next AVC/HEVC sample DTS should be equal to last sample DTS + last sample duration (in PES timescale)
    mp4SampleDuration = stretchedLastFrame || !mp4SampleDuration ? averageSampleDuration : mp4SampleDuration;
    const endDTS = lastDTS + mp4SampleDuration;
    this.nextVideoTs = nextVideoTs = endDTS - initTime;
    this.videoSampleDuration = mp4SampleDuration;
    this.isVideoContiguous = true;
    const moof = MP4.moof(
     track.sequenceNumber++,
     firstDTS,
     _extends(track, {
      samples: outputSamples,
     }),
    );
    const type = 'video';
    const data = {
     data1: moof,
     data2: mdat,
     startPTS: (minPTS - initTime) / timeScale,
     endPTS: (maxPTS + mp4SampleDuration - initTime) / timeScale,
     startDTS: (firstDTS - initTime) / timeScale,
     endDTS: nextVideoTs / timeScale,
     type,
     hasAudio: false,
     hasVideo: true,
     nb: outputSamples.length,
     dropped: track.dropped,
    };
    track.samples = [];
    track.dropped = 0;
    return data;
   }
   getSamplesPerFrame(track) {
    switch (track.segmentCodec) {
     case 'mp3':
      return MPEG_AUDIO_SAMPLE_PER_FRAME;
     case 'ac3':
      return AC3_SAMPLES_PER_FRAME;
     default:
      return AAC_SAMPLES_PER_FRAME;
    }
   }
   remuxAudio(track, timeOffset, contiguous, accurateTimeOffset, videoTimeOffset) {
    const inputTimeScale = track.inputTimeScale;
    const mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;
    const scaleFactor = inputTimeScale / mp4timeScale;
    const mp4SampleDuration = this.getSamplesPerFrame(track);
    const inputSampleDuration = mp4SampleDuration * scaleFactor;
    const initPTS = this._initPTS;
    const rawMPEG = track.segmentCodec === 'mp3' && this.typeSupported.mpeg;
    const outputSamples = [];
    const alignedWithVideo = videoTimeOffset !== undefined;
    let inputSamples = track.samples;
    let offset = rawMPEG ? 0 : 8;
    let nextAudioTs = this.nextAudioTs || -1;

    // window.audioSamples ? window.audioSamples.push(inputSamples.map(s => s.pts)) : (window.audioSamples = [inputSamples.map(s => s.pts)]);

    // for audio samples, also consider consecutive fragments as being contiguous (even if a level switch occurs),
    // for sake of clarity:
    // consecutive fragments are frags with
    //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR
    //  - less than 20 audio frames distance
    // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)
    // this helps ensuring audio continuity
    // and this also avoids audio glitches/cut when switching quality, or reporting wrong duration on first audio frame
    const initTime = (initPTS.baseTime * inputTimeScale) / initPTS.timescale;
    const timeOffsetMpegTS = initTime + timeOffset * inputTimeScale;
    this.isAudioContiguous = contiguous = contiguous || (inputSamples.length && nextAudioTs > 0 && ((accurateTimeOffset && Math.abs(timeOffsetMpegTS - (nextAudioTs + initTime)) < 9000) || Math.abs(normalizePts(inputSamples[0].pts, timeOffsetMpegTS) - (nextAudioTs + initTime)) < 20 * inputSampleDuration));

    // compute normalized PTS
    inputSamples.forEach(function (sample) {
     sample.pts = normalizePts(sample.pts, timeOffsetMpegTS);
    });
    if (!contiguous || nextAudioTs < 0) {
     // filter out sample with negative PTS that are not playable anyway
     // if we don't remove these negative samples, they will shift all audio samples forward.
     // leading to audio overlap between current / next fragment
     inputSamples = inputSamples.filter((sample) => sample.pts >= 0);

     // in case all samples have negative PTS, and have been filtered out, return now
     if (!inputSamples.length) {
      return;
     }
     if (videoTimeOffset === 0) {
      // Set the start to match video so that start gaps larger than inputSampleDuration are filled with silence
      nextAudioTs = 0;
     } else if (accurateTimeOffset && !alignedWithVideo) {
      // When not seeking, not live, and LevelDetails.PTSKnown, use fragment start as predicted next audio PTS
      nextAudioTs = Math.max(0, timeOffsetMpegTS - initTime);
     } else {
      // if frags are not contiguous and if we cant trust time offset, let's use first sample PTS as next audio PTS
      nextAudioTs = inputSamples[0].pts - initTime;
     }
    }

    // If the audio track is missing samples, the frames seem to get "left-shifted" within the
    // resulting mp4 segment, causing sync issues and leaving gaps at the end of the audio segment.
    // In an effort to prevent this from happening, we inject frames here where there are gaps.
    // When possible, we inject a silent frame; when that's not possible, we duplicate the last
    // frame.

    if (track.segmentCodec === 'aac') {
     const maxAudioFramesDrift = this.config.maxAudioFramesDrift;
     for (let i = 0, nextPts = nextAudioTs + initTime; i < inputSamples.length; i++) {
      // First, let's see how far off this frame is from where we expect it to be
      const sample = inputSamples[i];
      const pts = sample.pts;
      const delta = pts - nextPts;
      const duration = Math.abs((1000 * delta) / inputTimeScale);

      // When remuxing with video, if we're overlapping by more than a duration, drop this sample to stay in sync
      if (delta <= -maxAudioFramesDrift * inputSampleDuration && alignedWithVideo) {
       if (i === 0) {
        this.warn(`Audio frame @ ${(pts / inputTimeScale).toFixed(3)}s overlaps marker by ${Math.round((1000 * delta) / inputTimeScale)} ms.`);
        this.nextAudioTs = nextAudioTs = pts - initTime;
        nextPts = pts;
       }
      } // eslint-disable-line brace-style

      // Insert missing frames if:
      // 1: We're more than maxAudioFramesDrift frame away
      // 2: Not more than MAX_SILENT_FRAME_DURATION away
      // 3: currentTime (aka nextPtsNorm) is not 0
      // 4: remuxing with video (videoTimeOffset !== undefined)
      else if (delta >= maxAudioFramesDrift * inputSampleDuration && duration < MAX_SILENT_FRAME_DURATION && alignedWithVideo) {
       let missing = Math.round(delta / inputSampleDuration);
       // Adjust nextPts so that silent samples are aligned with media pts. This will prevent media samples from
       // later being shifted if nextPts is based on timeOffset and delta is not a multiple of inputSampleDuration.
       nextPts = pts - missing * inputSampleDuration;
       while (nextPts < 0 && missing && inputSampleDuration) {
        missing--;
        nextPts += inputSampleDuration;
       }
       if (i === 0) {
        this.nextAudioTs = nextAudioTs = nextPts - initTime;
       }
       this.warn(`Injecting ${missing} audio frames @ ${((nextPts - initTime) / inputTimeScale).toFixed(3)}s due to ${Math.round((1000 * delta) / inputTimeScale)} ms gap.`);
       for (let j = 0; j < missing; j++) {
        let fillFrame = AAC.getSilentFrame(track.parsedCodec || track.manifestCodec || track.codec, track.channelCount);
        if (!fillFrame) {
         this.log('Unable to get silent frame for given audio codec; duplicating last frame instead.');
         fillFrame = sample.unit.subarray();
        }
        inputSamples.splice(i, 0, {
         unit: fillFrame,
         pts: nextPts,
        });
        nextPts += inputSampleDuration;
        i++;
       }
      }
      sample.pts = nextPts;
      nextPts += inputSampleDuration;
     }
    }
    let firstPTS = null;
    let lastPTS = null;
    let mdat;
    let mdatSize = 0;
    let sampleLength = inputSamples.length;
    while (sampleLength--) {
     mdatSize += inputSamples[sampleLength].unit.byteLength;
    }
    for (let j = 0, _nbSamples = inputSamples.length; j < _nbSamples; j++) {
     const audioSample = inputSamples[j];
     const unit = audioSample.unit;
     let pts = audioSample.pts;
     if (lastPTS !== null) {
      // If we have more than one sample, set the duration of the sample to the "real" duration; the PTS diff with
      // the previous sample
      const prevSample = outputSamples[j - 1];
      prevSample.duration = Math.round((pts - lastPTS) / scaleFactor);
     } else {
      if (contiguous && track.segmentCodec === 'aac') {
       // set PTS/DTS to expected PTS/DTS
       pts = nextAudioTs + initTime;
      }
      // remember first PTS of our audioSamples
      firstPTS = pts;
      if (mdatSize > 0) {
       /* concatenate the audio data and construct the mdat in place
            (need 8 more bytes to fill length and mdat type) */
       mdatSize += offset;
       try {
        mdat = new Uint8Array(mdatSize);
       } catch (err) {
        this.observer.emit(Events.ERROR, Events.ERROR, {
         type: ErrorTypes.MUX_ERROR,
         details: ErrorDetails.REMUX_ALLOC_ERROR,
         fatal: false,
         error: err,
         bytes: mdatSize,
         reason: `fail allocating audio mdat ${mdatSize}`,
        });
        return;
       }
       if (!rawMPEG) {
        const view = new DataView(mdat.buffer);
        view.setUint32(0, mdatSize);
        mdat.set(MP4.types.mdat, 4);
       }
      } else {
       // no audio samples
       return;
      }
     }
     mdat.set(unit, offset);
     const unitLen = unit.byteLength;
     offset += unitLen;
     // Default the sample's duration to the computed mp4SampleDuration, which will either be 1024 for AAC or 1152 for MPEG
     // In the case that we have 1 sample, this will be the duration. If we have more than one sample, the duration
     // becomes the PTS diff with the previous sample
     outputSamples.push(createMp4Sample(true, mp4SampleDuration, unitLen, 0));
     lastPTS = pts;
    }

    // We could end up with no audio samples if all input samples were overlapping with the previously remuxed ones
    const nbSamples = outputSamples.length;
    if (!nbSamples) {
     return;
    }

    // The next audio sample PTS should be equal to last sample PTS + duration
    const lastSample = outputSamples[outputSamples.length - 1];
    nextAudioTs = lastPTS - initTime;
    this.nextAudioTs = nextAudioTs + scaleFactor * lastSample.duration;

    // Set the track samples from inputSamples to outputSamples before remuxing
    const moof = rawMPEG
     ? new Uint8Array(0)
     : MP4.moof(
        track.sequenceNumber++,
        firstPTS / scaleFactor,
        _extends({}, track, {
         samples: outputSamples,
        }),
       );

    // Clear the track samples. This also clears the samples array in the demuxer, since the reference is shared
    track.samples = [];
    const start = (firstPTS - initTime) / inputTimeScale;
    const end = nextAudioTs / inputTimeScale;
    const type = 'audio';
    const audioData = {
     data1: moof,
     data2: mdat,
     startPTS: start,
     endPTS: end,
     startDTS: start,
     endDTS: end,
     type,
     hasAudio: true,
     hasVideo: false,
     nb: nbSamples,
    };
    this.isAudioContiguous = true;
    return audioData;
   }
  }
  function normalizePts(value, reference) {
   let offset;
   if (reference === null) {
    return value;
   }
   if (reference < value) {
    // - 2^33
    offset = -8589934592;
   } else {
    // + 2^33
    offset = 8589934592;
   }
   /* PTS is 33bit (from 0 to 2^33 -1)
    if diff between value and reference is bigger than half of the amplitude (2^32) then it means that
    PTS looping occured. fill the gap */
   while (Math.abs(value - reference) > 4294967296) {
    value += offset;
   }
   return value;
  }
  function findKeyframeIndex(samples) {
   for (let i = 0; i < samples.length; i++) {
    if (samples[i].key) {
     return i;
    }
   }
   return -1;
  }
  function flushTextTrackMetadataCueSamples(track, timeOffset, initPTS, initDTS) {
   const length = track.samples.length;
   if (!length) {
    return;
   }
   const inputTimeScale = track.inputTimeScale;
   for (let index = 0; index < length; index++) {
    const sample = track.samples[index];
    // setting id3 pts, dts to relative time
    // using this._initPTS and this._initDTS to calculate relative time
    sample.pts = normalizePts(sample.pts - (initPTS.baseTime * inputTimeScale) / initPTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;
    sample.dts = normalizePts(sample.dts - (initDTS.baseTime * inputTimeScale) / initDTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;
   }
   const samples = track.samples;
   track.samples = [];
   return {
    samples,
   };
  }
  function flushTextTrackUserdataCueSamples(track, timeOffset, initPTS) {
   const length = track.samples.length;
   if (!length) {
    return;
   }
   const inputTimeScale = track.inputTimeScale;
   for (let index = 0; index < length; index++) {
    const sample = track.samples[index];
    // setting text pts, dts to relative time
    // using this._initPTS and this._initDTS to calculate relative time
    sample.pts = normalizePts(sample.pts - (initPTS.baseTime * inputTimeScale) / initPTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;
   }
   track.samples.sort((a, b) => a.pts - b.pts);
   const samples = track.samples;
   track.samples = [];
   return {
    samples,
   };
  }

  class PassThroughRemuxer extends Logger {
   constructor(observer, config, typeSupported, logger) {
    super('passthrough-remuxer', logger);
    this.emitInitSegment = false;
    this.audioCodec = void 0;
    this.videoCodec = void 0;
    this.initData = void 0;
    this.initPTS = null;
    this.initTracks = void 0;
    this.lastEndTime = null;
    this.isVideoContiguous = false;
   }
   destroy() {}
   resetTimeStamp(defaultInitPTS) {
    this.lastEndTime = null;
    const initPTS = this.initPTS;
    if (initPTS && defaultInitPTS) {
     if (initPTS.baseTime === defaultInitPTS.baseTime && initPTS.timescale === defaultInitPTS.timescale) {
      return;
     }
    }
    this.initPTS = defaultInitPTS;
   }
   resetNextTimestamp() {
    this.isVideoContiguous = false;
    this.lastEndTime = null;
   }
   resetInitSegment(initSegment, audioCodec, videoCodec, decryptdata) {
    this.audioCodec = audioCodec;
    this.videoCodec = videoCodec;
    this.generateInitSegment(initSegment, decryptdata);
    this.emitInitSegment = true;
   }
   generateInitSegment(initSegment, decryptdata) {
    let { audioCodec, videoCodec } = this;
    if (!(initSegment != null && initSegment.byteLength)) {
     this.initTracks = undefined;
     this.initData = undefined;
     return;
    }
    const { audio, video } = (this.initData = parseInitSegment(initSegment));
    if (decryptdata) {
     patchEncyptionData(initSegment, decryptdata);
    } else {
     const eitherTrack = audio || video;
     if (eitherTrack != null && eitherTrack.encrypted) {
      this.warn(`Init segment with encrypted track with has no key ("${eitherTrack.codec}")!`);
     }
    }

    // Get codec from initSegment
    if (audio) {
     audioCodec = getParsedTrackCodec(audio, ElementaryStreamTypes.AUDIO, this);
    }
    if (video) {
     videoCodec = getParsedTrackCodec(video, ElementaryStreamTypes.VIDEO, this);
    }
    const tracks = {};
    if (audio && video) {
     tracks.audiovideo = {
      container: 'video/mp4',
      codec: audioCodec + ',' + videoCodec,
      supplemental: video.supplemental,
      encrypted: video.encrypted,
      initSegment,
      id: 'main',
     };
    } else if (audio) {
     tracks.audio = {
      container: 'audio/mp4',
      codec: audioCodec,
      encrypted: audio.encrypted,
      initSegment,
      id: 'audio',
     };
    } else if (video) {
     tracks.video = {
      container: 'video/mp4',
      codec: videoCodec,
      supplemental: video.supplemental,
      encrypted: video.encrypted,
      initSegment,
      id: 'main',
     };
    } else {
     this.warn('initSegment does not contain moov or trak boxes.');
    }
    this.initTracks = tracks;
   }
   remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset) {
    var _initData, _initData2;
    let { initPTS, lastEndTime } = this;
    const result = {
     audio: undefined,
     video: undefined,
     text: textTrack,
     id3: id3Track,
     initSegment: undefined,
    };

    // If we haven't yet set a lastEndDTS, or it was reset, set it to the provided timeOffset. We want to use the
    // lastEndDTS over timeOffset whenever possible; during progressive playback, the media source will not update
    // the media duration (which is what timeOffset is provided as) before we need to process the next chunk.
    if (!isFiniteNumber(lastEndTime)) {
     lastEndTime = this.lastEndTime = timeOffset || 0;
    }

    // The binary segment data is added to the videoTrack in the mp4demuxer. We don't check to see if the data is only
    // audio or video (or both); adding it to video was an arbitrary choice.
    const data = videoTrack.samples;
    if (!data.length) {
     return result;
    }
    const initSegment = {
     initPTS: undefined,
     timescale: undefined,
     trackId: undefined,
    };
    let initData = this.initData;
    if (!((_initData = initData) != null && _initData.length)) {
     this.generateInitSegment(data);
     initData = this.initData;
    }
    if (!((_initData2 = initData) != null && _initData2.length)) {
     // We can't remux if the initSegment could not be generated
     this.warn('Failed to generate initSegment.');
     return result;
    }
    if (this.emitInitSegment) {
     initSegment.tracks = this.initTracks;
     this.emitInitSegment = false;
    }
    const trackSampleData = getSampleData(data, initData, this);
    const audioSampleTimestamps = initData.audio ? trackSampleData[initData.audio.id] : null;
    const videoSampleTimestamps = initData.video ? trackSampleData[initData.video.id] : null;
    const videoStartTime = toStartEndOrDefault(videoSampleTimestamps, Infinity);
    const audioStartTime = toStartEndOrDefault(audioSampleTimestamps, Infinity);
    const videoEndTime = toStartEndOrDefault(videoSampleTimestamps, 0, true);
    const audioEndTime = toStartEndOrDefault(audioSampleTimestamps, 0, true);
    let decodeTime = timeOffset;
    let duration = 0;
    const syncOnAudio = audioSampleTimestamps && (!videoSampleTimestamps || (!initPTS && audioStartTime < videoStartTime) || (initPTS && initPTS.trackId === initData.audio.id));
    const baseOffsetSamples = syncOnAudio ? audioSampleTimestamps : videoSampleTimestamps;
    if (baseOffsetSamples) {
     const timescale = baseOffsetSamples.timescale;
     const baseTime = baseOffsetSamples.start - timeOffset * timescale;
     const trackId = syncOnAudio ? initData.audio.id : initData.video.id;
     decodeTime = baseOffsetSamples.start / timescale;
     duration = syncOnAudio ? audioEndTime - audioStartTime : videoEndTime - videoStartTime;
     if ((accurateTimeOffset || !initPTS) && (isInvalidInitPts(initPTS, decodeTime, timeOffset, duration) || timescale !== initPTS.timescale)) {
      if (initPTS) {
       this.warn(`Timestamps at playlist time: ${accurateTimeOffset ? '' : '~'}${timeOffset} ${baseTime / timescale} != initPTS: ${initPTS.baseTime / initPTS.timescale} (${initPTS.baseTime}/${initPTS.timescale}) trackId: ${initPTS.trackId}`);
      }
      this.log(`Found initPTS at playlist time: ${timeOffset} offset: ${decodeTime - timeOffset} (${baseTime}/${timescale}) trackId: ${trackId}`);
      initPTS = null;
      initSegment.initPTS = baseTime;
      initSegment.timescale = timescale;
      initSegment.trackId = trackId;
     }
    } else {
     this.warn(`No audio or video samples found for initPTS at playlist time: ${timeOffset}`);
    }
    if (!initPTS) {
     if (!initSegment.timescale || initSegment.trackId === undefined || initSegment.initPTS === undefined) {
      this.warn('Could not set initPTS');
      initSegment.initPTS = decodeTime;
      initSegment.timescale = 1;
      initSegment.trackId = -1;
     }
     this.initPTS = initPTS = {
      baseTime: initSegment.initPTS,
      timescale: initSegment.timescale,
      trackId: initSegment.trackId,
     };
    } else {
     initSegment.initPTS = initPTS.baseTime;
     initSegment.timescale = initPTS.timescale;
     initSegment.trackId = initPTS.trackId;
    }
    const startTime = decodeTime - initPTS.baseTime / initPTS.timescale;
    const endTime = startTime + duration;
    if (duration > 0) {
     this.lastEndTime = endTime;
    } else {
     this.warn('Duration parsed from mp4 should be greater than zero');
     this.resetNextTimestamp();
    }
    const hasAudio = !!initData.audio;
    const hasVideo = !!initData.video;
    let type = '';
    if (hasAudio) {
     type += 'audio';
    }
    if (hasVideo) {
     type += 'video';
    }
    const encrypted = (initData.audio ? initData.audio.encrypted : false) || (initData.video ? initData.video.encrypted : false);
    const track = {
     data1: data,
     startPTS: startTime,
     startDTS: startTime,
     endPTS: endTime,
     endDTS: endTime,
     type,
     hasAudio,
     hasVideo,
     nb: 1,
     dropped: 0,
     encrypted,
    };
    result.audio = hasAudio && !hasVideo ? track : undefined;
    result.video = hasVideo ? track : undefined;
    const videoSampleCount = videoSampleTimestamps == null ? void 0 : videoSampleTimestamps.sampleCount;
    if (videoSampleCount) {
     const firstKeyFrame = videoSampleTimestamps.keyFrameIndex;
     const independent = firstKeyFrame !== -1;
     track.nb = videoSampleCount;
     track.dropped = firstKeyFrame === 0 || this.isVideoContiguous ? 0 : independent ? firstKeyFrame : videoSampleCount;
     track.independent = independent;
     track.firstKeyFrame = firstKeyFrame;
     if (independent && videoSampleTimestamps.keyFrameStart) {
      track.firstKeyFramePTS = (videoSampleTimestamps.keyFrameStart - initPTS.baseTime) / initPTS.timescale;
     }
     if (!this.isVideoContiguous) {
      result.independent = independent;
     }
     this.isVideoContiguous || (this.isVideoContiguous = independent);
     if (track.dropped) {
      this.warn(`fmp4 does not start with IDR: firstIDR ${firstKeyFrame}/${videoSampleCount} dropped: ${track.dropped} start: ${track.firstKeyFramePTS || 'NA'}`);
     }
    }
    result.initSegment = initSegment;
    result.id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, initPTS, initPTS);
    if (textTrack.samples.length) {
     result.text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, initPTS);
    }
    return result;
   }
  }
  function toStartEndOrDefault(trackTimes, defaultValue, end = false) {
   return (trackTimes == null ? void 0 : trackTimes.start) !== undefined ? (trackTimes.start + (end ? trackTimes.duration : 0)) / trackTimes.timescale : defaultValue;
  }
  function isInvalidInitPts(initPTS, startDTS, timeOffset, duration) {
   if (initPTS === null) {
    return true;
   }
   // InitPTS is invalid when distance from program would be more than segment duration or a minimum of one second
   const minDuration = Math.max(duration, 1);
   const startTime = startDTS - initPTS.baseTime / initPTS.timescale;
   return Math.abs(startTime - timeOffset) > minDuration;
  }
  function getParsedTrackCodec(track, type, logger) {
   const parsedCodec = track.codec;
   if (parsedCodec && parsedCodec.length > 4) {
    return parsedCodec;
   }
   if (type === ElementaryStreamTypes.AUDIO) {
    if (parsedCodec === 'ec-3' || parsedCodec === 'ac-3' || parsedCodec === 'alac') {
     return parsedCodec;
    }
    if (parsedCodec === 'fLaC' || parsedCodec === 'Opus') {
     // Opting not to get `preferManagedMediaSource` from player config for isSupported() check for simplicity
     const preferManagedMediaSource = false;
     return getCodecCompatibleName(parsedCodec, preferManagedMediaSource);
    }
    logger.warn(`Unhandled audio codec "${parsedCodec}" in mp4 MAP`);
    return parsedCodec || 'mp4a';
   }
   // Provide defaults based on codec type
   // This allows for some playback of some fmp4 playlists without CODECS defined in manifest
   logger.warn(`Unhandled video codec "${parsedCodec}" in mp4 MAP`);
   return parsedCodec || 'avc1';
  }

  let now;
  // performance.now() not available on WebWorker, at least on Safari Desktop
  try {
   now = self.performance.now.bind(self.performance);
  } catch (err) {
   now = Date.now;
  }
  const muxConfig = [
   {
    demux: MP4Demuxer,
    remux: PassThroughRemuxer,
   },
   {
    demux: TSDemuxer,
    remux: MP4Remuxer,
   },
   {
    demux: AACDemuxer,
    remux: MP4Remuxer,
   },
   {
    demux: MP3Demuxer,
    remux: MP4Remuxer,
   },
  ];
  {
   muxConfig.splice(2, 0, {
    demux: AC3Demuxer,
    remux: MP4Remuxer,
   });
  }
  class Transmuxer {
   constructor(observer, typeSupported, config, vendor, id, logger) {
    this.asyncResult = false;
    this.logger = void 0;
    this.observer = void 0;
    this.typeSupported = void 0;
    this.config = void 0;
    this.id = void 0;
    this.demuxer = void 0;
    this.remuxer = void 0;
    this.decrypter = void 0;
    this.probe = void 0;
    this.decryptionPromise = null;
    this.transmuxConfig = void 0;
    this.currentTransmuxState = void 0;
    this.observer = observer;
    this.typeSupported = typeSupported;
    this.config = config;
    this.id = id;
    this.logger = logger;
   }
   configure(transmuxConfig) {
    this.transmuxConfig = transmuxConfig;
    if (this.decrypter) {
     this.decrypter.reset();
    }
   }
   push(data, decryptdata, chunkMeta, state) {
    const stats = chunkMeta.transmuxing;
    stats.executeStart = now();
    let uintData = new Uint8Array(data);
    const { currentTransmuxState, transmuxConfig } = this;
    if (state) {
     this.currentTransmuxState = state;
    }
    const { contiguous, discontinuity, trackSwitch, accurateTimeOffset, timeOffset, initSegmentChange } = state || currentTransmuxState;
    const { audioCodec, videoCodec, defaultInitPts, duration, initSegmentData } = transmuxConfig;
    const keyData = getEncryptionType(uintData, decryptdata);
    if (keyData && isFullSegmentEncryption(keyData.method)) {
     const decrypter = this.getDecrypter();
     const aesMode = getAesModeFromFullSegmentMethod(keyData.method);

     // Software decryption is synchronous; webCrypto is not
     if (decrypter.isSync()) {
      // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached
      // data is handled in the flush() call
      let decryptedData = decrypter.softwareDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer, aesMode);
      // For Low-Latency HLS Parts, decrypt in place, since part parsing is expected on push progress
      const loadingParts = chunkMeta.part > -1;
      if (loadingParts) {
       const _data = decrypter.flush();
       decryptedData = _data ? _data.buffer : _data;
      }
      if (!decryptedData) {
       stats.executeEnd = now();
       return emptyResult(chunkMeta);
      }
      uintData = new Uint8Array(decryptedData);
     } else {
      this.asyncResult = true;
      this.decryptionPromise = decrypter.webCryptoDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer, aesMode).then((decryptedData) => {
       // Calling push here is important; if flush() is called while this is still resolving, this ensures that
       // the decrypted data has been transmuxed
       const result = this.push(decryptedData, null, chunkMeta);
       this.decryptionPromise = null;
       return result;
      });
      return this.decryptionPromise;
     }
    }
    const resetMuxers = this.needsProbing(discontinuity, trackSwitch);
    if (resetMuxers) {
     const error = this.configureTransmuxer(uintData);
     if (error) {
      this.logger.warn(`[transmuxer] ${error.message}`);
      this.observer.emit(Events.ERROR, Events.ERROR, {
       type: ErrorTypes.MEDIA_ERROR,
       details: ErrorDetails.FRAG_PARSING_ERROR,
       fatal: false,
       error,
       reason: error.message,
      });
      stats.executeEnd = now();
      return emptyResult(chunkMeta);
     }
    }
    if (discontinuity || trackSwitch || initSegmentChange || resetMuxers) {
     this.resetInitSegment(initSegmentData, audioCodec, videoCodec, duration, decryptdata);
    }
    if (discontinuity || initSegmentChange || resetMuxers) {
     this.resetInitialTimestamp(defaultInitPts);
    }
    if (!contiguous) {
     this.resetContiguity();
    }
    const result = this.transmux(uintData, keyData, timeOffset, accurateTimeOffset, chunkMeta);
    this.asyncResult = isPromise(result);
    const currentState = this.currentTransmuxState;
    currentState.contiguous = true;
    currentState.discontinuity = false;
    currentState.trackSwitch = false;
    stats.executeEnd = now();
    return result;
   }

   // Due to data caching, flush calls can produce more than one TransmuxerResult (hence the Array type)
   flush(chunkMeta) {
    const stats = chunkMeta.transmuxing;
    stats.executeStart = now();
    const { decrypter, currentTransmuxState, decryptionPromise } = this;
    if (decryptionPromise) {
     this.asyncResult = true;
     // Upon resolution, the decryption promise calls push() and returns its TransmuxerResult up the stack. Therefore
     // only flushing is required for async decryption
     return decryptionPromise.then(() => {
      return this.flush(chunkMeta);
     });
    }
    const transmuxResults = [];
    const { timeOffset } = currentTransmuxState;
    if (decrypter) {
     // The decrypter may have data cached, which needs to be demuxed. In this case we'll have two TransmuxResults
     // This happens in the case that we receive only 1 push call for a segment (either for non-progressive downloads,
     // or for progressive downloads with small segments)
     const decryptedData = decrypter.flush();
     if (decryptedData) {
      // Push always returns a TransmuxerResult if decryptdata is null
      transmuxResults.push(this.push(decryptedData.buffer, null, chunkMeta));
     }
    }
    const { demuxer, remuxer } = this;
    if (!demuxer || !remuxer) {
     // If probing failed, then Hls.js has been given content its not able to handle
     stats.executeEnd = now();
     const emptyResults = [emptyResult(chunkMeta)];
     if (this.asyncResult) {
      return Promise.resolve(emptyResults);
     }
     return emptyResults;
    }
    const demuxResultOrPromise = demuxer.flush(timeOffset);
    if (isPromise(demuxResultOrPromise)) {
     this.asyncResult = true;
     // Decrypt final SAMPLE-AES samples
     return demuxResultOrPromise.then((demuxResult) => {
      this.flushRemux(transmuxResults, demuxResult, chunkMeta);
      return transmuxResults;
     });
    }
    this.flushRemux(transmuxResults, demuxResultOrPromise, chunkMeta);
    if (this.asyncResult) {
     return Promise.resolve(transmuxResults);
    }
    return transmuxResults;
   }
   flushRemux(transmuxResults, demuxResult, chunkMeta) {
    const { audioTrack, videoTrack, id3Track, textTrack } = demuxResult;
    const { accurateTimeOffset, timeOffset } = this.currentTransmuxState;
    this.logger.log(`[transmuxer.ts]: Flushed ${this.id} sn: ${chunkMeta.sn}${chunkMeta.part > -1 ? ' part: ' + chunkMeta.part : ''} of ${this.id === PlaylistLevelType.MAIN ? 'level' : 'track'} ${chunkMeta.level}`);
    const remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, true, this.id);
    transmuxResults.push({
     remuxResult,
     chunkMeta,
    });
    chunkMeta.transmuxing.executeEnd = now();
   }
   resetInitialTimestamp(defaultInitPts) {
    const { demuxer, remuxer } = this;
    if (!demuxer || !remuxer) {
     return;
    }
    demuxer.resetTimeStamp(defaultInitPts);
    remuxer.resetTimeStamp(defaultInitPts);
   }
   resetContiguity() {
    const { demuxer, remuxer } = this;
    if (!demuxer || !remuxer) {
     return;
    }
    demuxer.resetContiguity();
    remuxer.resetNextTimestamp();
   }
   resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration, decryptdata) {
    const { demuxer, remuxer } = this;
    if (!demuxer || !remuxer) {
     return;
    }
    demuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration);
    remuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, decryptdata);
   }
   destroy() {
    if (this.demuxer) {
     this.demuxer.destroy();
     this.demuxer = undefined;
    }
    if (this.remuxer) {
     this.remuxer.destroy();
     this.remuxer = undefined;
    }
   }
   transmux(data, keyData, timeOffset, accurateTimeOffset, chunkMeta) {
    let result;
    if (keyData && keyData.method === 'SAMPLE-AES') {
     result = this.transmuxSampleAes(data, keyData, timeOffset, accurateTimeOffset, chunkMeta);
    } else {
     result = this.transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta);
    }
    return result;
   }
   transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta) {
    const { audioTrack, videoTrack, id3Track, textTrack } = this.demuxer.demux(data, timeOffset, false, !this.config.progressive);
    const remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, false, this.id);
    return {
     remuxResult,
     chunkMeta,
    };
   }
   transmuxSampleAes(data, decryptData, timeOffset, accurateTimeOffset, chunkMeta) {
    return this.demuxer.demuxSampleAes(data, decryptData, timeOffset).then((demuxResult) => {
     const remuxResult = this.remuxer.remux(demuxResult.audioTrack, demuxResult.videoTrack, demuxResult.id3Track, demuxResult.textTrack, timeOffset, accurateTimeOffset, false, this.id);
     return {
      remuxResult,
      chunkMeta,
     };
    });
   }
   configureTransmuxer(data) {
    const { config, observer, typeSupported } = this;
    // probe for content type
    let mux;
    for (let i = 0, len = muxConfig.length; i < len; i++) {
     var _muxConfig$i$demux;
     if ((_muxConfig$i$demux = muxConfig[i].demux) != null && _muxConfig$i$demux.probe(data, this.logger)) {
      mux = muxConfig[i];
      break;
     }
    }
    if (!mux) {
     return new Error('Failed to find demuxer by probing fragment data');
    }
    // so let's check that current remuxer and demuxer are still valid
    const demuxer = this.demuxer;
    const remuxer = this.remuxer;
    const Remuxer = mux.remux;
    const Demuxer = mux.demux;
    if (!remuxer || !(remuxer instanceof Remuxer)) {
     this.remuxer = new Remuxer(observer, config, typeSupported, this.logger);
    }
    if (!demuxer || !(demuxer instanceof Demuxer)) {
     this.demuxer = new Demuxer(observer, config, typeSupported, this.logger);
     this.probe = Demuxer.probe;
    }
   }
   needsProbing(discontinuity, trackSwitch) {
    // in case of continuity change, or track switch
    // we might switch from content type (AAC container to TS container, or TS to fmp4 for example)
    return !this.demuxer || !this.remuxer || discontinuity || trackSwitch;
   }
   getDecrypter() {
    let decrypter = this.decrypter;
    if (!decrypter) {
     decrypter = this.decrypter = new Decrypter(this.config);
    }
    return decrypter;
   }
  }
  function getEncryptionType(data, decryptData) {
   let encryptionType = null;
   if (data.byteLength > 0 && (decryptData == null ? void 0 : decryptData.key) != null && decryptData.iv !== null && decryptData.method != null) {
    encryptionType = decryptData;
   }
   return encryptionType;
  }
  const emptyResult = (chunkMeta) => ({
   remuxResult: {},
   chunkMeta,
  });
  function isPromise(p) {
   return 'then' in p && p.then instanceof Function;
  }
  class TransmuxConfig {
   constructor(audioCodec, videoCodec, initSegmentData, duration, defaultInitPts) {
    this.audioCodec = void 0;
    this.videoCodec = void 0;
    this.initSegmentData = void 0;
    this.duration = void 0;
    this.defaultInitPts = void 0;
    this.audioCodec = audioCodec;
    this.videoCodec = videoCodec;
    this.initSegmentData = initSegmentData;
    this.duration = duration;
    this.defaultInitPts = defaultInitPts || null;
   }
  }
  class TransmuxState {
   constructor(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange) {
    this.discontinuity = void 0;
    this.contiguous = void 0;
    this.accurateTimeOffset = void 0;
    this.trackSwitch = void 0;
    this.timeOffset = void 0;
    this.initSegmentChange = void 0;
    this.discontinuity = discontinuity;
    this.contiguous = contiguous;
    this.accurateTimeOffset = accurateTimeOffset;
    this.trackSwitch = trackSwitch;
    this.timeOffset = timeOffset;
    this.initSegmentChange = initSegmentChange;
   }
  }

  let transmuxerInstanceCount = 0;
  class TransmuxerInterface {
   constructor(_hls, id, onTransmuxComplete, onFlush) {
    this.error = null;
    this.hls = void 0;
    this.id = void 0;
    this.instanceNo = transmuxerInstanceCount++;
    this.observer = void 0;
    this.frag = null;
    this.part = null;
    this.useWorker = void 0;
    this.workerContext = null;
    this.transmuxer = null;
    this.onTransmuxComplete = void 0;
    this.onFlush = void 0;
    this.onWorkerMessage = (event) => {
     const data = event.data;
     const hls = this.hls;
     if (!hls || !(data != null && data.event) || data.instanceNo !== this.instanceNo) {
      return;
     }
     switch (data.event) {
      case 'init': {
       var _this$workerContext;
       const objectURL = (_this$workerContext = this.workerContext) == null ? void 0 : _this$workerContext.objectURL;
       if (objectURL) {
        // revoke the Object URL that was used to create transmuxer worker, so as not to leak it
        self.URL.revokeObjectURL(objectURL);
       }
       break;
      }
      case 'transmuxComplete': {
       this.handleTransmuxComplete(data.data);
       break;
      }
      case 'flush': {
       this.onFlush(data.data);
       break;
      }

      // pass logs from the worker thread to the main logger
      case 'workerLog': {
       if (hls.logger[data.data.logType]) {
        hls.logger[data.data.logType](data.data.message);
       }
       break;
      }
      default: {
       data.data = data.data || {};
       data.data.frag = this.frag;
       data.data.part = this.part;
       data.data.id = this.id;
       hls.trigger(data.event, data.data);
       break;
      }
     }
    };
    this.onWorkerError = (event) => {
     if (!this.hls) {
      return;
     }
     const error = new Error(`${event.message}  (${event.filename}:${event.lineno})`);
     this.hls.config.enableWorker = false;
     this.hls.logger.warn(`Error in "${this.id}" Web Worker, fallback to inline`);
     this.hls.trigger(Events.ERROR, {
      type: ErrorTypes.OTHER_ERROR,
      details: ErrorDetails.INTERNAL_EXCEPTION,
      fatal: false,
      event: 'demuxerWorker',
      error,
     });
    };
    const config = _hls.config;
    this.hls = _hls;
    this.id = id;
    this.useWorker = !!config.enableWorker;
    this.onTransmuxComplete = onTransmuxComplete;
    this.onFlush = onFlush;
    const forwardMessage = (ev, data) => {
     data = data || {};
     data.frag = this.frag || undefined;
     if (ev === Events.ERROR) {
      data = data;
      data.parent = this.id;
      data.part = this.part;
      this.error = data.error;
     }
     this.hls.trigger(ev, data);
    };

    // forward events to main thread
    this.observer = new EventEmitter();
    this.observer.on(Events.FRAG_DECRYPTED, forwardMessage);
    this.observer.on(Events.ERROR, forwardMessage);
    const m2tsTypeSupported = getM2TSSupportedAudioTypes(config.preferManagedMediaSource);
    if (this.useWorker && typeof Worker !== 'undefined') {
     const logger = this.hls.logger;
     const canCreateWorker = config.workerPath || hasUMDWorker();
     if (canCreateWorker) {
      try {
       if (config.workerPath) {
        logger.log(`loading Web Worker ${config.workerPath} for "${id}"`);
        this.workerContext = loadWorker(config.workerPath);
       } else {
        logger.log(`injecting Web Worker for "${id}"`);
        this.workerContext = injectWorker();
       }
       const { worker } = this.workerContext;
       worker.addEventListener('message', this.onWorkerMessage);
       worker.addEventListener('error', this.onWorkerError);
       worker.postMessage({
        instanceNo: this.instanceNo,
        cmd: 'init',
        typeSupported: m2tsTypeSupported,
        id,
        config: stringify(config),
       });
      } catch (err) {
       logger.warn(`Error setting up "${id}" Web Worker, fallback to inline`, err);
       this.terminateWorker();
       this.error = null;
       this.transmuxer = new Transmuxer(this.observer, m2tsTypeSupported, config, '', id, _hls.logger);
      }
      return;
     }
    }
    this.transmuxer = new Transmuxer(this.observer, m2tsTypeSupported, config, '', id, _hls.logger);
   }
   reset() {
    this.frag = null;
    this.part = null;
    if (this.workerContext) {
     const instanceNo = this.instanceNo;
     this.instanceNo = transmuxerInstanceCount++;
     const config = this.hls.config;
     const m2tsTypeSupported = getM2TSSupportedAudioTypes(config.preferManagedMediaSource);
     this.workerContext.worker.postMessage({
      instanceNo: this.instanceNo,
      cmd: 'reset',
      resetNo: instanceNo,
      typeSupported: m2tsTypeSupported,
      id: this.id,
      config: stringify(config),
     });
    }
   }
   terminateWorker() {
    if (this.workerContext) {
     const { worker } = this.workerContext;
     this.workerContext = null;
     worker.removeEventListener('message', this.onWorkerMessage);
     worker.removeEventListener('error', this.onWorkerError);
     removeWorkerFromStore(this.hls.config.workerPath);
    }
   }
   destroy() {
    if (this.workerContext) {
     this.terminateWorker();
     // @ts-ignore
     this.onWorkerMessage = this.onWorkerError = null;
    } else {
     const transmuxer = this.transmuxer;
     if (transmuxer) {
      transmuxer.destroy();
      this.transmuxer = null;
     }
    }
    const observer = this.observer;
    if (observer) {
     observer.removeAllListeners();
    }
    this.frag = null;
    this.part = null;
    // @ts-ignore
    this.observer = null;
    // @ts-ignore
    this.hls = null;
   }
   push(data, initSegmentData, audioCodec, videoCodec, frag, part, duration, accurateTimeOffset, chunkMeta, defaultInitPTS) {
    var _frag$initSegment, _lastFrag$initSegment;
    chunkMeta.transmuxing.start = self.performance.now();
    const { instanceNo, transmuxer } = this;
    const timeOffset = part ? part.start : frag.start;
    // TODO: push "clear-lead" decrypt data for unencrypted fragments in streams with encrypted ones
    const decryptdata = frag.decryptdata;
    const lastFrag = this.frag;
    const discontinuity = !(lastFrag && frag.cc === lastFrag.cc);
    const trackSwitch = !(lastFrag && chunkMeta.level === lastFrag.level);
    const snDiff = lastFrag ? chunkMeta.sn - lastFrag.sn : -1;
    const partDiff = this.part ? chunkMeta.part - this.part.index : -1;
    const progressive = snDiff === 0 && chunkMeta.id > 1 && chunkMeta.id === (lastFrag == null ? void 0 : lastFrag.stats.chunkCount);
    const contiguous = !trackSwitch && (snDiff === 1 || (snDiff === 0 && (partDiff === 1 || (progressive && partDiff <= 0))));
    const now = self.performance.now();
    if (trackSwitch || snDiff || frag.stats.parsing.start === 0) {
     frag.stats.parsing.start = now;
    }
    if (part && (partDiff || !contiguous)) {
     part.stats.parsing.start = now;
    }
    const initSegmentChange = !(lastFrag && ((_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.url) === ((_lastFrag$initSegment = lastFrag.initSegment) == null ? void 0 : _lastFrag$initSegment.url));
    const state = new TransmuxState(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange);
    if (!contiguous || discontinuity || initSegmentChange) {
     this.hls.logger.log(`[transmuxer-interface]: Starting new transmux session for ${frag.type} sn: ${chunkMeta.sn}${chunkMeta.part > -1 ? ' part: ' + chunkMeta.part : ''} ${this.id === PlaylistLevelType.MAIN ? 'level' : 'track'}: ${chunkMeta.level} id: ${chunkMeta.id}
        discontinuity: ${discontinuity}
        trackSwitch: ${trackSwitch}
        contiguous: ${contiguous}
        accurateTimeOffset: ${accurateTimeOffset}
        timeOffset: ${timeOffset}
        initSegmentChange: ${initSegmentChange}`);
     const config = new TransmuxConfig(audioCodec, videoCodec, initSegmentData, duration, defaultInitPTS);
     this.configureTransmuxer(config);
    }
    this.frag = frag;
    this.part = part;

    // Frags with sn of 'initSegment' are not transmuxed
    if (this.workerContext) {
     // post fragment payload as transferable objects for ArrayBuffer (no copy)
     this.workerContext.worker.postMessage(
      {
       instanceNo,
       cmd: 'demux',
       data,
       decryptdata,
       chunkMeta,
       state,
      },
      data instanceof ArrayBuffer ? [data] : [],
     );
    } else if (transmuxer) {
     const transmuxResult = transmuxer.push(data, decryptdata, chunkMeta, state);
     if (isPromise(transmuxResult)) {
      transmuxResult
       .then((data) => {
        this.handleTransmuxComplete(data);
       })
       .catch((error) => {
        this.transmuxerError(error, chunkMeta, 'transmuxer-interface push error');
       });
     } else {
      this.handleTransmuxComplete(transmuxResult);
     }
    }
   }
   flush(chunkMeta) {
    chunkMeta.transmuxing.start = self.performance.now();
    const { instanceNo, transmuxer } = this;
    if (this.workerContext) {
     this.workerContext.worker.postMessage({
      instanceNo,
      cmd: 'flush',
      chunkMeta,
     });
    } else if (transmuxer) {
     const transmuxResult = transmuxer.flush(chunkMeta);
     if (isPromise(transmuxResult)) {
      transmuxResult
       .then((data) => {
        this.handleFlushResult(data, chunkMeta);
       })
       .catch((error) => {
        this.transmuxerError(error, chunkMeta, 'transmuxer-interface flush error');
       });
     } else {
      this.handleFlushResult(transmuxResult, chunkMeta);
     }
    }
   }
   transmuxerError(error, chunkMeta, reason) {
    if (!this.hls) {
     return;
    }
    this.error = error;
    this.hls.trigger(Events.ERROR, {
     type: ErrorTypes.MEDIA_ERROR,
     details: ErrorDetails.FRAG_PARSING_ERROR,
     chunkMeta,
     frag: this.frag || undefined,
     part: this.part || undefined,
     fatal: false,
     error,
     err: error,
     reason,
    });
   }
   handleFlushResult(results, chunkMeta) {
    results.forEach((result) => {
     this.handleTransmuxComplete(result);
    });
    this.onFlush(chunkMeta);
   }
   configureTransmuxer(config) {
    const { instanceNo, transmuxer } = this;
    if (this.workerContext) {
     this.workerContext.worker.postMessage({
      instanceNo,
      cmd: 'configure',
      config,
     });
    } else if (transmuxer) {
     transmuxer.configure(config);
    }
   }
   handleTransmuxComplete(result) {
    result.chunkMeta.transmuxing.end = self.performance.now();
    this.onTransmuxComplete(result);
   }
  }

  const TICK_INTERVAL$3 = 100; // how often to tick in ms

  class AudioStreamController extends BaseStreamController {
   constructor(hls, fragmentTracker, keyLoader) {
    super(hls, fragmentTracker, keyLoader, 'audio-stream-controller', PlaylistLevelType.AUDIO);
    this.mainAnchor = null;
    this.mainFragLoading = null;
    this.audioOnly = false;
    this.bufferedTrack = null;
    this.switchingTrack = null;
    this.trackId = -1;
    this.waitingData = null;
    this.mainDetails = null;
    this.flushing = false;
    this.bufferFlushed = false;
    this.cachedTrackLoadedData = null;
    this.registerListeners();
   }
   onHandlerDestroying() {
    this.unregisterListeners();
    super.onHandlerDestroying();
    this.resetItem();
   }
   resetItem() {
    this.mainDetails = this.mainAnchor = this.mainFragLoading = this.bufferedTrack = this.switchingTrack = this.waitingData = this.cachedTrackLoadedData = null;
   }
   registerListeners() {
    super.registerListeners();
    const { hls } = this;
    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.on(Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);
    hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
    hls.on(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
    hls.on(Events.BUFFER_RESET, this.onBufferReset, this);
    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);
    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
    hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
    hls.on(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);
    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);
    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);
   }
   unregisterListeners() {
    const { hls } = this;
    if (!hls) {
     return;
    }
    super.unregisterListeners();
    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.off(Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);
    hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
    hls.off(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
    hls.off(Events.BUFFER_RESET, this.onBufferReset, this);
    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);
    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
    hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
    hls.off(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);
    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);
    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);
   }

   // INIT_PTS_FOUND is triggered when the video track parsed in the stream-controller has a new PTS value
   onInitPtsFound(event, { frag, id, initPTS, timescale, trackId }) {
    // Always update the new INIT PTS
    // Can change due level switch
    if (id === PlaylistLevelType.MAIN) {
     const cc = frag.cc;
     const inFlightFrag = this.fragCurrent;
     this.initPTS[cc] = {
      baseTime: initPTS,
      timescale,
      trackId,
     };
     this.log(`InitPTS for cc: ${cc} found from main: ${initPTS / timescale} (${initPTS}/${timescale}) trackId: ${trackId}`);
     this.mainAnchor = frag;
     // If we are waiting, tick immediately to unblock audio fragment transmuxing
     if (this.state === State.WAITING_INIT_PTS) {
      const waitingData = this.waitingData;
      if ((!waitingData && !this.loadingParts) || (waitingData && waitingData.frag.cc !== cc)) {
       this.syncWithAnchor(frag, waitingData == null ? void 0 : waitingData.frag);
      }
     } else if (!this.hls.hasEnoughToStart && inFlightFrag && inFlightFrag.cc !== cc) {
      inFlightFrag.abortRequests();
      this.syncWithAnchor(frag, inFlightFrag);
     } else if (this.state === State.IDLE) {
      this.tick();
     }
    }
   }
   getLoadPosition() {
    if (!this.startFragRequested && this.nextLoadPosition >= 0) {
     return this.nextLoadPosition;
    }
    return super.getLoadPosition();
   }
   syncWithAnchor(mainAnchor, waitingToAppend) {
    var _this$mainFragLoading;
    // Drop waiting fragment if videoTrackCC has changed since waitingFragment was set and initPTS was not found
    const mainFragLoading = ((_this$mainFragLoading = this.mainFragLoading) == null ? void 0 : _this$mainFragLoading.frag) || null;
    if (waitingToAppend) {
     if ((mainFragLoading == null ? void 0 : mainFragLoading.cc) === waitingToAppend.cc) {
      // Wait for loading frag to complete and INIT_PTS_FOUND
      return;
     }
    }
    const targetDiscontinuity = (mainFragLoading || mainAnchor).cc;
    const trackDetails = this.getLevelDetails();
    const pos = this.getLoadPosition();
    const syncFrag = findNearestWithCC(trackDetails, targetDiscontinuity, pos);
    // Only stop waiting for audioFrag.cc if an audio segment of the same discontinuity domain (cc) is found
    if (syncFrag) {
     this.log(`Syncing with main frag at ${syncFrag.start} cc ${syncFrag.cc}`);
     this.startFragRequested = false;
     this.nextLoadPosition = syncFrag.start;
     this.resetLoadingState();
     if (this.state === State.IDLE) {
      this.doTickIdle();
     }
    }
   }
   startLoad(startPosition, skipSeekToStartPosition) {
    if (!this.levels) {
     this.startPosition = startPosition;
     this.state = State.STOPPED;
     return;
    }
    const lastCurrentTime = this.lastCurrentTime;
    this.stopLoad();
    this.setInterval(TICK_INTERVAL$3);
    if (lastCurrentTime > 0 && startPosition === -1) {
     this.log(`Override startPosition with lastCurrentTime @${lastCurrentTime.toFixed(3)}`);
     startPosition = lastCurrentTime;
     this.state = State.IDLE;
    } else {
     this.state = State.WAITING_TRACK;
    }
    this.nextLoadPosition = this.lastCurrentTime = startPosition + this.timelineOffset;
    this.startPosition = skipSeekToStartPosition ? -1 : startPosition;
    this.tick();
   }
   doTick() {
    switch (this.state) {
     case State.IDLE:
      this.doTickIdle();
      break;
     case State.WAITING_TRACK: {
      const { levels, trackId } = this;
      const currenTrack = levels == null ? void 0 : levels[trackId];
      const details = currenTrack == null ? void 0 : currenTrack.details;
      if (details && !this.waitForLive(currenTrack)) {
       if (this.waitForCdnTuneIn(details)) {
        break;
       }
       this.state = State.WAITING_INIT_PTS;
      }
      break;
     }
     case State.FRAG_LOADING_WAITING_RETRY: {
      var _this$media;
      const now = performance.now();
      const retryDate = this.retryDate;
      // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading
      if (!retryDate || now >= retryDate || ((_this$media = this.media) != null && _this$media.seeking)) {
       const { levels, trackId } = this;
       this.log('RetryDate reached, switch back to IDLE state');
       this.resetStartWhenNotLoaded((levels == null ? void 0 : levels[trackId]) || null);
       this.state = State.IDLE;
      }
      break;
     }
     case State.WAITING_INIT_PTS: {
      // Ensure we don't get stuck in the WAITING_INIT_PTS state if the waiting frag CC doesn't match any initPTS
      const waitingData = this.waitingData;
      if (waitingData) {
       const { frag, part, cache, complete } = waitingData;
       const mainAnchor = this.mainAnchor;
       if (this.initPTS[frag.cc] !== undefined) {
        this.waitingData = null;
        this.state = State.FRAG_LOADING;
        const payload = cache.flush().buffer;
        const data = {
         frag,
         part,
         payload,
         networkDetails: null,
        };
        this._handleFragmentLoadProgress(data);
        if (complete) {
         super._handleFragmentLoadComplete(data);
        }
       } else if (mainAnchor && mainAnchor.cc !== waitingData.frag.cc) {
        this.syncWithAnchor(mainAnchor, waitingData.frag);
       }
      } else {
       this.state = State.IDLE;
      }
     }
    }
    this.onTickEnd();
   }
   resetLoadingState() {
    const waitingData = this.waitingData;
    if (waitingData) {
     this.fragmentTracker.removeFragment(waitingData.frag);
     this.waitingData = null;
    }
    super.resetLoadingState();
   }
   onTickEnd() {
    const { media } = this;
    if (!(media != null && media.readyState)) {
     // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)
     return;
    }
    this.lastCurrentTime = media.currentTime;
   }
   doTickIdle() {
    var _this$mainFragLoading2;
    const { hls, levels, media, trackId } = this;
    const config = hls.config;

    // 1. if buffering is suspended
    // 2. if video not attached AND
    //    start fragment already requested OR start frag prefetch not enabled
    // 3. if tracks or track not loaded and selected
    // then exit loop
    // => if media not attached but start frag prefetch is enabled and start frag not requested yet, we will not exit loop
    if (!this.buffering || (!media && !this.primaryPrefetch && (this.startFragRequested || !config.startFragPrefetch)) || !(levels != null && levels[trackId])) {
     return;
    }
    const levelInfo = levels[trackId];
    const trackDetails = levelInfo.details;
    if (!trackDetails || this.waitForLive(levelInfo) || this.waitForCdnTuneIn(trackDetails)) {
     this.state = State.WAITING_TRACK;
     this.startFragRequested = false;
     return;
    }
    const bufferable = this.mediaBuffer ? this.mediaBuffer : this.media;
    if (this.bufferFlushed && bufferable) {
     this.bufferFlushed = false;
     this.afterBufferFlushed(bufferable, ElementaryStreamTypes.AUDIO, PlaylistLevelType.AUDIO);
    }
    const bufferInfo = this.getFwdBufferInfo(bufferable, PlaylistLevelType.AUDIO);
    if (bufferInfo === null) {
     return;
    }
    if (!this.switchingTrack && this._streamEnded(bufferInfo, trackDetails)) {
     hls.trigger(Events.BUFFER_EOS, {
      type: 'audio',
     });
     this.state = State.ENDED;
     return;
    }
    const bufferLen = bufferInfo.len;
    const maxBufLen = hls.maxBufferLength;
    const fragments = trackDetails.fragments;
    const start = fragments[0].start;
    const loadPosition = this.getLoadPosition();
    const targetBufferTime = this.flushing ? loadPosition : bufferInfo.end;
    if (this.switchingTrack && media) {
     const pos = loadPosition;
     // if currentTime (pos) is less than alt audio playlist start time, it means that alt audio is ahead of currentTime
     if (trackDetails.PTSKnown && pos < start) {
      // if everything is buffered from pos to start or if audio buffer upfront, let's seek to start
      if (bufferInfo.end > start || bufferInfo.nextStart) {
       this.log('Alt audio track ahead of main track, seek to start of alt audio track');
       media.currentTime = start + 0.05;
      }
     }
    }

    // if buffer length is less than maxBufLen, or near the end, find a fragment to load
    if (bufferLen >= maxBufLen && !this.switchingTrack && targetBufferTime < fragments[fragments.length - 1].start) {
     return;
    }
    let frag = this.getNextFragment(targetBufferTime, trackDetails);
    // Avoid loop loading by using nextLoadPosition set for backtracking and skipping consecutive GAP tags
    if (frag && this.isLoopLoading(frag, targetBufferTime)) {
     frag = this.getNextFragmentLoopLoading(frag, trackDetails, bufferInfo, PlaylistLevelType.MAIN, maxBufLen);
    }
    if (!frag) {
     this.bufferFlushed = true;
     return;
    }

    // Request audio segments up to one fragment ahead of main stream-controller
    let mainFragLoading = ((_this$mainFragLoading2 = this.mainFragLoading) == null ? void 0 : _this$mainFragLoading2.frag) || null;
    if (!this.audioOnly && this.startFragRequested && mainFragLoading && isMediaFragment(frag) && !frag.endList && (!trackDetails.live || (!this.loadingParts && targetBufferTime < this.hls.liveSyncPosition))) {
     if (this.fragmentTracker.getState(mainFragLoading) === FragmentState.OK) {
      this.mainFragLoading = mainFragLoading = null;
     }
     if (mainFragLoading && isMediaFragment(mainFragLoading)) {
      if (frag.start > mainFragLoading.end) {
       // Get buffered frag at target position from tracker (loaded out of sequence)
       const mainFragAtPos = this.fragmentTracker.getFragAtPos(targetBufferTime, PlaylistLevelType.MAIN);
       if (mainFragAtPos && mainFragAtPos.end > mainFragLoading.end) {
        mainFragLoading = mainFragAtPos;
        this.mainFragLoading = {
         frag: mainFragAtPos,
         targetBufferTime: null,
        };
       }
      }
      const atBufferSyncLimit = frag.start > mainFragLoading.end;
      if (atBufferSyncLimit) {
       return;
      }
     }
    }
    this.loadFragment(frag, levelInfo, targetBufferTime);
   }
   onMediaDetaching(event, data) {
    this.bufferFlushed = this.flushing = false;
    super.onMediaDetaching(event, data);
   }
   onAudioTracksUpdated(event, { audioTracks }) {
    // Reset tranxmuxer is essential for large context switches (Content Steering)
    this.resetTransmuxer();
    this.levels = audioTracks.map((mediaPlaylist) => new Level(mediaPlaylist));
   }
   onAudioTrackSwitching(event, data) {
    // if any URL found on new audio track, it is an alternate audio track
    const altAudio = !!data.url;
    this.trackId = data.id;
    const { fragCurrent } = this;
    if (fragCurrent) {
     fragCurrent.abortRequests();
     this.removeUnbufferedFrags(fragCurrent.start);
    }
    this.resetLoadingState();

    // should we switch tracks ?
    if (altAudio) {
     this.switchingTrack = data;
     // main audio track are handled by stream-controller, just do something if switching to alt audio track
     this.flushAudioIfNeeded(data);
     if (this.state !== State.STOPPED) {
      // switching to audio track, start timer if not already started
      this.setInterval(TICK_INTERVAL$3);
      this.state = State.IDLE;
      this.tick();
     }
    } else {
     // destroy useless transmuxer when switching audio to main
     this.resetTransmuxer();
     this.switchingTrack = null;
     this.bufferedTrack = data;
     this.clearInterval();
    }
   }
   onManifestLoading() {
    super.onManifestLoading();
    this.bufferFlushed = this.flushing = this.audioOnly = false;
    this.resetItem();
    this.trackId = -1;
   }
   onLevelLoaded(event, data) {
    this.mainDetails = data.details;
    const cachedTrackLoadedData = this.cachedTrackLoadedData;
    if (cachedTrackLoadedData) {
     this.cachedTrackLoadedData = null;
     this.onAudioTrackLoaded(Events.AUDIO_TRACK_LOADED, cachedTrackLoadedData);
    }
   }
   onAudioTrackLoaded(event, data) {
    var _trackLevel$details;
    const { levels } = this;
    const { details: newDetails, id: trackId, groupId, track } = data;
    if (!levels) {
     this.warn(`Audio tracks reset while loading track ${trackId} "${track.name}" of "${groupId}"`);
     return;
    }
    const mainDetails = this.mainDetails;
    if (!mainDetails || newDetails.endCC > mainDetails.endCC || mainDetails.expired) {
     this.cachedTrackLoadedData = data;
     if (this.state !== State.STOPPED) {
      this.state = State.WAITING_TRACK;
     }
     return;
    }
    this.cachedTrackLoadedData = null;
    this.log(`Audio track ${trackId} "${track.name}" of "${groupId}" loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''},duration:${newDetails.totalduration}`);
    const trackLevel = levels[trackId];
    let sliding = 0;
    if (newDetails.live || ((_trackLevel$details = trackLevel.details) != null && _trackLevel$details.live)) {
     this.checkLiveUpdate(newDetails);
     if (newDetails.deltaUpdateFailed) {
      return;
     }
     if (trackLevel.details) {
      var _this$levelLastLoaded;
      sliding = this.alignPlaylists(newDetails, trackLevel.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);
     }
     if (!newDetails.alignedSliding) {
      // Align audio rendition with the "main" playlist on discontinuity change
      // or program-date-time (PDT)
      alignDiscontinuities(newDetails, mainDetails);
      if (!newDetails.alignedSliding) {
       alignMediaPlaylistByPDT(newDetails, mainDetails);
      }
      sliding = newDetails.fragmentStart;
     }
    }
    trackLevel.details = newDetails;
    this.levelLastLoaded = trackLevel;

    // compute start position if we are aligned with the main playlist
    if (!this.startFragRequested) {
     this.setStartPosition(mainDetails, sliding);
    }
    this.hls.trigger(Events.AUDIO_TRACK_UPDATED, {
     details: newDetails,
     id: trackId,
     groupId: data.groupId,
    });

    // only switch back to IDLE state if we were waiting for track to start downloading a new fragment
    if (this.state === State.WAITING_TRACK && !this.waitForCdnTuneIn(newDetails)) {
     this.state = State.IDLE;
    }

    // trigger handler right now
    this.tick();
   }
   _handleFragmentLoadProgress(data) {
    var _frag$initSegment;
    const frag = data.frag;
    const { part, payload } = data;
    const { config, trackId, levels } = this;
    if (!levels) {
     this.warn(`Audio tracks were reset while fragment load was in progress. Fragment ${frag.sn} of level ${frag.level} will not be buffered`);
     return;
    }
    const track = levels[trackId];
    if (!track) {
     this.warn('Audio track is undefined on fragment load progress');
     return;
    }
    const details = track.details;
    if (!details) {
     this.warn('Audio track details undefined on fragment load progress');
     this.removeUnbufferedFrags(frag.start);
     return;
    }
    const audioCodec = config.defaultAudioCodec || track.audioCodec || 'mp4a.40.2';
    let transmuxer = this.transmuxer;
    if (!transmuxer) {
     transmuxer = this.transmuxer = new TransmuxerInterface(this.hls, PlaylistLevelType.AUDIO, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));
    }

    // Check if we have video initPTS
    // If not we need to wait for it
    const initPTS = this.initPTS[frag.cc];
    const initSegmentData = (_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.data;
    if (initPTS !== undefined) {
     // this.log(`Transmuxing ${sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);
     // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)
     const accurateTimeOffset = false; // details.PTSKnown || !details.live;
     const partIndex = part ? part.index : -1;
     const partial = partIndex !== -1;
     const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);
     transmuxer.push(payload, initSegmentData, audioCodec, '', frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);
    } else {
     this.log(`Unknown video PTS for cc ${frag.cc}, waiting for video PTS before demuxing audio frag ${frag.sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);
     const { cache } = (this.waitingData = this.waitingData || {
      frag,
      part,
      cache: new ChunkCache(),
      complete: false,
     });
     cache.push(new Uint8Array(payload));
     if (this.state !== State.STOPPED) {
      this.state = State.WAITING_INIT_PTS;
     }
    }
   }
   _handleFragmentLoadComplete(fragLoadedData) {
    if (this.waitingData) {
     this.waitingData.complete = true;
     return;
    }
    super._handleFragmentLoadComplete(fragLoadedData);
   }
   onBufferReset /* event: Events.BUFFER_RESET */() {
    // reset reference to sourcebuffers
    this.mediaBuffer = null;
   }
   onBufferCreated(event, data) {
    this.bufferFlushed = this.flushing = false;
    const audioTrack = data.tracks.audio;
    if (audioTrack) {
     this.mediaBuffer = audioTrack.buffer || null;
    }
   }
   onFragLoading(event, data) {
    if (!this.audioOnly && data.frag.type === PlaylistLevelType.MAIN && isMediaFragment(data.frag)) {
     this.mainFragLoading = data;
     if (this.state === State.IDLE) {
      this.tick();
     }
    }
   }
   onFragBuffered(event, data) {
    const { frag, part } = data;
    if (frag.type !== PlaylistLevelType.AUDIO) {
     if (!this.audioOnly && frag.type === PlaylistLevelType.MAIN && !frag.elementaryStreams.video && !frag.elementaryStreams.audiovideo) {
      this.audioOnly = true;
      this.mainFragLoading = null;
     }
     return;
    }
    if (this.fragContextChanged(frag)) {
     // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion
     // Avoid setting state back to IDLE or concluding the audio switch; otherwise, the switched-to track will not buffer
     this.warn(`Fragment ${frag.sn}${part ? ' p: ' + part.index : ''} of level ${frag.level} finished buffering, but was aborted. state: ${this.state}, audioSwitch: ${this.switchingTrack ? this.switchingTrack.name : 'false'}`);
     return;
    }
    if (isMediaFragment(frag)) {
     this.fragPrevious = frag;
     const track = this.switchingTrack;
     if (track) {
      this.bufferedTrack = track;
      this.switchingTrack = null;
      this.hls.trigger(Events.AUDIO_TRACK_SWITCHED, _objectSpread2({}, track));
     }
    }
    this.fragBufferedComplete(frag, part);
    if (this.media) {
     this.tick();
    }
   }
   onError(event, data) {
    var _data$context;
    if (data.fatal) {
     this.state = State.ERROR;
     return;
    }
    switch (data.details) {
     case ErrorDetails.FRAG_GAP:
     case ErrorDetails.FRAG_PARSING_ERROR:
     case ErrorDetails.FRAG_DECRYPT_ERROR:
     case ErrorDetails.FRAG_LOAD_ERROR:
     case ErrorDetails.FRAG_LOAD_TIMEOUT:
     case ErrorDetails.KEY_LOAD_ERROR:
     case ErrorDetails.KEY_LOAD_TIMEOUT:
      this.onFragmentOrKeyLoadError(PlaylistLevelType.AUDIO, data);
      break;
     case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:
     case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:
     case ErrorDetails.LEVEL_PARSING_ERROR:
      // in case of non fatal error while loading track, if not retrying to load track, switch back to IDLE
      if (!data.levelRetry && this.state === State.WAITING_TRACK && ((_data$context = data.context) == null ? void 0 : _data$context.type) === PlaylistContextType.AUDIO_TRACK) {
       this.state = State.IDLE;
      }
      break;
     case ErrorDetails.BUFFER_ADD_CODEC_ERROR:
     case ErrorDetails.BUFFER_APPEND_ERROR:
      if (data.parent !== 'audio') {
       return;
      }
      if (!this.reduceLengthAndFlushBuffer(data)) {
       this.resetLoadingState();
      }
      break;
     case ErrorDetails.BUFFER_FULL_ERROR:
      if (data.parent !== 'audio') {
       return;
      }
      if (this.reduceLengthAndFlushBuffer(data)) {
       this.bufferedTrack = null;
       super.flushMainBuffer(0, Number.POSITIVE_INFINITY, 'audio');
      }
      break;
     case ErrorDetails.INTERNAL_EXCEPTION:
      this.recoverWorkerError(data);
      break;
    }
   }
   onBufferFlushing(event, { type }) {
    if (type !== ElementaryStreamTypes.VIDEO) {
     this.flushing = true;
    }
   }
   onBufferFlushed(event, { type }) {
    if (type !== ElementaryStreamTypes.VIDEO) {
     this.flushing = false;
     this.bufferFlushed = true;
     if (this.state === State.ENDED) {
      this.state = State.IDLE;
     }
     const mediaBuffer = this.mediaBuffer || this.media;
     if (mediaBuffer) {
      this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.AUDIO);
      this.tick();
     }
    }
   }
   _handleTransmuxComplete(transmuxResult) {
    var _id3$samples;
    const id = 'audio';
    const { hls } = this;
    const { remuxResult, chunkMeta } = transmuxResult;
    const context = this.getCurrentContext(chunkMeta);
    if (!context) {
     this.resetWhenMissingContext(chunkMeta);
     return;
    }
    const { frag, part, level } = context;
    const { details } = level;
    const { audio, text, id3, initSegment } = remuxResult;

    // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.
    // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.
    if (this.fragContextChanged(frag) || !details) {
     this.fragmentTracker.removeFragment(frag);
     return;
    }
    this.state = State.PARSING;
    if (this.switchingTrack && audio) {
     this.completeAudioSwitch(this.switchingTrack);
    }
    if (initSegment != null && initSegment.tracks) {
     const mapFragment = frag.initSegment || frag;
     if (this.unhandledEncryptionError(initSegment, frag)) {
      return;
     }
     this._bufferInitSegment(level, initSegment.tracks, mapFragment, chunkMeta);
     hls.trigger(Events.FRAG_PARSING_INIT_SEGMENT, {
      frag: mapFragment,
      id,
      tracks: initSegment.tracks,
     });
     // Only flush audio from old audio tracks when PTS is known on new audio track
    }
    if (audio) {
     const { startPTS, endPTS, startDTS, endDTS } = audio;
     if (part) {
      part.elementaryStreams[ElementaryStreamTypes.AUDIO] = {
       startPTS,
       endPTS,
       startDTS,
       endDTS,
      };
     }
     frag.setElementaryStreamInfo(ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);
     this.bufferFragmentData(audio, frag, part, chunkMeta);
    }
    if (id3 != null && (_id3$samples = id3.samples) != null && _id3$samples.length) {
     const emittedID3 = _extends(
      {
       id,
       frag,
       details,
      },
      id3,
     );
     hls.trigger(Events.FRAG_PARSING_METADATA, emittedID3);
    }
    if (text) {
     const emittedText = _extends(
      {
       id,
       frag,
       details,
      },
      text,
     );
     hls.trigger(Events.FRAG_PARSING_USERDATA, emittedText);
    }
   }
   _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {
    if (this.state !== State.PARSING) {
     return;
    }
    // delete any video track found on audio transmuxer
    if (tracks.video) {
     delete tracks.video;
    }
    if (tracks.audiovideo) {
     delete tracks.audiovideo;
    }

    // include levelCodec in audio and video tracks
    if (!tracks.audio) {
     return;
    }
    const track = tracks.audio;
    track.id = PlaylistLevelType.AUDIO;
    const variantAudioCodecs = currentLevel.audioCodec;
    this.log(`Init audio buffer, container:${track.container}, codecs[level/parsed]=[${variantAudioCodecs}/${track.codec}]`);
    // SourceBuffer will use track.levelCodec if defined
    if (variantAudioCodecs && variantAudioCodecs.split(',').length === 1) {
     track.levelCodec = variantAudioCodecs;
    }
    this.hls.trigger(Events.BUFFER_CODECS, tracks);
    const initSegment = track.initSegment;
    if (initSegment != null && initSegment.byteLength) {
     const segment = {
      type: 'audio',
      frag,
      part: null,
      chunkMeta,
      parent: frag.type,
      data: initSegment,
     };
     this.hls.trigger(Events.BUFFER_APPENDING, segment);
    }
    // trigger handler right now
    this.tickImmediate();
   }
   loadFragment(frag, track, targetBufferTime) {
    // only load if fragment is not loaded or if in audio switch
    const fragState = this.fragmentTracker.getState(frag);

    // we force a frag loading in audio switch as fragment tracker might not have evicted previous frags in case of quick audio switch
    if (this.switchingTrack || fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {
     var _track$details;
     if (!isMediaFragment(frag)) {
      this._loadInitSegment(frag, track);
     } else if ((_track$details = track.details) != null && _track$details.live && !this.initPTS[frag.cc]) {
      this.log(`Waiting for video PTS in continuity counter ${frag.cc} of live stream before loading audio fragment ${frag.sn} of level ${this.trackId}`);
      this.state = State.WAITING_INIT_PTS;
      const mainDetails = this.mainDetails;
      if (mainDetails && mainDetails.fragmentStart !== track.details.fragmentStart) {
       alignMediaPlaylistByPDT(track.details, mainDetails);
      }
     } else {
      super.loadFragment(frag, track, targetBufferTime);
     }
    } else {
     this.clearTrackerIfNeeded(frag);
    }
   }
   flushAudioIfNeeded(switchingTrack) {
    if (this.media && this.bufferedTrack) {
     const { name, lang, assocLang, characteristics, audioCodec, channels } = this.bufferedTrack;
     if (
      !matchesOption(
       {
        name,
        lang,
        assocLang,
        characteristics,
        audioCodec,
        channels,
       },
       switchingTrack,
       audioMatchPredicate,
      )
     ) {
      if (useAlternateAudio(switchingTrack.url, this.hls)) {
       this.log('Switching audio track : flushing all audio');
       super.flushMainBuffer(0, Number.POSITIVE_INFINITY, 'audio');
       this.bufferedTrack = null;
      } else {
       // Main is being buffered. Set bufferedTrack so that it is flushed when switching back to alt-audio
       this.bufferedTrack = switchingTrack;
      }
     }
    }
   }
   completeAudioSwitch(switchingTrack) {
    const { hls } = this;
    this.flushAudioIfNeeded(switchingTrack);
    this.bufferedTrack = switchingTrack;
    this.switchingTrack = null;
    hls.trigger(Events.AUDIO_TRACK_SWITCHED, _objectSpread2({}, switchingTrack));
   }
  }

  class BasePlaylistController extends Logger {
   constructor(hls, logPrefix) {
    super(logPrefix, hls.logger);
    this.hls = void 0;
    this.canLoad = false;
    this.timer = -1;
    this.hls = hls;
   }
   destroy() {
    this.clearTimer();
    // @ts-ignore
    this.hls = this.log = this.warn = null;
   }
   clearTimer() {
    if (this.timer !== -1) {
     self.clearTimeout(this.timer);
     this.timer = -1;
    }
   }
   startLoad() {
    this.canLoad = true;
    this.loadPlaylist();
   }
   stopLoad() {
    this.canLoad = false;
    this.clearTimer();
   }
   switchParams(playlistUri, previous, current) {
    const renditionReports = previous == null ? void 0 : previous.renditionReports;
    if (renditionReports) {
     let foundIndex = -1;
     for (let i = 0; i < renditionReports.length; i++) {
      const attr = renditionReports[i];
      let uri;
      try {
       uri = new self.URL(attr.URI, previous.url).href;
      } catch (error) {
       this.warn(`Could not construct new URL for Rendition Report: ${error}`);
       uri = attr.URI || '';
      }
      // Use exact match. Otherwise, the last partial match, if any, will be used
      // (Playlist URI includes a query string that the Rendition Report does not)
      if (uri === playlistUri) {
       foundIndex = i;
       break;
      } else if (uri === playlistUri.substring(0, uri.length)) {
       foundIndex = i;
      }
     }
     if (foundIndex !== -1) {
      const attr = renditionReports[foundIndex];
      const msn = parseInt(attr['LAST-MSN']) || previous.lastPartSn;
      let part = parseInt(attr['LAST-PART']) || previous.lastPartIndex;
      if (this.hls.config.lowLatencyMode) {
       const currentGoal = Math.min(previous.age - previous.partTarget, previous.targetduration);
       if (part >= 0 && currentGoal > previous.partTarget) {
        part += 1;
       }
      }
      const skip = current && getSkipValue(current);
      return new HlsUrlParameters(msn, part >= 0 ? part : undefined, skip);
     }
    }
   }
   loadPlaylist(hlsUrlParameters) {
    // Loading is handled by the subclasses
    this.clearTimer();
   }
   loadingPlaylist(playlist, hlsUrlParameters) {
    // Loading is handled by the subclasses
    this.clearTimer();
   }
   shouldLoadPlaylist(playlist) {
    return this.canLoad && !!playlist && !!playlist.url && (!playlist.details || playlist.details.live);
   }
   getUrlWithDirectives(uri, hlsUrlParameters) {
    if (hlsUrlParameters) {
     try {
      return hlsUrlParameters.addDirectives(uri);
     } catch (error) {
      this.warn(`Could not construct new URL with HLS Delivery Directives: ${error}`);
     }
    }
    return uri;
   }
   playlistLoaded(index, data, previousDetails) {
    const { details, stats } = data;

    // Set last updated date-time
    const now = self.performance.now();
    const elapsed = stats.loading.first ? Math.max(0, now - stats.loading.first) : 0;
    details.advancedDateTime = Date.now() - elapsed;

    // shift fragment starts with timelineOffset
    const timelineOffset = this.hls.config.timelineOffset;
    if (timelineOffset !== details.appliedTimelineOffset) {
     const offset = Math.max(timelineOffset || 0, 0);
     details.appliedTimelineOffset = offset;
     details.fragments.forEach((frag) => {
      frag.setStart(frag.playlistOffset + offset);
     });
    }

    // if current playlist is a live playlist, arm a timer to reload it
    if (details.live || (previousDetails != null && previousDetails.live)) {
     const levelOrTrack = 'levelInfo' in data ? data.levelInfo : data.track;
     details.reloaded(previousDetails);
     // Merge live playlists to adjust fragment starts and fill in delta playlist skipped segments
     if (previousDetails && details.fragments.length > 0) {
      mergeDetails(previousDetails, details, this);
      const error = details.playlistParsingError;
      if (error) {
       this.warn(error);
       const hls = this.hls;
       if (!hls.config.ignorePlaylistParsingErrors) {
        var _details$fragments$;
        const { networkDetails } = data;
        hls.trigger(Events.ERROR, {
         type: ErrorTypes.NETWORK_ERROR,
         details: ErrorDetails.LEVEL_PARSING_ERROR,
         fatal: false,
         url: details.url,
         error,
         reason: error.message,
         level: data.level || undefined,
         parent: (_details$fragments$ = details.fragments[0]) == null ? void 0 : _details$fragments$.type,
         networkDetails,
         stats,
        });
        return;
       }
       details.playlistParsingError = null;
      }
     }
     if (details.requestScheduled === -1) {
      details.requestScheduled = stats.loading.start;
     }
     const bufferInfo = this.hls.mainForwardBufferInfo;
     const position = bufferInfo ? bufferInfo.end - bufferInfo.len : 0;
     const distanceToLiveEdgeMs = (details.edge - position) * 1000;
     const reloadInterval = computeReloadInterval(details, distanceToLiveEdgeMs);
     if (details.requestScheduled + reloadInterval < now) {
      details.requestScheduled = now;
     } else {
      details.requestScheduled += reloadInterval;
     }
     this.log(`live playlist ${index} ${details.advanced ? 'REFRESHED ' + details.lastPartSn + '-' + details.lastPartIndex : details.updated ? 'UPDATED' : 'MISSED'}`);
     if (!this.canLoad || !details.live) {
      return;
     }
     let deliveryDirectives;
     let msn = undefined;
     let part = undefined;
     if (details.canBlockReload && details.endSN && details.advanced) {
      // Load level with LL-HLS delivery directives
      const lowLatencyMode = this.hls.config.lowLatencyMode;
      const lastPartSn = details.lastPartSn;
      const endSn = details.endSN;
      const lastPartIndex = details.lastPartIndex;
      const hasParts = lastPartIndex !== -1;
      const atLastPartOfSegment = lastPartSn === endSn;
      if (hasParts) {
       // When low latency mode is disabled, request the last part of the next segment
       if (atLastPartOfSegment) {
        msn = endSn + 1;
        part = lowLatencyMode ? 0 : lastPartIndex;
       } else {
        msn = lastPartSn;
        part = lowLatencyMode ? lastPartIndex + 1 : details.maxPartIndex;
       }
      } else {
       msn = endSn + 1;
      }
      // Low-Latency CDN Tune-in: "age" header and time since load indicates we're behind by more than one part
      // Update directives to obtain the Playlist that has the estimated additional duration of media
      const lastAdvanced = details.age;
      const cdnAge = lastAdvanced + details.ageHeader;
      let currentGoal = Math.min(cdnAge - details.partTarget, details.targetduration * 1.5);
      if (currentGoal > 0) {
       if (cdnAge > details.targetduration * 3) {
        // Omit segment and part directives when the last response was more than 3 target durations ago,
        this.log(`Playlist last advanced ${lastAdvanced.toFixed(2)}s ago. Omitting segment and part directives.`);
        msn = undefined;
        part = undefined;
       } else if (previousDetails != null && previousDetails.tuneInGoal && cdnAge - details.partTarget > previousDetails.tuneInGoal) {
        // If we attempted to get the next or latest playlist update, but currentGoal increased,
        // then we either can't catchup, or the "age" header cannot be trusted.
        this.warn(`CDN Tune-in goal increased from: ${previousDetails.tuneInGoal} to: ${currentGoal} with playlist age: ${details.age}`);
        currentGoal = 0;
       } else {
        const segments = Math.floor(currentGoal / details.targetduration);
        msn += segments;
        if (part !== undefined) {
         const parts = Math.round((currentGoal % details.targetduration) / details.partTarget);
         part += parts;
        }
        this.log(`CDN Tune-in age: ${details.ageHeader}s last advanced ${lastAdvanced.toFixed(2)}s goal: ${currentGoal} skip sn ${segments} to part ${part}`);
       }
       details.tuneInGoal = currentGoal;
      }
      deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);
      if (lowLatencyMode || !atLastPartOfSegment) {
       details.requestScheduled = now;
       this.loadingPlaylist(levelOrTrack, deliveryDirectives);
       return;
      }
     } else if (details.canBlockReload || details.canSkipUntil) {
      deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);
     }
     if (deliveryDirectives && msn !== undefined && details.canBlockReload) {
      details.requestScheduled = stats.loading.first + Math.max(reloadInterval - elapsed * 2, reloadInterval / 2);
     }
     this.scheduleLoading(levelOrTrack, deliveryDirectives, details);
    } else {
     this.clearTimer();
    }
   }
   scheduleLoading(levelOrTrack, deliveryDirectives, updatedDetails) {
    const details = updatedDetails || levelOrTrack.details;
    if (!details) {
     this.loadingPlaylist(levelOrTrack, deliveryDirectives);
     return;
    }
    const now = self.performance.now();
    const requestScheduled = details.requestScheduled;
    if (now >= requestScheduled) {
     this.loadingPlaylist(levelOrTrack, deliveryDirectives);
     return;
    }
    const estimatedTimeUntilUpdate = requestScheduled - now;
    this.log(`reload live playlist ${levelOrTrack.name || levelOrTrack.bitrate + 'bps'} in ${Math.round(estimatedTimeUntilUpdate)} ms`);
    this.clearTimer();
    this.timer = self.setTimeout(() => this.loadingPlaylist(levelOrTrack, deliveryDirectives), estimatedTimeUntilUpdate);
   }
   getDeliveryDirectives(details, previousDeliveryDirectives, msn, part) {
    let skip = getSkipValue(details);
    if (previousDeliveryDirectives != null && previousDeliveryDirectives.skip && details.deltaUpdateFailed) {
     msn = previousDeliveryDirectives.msn;
     part = previousDeliveryDirectives.part;
     skip = HlsSkip.No;
    }
    return new HlsUrlParameters(msn, part, skip);
   }
   checkRetry(errorEvent) {
    const errorDetails = errorEvent.details;
    const isTimeout = isTimeoutError(errorEvent);
    const errorAction = errorEvent.errorAction;
    const { action, retryCount = 0, retryConfig } = errorAction || {};
    const retry = !!errorAction && !!retryConfig && (action === NetworkErrorAction.RetryRequest || (!errorAction.resolved && action === NetworkErrorAction.SendAlternateToPenaltyBox));
    if (retry) {
     var _errorEvent$context;
     if (retryCount >= retryConfig.maxNumRetry) {
      return false;
     }
     if (isTimeout && (_errorEvent$context = errorEvent.context) != null && _errorEvent$context.deliveryDirectives) {
      // The LL-HLS request already timed out so retry immediately
      this.warn(`Retrying playlist loading ${retryCount + 1}/${retryConfig.maxNumRetry} after "${errorDetails}" without delivery-directives`);
      this.loadPlaylist();
     } else {
      const delay = getRetryDelay(retryConfig, retryCount);
      // Schedule level/track reload
      this.clearTimer();
      this.timer = self.setTimeout(() => this.loadPlaylist(), delay);
      this.warn(`Retrying playlist loading ${retryCount + 1}/${retryConfig.maxNumRetry} after "${errorDetails}" in ${delay}ms`);
     }
     // `levelRetry = true` used to inform other controllers that a retry is happening
     errorEvent.levelRetry = true;
     errorAction.resolved = true;
    }
    return retry;
   }
  }

  function subtitleOptionsIdentical(trackList1, trackList2) {
   if (trackList1.length !== trackList2.length) {
    return false;
   }
   for (let i = 0; i < trackList1.length; i++) {
    if (!mediaAttributesIdentical(trackList1[i].attrs, trackList2[i].attrs)) {
     return false;
    }
   }
   return true;
  }
  function mediaAttributesIdentical(attrs1, attrs2, customAttributes) {
   // Media options with the same rendition ID must be bit identical
   const stableRenditionId = attrs1['STABLE-RENDITION-ID'];
   if (stableRenditionId && !customAttributes) {
    return stableRenditionId === attrs2['STABLE-RENDITION-ID'];
   }
   // When rendition ID is not present, compare attributes
   return !(customAttributes || ['LANGUAGE', 'NAME', 'CHARACTERISTICS', 'AUTOSELECT', 'DEFAULT', 'FORCED', 'ASSOC-LANGUAGE']).some((subtitleAttribute) => attrs1[subtitleAttribute] !== attrs2[subtitleAttribute]);
  }
  function subtitleTrackMatchesTextTrack(subtitleTrack, textTrack) {
   return textTrack.label.toLowerCase() === subtitleTrack.name.toLowerCase() && (!textTrack.language || textTrack.language.toLowerCase() === (subtitleTrack.lang || '').toLowerCase());
  }

  class AudioTrackController extends BasePlaylistController {
   constructor(hls) {
    super(hls, 'audio-track-controller');
    this.tracks = [];
    this.groupIds = null;
    this.tracksInGroup = [];
    this.trackId = -1;
    this.currentTrack = null;
    this.selectDefaultTrack = true;
    this.registerListeners();
   }
   registerListeners() {
    const { hls } = this;
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);
    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
    hls.on(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
    hls.on(Events.ERROR, this.onError, this);
   }
   unregisterListeners() {
    const { hls } = this;
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);
    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
    hls.off(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
    hls.off(Events.ERROR, this.onError, this);
   }
   destroy() {
    this.unregisterListeners();
    this.tracks.length = 0;
    this.tracksInGroup.length = 0;
    this.currentTrack = null;
    super.destroy();
   }
   onManifestLoading() {
    this.tracks = [];
    this.tracksInGroup = [];
    this.groupIds = null;
    this.currentTrack = null;
    this.trackId = -1;
    this.selectDefaultTrack = true;
   }
   onManifestParsed(event, data) {
    this.tracks = data.audioTracks || [];
   }
   onAudioTrackLoaded(event, data) {
    const { id, groupId, details } = data;
    const trackInActiveGroup = this.tracksInGroup[id];
    if (!trackInActiveGroup || trackInActiveGroup.groupId !== groupId) {
     this.warn(`Audio track with id:${id} and group:${groupId} not found in active group ${trackInActiveGroup == null ? void 0 : trackInActiveGroup.groupId}`);
     return;
    }
    const curDetails = trackInActiveGroup.details;
    trackInActiveGroup.details = data.details;
    this.log(`Audio track ${id} "${trackInActiveGroup.name}" lang:${trackInActiveGroup.lang} group:${groupId} loaded [${details.startSN}-${details.endSN}]`);
    if (id === this.trackId) {
     this.playlistLoaded(id, data, curDetails);
    }
   }
   onLevelLoading(event, data) {
    this.switchLevel(data.level);
   }
   onLevelSwitching(event, data) {
    this.switchLevel(data.level);
   }
   switchLevel(levelIndex) {
    const levelInfo = this.hls.levels[levelIndex];
    if (!levelInfo) {
     return;
    }
    const audioGroups = levelInfo.audioGroups || null;
    const currentGroups = this.groupIds;
    let currentTrack = this.currentTrack;
    if (!audioGroups || (currentGroups == null ? void 0 : currentGroups.length) !== (audioGroups == null ? void 0 : audioGroups.length) || (audioGroups != null && audioGroups.some((groupId) => (currentGroups == null ? void 0 : currentGroups.indexOf(groupId)) === -1))) {
     this.groupIds = audioGroups;
     this.trackId = -1;
     this.currentTrack = null;
     const audioTracks = this.tracks.filter((track) => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);
     if (audioTracks.length) {
      // Disable selectDefaultTrack if there are no default tracks
      if (this.selectDefaultTrack && !audioTracks.some((track) => track.default)) {
       this.selectDefaultTrack = false;
      }
      // track.id should match hls.audioTracks index
      audioTracks.forEach((track, i) => {
       track.id = i;
      });
     } else if (!currentTrack && !this.tracksInGroup.length) {
      // Do not dispatch AUDIO_TRACKS_UPDATED when there were and are no tracks
      return;
     }
     this.tracksInGroup = audioTracks;

     // Find preferred track
     const audioPreference = this.hls.config.audioPreference;
     if (!currentTrack && audioPreference) {
      const groupIndex = findMatchingOption(audioPreference, audioTracks, audioMatchPredicate);
      if (groupIndex > -1) {
       currentTrack = audioTracks[groupIndex];
      } else {
       const allIndex = findMatchingOption(audioPreference, this.tracks);
       currentTrack = this.tracks[allIndex];
      }
     }

     // Select initial track
     let trackId = this.findTrackId(currentTrack);
     if (trackId === -1 && currentTrack) {
      trackId = this.findTrackId(null);
     }

     // Dispatch events and load track if needed
     const audioTracksUpdated = {
      audioTracks,
     };
     this.log(`Updating audio tracks, ${audioTracks.length} track(s) found in group(s): ${audioGroups == null ? void 0 : audioGroups.join(',')}`);
     this.hls.trigger(Events.AUDIO_TRACKS_UPDATED, audioTracksUpdated);
     const selectedTrackId = this.trackId;
     if (trackId !== -1 && selectedTrackId === -1) {
      this.setAudioTrack(trackId);
     } else if (audioTracks.length && selectedTrackId === -1) {
      var _this$groupIds;
      const error = new Error(`No audio track selected for current audio group-ID(s): ${(_this$groupIds = this.groupIds) == null ? void 0 : _this$groupIds.join(',')} track count: ${audioTracks.length}`);
      this.warn(error.message);
      this.hls.trigger(Events.ERROR, {
       type: ErrorTypes.MEDIA_ERROR,
       details: ErrorDetails.AUDIO_TRACK_LOAD_ERROR,
       fatal: true,
       error,
      });
     }
    }
   }
   onError(event, data) {
    if (data.fatal || !data.context) {
     return;
    }
    if (data.context.type === PlaylistContextType.AUDIO_TRACK && data.context.id === this.trackId && (!this.groupIds || this.groupIds.indexOf(data.context.groupId) !== -1)) {
     this.checkRetry(data);
    }
   }
   get allAudioTracks() {
    return this.tracks;
   }
   get audioTracks() {
    return this.tracksInGroup;
   }
   get audioTrack() {
    return this.trackId;
   }
   set audioTrack(newId) {
    // If audio track is selected from API then don't choose from the manifest default track
    this.selectDefaultTrack = false;
    this.setAudioTrack(newId);
   }
   setAudioOption(audioOption) {
    const hls = this.hls;
    hls.config.audioPreference = audioOption;
    if (audioOption) {
     const allAudioTracks = this.allAudioTracks;
     this.selectDefaultTrack = false;
     if (allAudioTracks.length) {
      // First see if current option matches (no switch op)
      const currentTrack = this.currentTrack;
      if (currentTrack && matchesOption(audioOption, currentTrack, audioMatchPredicate)) {
       return currentTrack;
      }
      // Find option in available tracks (tracksInGroup)
      const groupIndex = findMatchingOption(audioOption, this.tracksInGroup, audioMatchPredicate);
      if (groupIndex > -1) {
       const track = this.tracksInGroup[groupIndex];
       this.setAudioTrack(groupIndex);
       return track;
      } else if (currentTrack) {
       // Find option in nearest level audio group
       let searchIndex = hls.loadLevel;
       if (searchIndex === -1) {
        searchIndex = hls.firstAutoLevel;
       }
       const switchIndex = findClosestLevelWithAudioGroup(audioOption, hls.levels, allAudioTracks, searchIndex, audioMatchPredicate);
       if (switchIndex === -1) {
        // could not find matching variant
        return null;
       }
       // and switch level to acheive the audio group switch
       hls.nextLoadLevel = switchIndex;
      }
      if (audioOption.channels || audioOption.audioCodec) {
       // Could not find a match with codec / channels predicate
       // Find a match without channels or codec
       const withoutCodecAndChannelsMatch = findMatchingOption(audioOption, allAudioTracks);
       if (withoutCodecAndChannelsMatch > -1) {
        return allAudioTracks[withoutCodecAndChannelsMatch];
       }
      }
     }
    }
    return null;
   }
   setAudioTrack(newId) {
    const tracks = this.tracksInGroup;

    // check if level idx is valid
    if (newId < 0 || newId >= tracks.length) {
     this.warn(`Invalid audio track id: ${newId}`);
     return;
    }
    this.selectDefaultTrack = false;
    const lastTrack = this.currentTrack;
    const track = tracks[newId];
    const trackLoaded = track.details && !track.details.live;
    if (newId === this.trackId && track === lastTrack && trackLoaded) {
     return;
    }
    this.log(`Switching to audio-track ${newId} "${track.name}" lang:${track.lang} group:${track.groupId} channels:${track.channels}`);
    this.trackId = newId;
    this.currentTrack = track;
    this.hls.trigger(Events.AUDIO_TRACK_SWITCHING, _objectSpread2({}, track));
    // Do not reload track unless live
    if (trackLoaded) {
     return;
    }
    const hlsUrlParameters = this.switchParams(track.url, lastTrack == null ? void 0 : lastTrack.details, track.details);
    this.loadPlaylist(hlsUrlParameters);
   }
   findTrackId(currentTrack) {
    const audioTracks = this.tracksInGroup;
    for (let i = 0; i < audioTracks.length; i++) {
     const track = audioTracks[i];
     if (this.selectDefaultTrack && !track.default) {
      continue;
     }
     if (!currentTrack || matchesOption(currentTrack, track, audioMatchPredicate)) {
      return i;
     }
    }
    if (currentTrack) {
     const { name, lang, assocLang, characteristics, audioCodec, channels } = currentTrack;
     for (let i = 0; i < audioTracks.length; i++) {
      const track = audioTracks[i];
      if (
       matchesOption(
        {
         name,
         lang,
         assocLang,
         characteristics,
         audioCodec,
         channels,
        },
        track,
        audioMatchPredicate,
       )
      ) {
       return i;
      }
     }
     for (let i = 0; i < audioTracks.length; i++) {
      const track = audioTracks[i];
      if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE', 'ASSOC-LANGUAGE', 'CHARACTERISTICS'])) {
       return i;
      }
     }
     for (let i = 0; i < audioTracks.length; i++) {
      const track = audioTracks[i];
      if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE'])) {
       return i;
      }
     }
    }
    return -1;
   }
   loadPlaylist(hlsUrlParameters) {
    super.loadPlaylist();
    const audioTrack = this.currentTrack;
    if (!this.shouldLoadPlaylist(audioTrack)) {
     return;
    }
    // Do not load audio rendition with URI matching main variant URI
    if (useAlternateAudio(audioTrack.url, this.hls)) {
     this.scheduleLoading(audioTrack, hlsUrlParameters);
    }
   }
   loadingPlaylist(audioTrack, hlsUrlParameters) {
    super.loadingPlaylist(audioTrack, hlsUrlParameters);
    const id = audioTrack.id;
    const groupId = audioTrack.groupId;
    const url = this.getUrlWithDirectives(audioTrack.url, hlsUrlParameters);
    const details = audioTrack.details;
    const age = details == null ? void 0 : details.age;
    this.log(`Loading audio-track ${id} "${audioTrack.name}" lang:${audioTrack.lang} group:${groupId}${(hlsUrlParameters == null ? void 0 : hlsUrlParameters.msn) !== undefined ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : ''}${age && details.live ? ' age ' + age.toFixed(1) + (details.type ? ' ' + details.type || 0 : '') : ''} ${url}`);
    this.hls.trigger(Events.AUDIO_TRACK_LOADING, {
     url,
     id,
     groupId,
     deliveryDirectives: hlsUrlParameters || null,
     track: audioTrack,
    });
   }
  }

  class BufferOperationQueue {
   constructor(sourceBufferReference) {
    this.tracks = void 0;
    this.queues = {
     video: [],
     audio: [],
     audiovideo: [],
    };
    this.tracks = sourceBufferReference;
   }
   destroy() {
    this.tracks = this.queues = null;
   }
   append(operation, type, pending) {
    if (this.queues === null || this.tracks === null) {
     return;
    }
    const queue = this.queues[type];
    queue.push(operation);
    if (queue.length === 1 && !pending) {
     this.executeNext(type);
    }
   }
   appendBlocker(type) {
    return new Promise((resolve) => {
     const operation = {
      label: 'async-blocker',
      execute: resolve,
      onStart: () => {},
      onComplete: () => {},
      onError: () => {},
     };
     this.append(operation, type);
    });
   }
   prependBlocker(type) {
    return new Promise((resolve) => {
     if (this.queues) {
      const operation = {
       label: 'async-blocker-prepend',
       execute: resolve,
       onStart: () => {},
       onComplete: () => {},
       onError: () => {},
      };
      this.queues[type].unshift(operation);
     }
    });
   }
   removeBlockers() {
    if (this.queues === null) {
     return;
    }
    [this.queues.video, this.queues.audio, this.queues.audiovideo].forEach((queue) => {
     var _queue$;
     const label = (_queue$ = queue[0]) == null ? void 0 : _queue$.label;
     if (label === 'async-blocker' || label === 'async-blocker-prepend') {
      queue[0].execute();
      queue.splice(0, 1);
     }
    });
   }
   unblockAudio(op) {
    if (this.queues === null) {
     return;
    }
    const queue = this.queues.audio;
    if (queue[0] === op) {
     this.shiftAndExecuteNext('audio');
    }
   }
   executeNext(type) {
    if (this.queues === null || this.tracks === null) {
     return;
    }
    const queue = this.queues[type];
    if (queue.length) {
     const operation = queue[0];
     try {
      // Operations are expected to result in an 'updateend' event being fired. If not, the queue will lock. Operations
      // which do not end with this event must call _onSBUpdateEnd manually
      operation.execute();
     } catch (error) {
      var _this$tracks$type;
      operation.onError(error);
      if (this.queues === null || this.tracks === null) {
       return;
      }

      // Only shift the current operation off, otherwise the updateend handler will do this for us
      const sb = (_this$tracks$type = this.tracks[type]) == null ? void 0 : _this$tracks$type.buffer;
      if (!(sb != null && sb.updating)) {
       this.shiftAndExecuteNext(type);
      }
     }
    }
   }
   shiftAndExecuteNext(type) {
    if (this.queues === null) {
     return;
    }
    this.queues[type].shift();
    this.executeNext(type);
   }
   current(type) {
    var _this$queues;
    return ((_this$queues = this.queues) == null ? void 0 : _this$queues[type][0]) || null;
   }
   toString() {
    const { queues, tracks } = this;
    if (queues === null || tracks === null) {
     return `<destroyed>`;
    }
    return `
${this.list('video')}
${this.list('audio')}
${this.list('audiovideo')}}`;
   }
   list(type) {
    var _this$queues2, _this$tracks;
    return ((_this$queues2 = this.queues) != null && _this$queues2[type]) || ((_this$tracks = this.tracks) != null && _this$tracks[type]) ? `${type}: (${this.listSbInfo(type)}) ${this.listOps(type)}` : '';
   }
   listSbInfo(type) {
    var _this$tracks2;
    const track = (_this$tracks2 = this.tracks) == null ? void 0 : _this$tracks2[type];
    const sb = track == null ? void 0 : track.buffer;
    if (!sb) {
     return 'none';
    }
    return `SourceBuffer${sb.updating ? ' updating' : ''}${track.ended ? ' ended' : ''}${track.ending ? ' ending' : ''}`;
   }
   listOps(type) {
    var _this$queues3;
    return ((_this$queues3 = this.queues) == null ? void 0 : _this$queues3[type].map((op) => op.label).join(', ')) || '';
   }
  }

  const VIDEO_CODEC_PROFILE_REPLACE = /(avc[1234]|hvc1|hev1|dvh[1e]|vp09|av01)(?:\.[^.,]+)+/;
  const TRACK_REMOVED_ERROR_NAME = 'HlsJsTrackRemovedError';
  class HlsJsTrackRemovedError extends Error {
   constructor(message) {
    super(message);
    this.name = TRACK_REMOVED_ERROR_NAME;
   }
  }
  class BufferController extends Logger {
   constructor(hls, fragmentTracker) {
    super('buffer-controller', hls.logger);
    this.hls = void 0;
    this.fragmentTracker = void 0;
    // The level details used to determine duration, target-duration and live
    this.details = null;
    // cache the self generated object url to detect hijack of video tag
    this._objectUrl = null;
    // A queue of buffer operations which require the SourceBuffer to not be updating upon execution
    this.operationQueue = null;
    // The total number track codecs expected before any sourceBuffers are created (2: audio and video or 1: audiovideo | audio | video)
    this.bufferCodecEventsTotal = 0;
    // A reference to the attached media element
    this.media = null;
    // A reference to the active media source
    this.mediaSource = null;
    // Last MP3 audio chunk appended
    this.lastMpegAudioChunk = null;
    // Audio fragment blocked from appending until corresponding video appends or context changes
    this.blockedAudioAppend = null;
    // Keep track of video append position for unblocking audio
    this.lastVideoAppendEnd = 0;
    // Whether or not to use ManagedMediaSource API and append source element to media element.
    this.appendSource = void 0;
    // Transferred MediaSource information used to detmerine if duration end endstream may be appended
    this.transferData = void 0;
    // Directives used to override default MediaSource handling
    this.overrides = void 0;
    // Error counters
    this.appendErrors = {
     audio: 0,
     video: 0,
     audiovideo: 0,
    };
    // Record of required or created buffers by type. SourceBuffer is stored in Track.buffer once created.
    this.tracks = {};
    // Array of SourceBuffer type and SourceBuffer (or null). One entry per TrackSet in this.tracks.
    this.sourceBuffers = [
     [null, null],
     [null, null],
    ];
    this._onEndStreaming = (event) => {
     var _this$mediaSource;
     if (!this.hls) {
      return;
     }
     if (((_this$mediaSource = this.mediaSource) == null ? void 0 : _this$mediaSource.readyState) !== 'open') {
      return;
     }
     this.hls.pauseBuffering();
    };
    this._onStartStreaming = (event) => {
     if (!this.hls) {
      return;
     }
     this.hls.resumeBuffering();
    };
    // Keep as arrow functions so that we can directly reference these functions directly as event listeners
    this._onMediaSourceOpen = (e) => {
     const { media, mediaSource } = this;
     if (e) {
      this.log('Media source opened');
     }
     if (!media || !mediaSource) {
      return;
     }
     // once received, don't listen anymore to sourceopen event
     mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);
     media.removeEventListener('emptied', this._onMediaEmptied);
     this.updateDuration();
     this.hls.trigger(Events.MEDIA_ATTACHED, {
      media,
      mediaSource: mediaSource,
     });
     if (this.mediaSource !== null) {
      this.checkPendingTracks();
     }
    };
    this._onMediaSourceClose = () => {
     this.log('Media source closed');
    };
    this._onMediaSourceEnded = () => {
     this.log('Media source ended');
    };
    this._onMediaEmptied = () => {
     const { mediaSrc, _objectUrl } = this;
     if (mediaSrc !== _objectUrl) {
      this.error(`Media element src was set while attaching MediaSource (${_objectUrl} > ${mediaSrc})`);
     }
    };
    this.hls = hls;
    this.fragmentTracker = fragmentTracker;
    this.appendSource = isManagedMediaSource(getMediaSource(hls.config.preferManagedMediaSource));
    this.initTracks();
    this.registerListeners();
   }
   hasSourceTypes() {
    return Object.keys(this.tracks).length > 0;
   }
   destroy() {
    this.unregisterListeners();
    this.details = null;
    this.lastMpegAudioChunk = this.blockedAudioAppend = null;
    this.transferData = this.overrides = undefined;
    if (this.operationQueue) {
     this.operationQueue.destroy();
     this.operationQueue = null;
    }
    // @ts-ignore
    this.hls = this.fragmentTracker = null;
    // @ts-ignore
    this._onMediaSourceOpen = this._onMediaSourceClose = null;
    // @ts-ignore
    this._onMediaSourceEnded = null;
    // @ts-ignore
    this._onStartStreaming = this._onEndStreaming = null;
   }
   registerListeners() {
    const { hls } = this;
    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.on(Events.BUFFER_RESET, this.onBufferReset, this);
    hls.on(Events.BUFFER_APPENDING, this.onBufferAppending, this);
    hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);
    hls.on(Events.BUFFER_EOS, this.onBufferEos, this);
    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
    hls.on(Events.FRAG_PARSED, this.onFragParsed, this);
    hls.on(Events.FRAG_CHANGED, this.onFragChanged, this);
    hls.on(Events.ERROR, this.onError, this);
   }
   unregisterListeners() {
    const { hls } = this;
    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.off(Events.BUFFER_RESET, this.onBufferReset, this);
    hls.off(Events.BUFFER_APPENDING, this.onBufferAppending, this);
    hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);
    hls.off(Events.BUFFER_EOS, this.onBufferEos, this);
    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
    hls.off(Events.FRAG_PARSED, this.onFragParsed, this);
    hls.off(Events.FRAG_CHANGED, this.onFragChanged, this);
    hls.off(Events.ERROR, this.onError, this);
   }
   transferMedia() {
    const { media, mediaSource } = this;
    if (!media) {
     return null;
    }
    const tracks = {};
    if (this.operationQueue) {
     const updating = this.isUpdating();
     if (!updating) {
      this.operationQueue.removeBlockers();
     }
     const queued = this.isQueued();
     if (updating || queued) {
      this.warn(`Transfering MediaSource with${queued ? ' operations in queue' : ''}${updating ? ' updating SourceBuffer(s)' : ''} ${this.operationQueue}`);
     }
     this.operationQueue.destroy();
    }
    const transferData = this.transferData;
    if (!this.sourceBufferCount && transferData && transferData.mediaSource === mediaSource) {
     _extends(tracks, transferData.tracks);
    } else {
     this.sourceBuffers.forEach((tuple) => {
      const [type] = tuple;
      if (type) {
       tracks[type] = _extends({}, this.tracks[type]);
       this.removeBuffer(type);
      }
      tuple[0] = tuple[1] = null;
     });
    }
    return {
     media,
     mediaSource,
     tracks,
    };
   }
   initTracks() {
    const tracks = {};
    this.sourceBuffers = [
     [null, null],
     [null, null],
    ];
    this.tracks = tracks;
    this.resetQueue();
    this.resetAppendErrors();
    this.lastMpegAudioChunk = this.blockedAudioAppend = null;
    this.lastVideoAppendEnd = 0;
   }
   onManifestLoading() {
    this.bufferCodecEventsTotal = 0;
    this.details = null;
   }
   onManifestParsed(event, data) {
    var _this$transferData;
    // in case of alt audio 2 BUFFER_CODECS events will be triggered, one per stream controller
    // sourcebuffers will be created all at once when the expected nb of tracks will be reached
    // in case alt audio is not used, only one BUFFER_CODEC event will be fired from main stream controller
    // it will contain the expected nb of source buffers, no need to compute it
    let codecEvents = 2;
    if ((data.audio && !data.video) || !data.altAudio) {
     codecEvents = 1;
    }
    this.bufferCodecEventsTotal = codecEvents;
    this.log(`${codecEvents} bufferCodec event(s) expected.`);
    if ((_this$transferData = this.transferData) != null && _this$transferData.mediaSource && this.sourceBufferCount && codecEvents) {
     this.bufferCreated();
    }
   }
   onMediaAttaching(event, data) {
    const media = (this.media = data.media);
    this.transferData = this.overrides = undefined;
    const MediaSource = getMediaSource(this.appendSource);
    if (MediaSource) {
     const transferringMedia = !!data.mediaSource;
     if (transferringMedia || data.overrides) {
      this.transferData = data;
      this.overrides = data.overrides;
     }
     const ms = (this.mediaSource = data.mediaSource || new MediaSource());
     this.assignMediaSource(ms);
     if (transferringMedia) {
      this._objectUrl = media.src;
      this.attachTransferred();
     } else {
      // cache the locally generated object url
      const objectUrl = (this._objectUrl = self.URL.createObjectURL(ms));
      // link video and media Source
      if (this.appendSource) {
       try {
        media.removeAttribute('src');
        // ManagedMediaSource will not open without disableRemotePlayback set to false or source alternatives
        const MMS = self.ManagedMediaSource;
        media.disableRemotePlayback = media.disableRemotePlayback || (MMS && ms instanceof MMS);
        removeSourceChildren(media);
        addSource(media, objectUrl);
        media.load();
       } catch (error) {
        media.src = objectUrl;
       }
      } else {
       media.src = objectUrl;
      }
     }
     media.addEventListener('emptied', this._onMediaEmptied);
    }
   }
   assignMediaSource(ms) {
    var _this$transferData2, _ms$constructor;
    this.log(`${((_this$transferData2 = this.transferData) == null ? void 0 : _this$transferData2.mediaSource) === ms ? 'transferred' : 'created'} media source: ${(_ms$constructor = ms.constructor) == null ? void 0 : _ms$constructor.name}`);
    // MediaSource listeners are arrow functions with a lexical scope, and do not need to be bound
    ms.addEventListener('sourceopen', this._onMediaSourceOpen);
    ms.addEventListener('sourceended', this._onMediaSourceEnded);
    ms.addEventListener('sourceclose', this._onMediaSourceClose);
    if (this.appendSource) {
     ms.addEventListener('startstreaming', this._onStartStreaming);
     ms.addEventListener('endstreaming', this._onEndStreaming);
    }
   }
   attachTransferred() {
    const media = this.media;
    const data = this.transferData;
    if (!data || !media) {
     return;
    }
    const requiredTracks = this.tracks;
    const transferredTracks = data.tracks;
    const trackNames = transferredTracks ? Object.keys(transferredTracks) : null;
    const trackCount = trackNames ? trackNames.length : 0;
    const mediaSourceOpenCallback = () => {
     Promise.resolve().then(() => {
      if (this.media && this.mediaSourceOpenOrEnded) {
       this._onMediaSourceOpen();
      }
     });
    };
    if (transferredTracks && trackNames && trackCount) {
     if (!this.tracksReady) {
      // Wait for CODECS event(s)
      this.hls.config.startFragPrefetch = true;
      this.log(`attachTransferred: waiting for SourceBuffer track info`);
      return;
     }
     this.log(`attachTransferred: (bufferCodecEventsTotal ${this.bufferCodecEventsTotal})
required tracks: ${stringify(requiredTracks, (key, value) => (key === 'initSegment' ? undefined : value))};
transfer tracks: ${stringify(transferredTracks, (key, value) => (key === 'initSegment' ? undefined : value))}}`);
     if (!isCompatibleTrackChange(transferredTracks, requiredTracks)) {
      // destroy attaching media source
      data.mediaSource = null;
      data.tracks = undefined;
      const currentTime = media.currentTime;
      const details = this.details;
      const startTime = Math.max(currentTime, (details == null ? void 0 : details.fragments[0].start) || 0);
      if (startTime - currentTime > 1) {
       this.log(`attachTransferred: waiting for playback to reach new tracks start time ${currentTime} -> ${startTime}`);
       return;
      }
      this.warn(`attachTransferred: resetting MediaSource for incompatible tracks ("${Object.keys(transferredTracks)}"->"${Object.keys(requiredTracks)}") start time: ${startTime} currentTime: ${currentTime}`);
      this.onMediaDetaching(Events.MEDIA_DETACHING, {});
      this.onMediaAttaching(Events.MEDIA_ATTACHING, data);
      media.currentTime = startTime;
      return;
     }
     this.transferData = undefined;
     trackNames.forEach((trackName) => {
      const type = trackName;
      const track = transferredTracks[type];
      if (track) {
       const sb = track.buffer;
       if (sb) {
        // Purge fragment tracker of ejected segments for existing buffer
        const fragmentTracker = this.fragmentTracker;
        const playlistType = track.id;
        if (fragmentTracker.hasFragments(playlistType) || fragmentTracker.hasParts(playlistType)) {
         const bufferedTimeRanges = BufferHelper.getBuffered(sb);
         fragmentTracker.detectEvictedFragments(type, bufferedTimeRanges, playlistType, null, true);
        }
        // Transfer SourceBuffer
        const sbIndex = sourceBufferNameToIndex(type);
        const sbTuple = [type, sb];
        this.sourceBuffers[sbIndex] = sbTuple;
        if (sb.updating && this.operationQueue) {
         this.operationQueue.prependBlocker(type);
        }
        this.trackSourceBuffer(type, track);
       }
      }
     });
     mediaSourceOpenCallback();
     this.bufferCreated();
    } else {
     this.log(`attachTransferred: MediaSource w/o SourceBuffers`);
     mediaSourceOpenCallback();
    }
   }
   get mediaSourceOpenOrEnded() {
    var _this$mediaSource2;
    const readyState = (_this$mediaSource2 = this.mediaSource) == null ? void 0 : _this$mediaSource2.readyState;
    return readyState === 'open' || readyState === 'ended';
   }
   onMediaDetaching(event, data) {
    const transferringMedia = !!data.transferMedia;
    this.transferData = this.overrides = undefined;
    const { media, mediaSource, _objectUrl } = this;
    if (mediaSource) {
     this.log(`media source ${transferringMedia ? 'transferring' : 'detaching'}`);
     if (transferringMedia) {
      // Detach SourceBuffers without removing from MediaSource
      // and leave `tracks` (required SourceBuffers configuration)
      this.sourceBuffers.forEach(([type]) => {
       if (type) {
        this.removeBuffer(type);
       }
      });
      this.resetQueue();
     } else {
      if (this.mediaSourceOpenOrEnded) {
       const open = mediaSource.readyState === 'open';
       try {
        const sourceBuffers = mediaSource.sourceBuffers;
        for (let i = sourceBuffers.length; i--; ) {
         if (open) {
          sourceBuffers[i].abort();
         }
         mediaSource.removeSourceBuffer(sourceBuffers[i]);
        }
        if (open) {
         // endOfStream could trigger exception if any sourcebuffer is in updating state
         // we don't really care about checking sourcebuffer state here,
         // as we are anyway detaching the MediaSource
         // let's just avoid this exception to propagate
         mediaSource.endOfStream();
        }
       } catch (err) {
        this.warn(`onMediaDetaching: ${err.message} while calling endOfStream`);
       }
      }
      // Clean up the SourceBuffers by invoking onBufferReset
      if (this.sourceBufferCount) {
       this.onBufferReset();
      }
     }
     mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);
     mediaSource.removeEventListener('sourceended', this._onMediaSourceEnded);
     mediaSource.removeEventListener('sourceclose', this._onMediaSourceClose);
     if (this.appendSource) {
      mediaSource.removeEventListener('startstreaming', this._onStartStreaming);
      mediaSource.removeEventListener('endstreaming', this._onEndStreaming);
     }
     this.mediaSource = null;
     this._objectUrl = null;
    }

    // Detach properly the MediaSource from the HTMLMediaElement as
    // suggested in https://github.com/w3c/media-source/issues/53.
    if (media) {
     media.removeEventListener('emptied', this._onMediaEmptied);
     if (!transferringMedia) {
      if (_objectUrl) {
       self.URL.revokeObjectURL(_objectUrl);
      }

      // clean up video tag src only if it's our own url. some external libraries might
      // hijack the video tag and change its 'src' without destroying the Hls instance first
      if (this.mediaSrc === _objectUrl) {
       media.removeAttribute('src');
       if (this.appendSource) {
        removeSourceChildren(media);
       }
       media.load();
      } else {
       this.warn('media|source.src was changed by a third party - skip cleanup');
      }
     }
     this.media = null;
    }
    this.hls.trigger(Events.MEDIA_DETACHED, data);
   }
   onBufferReset() {
    this.sourceBuffers.forEach(([type]) => {
     if (type) {
      this.resetBuffer(type);
     }
    });
    this.initTracks();
   }
   resetBuffer(type) {
    var _this$tracks$type;
    const sb = (_this$tracks$type = this.tracks[type]) == null ? void 0 : _this$tracks$type.buffer;
    this.removeBuffer(type);
    if (sb) {
     try {
      var _this$mediaSource3;
      if ((_this$mediaSource3 = this.mediaSource) != null && _this$mediaSource3.sourceBuffers.length) {
       this.mediaSource.removeSourceBuffer(sb);
      }
     } catch (err) {
      this.warn(`onBufferReset ${type}`, err);
     }
    }
    delete this.tracks[type];
   }
   removeBuffer(type) {
    this.removeBufferListeners(type);
    this.sourceBuffers[sourceBufferNameToIndex(type)] = [null, null];
    const track = this.tracks[type];
    if (track) {
     track.buffer = undefined;
    }
   }
   resetQueue() {
    if (this.operationQueue) {
     this.operationQueue.destroy();
    }
    this.operationQueue = new BufferOperationQueue(this.tracks);
   }
   onBufferCodecs(event, data) {
    const tracks = this.tracks;
    const trackNames = Object.keys(data);
    this.log(`BUFFER_CODECS: "${trackNames}" (current SB count ${this.sourceBufferCount})`);
    const unmuxedToMuxed = ('audiovideo' in data && (tracks.audio || tracks.video)) || (tracks.audiovideo && ('audio' in data || 'video' in data));
    const muxedToUnmuxed = !unmuxedToMuxed && this.sourceBufferCount && this.media && trackNames.some((sbName) => !tracks[sbName]);
    if (unmuxedToMuxed || muxedToUnmuxed) {
     this.warn(`Unsupported transition between "${Object.keys(tracks)}" and "${trackNames}" SourceBuffers`);
     // Do not add incompatible track ('audiovideo' <-> 'video'/'audio').
     // Allow following onBufferAppending handle to trigger BUFFER_APPEND_ERROR.
     // This will either be resolved by level switch or could be handled with recoverMediaError().
     return;
    }
    trackNames.forEach((trackName) => {
     var _this$transferData3, _trackCodec;
     const parsedTrack = data[trackName];
     const { id, codec, levelCodec, container, metadata, supplemental } = parsedTrack;
     let track = tracks[trackName];
     const transferredTrack = (_this$transferData3 = this.transferData) == null || (_this$transferData3 = _this$transferData3.tracks) == null ? void 0 : _this$transferData3[trackName];
     const sbTrack = transferredTrack != null && transferredTrack.buffer ? transferredTrack : track;
     const sbCodec = (sbTrack == null ? void 0 : sbTrack.pendingCodec) || (sbTrack == null ? void 0 : sbTrack.codec);
     const trackLevelCodec = sbTrack == null ? void 0 : sbTrack.levelCodec;
     if (!track) {
      track = tracks[trackName] = {
       buffer: undefined,
       listeners: [],
       codec,
       supplemental,
       container,
       levelCodec,
       metadata,
       id,
      };
     }
     // check if SourceBuffer codec needs to change
     const currentCodecFull = pickMostCompleteCodecName(sbCodec, trackLevelCodec);
     const currentCodec = currentCodecFull == null ? void 0 : currentCodecFull.replace(VIDEO_CODEC_PROFILE_REPLACE, '$1');
     let trackCodec = pickMostCompleteCodecName(codec, levelCodec);
     const nextCodec = (_trackCodec = trackCodec) == null ? void 0 : _trackCodec.replace(VIDEO_CODEC_PROFILE_REPLACE, '$1');
     if (trackCodec && currentCodecFull && currentCodec !== nextCodec) {
      if (trackName.slice(0, 5) === 'audio') {
       trackCodec = getCodecCompatibleName(trackCodec, this.appendSource);
      }
      this.log(`switching codec ${sbCodec} to ${trackCodec}`);
      if (trackCodec !== (track.pendingCodec || track.codec)) {
       track.pendingCodec = trackCodec;
      }
      track.container = container;
      this.appendChangeType(trackName, container, trackCodec);
     }
    });
    if (this.tracksReady || this.sourceBufferCount) {
     data.tracks = this.sourceBufferTracks;
    }

    // if sourcebuffers already created, do nothing ...
    if (this.sourceBufferCount) {
     return;
    }
    if (this.mediaSourceOpenOrEnded) {
     this.checkPendingTracks();
    }
   }
   get sourceBufferTracks() {
    return Object.keys(this.tracks).reduce((baseTracks, type) => {
     const track = this.tracks[type];
     baseTracks[type] = {
      id: track.id,
      container: track.container,
      codec: track.codec,
      levelCodec: track.levelCodec,
     };
     return baseTracks;
    }, {});
   }
   appendChangeType(type, container, codec) {
    const mimeType = `${container};codecs=${codec}`;
    const operation = {
     label: `change-type=${mimeType}`,
     execute: () => {
      const track = this.tracks[type];
      if (track) {
       const sb = track.buffer;
       if (sb != null && sb.changeType) {
        this.log(`changing ${type} sourceBuffer type to ${mimeType}`);
        sb.changeType(mimeType);
        track.codec = codec;
        track.container = container;
       }
      }
      this.shiftAndExecuteNext(type);
     },
     onStart: () => {},
     onComplete: () => {},
     onError: (error) => {
      this.warn(`Failed to change ${type} SourceBuffer type`, error);
     },
    };
    this.append(operation, type, this.isPending(this.tracks[type]));
   }
   blockAudio(partOrFrag) {
    var _this$fragmentTracker;
    const pStart = partOrFrag.start;
    const pTime = pStart + partOrFrag.duration * 0.05;
    const atGap = ((_this$fragmentTracker = this.fragmentTracker.getAppendedFrag(pStart, PlaylistLevelType.MAIN)) == null ? void 0 : _this$fragmentTracker.gap) === true;
    if (atGap) {
     return;
    }
    const op = {
     label: 'block-audio',
     execute: () => {
      var _this$fragmentTracker2;
      const videoTrack = this.tracks.video;
      if (this.lastVideoAppendEnd > pTime || (videoTrack != null && videoTrack.buffer && BufferHelper.isBuffered(videoTrack.buffer, pTime)) || ((_this$fragmentTracker2 = this.fragmentTracker.getAppendedFrag(pTime, PlaylistLevelType.MAIN)) == null ? void 0 : _this$fragmentTracker2.gap) === true) {
       this.blockedAudioAppend = null;
       this.shiftAndExecuteNext('audio');
      }
     },
     onStart: () => {},
     onComplete: () => {},
     onError: (error) => {
      this.warn('Error executing block-audio operation', error);
     },
    };
    this.blockedAudioAppend = {
     op,
     frag: partOrFrag,
    };
    this.append(op, 'audio', true);
   }
   unblockAudio() {
    const { blockedAudioAppend, operationQueue } = this;
    if (blockedAudioAppend && operationQueue) {
     this.blockedAudioAppend = null;
     operationQueue.unblockAudio(blockedAudioAppend.op);
    }
   }
   onBufferAppending(event, eventData) {
    const { tracks } = this;
    const { data, type, parent, frag, part, chunkMeta, offset } = eventData;
    const chunkStats = chunkMeta.buffering[type];
    const { sn, cc } = frag;
    const bufferAppendingStart = self.performance.now();
    chunkStats.start = bufferAppendingStart;
    const fragBuffering = frag.stats.buffering;
    const partBuffering = part ? part.stats.buffering : null;
    if (fragBuffering.start === 0) {
     fragBuffering.start = bufferAppendingStart;
    }
    if (partBuffering && partBuffering.start === 0) {
     partBuffering.start = bufferAppendingStart;
    }

    // TODO: Only update timestampOffset when audio/mpeg fragment or part is not contiguous with previously appended
    // Adjusting `SourceBuffer.timestampOffset` (desired point in the timeline where the next frames should be appended)
    // in Chrome browser when we detect MPEG audio container and time delta between level PTS and `SourceBuffer.timestampOffset`
    // is greater than 100ms (this is enough to handle seek for VOD or level change for LIVE videos).
    // More info here: https://github.com/video-dev/hls.js/issues/332#issuecomment-257986486
    const audioTrack = tracks.audio;
    let checkTimestampOffset = false;
    if (type === 'audio' && (audioTrack == null ? void 0 : audioTrack.container) === 'audio/mpeg') {
     checkTimestampOffset = !this.lastMpegAudioChunk || chunkMeta.id === 1 || this.lastMpegAudioChunk.sn !== chunkMeta.sn;
     this.lastMpegAudioChunk = chunkMeta;
    }

    // Block audio append until overlapping video append
    const videoTrack = tracks.video;
    const videoSb = videoTrack == null ? void 0 : videoTrack.buffer;
    if (videoSb && sn !== 'initSegment') {
     const partOrFrag = part || frag;
     const blockedAudioAppend = this.blockedAudioAppend;
     if (type === 'audio' && parent !== 'main' && !this.blockedAudioAppend && !(videoTrack.ending || videoTrack.ended)) {
      const pStart = partOrFrag.start;
      const pTime = pStart + partOrFrag.duration * 0.05;
      const vbuffered = videoSb.buffered;
      const vappending = this.currentOp('video');
      if (!vbuffered.length && !vappending) {
       // wait for video before appending audio
       this.blockAudio(partOrFrag);
      } else if (!vappending && !BufferHelper.isBuffered(videoSb, pTime) && this.lastVideoAppendEnd < pTime) {
       // audio is ahead of video
       this.blockAudio(partOrFrag);
      }
     } else if (type === 'video') {
      const videoAppendEnd = partOrFrag.end;
      if (blockedAudioAppend) {
       const audioStart = blockedAudioAppend.frag.start;
       if (videoAppendEnd > audioStart || videoAppendEnd < this.lastVideoAppendEnd || BufferHelper.isBuffered(videoSb, audioStart)) {
        this.unblockAudio();
       }
      }
      this.lastVideoAppendEnd = videoAppendEnd;
     }
    }
    const fragStart = (part || frag).start;
    const operation = {
     label: `append-${type}`,
     execute: () => {
      var _this$tracks$type2;
      chunkStats.executeStart = self.performance.now();
      const sb = (_this$tracks$type2 = this.tracks[type]) == null ? void 0 : _this$tracks$type2.buffer;
      if (sb) {
       if (checkTimestampOffset) {
        this.updateTimestampOffset(sb, fragStart, 0.1, type, sn, cc);
       } else if (offset !== undefined && isFiniteNumber(offset)) {
        this.updateTimestampOffset(sb, offset, 0.000001, type, sn, cc);
       }
      }
      this.appendExecutor(data, type);
     },
     onStart: () => {
      // logger.debug(`[buffer-controller]: ${type} SourceBuffer updatestart`);
     },
     onComplete: () => {
      // logger.debug(`[buffer-controller]: ${type} SourceBuffer updateend`);
      const end = self.performance.now();
      chunkStats.executeEnd = chunkStats.end = end;
      if (fragBuffering.first === 0) {
       fragBuffering.first = end;
      }
      if (partBuffering && partBuffering.first === 0) {
       partBuffering.first = end;
      }
      const timeRanges = {};
      this.sourceBuffers.forEach(([type, sb]) => {
       if (type) {
        timeRanges[type] = BufferHelper.getBuffered(sb);
       }
      });
      this.appendErrors[type] = 0;
      if (type === 'audio' || type === 'video') {
       this.appendErrors.audiovideo = 0;
      } else {
       this.appendErrors.audio = 0;
       this.appendErrors.video = 0;
      }
      this.hls.trigger(Events.BUFFER_APPENDED, {
       type,
       frag,
       part,
       chunkMeta,
       parent: frag.type,
       timeRanges,
      });
     },
     onError: (error) => {
      var _this$media;
      // in case any error occured while appending, put back segment in segments table
      const event = {
       type: ErrorTypes.MEDIA_ERROR,
       parent: frag.type,
       details: ErrorDetails.BUFFER_APPEND_ERROR,
       sourceBufferName: type,
       frag,
       part,
       chunkMeta,
       error,
       err: error,
       fatal: false,
      };
      const mediaError = (_this$media = this.media) == null ? void 0 : _this$media.error;
      if (error.code === DOMException.QUOTA_EXCEEDED_ERR || error.name == 'QuotaExceededError' || `quota` in error) {
       // QuotaExceededError: http://www.w3.org/TR/html5/infrastructure.html#quotaexceedederror
       // let's stop appending any segments, and report BUFFER_FULL_ERROR error
       event.details = ErrorDetails.BUFFER_FULL_ERROR;
      } else if (error.code === DOMException.INVALID_STATE_ERR && this.mediaSourceOpenOrEnded && !mediaError) {
       // Allow retry for "Failed to execute 'appendBuffer' on 'SourceBuffer': This SourceBuffer is still processing" errors
       event.errorAction = createDoNothingErrorAction(true);
      } else if (error.name === TRACK_REMOVED_ERROR_NAME && this.sourceBufferCount === 0) {
       // Do nothing if sourceBuffers were removed (media is detached and append was not aborted)
       event.errorAction = createDoNothingErrorAction(true);
      } else {
       const appendErrorCount = ++this.appendErrors[type];
       /* with UHD content, we could get loop of quota exceeded error until
            browser is able to evict some data from sourcebuffer. Retrying can help recover.
          */
       this.warn(`Failed ${appendErrorCount}/${this.hls.config.appendErrorMaxRetry} times to append segment in "${type}" sourceBuffer (${mediaError ? mediaError : 'no media error'})`);
       if (appendErrorCount >= this.hls.config.appendErrorMaxRetry || !!mediaError) {
        event.fatal = true;
       }
      }
      this.hls.trigger(Events.ERROR, event);
     },
    };
    this.append(operation, type, this.isPending(this.tracks[type]));
   }
   getFlushOp(type, start, end) {
    this.log(`queuing "${type}" remove ${start}-${end}`);
    return {
     label: 'remove',
     execute: () => {
      this.removeExecutor(type, start, end);
     },
     onStart: () => {
      // logger.debug(`[buffer-controller]: Started flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);
     },
     onComplete: () => {
      // logger.debug(`[buffer-controller]: Finished flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);
      this.hls.trigger(Events.BUFFER_FLUSHED, {
       type,
      });
     },
     onError: (error) => {
      this.warn(`Failed to remove ${start}-${end} from "${type}" SourceBuffer`, error);
     },
    };
   }
   onBufferFlushing(event, data) {
    const { type, startOffset, endOffset } = data;
    if (type) {
     this.append(this.getFlushOp(type, startOffset, endOffset), type);
    } else {
     this.sourceBuffers.forEach(([type]) => {
      if (type) {
       this.append(this.getFlushOp(type, startOffset, endOffset), type);
      }
     });
    }
   }
   onFragParsed(event, data) {
    const { frag, part } = data;
    const buffersAppendedTo = [];
    const elementaryStreams = part ? part.elementaryStreams : frag.elementaryStreams;
    if (elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO]) {
     buffersAppendedTo.push('audiovideo');
    } else {
     if (elementaryStreams[ElementaryStreamTypes.AUDIO]) {
      buffersAppendedTo.push('audio');
     }
     if (elementaryStreams[ElementaryStreamTypes.VIDEO]) {
      buffersAppendedTo.push('video');
     }
    }
    const onUnblocked = () => {
     const now = self.performance.now();
     frag.stats.buffering.end = now;
     if (part) {
      part.stats.buffering.end = now;
     }
     const stats = part ? part.stats : frag.stats;
     this.hls.trigger(Events.FRAG_BUFFERED, {
      frag,
      part,
      stats,
      id: frag.type,
     });
    };
    if (buffersAppendedTo.length === 0) {
     this.warn(`Fragments must have at least one ElementaryStreamType set. type: ${frag.type} level: ${frag.level} sn: ${frag.sn}`);
    }
    this.blockBuffers(onUnblocked, buffersAppendedTo).catch((error) => {
     this.warn(`Fragment buffered callback ${error}`);
     this.stepOperationQueue(this.sourceBufferTypes);
    });
   }
   onFragChanged(event, data) {
    this.trimBuffers();
   }
   get bufferedToEnd() {
    return (
     this.sourceBufferCount > 0 &&
     !this.sourceBuffers.some(([type]) => {
      if (type) {
       const track = this.tracks[type];
       if (track) {
        return !track.ended || track.ending;
       }
      }
      return false;
     })
    );
   }

   // on BUFFER_EOS mark matching sourcebuffer(s) as "ending" and "ended" and queue endOfStream after remaining operations(s)
   // an undefined data.type will mark all buffers as EOS.
   onBufferEos(event, data) {
    var _this$overrides;
    this.sourceBuffers.forEach(([type]) => {
     if (type) {
      const track = this.tracks[type];
      if (!data.type || data.type === type) {
       track.ending = true;
       if (!track.ended) {
        track.ended = true;
        this.log(`${type} buffer reached EOS`);
       }
      }
     }
    });
    const allowEndOfStream = ((_this$overrides = this.overrides) == null ? void 0 : _this$overrides.endOfStream) !== false;
    const allTracksEnding =
     this.sourceBufferCount > 0 &&
     !this.sourceBuffers.some(([type]) => {
      var _this$tracks$type3;
      return type && !((_this$tracks$type3 = this.tracks[type]) != null && _this$tracks$type3.ended);
     });
    if (allTracksEnding) {
     if (allowEndOfStream) {
      this.log(`Queueing EOS`);
      this.blockUntilOpen(() => {
       this.tracksEnded();
       const { mediaSource } = this;
       if (!mediaSource || mediaSource.readyState !== 'open') {
        if (mediaSource) {
         this.log(`Could not call mediaSource.endOfStream(). mediaSource.readyState: ${mediaSource.readyState}`);
        }
        return;
       }
       this.log(`Calling mediaSource.endOfStream()`);
       // Allow this to throw and be caught by the enqueueing function
       mediaSource.endOfStream();
       this.hls.trigger(Events.BUFFERED_TO_END, undefined);
      });
     } else {
      this.tracksEnded();
      this.hls.trigger(Events.BUFFERED_TO_END, undefined);
     }
    } else if (data.type === 'video') {
     // Make sure pending audio appends are unblocked when video reaches end
     this.unblockAudio();
    }
   }
   tracksEnded() {
    this.sourceBuffers.forEach(([type]) => {
     if (type !== null) {
      const track = this.tracks[type];
      if (track) {
       track.ending = false;
      }
     }
    });
   }
   onLevelUpdated(event, { details }) {
    if (!details.fragments.length) {
     return;
    }
    this.details = details;
    this.updateDuration();
   }
   updateDuration() {
    this.blockUntilOpen(() => {
     const durationAndRange = this.getDurationAndRange();
     if (!durationAndRange) {
      return;
     }
     this.updateMediaSource(durationAndRange);
    });
   }
   onError(event, data) {
    if (data.details === ErrorDetails.BUFFER_APPEND_ERROR && data.frag) {
     var _data$errorAction;
     const nextAutoLevel = (_data$errorAction = data.errorAction) == null ? void 0 : _data$errorAction.nextAutoLevel;
     if (isFiniteNumber(nextAutoLevel) && nextAutoLevel !== data.frag.level) {
      this.resetAppendErrors();
     }
    }
   }
   resetAppendErrors() {
    this.appendErrors = {
     audio: 0,
     video: 0,
     audiovideo: 0,
    };
   }
   trimBuffers() {
    const { hls, details, media } = this;
    if (!media || details === null) {
     return;
    }
    if (!this.sourceBufferCount) {
     return;
    }
    const config = hls.config;
    const currentTime = media.currentTime;
    const targetDuration = details.levelTargetDuration;

    // Support for deprecated liveBackBufferLength
    const backBufferLength = details.live && config.liveBackBufferLength !== null ? config.liveBackBufferLength : config.backBufferLength;
    if (isFiniteNumber(backBufferLength) && backBufferLength >= 0) {
     const maxBackBufferLength = Math.max(backBufferLength, targetDuration);
     const targetBackBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration - maxBackBufferLength;
     this.flushBackBuffer(currentTime, targetDuration, targetBackBufferPosition);
    }
    const frontBufferFlushThreshold = config.frontBufferFlushThreshold;
    if (isFiniteNumber(frontBufferFlushThreshold) && frontBufferFlushThreshold > 0) {
     const frontBufferLength = Math.max(config.maxBufferLength, frontBufferFlushThreshold);
     const maxFrontBufferLength = Math.max(frontBufferLength, targetDuration);
     const targetFrontBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration + maxFrontBufferLength;
     this.flushFrontBuffer(currentTime, targetDuration, targetFrontBufferPosition);
    }
   }
   flushBackBuffer(currentTime, targetDuration, targetBackBufferPosition) {
    this.sourceBuffers.forEach(([type, sb]) => {
     if (sb) {
      const buffered = BufferHelper.getBuffered(sb);
      // when target buffer start exceeds actual buffer start
      if (buffered.length > 0 && targetBackBufferPosition > buffered.start(0)) {
       var _this$details;
       this.hls.trigger(Events.BACK_BUFFER_REACHED, {
        bufferEnd: targetBackBufferPosition,
       });

       // Support for deprecated event:
       const track = this.tracks[type];
       if ((_this$details = this.details) != null && _this$details.live) {
        this.hls.trigger(Events.LIVE_BACK_BUFFER_REACHED, {
         bufferEnd: targetBackBufferPosition,
        });
       } else if (track != null && track.ended) {
        this.log(`Cannot flush ${type} back buffer while SourceBuffer is in ended state`);
        return;
       }
       this.hls.trigger(Events.BUFFER_FLUSHING, {
        startOffset: 0,
        endOffset: targetBackBufferPosition,
        type,
       });
      }
     }
    });
   }
   flushFrontBuffer(currentTime, targetDuration, targetFrontBufferPosition) {
    this.sourceBuffers.forEach(([type, sb]) => {
     if (sb) {
      const buffered = BufferHelper.getBuffered(sb);
      const numBufferedRanges = buffered.length;
      // The buffer is either empty or contiguous
      if (numBufferedRanges < 2) {
       return;
      }
      const bufferStart = buffered.start(numBufferedRanges - 1);
      const bufferEnd = buffered.end(numBufferedRanges - 1);
      // No flush if we can tolerate the current buffer length or the current buffer range we would flush is contiguous with current position
      if (targetFrontBufferPosition > bufferStart || (currentTime >= bufferStart && currentTime <= bufferEnd)) {
       return;
      }
      this.hls.trigger(Events.BUFFER_FLUSHING, {
       startOffset: bufferStart,
       endOffset: Infinity,
       type,
      });
     }
    });
   }

   /**
    * Update Media Source duration to current level duration or override to Infinity if configuration parameter
    * 'liveDurationInfinity` is set to `true`
    * More details: https://github.com/video-dev/hls.js/issues/355
    */
   getDurationAndRange() {
    var _this$overrides2;
    const { details, mediaSource } = this;
    if (!details || !this.media || (mediaSource == null ? void 0 : mediaSource.readyState) !== 'open') {
     return null;
    }
    const playlistEnd = details.edge;
    if (details.live && this.hls.config.liveDurationInfinity) {
     const len = details.fragments.length;
     if (len && !!mediaSource.setLiveSeekableRange) {
      const start = Math.max(0, details.fragmentStart);
      const end = Math.max(start, playlistEnd);
      return {
       duration: Infinity,
       start,
       end,
      };
     }
     return {
      duration: Infinity,
     };
    }
    const overrideDuration = (_this$overrides2 = this.overrides) == null ? void 0 : _this$overrides2.duration;
    if (overrideDuration) {
     if (!isFiniteNumber(overrideDuration)) {
      return null;
     }
     return {
      duration: overrideDuration,
     };
    }
    const mediaDuration = this.media.duration;
    const msDuration = isFiniteNumber(mediaSource.duration) ? mediaSource.duration : 0;
    if ((playlistEnd > msDuration && playlistEnd > mediaDuration) || !isFiniteNumber(mediaDuration)) {
     return {
      duration: playlistEnd,
     };
    }
    return null;
   }
   updateMediaSource({ duration, start, end }) {
    const mediaSource = this.mediaSource;
    if (!this.media || !mediaSource || mediaSource.readyState !== 'open') {
     return;
    }
    if (mediaSource.duration !== duration) {
     if (isFiniteNumber(duration)) {
      this.log(`Updating MediaSource duration to ${duration.toFixed(3)}`);
     }
     mediaSource.duration = duration;
    }
    if (start !== undefined && end !== undefined) {
     this.log(`MediaSource duration is set to ${mediaSource.duration}. Setting seekable range to ${start}-${end}.`);
     mediaSource.setLiveSeekableRange(start, end);
    }
   }
   get tracksReady() {
    const pendingTrackCount = this.pendingTrackCount;
    return pendingTrackCount > 0 && (pendingTrackCount >= this.bufferCodecEventsTotal || this.isPending(this.tracks.audiovideo));
   }
   checkPendingTracks() {
    const { bufferCodecEventsTotal, pendingTrackCount, tracks } = this;
    this.log(`checkPendingTracks (pending: ${pendingTrackCount} codec events expected: ${bufferCodecEventsTotal}) ${stringify(tracks)}`);
    // Check if we've received all of the expected bufferCodec events. When none remain, create all the sourceBuffers at once.
    // This is important because the MSE spec allows implementations to throw QuotaExceededErrors if creating new sourceBuffers after
    // data has been appended to existing ones.
    // 2 tracks is the max (one for audio, one for video). If we've reach this max go ahead and create the buffers.
    if (this.tracksReady) {
     var _this$transferData4;
     const transferredTracks = (_this$transferData4 = this.transferData) == null ? void 0 : _this$transferData4.tracks;
     if (transferredTracks && Object.keys(transferredTracks).length) {
      this.attachTransferred();
     } else {
      // ok, let's create them now !
      this.createSourceBuffers();
     }
    }
   }
   bufferCreated() {
    if (this.sourceBufferCount) {
     const tracks = {};
     this.sourceBuffers.forEach(([type, buffer]) => {
      if (type) {
       const track = this.tracks[type];
       tracks[type] = {
        buffer,
        container: track.container,
        codec: track.codec,
        supplemental: track.supplemental,
        levelCodec: track.levelCodec,
        id: track.id,
        metadata: track.metadata,
       };
      }
     });
     this.hls.trigger(Events.BUFFER_CREATED, {
      tracks,
     });
     this.log(`SourceBuffers created. Running queue: ${this.operationQueue}`);
     this.sourceBuffers.forEach(([type]) => {
      this.executeNext(type);
     });
    } else {
     const error = new Error('could not create source buffer for media codec(s)');
     this.hls.trigger(Events.ERROR, {
      type: ErrorTypes.MEDIA_ERROR,
      details: ErrorDetails.BUFFER_INCOMPATIBLE_CODECS_ERROR,
      fatal: true,
      error,
      reason: error.message,
     });
    }
   }
   createSourceBuffers() {
    const { tracks, sourceBuffers, mediaSource } = this;
    if (!mediaSource) {
     throw new Error('createSourceBuffers called when mediaSource was null');
    }
    for (const trackName in tracks) {
     const type = trackName;
     const track = tracks[type];
     if (this.isPending(track)) {
      const codec = this.getTrackCodec(track, type);
      const mimeType = `${track.container};codecs=${codec}`;
      track.codec = codec;
      this.log(`creating sourceBuffer(${mimeType})${this.currentOp(type) ? ' Queued' : ''} ${stringify(track)}`);
      try {
       const sb = mediaSource.addSourceBuffer(mimeType);
       const sbIndex = sourceBufferNameToIndex(type);
       const sbTuple = [type, sb];
       sourceBuffers[sbIndex] = sbTuple;
       track.buffer = sb;
      } catch (error) {
       var _this$operationQueue;
       this.error(`error while trying to add sourceBuffer: ${error.message}`);
       // remove init segment from queue and delete track info
       this.shiftAndExecuteNext(type);
       (_this$operationQueue = this.operationQueue) == null || _this$operationQueue.removeBlockers();
       delete this.tracks[type];
       this.hls.trigger(Events.ERROR, {
        type: ErrorTypes.MEDIA_ERROR,
        details: ErrorDetails.BUFFER_ADD_CODEC_ERROR,
        fatal: false,
        error,
        sourceBufferName: type,
        mimeType: mimeType,
        parent: track.id,
       });
       return;
      }
      this.trackSourceBuffer(type, track);
     }
    }
    this.bufferCreated();
   }
   getTrackCodec(track, trackName) {
    // Use supplemental video codec when supported when adding SourceBuffer (#5558)
    const supplementalCodec = track.supplemental;
    let trackCodec = track.codec;
    if (supplementalCodec && (trackName === 'video' || trackName === 'audiovideo') && areCodecsMediaSourceSupported(supplementalCodec, 'video')) {
     trackCodec = replaceVideoCodec(trackCodec, supplementalCodec);
    }
    const codec = pickMostCompleteCodecName(trackCodec, track.levelCodec);
    if (codec) {
     if (trackName.slice(0, 5) === 'audio') {
      return getCodecCompatibleName(codec, this.appendSource);
     }
     return codec;
    }
    return '';
   }
   trackSourceBuffer(type, track) {
    const buffer = track.buffer;
    if (!buffer) {
     return;
    }
    const codec = this.getTrackCodec(track, type);
    this.tracks[type] = {
     buffer,
     codec,
     container: track.container,
     levelCodec: track.levelCodec,
     supplemental: track.supplemental,
     metadata: track.metadata,
     id: track.id,
     listeners: [],
    };
    this.removeBufferListeners(type);
    this.addBufferListener(type, 'updatestart', this.onSBUpdateStart);
    this.addBufferListener(type, 'updateend', this.onSBUpdateEnd);
    this.addBufferListener(type, 'error', this.onSBUpdateError);
    // ManagedSourceBuffer bufferedchange event
    if (this.appendSource) {
     this.addBufferListener(type, 'bufferedchange', (type, event) => {
      // If media was ejected check for a change. Added ranges are redundant with changes on 'updateend' event.
      const removedRanges = event.removedRanges;
      if (removedRanges != null && removedRanges.length) {
       this.hls.trigger(Events.BUFFER_FLUSHED, {
        type: type,
       });
      }
     });
    }
   }
   get mediaSrc() {
    var _this$media2, _this$media2$querySel;
    const media = ((_this$media2 = this.media) == null || (_this$media2$querySel = _this$media2.querySelector) == null ? void 0 : _this$media2$querySel.call(_this$media2, 'source')) || this.media;
    return media == null ? void 0 : media.src;
   }
   onSBUpdateStart(type) {
    const operation = this.currentOp(type);
    if (!operation) {
     return;
    }
    operation.onStart();
   }
   onSBUpdateEnd(type) {
    var _this$mediaSource4;
    if (((_this$mediaSource4 = this.mediaSource) == null ? void 0 : _this$mediaSource4.readyState) === 'closed') {
     this.resetBuffer(type);
     return;
    }
    const operation = this.currentOp(type);
    if (!operation) {
     return;
    }
    operation.onComplete();
    this.shiftAndExecuteNext(type);
   }
   onSBUpdateError(type, event) {
    var _this$mediaSource5;
    const error = new Error(`${type} SourceBuffer error. MediaSource readyState: ${(_this$mediaSource5 = this.mediaSource) == null ? void 0 : _this$mediaSource5.readyState}`);
    this.error(`${error}`, event);
    // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error
    // SourceBuffer errors are not necessarily fatal; if so, the HTMLMediaElement will fire an error event
    this.hls.trigger(Events.ERROR, {
     type: ErrorTypes.MEDIA_ERROR,
     details: ErrorDetails.BUFFER_APPENDING_ERROR,
     sourceBufferName: type,
     error,
     fatal: false,
    });
    // updateend is always fired after error, so we'll allow that to shift the current operation off of the queue
    const operation = this.currentOp(type);
    if (operation) {
     operation.onError(error);
    }
   }
   updateTimestampOffset(sb, timestampOffset, tolerance, type, sn, cc) {
    const delta = timestampOffset - sb.timestampOffset;
    if (Math.abs(delta) >= tolerance) {
     this.log(`Updating ${type} SourceBuffer timestampOffset to ${timestampOffset} (sn: ${sn} cc: ${cc})`);
     sb.timestampOffset = timestampOffset;
    }
   }

   // This method must result in an updateend event; if remove is not called, onSBUpdateEnd must be called manually
   removeExecutor(type, startOffset, endOffset) {
    const { media, mediaSource } = this;
    const track = this.tracks[type];
    const sb = track == null ? void 0 : track.buffer;
    if (!media || !mediaSource || !sb) {
     this.warn(`Attempting to remove from the ${type} SourceBuffer, but it does not exist`);
     this.shiftAndExecuteNext(type);
     return;
    }
    const mediaDuration = isFiniteNumber(media.duration) ? media.duration : Infinity;
    const msDuration = isFiniteNumber(mediaSource.duration) ? mediaSource.duration : Infinity;
    const removeStart = Math.max(0, startOffset);
    const removeEnd = Math.min(endOffset, mediaDuration, msDuration);
    if (removeEnd > removeStart && (!track.ending || track.ended)) {
     track.ended = false;
     this.log(`Removing [${removeStart},${removeEnd}] from the ${type} SourceBuffer`);
     sb.remove(removeStart, removeEnd);
    } else {
     // Cycle the queue
     this.shiftAndExecuteNext(type);
    }
   }

   // This method must result in an updateend event; if append is not called, onSBUpdateEnd must be called manually
   appendExecutor(data, type) {
    const track = this.tracks[type];
    const sb = track == null ? void 0 : track.buffer;
    if (!sb) {
     throw new HlsJsTrackRemovedError(`Attempting to append to the ${type} SourceBuffer, but it does not exist`);
    }
    track.ending = false;
    track.ended = false;
    sb.appendBuffer(data);
   }
   blockUntilOpen(callback) {
    if (this.isUpdating() || this.isQueued()) {
     this.blockBuffers(callback).catch((error) => {
      this.warn(`SourceBuffer blocked callback ${error}`);
      this.stepOperationQueue(this.sourceBufferTypes);
     });
    } else {
     try {
      callback();
     } catch (error) {
      this.warn(`Callback run without blocking ${this.operationQueue} ${error}`);
     }
    }
   }
   isUpdating() {
    return this.sourceBuffers.some(([type, sb]) => type && sb.updating);
   }
   isQueued() {
    return this.sourceBuffers.some(([type]) => type && !!this.currentOp(type));
   }
   isPending(track) {
    return !!track && !track.buffer;
   }

   // Enqueues an operation to each SourceBuffer queue which, upon execution, resolves a promise. When all promises
   // resolve, the onUnblocked function is executed. Functions calling this method do not need to unblock the queue
   // upon completion, since we already do it here
   blockBuffers(onUnblocked, bufferNames = this.sourceBufferTypes) {
    if (!bufferNames.length) {
     this.log('Blocking operation requested, but no SourceBuffers exist');
     return Promise.resolve().then(onUnblocked);
    }
    const { operationQueue } = this;

    // logger.debug(`[buffer-controller]: Blocking ${buffers} SourceBuffer`);
    const blockingOperations = bufferNames.map((type) => this.appendBlocker(type));
    const audioBlocked = bufferNames.length > 1 && !!this.blockedAudioAppend;
    if (audioBlocked) {
     this.unblockAudio();
    }
    return Promise.all(blockingOperations).then((result) => {
     if (operationQueue !== this.operationQueue) {
      return;
     }
     // logger.debug(`[buffer-controller]: Blocking operation resolved; unblocking ${buffers} SourceBuffer`);
     onUnblocked();
     this.stepOperationQueue(this.sourceBufferTypes);
    });
   }
   stepOperationQueue(bufferNames) {
    bufferNames.forEach((type) => {
     var _this$tracks$type4;
     const sb = (_this$tracks$type4 = this.tracks[type]) == null ? void 0 : _this$tracks$type4.buffer;
     // Only cycle the queue if the SB is not updating. There's a bug in Chrome which sets the SB updating flag to
     // true when changing the MediaSource duration (https://bugs.chromium.org/p/chromium/issues/detail?id=959359&can=2&q=mediasource%20duration)
     // While this is a workaround, it's probably useful to have around
     if (!sb || sb.updating) {
      return;
     }
     this.shiftAndExecuteNext(type);
    });
   }
   append(operation, type, pending) {
    if (this.operationQueue) {
     this.operationQueue.append(operation, type, pending);
    }
   }
   appendBlocker(type) {
    if (this.operationQueue) {
     return this.operationQueue.appendBlocker(type);
    }
   }
   currentOp(type) {
    if (this.operationQueue) {
     return this.operationQueue.current(type);
    }
    return null;
   }
   executeNext(type) {
    if (type && this.operationQueue) {
     this.operationQueue.executeNext(type);
    }
   }
   shiftAndExecuteNext(type) {
    if (this.operationQueue) {
     this.operationQueue.shiftAndExecuteNext(type);
    }
   }
   get pendingTrackCount() {
    return Object.keys(this.tracks).reduce((acc, type) => acc + (this.isPending(this.tracks[type]) ? 1 : 0), 0);
   }
   get sourceBufferCount() {
    return this.sourceBuffers.reduce((acc, [type]) => acc + (type ? 1 : 0), 0);
   }
   get sourceBufferTypes() {
    return this.sourceBuffers.map(([type]) => type).filter((type) => !!type);
   }
   addBufferListener(type, event, fn) {
    const track = this.tracks[type];
    if (!track) {
     return;
    }
    const buffer = track.buffer;
    if (!buffer) {
     return;
    }
    const listener = fn.bind(this, type);
    track.listeners.push({
     event,
     listener,
    });
    buffer.addEventListener(event, listener);
   }
   removeBufferListeners(type) {
    const track = this.tracks[type];
    if (!track) {
     return;
    }
    const buffer = track.buffer;
    if (!buffer) {
     return;
    }
    track.listeners.forEach((l) => {
     buffer.removeEventListener(l.event, l.listener);
    });
    track.listeners.length = 0;
   }
  }
  function removeSourceChildren(node) {
   const sourceChildren = node.querySelectorAll('source');
   [].slice.call(sourceChildren).forEach((source) => {
    node.removeChild(source);
   });
  }
  function addSource(media, url) {
   const source = self.document.createElement('source');
   source.type = 'video/mp4';
   source.src = url;
   media.appendChild(source);
  }
  function sourceBufferNameToIndex(type) {
   return type === 'audio' ? 1 : 0;
  }

  class CapLevelController {
   constructor(hls) {
    this.hls = void 0;
    this.autoLevelCapping = void 0;
    this.firstLevel = void 0;
    this.media = void 0;
    this.restrictedLevels = void 0;
    this.timer = void 0;
    this.clientRect = void 0;
    this.streamController = void 0;
    this.hls = hls;
    this.autoLevelCapping = Number.POSITIVE_INFINITY;
    this.firstLevel = -1;
    this.media = null;
    this.restrictedLevels = [];
    this.timer = undefined;
    this.clientRect = null;
    this.registerListeners();
   }
   setStreamController(streamController) {
    this.streamController = streamController;
   }
   destroy() {
    if (this.hls) {
     this.unregisterListener();
    }
    if (this.timer) {
     this.stopCapping();
    }
    this.media = null;
    this.clientRect = null;
    // @ts-ignore
    this.hls = this.streamController = null;
   }
   registerListeners() {
    const { hls } = this;
    hls.on(Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);
    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
    hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);
    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
   }
   unregisterListener() {
    const { hls } = this;
    hls.off(Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);
    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
    hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);
    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
   }
   onFpsDropLevelCapping(event, data) {
    // Don't add a restricted level more than once
    const level = this.hls.levels[data.droppedLevel];
    if (this.isLevelAllowed(level)) {
     this.restrictedLevels.push({
      bitrate: level.bitrate,
      height: level.height,
      width: level.width,
     });
    }
   }
   onMediaAttaching(event, data) {
    this.media = data.media instanceof HTMLVideoElement ? data.media : null;
    this.clientRect = null;
    if (this.timer && this.hls.levels.length) {
     this.detectPlayerSize();
    }
   }
   onManifestParsed(event, data) {
    const hls = this.hls;
    this.restrictedLevels = [];
    this.firstLevel = data.firstLevel;
    if (hls.config.capLevelToPlayerSize && data.video) {
     // Start capping immediately if the manifest has signaled video codecs
     this.startCapping();
    }
   }
   onLevelsUpdated(event, data) {
    if (this.timer && isFiniteNumber(this.autoLevelCapping)) {
     this.detectPlayerSize();
    }
   }

   // Only activate capping when playing a video stream; otherwise, multi-bitrate audio-only streams will be restricted
   // to the first level
   onBufferCodecs(event, data) {
    const hls = this.hls;
    if (hls.config.capLevelToPlayerSize && data.video) {
     // If the manifest did not signal a video codec capping has been deferred until we're certain video is present
     this.startCapping();
    }
   }
   onMediaDetaching() {
    this.stopCapping();
    this.media = null;
   }
   detectPlayerSize() {
    if (this.media) {
     if (this.mediaHeight <= 0 || this.mediaWidth <= 0) {
      this.clientRect = null;
      return;
     }
     const levels = this.hls.levels;
     if (levels.length) {
      const hls = this.hls;
      const maxLevel = this.getMaxLevel(levels.length - 1);
      if (maxLevel !== this.autoLevelCapping) {
       hls.logger.log(`Setting autoLevelCapping to ${maxLevel}: ${levels[maxLevel].height}p@${levels[maxLevel].bitrate} for media ${this.mediaWidth}x${this.mediaHeight}`);
      }
      hls.autoLevelCapping = maxLevel;
      if (hls.autoLevelEnabled && hls.autoLevelCapping > this.autoLevelCapping && this.streamController) {
       // if auto level capping has a higher value for the previous one, flush the buffer using nextLevelSwitch
       // usually happen when the user go to the fullscreen mode.
       this.streamController.nextLevelSwitch();
      }
      this.autoLevelCapping = hls.autoLevelCapping;
     }
    }
   }

   /*
    * returns level should be the one with the dimensions equal or greater than the media (player) dimensions (so the video will be downscaled)
    */
   getMaxLevel(capLevelIndex) {
    const levels = this.hls.levels;
    if (!levels.length) {
     return -1;
    }
    const validLevels = levels.filter((level, index) => this.isLevelAllowed(level) && index <= capLevelIndex);
    this.clientRect = null;
    return CapLevelController.getMaxLevelByMediaSize(validLevels, this.mediaWidth, this.mediaHeight);
   }
   startCapping() {
    if (this.timer) {
     // Don't reset capping if started twice; this can happen if the manifest signals a video codec
     return;
    }
    this.autoLevelCapping = Number.POSITIVE_INFINITY;
    self.clearInterval(this.timer);
    this.timer = self.setInterval(this.detectPlayerSize.bind(this), 1000);
    this.detectPlayerSize();
   }
   stopCapping() {
    this.restrictedLevels = [];
    this.firstLevel = -1;
    this.autoLevelCapping = Number.POSITIVE_INFINITY;
    if (this.timer) {
     self.clearInterval(this.timer);
     this.timer = undefined;
    }
   }
   getDimensions() {
    if (this.clientRect) {
     return this.clientRect;
    }
    const media = this.media;
    const boundsRect = {
     width: 0,
     height: 0,
    };
    if (media) {
     const clientRect = media.getBoundingClientRect();
     boundsRect.width = clientRect.width;
     boundsRect.height = clientRect.height;
     if (!boundsRect.width && !boundsRect.height) {
      // When the media element has no width or height (equivalent to not being in the DOM),
      // then use its width and height attributes (media.width, media.height)
      boundsRect.width = clientRect.right - clientRect.left || media.width || 0;
      boundsRect.height = clientRect.bottom - clientRect.top || media.height || 0;
     }
    }
    this.clientRect = boundsRect;
    return boundsRect;
   }
   get mediaWidth() {
    return this.getDimensions().width * this.contentScaleFactor;
   }
   get mediaHeight() {
    return this.getDimensions().height * this.contentScaleFactor;
   }
   get contentScaleFactor() {
    let pixelRatio = 1;
    if (!this.hls.config.ignoreDevicePixelRatio) {
     try {
      pixelRatio = self.devicePixelRatio;
     } catch (e) {
      /* no-op */
     }
    }
    return Math.min(pixelRatio, this.hls.config.maxDevicePixelRatio);
   }
   isLevelAllowed(level) {
    const restrictedLevels = this.restrictedLevels;
    return !restrictedLevels.some((restrictedLevel) => {
     return level.bitrate === restrictedLevel.bitrate && level.width === restrictedLevel.width && level.height === restrictedLevel.height;
    });
   }
   static getMaxLevelByMediaSize(levels, width, height) {
    if (!(levels != null && levels.length)) {
     return -1;
    }

    // Levels can have the same dimensions but differing bandwidths - since levels are ordered, we can look to the next
    // to determine whether we've chosen the greatest bandwidth for the media's dimensions
    const atGreatestBandwidth = (curLevel, nextLevel) => {
     if (!nextLevel) {
      return true;
     }
     return curLevel.width !== nextLevel.width || curLevel.height !== nextLevel.height;
    };

    // If we run through the loop without breaking, the media's dimensions are greater than every level, so default to
    // the max level
    let maxLevelIndex = levels.length - 1;
    // Prevent changes in aspect-ratio from causing capping to toggle back and forth
    const squareSize = Math.max(width, height);
    for (let i = 0; i < levels.length; i += 1) {
     const level = levels[i];
     if ((level.width >= squareSize || level.height >= squareSize) && atGreatestBandwidth(level, levels[i + 1])) {
      maxLevelIndex = i;
      break;
     }
    }
    return maxLevelIndex;
   }
  }

  /**
   * Common Media Object Type
   *
   * @internal
   */
  const CmObjectType = {
   /**
    * text file, such as a manifest or playlist
    */
   MANIFEST: 'm',
   /**
    * audio only
    */
   AUDIO: 'a',
   /**
    * video only
    */
   VIDEO: 'v',
   /**
    * muxed audio and video
    */
   MUXED: 'av',
   /**
    * init segment
    */
   INIT: 'i',
   /**
    * caption or subtitle
    */
   CAPTION: 'c',
   /**
    * ISOBMFF timed text track
    */
   TIMED_TEXT: 'tt',
   /**
    * cryptographic key, license or certificate.
    */
   KEY: 'k',
   /**
    * other
    */
   OTHER: 'o',
  };

  /**
   * Common Media Client Data Object Type
   *
   * @group CMCD
   *
   * @beta
   *
   * @enum
   */
  const CmcdObjectType = CmObjectType;

  /**
   * Common Media Streaming Format
   *
   * @internal
   */
  const CmStreamingFormat = {
   /**
    * HTTP Live Streaming (HLS)
    */
   HLS: 'h',
  };

  /**
   * Common Media Client Data Streaming Format
   *
   * @group CMCD
   *
   * @enum
   *
   * @beta
   */
  const CmcdStreamingFormat = CmStreamingFormat;

  /**
   * Structured Field Item
   *
   * @group Structured Field
   *
   * @beta
   */
  class SfItem {
   constructor(value, params) {
    if (Array.isArray(value)) {
     value = value.map((v) => (v instanceof SfItem ? v : new SfItem(v)));
    }
    this.value = value;
    this.params = params;
   }
  }

  const DICT = 'Dict';

  function format(value) {
   if (Array.isArray(value)) {
    return JSON.stringify(value);
   }
   if (value instanceof Map) {
    return 'Map{}';
   }
   if (value instanceof Set) {
    return 'Set{}';
   }
   if (typeof value === 'object') {
    return JSON.stringify(value);
   }
   return String(value);
  }
  function throwError(action, src, type, cause) {
   return new Error(`failed to ${action} "${format(src)}" as ${type}`, {
    cause,
   });
  }

  function serializeError(src, type, cause) {
   return throwError('serialize', src, type, cause);
  }

  /**
   * A class to represent structured field tokens when `Symbol` is not available.
   *
   * @group Structured Field
   *
   * @beta
   */
  class SfToken {
   constructor(description) {
    this.description = description;
   }
  }

  const BARE_ITEM = 'Bare Item';

  const BOOLEAN = 'Boolean';

  // 4.1.9.  Serializing a Boolean
  //
  // Given a Boolean as input_boolean, return an ASCII string suitable for
  // use in a HTTP field value.
  //
  // 1.  If input_boolean is not a boolean, fail serialization.
  //
  // 2.  Let output be an empty string.
  //
  // 3.  Append "?" to output.
  //
  // 4.  If input_boolean is true, append "1" to output.
  //
  // 5.  If input_boolean is false, append "0" to output.
  //
  // 6.  Return output.
  function serializeBoolean(value) {
   if (typeof value !== 'boolean') {
    throw serializeError(value, BOOLEAN);
   }
   return value ? '?1' : '?0';
  }

  /**
   * Encodes binary data to base64
   *
   * @param binary - The binary data to encode
   * @returns The base64 encoded string
   *
   * @group Utils
   *
   * @beta
   */
  function encodeBase64(binary) {
   return btoa(String.fromCharCode(...binary));
  }

  const BYTES = 'Byte Sequence';

  // 4.1.8.  Serializing a Byte Sequence
  //
  // Given a Byte Sequence as input_bytes, return an ASCII string suitable
  // for use in a HTTP field value.
  //
  // 1.  If input_bytes is not a sequence of bytes, fail serialization.
  //
  // 2.  Let output be an empty string.
  //
  // 3.  Append ":" to output.
  //
  // 4.  Append the result of base64-encoding input_bytes as per
  //     [RFC4648], Section 4, taking account of the requirements below.
  //
  // 5.  Append ":" to output.
  //
  // 6.  Return output.
  //
  // The encoded data is required to be padded with "=", as per [RFC4648],
  // Section 3.2.
  //
  // Likewise, encoded data SHOULD have pad bits set to zero, as per
  // [RFC4648], Section 3.5, unless it is not possible to do so due to
  // implementation constraints.
  function serializeByteSequence(value) {
   if (ArrayBuffer.isView(value) === false) {
    throw serializeError(value, BYTES);
   }
   return `:${encodeBase64(value)}:`;
  }

  const INTEGER = 'Integer';

  function isInvalidInt(value) {
   return value < -999999999999999 || 999999999999999 < value;
  }

  // 4.1.4.  Serializing an Integer
  //
  // Given an Integer as input_integer, return an ASCII string suitable
  // for use in a HTTP field value.
  //
  // 1.  If input_integer is not an integer in the range of
  //     -999,999,999,999,999 to 999,999,999,999,999 inclusive, fail
  //     serialization.
  //
  // 2.  Let output be an empty string.
  //
  // 3.  If input_integer is less than (but not equal to) 0, append "-" to
  //     output.
  //
  // 4.  Append input_integer's numeric value represented in base 10 using
  //     only decimal digits to output.
  //
  // 5.  Return output.
  function serializeInteger(value) {
   if (isInvalidInt(value)) {
    throw serializeError(value, INTEGER);
   }
   return value.toString();
  }

  // 4.1.10.  Serializing a Date
  //
  // Given a Date as input_integer, return an ASCII string suitable for
  // use in an HTTP field value.
  // 1.  Let output be "@".
  // 2.  Append to output the result of running Serializing an Integer
  //     with input_date (Section 4.1.4).
  // 3.  Return output.
  function serializeDate(value) {
   return `@${serializeInteger(value.getTime() / 1000)}`;
  }

  /**
   * This implements the rounding procedure described in step 2 of the "Serializing a Decimal" specification.
   * This rounding style is known as "even rounding", "banker's rounding", or "commercial rounding".
   *
   * @param value - The value to round
   * @param precision - The number of decimal places to round to
   * @returns The rounded value
   *
   * @group Utils
   *
   * @beta
   */
  function roundToEven(value, precision) {
   if (value < 0) {
    return -roundToEven(-value, precision);
   }
   const decimalShift = Math.pow(10, precision);
   const isEquidistant = Math.abs(((value * decimalShift) % 1) - 0.5) < Number.EPSILON;
   if (isEquidistant) {
    // If the tail of the decimal place is 'equidistant' we round to the nearest even value
    const flooredValue = Math.floor(value * decimalShift);
    return (flooredValue % 2 === 0 ? flooredValue : flooredValue + 1) / decimalShift;
   } else {
    // Otherwise, proceed as normal
    return Math.round(value * decimalShift) / decimalShift;
   }
  }

  const DECIMAL = 'Decimal';

  // 4.1.5.  Serializing a Decimal
  //
  // Given a decimal number as input_decimal, return an ASCII string
  // suitable for use in a HTTP field value.
  //
  // 1.   If input_decimal is not a decimal number, fail serialization.
  //
  // 2.   If input_decimal has more than three significant digits to the
  //      right of the decimal point, round it to three decimal places,
  //      rounding the final digit to the nearest value, or to the even
  //      value if it is equidistant.
  //
  // 3.   If input_decimal has more than 12 significant digits to the left
  //      of the decimal point after rounding, fail serialization.
  //
  // 4.   Let output be an empty string.
  //
  // 5.   If input_decimal is less than (but not equal to) 0, append "-"
  //      to output.
  //
  // 6.   Append input_decimal's integer component represented in base 10
  //      (using only decimal digits) to output; if it is zero, append
  //      "0".
  //
  // 7.   Append "." to output.
  //
  // 8.   If input_decimal's fractional component is zero, append "0" to
  //      output.
  //
  // 9.   Otherwise, append the significant digits of input_decimal's
  //      fractional component represented in base 10 (using only decimal
  //      digits) to output.
  //
  // 10.  Return output.
  function serializeDecimal(value) {
   const roundedValue = roundToEven(value, 3); // round to 3 decimal places
   if (Math.floor(Math.abs(roundedValue)).toString().length > 12) {
    throw serializeError(value, DECIMAL);
   }
   const stringValue = roundedValue.toString();
   return stringValue.includes('.') ? stringValue : `${stringValue}.0`;
  }

  const STRING = 'String';

  const STRING_REGEX = /[\x00-\x1f\x7f]+/;

  // 4.1.6.  Serializing a String
  //
  // Given a String as input_string, return an ASCII string suitable for
  // use in a HTTP field value.
  //
  // 1.  Convert input_string into a sequence of ASCII characters; if
  //     conversion fails, fail serialization.
  //
  // 2.  If input_string contains characters in the range %x00-1f or %x7f
  //     (i.e., not in VCHAR or SP), fail serialization.
  //
  // 3.  Let output be the string DQUOTE.
  //
  // 4.  For each character char in input_string:
  //
  //     1.  If char is "\" or DQUOTE:
  //
  //         1.  Append "\" to output.
  //
  //     2.  Append char to output.
  //
  // 5.  Append DQUOTE to output.
  //
  // 6.  Return output.
  function serializeString(value) {
   if (STRING_REGEX.test(value)) {
    throw serializeError(value, STRING);
   }
   return `"${value.replace(/\\/g, `\\\\`).replace(/"/g, `\\"`)}"`;
  }

  /**
   * Converts a symbol to a string.
   *
   * @param symbol - The symbol to convert.
   *
   * @returns The string representation of the symbol.
   *
   * @internal
   */
  function symbolToStr(symbol) {
   return symbol.description || symbol.toString().slice(7, -1);
  }

  const TOKEN = 'Token';

  function serializeToken(token) {
   const value = symbolToStr(token);
   if (/^([a-zA-Z*])([!#$%&'*+\-.^_`|~\w:/]*)$/.test(value) === false) {
    throw serializeError(value, TOKEN);
   }
   return value;
  }

  // 4.1.3.1.  Serializing a Bare Item
  //
  // Given an Item as input_item, return an ASCII string suitable for use
  // in a HTTP field value.
  //
  // 1.  If input_item is an Integer, return the result of running
  //     Serializing an Integer (Section 4.1.4) with input_item.
  //
  // 2.  If input_item is a Decimal, return the result of running
  //     Serializing a Decimal (Section 4.1.5) with input_item.
  //
  // 3.  If input_item is a String, return the result of running
  //     Serializing a String (Section 4.1.6) with input_item.
  //
  // 4.  If input_item is a Token, return the result of running
  //     Serializing a Token (Section 4.1.7) with input_item.
  //
  // 5.  If input_item is a Boolean, return the result of running
  //     Serializing a Boolean (Section 4.1.9) with input_item.
  //
  // 6.  If input_item is a Byte Sequence, return the result of running
  //     Serializing a Byte Sequence (Section 4.1.8) with input_item.
  //
  // 7.  If input_item is a Date, return the result of running Serializing
  //     a Date (Section 4.1.10) with input_item.
  //
  // 8.  Otherwise, fail serialization.
  function serializeBareItem(value) {
   switch (typeof value) {
    case 'number':
     if (!isFiniteNumber(value)) {
      throw serializeError(value, BARE_ITEM);
     }
     if (Number.isInteger(value)) {
      return serializeInteger(value);
     }
     return serializeDecimal(value);
    case 'string':
     return serializeString(value);
    case 'symbol':
     return serializeToken(value);
    case 'boolean':
     return serializeBoolean(value);
    case 'object':
     if (value instanceof Date) {
      return serializeDate(value);
     }
     if (value instanceof Uint8Array) {
      return serializeByteSequence(value);
     }
     if (value instanceof SfToken) {
      return serializeToken(value);
     }
    default:
     // fail
     throw serializeError(value, BARE_ITEM);
   }
  }

  const KEY = 'Key';

  // 4.1.1.3.  Serializing a Key
  //
  // Given a key as input_key, return an ASCII string suitable for use in
  // a HTTP field value.
  //
  // 1.  Convert input_key into a sequence of ASCII characters; if
  //     conversion fails, fail serialization.
  //
  // 2.  If input_key contains characters not in lcalpha, DIGIT, "_", "-",
  //     ".", or "*" fail serialization.
  //
  // 3.  If the first character of input_key is not lcalpha or "*", fail
  //     serialization.
  //
  // 4.  Let output be an empty string.
  //
  // 5.  Append input_key to output.
  //
  // 6.  Return output.
  function serializeKey(value) {
   if (/^[a-z*][a-z0-9\-_.*]*$/.test(value) === false) {
    throw serializeError(value, KEY);
   }
   return value;
  }

  // 4.1.1.2.  Serializing Parameters
  //
  // Given an ordered Dictionary as input_parameters (each member having a
  // param_name and a param_value), return an ASCII string suitable for
  // use in a HTTP field value.
  //
  // 1.  Let output be an empty string.
  //
  // 2.  For each param_name with a value of param_value in
  //     input_parameters:
  //
  //     1.  Append ";" to output.
  //
  //     2.  Append the result of running Serializing a Key
  //         (Section 4.1.1.3) with param_name to output.
  //
  //     3.  If param_value is not Boolean true:
  //
  //         1.  Append "=" to output.
  //
  //         2.  Append the result of running Serializing a bare Item
  //             (Section 4.1.3.1) with param_value to output.
  //
  // 3.  Return output.
  function serializeParams(params) {
   if (params == null) {
    return '';
   }
   return Object.entries(params)
    .map(([key, value]) => {
     if (value === true) {
      return `;${serializeKey(key)}`; // omit true
     }
     return `;${serializeKey(key)}=${serializeBareItem(value)}`;
    })
    .join('');
  }

  // 4.1.3.  Serializing an Item
  //
  // Given an Item as bare_item and Parameters as item_parameters, return
  // an ASCII string suitable for use in a HTTP field value.
  //
  // 1.  Let output be an empty string.
  //
  // 2.  Append the result of running Serializing a Bare Item
  //     Section 4.1.3.1 with bare_item to output.
  //
  // 3.  Append the result of running Serializing Parameters
  //     Section 4.1.1.2 with item_parameters to output.
  //
  // 4.  Return output.
  function serializeItem(value) {
   if (value instanceof SfItem) {
    return `${serializeBareItem(value.value)}${serializeParams(value.params)}`;
   } else {
    return serializeBareItem(value);
   }
  }

  // 4.1.1.1.  Serializing an Inner List
  //
  // Given an array of (member_value, parameters) tuples as inner_list,
  // and parameters as list_parameters, return an ASCII string suitable
  // for use in a HTTP field value.
  //
  // 1.  Let output be the string "(".
  //
  // 2.  For each (member_value, parameters) of inner_list:
  //
  //     1.  Append the result of running Serializing an Item
  //         (Section 4.1.3) with (member_value, parameters) to output.
  //
  //     2.  If more values remain in inner_list, append a single SP to
  //         output.
  //
  // 3.  Append ")" to output.
  //
  // 4.  Append the result of running Serializing Parameters
  //     (Section 4.1.1.2) with list_parameters to output.
  //
  // 5.  Return output.
  function serializeInnerList(value) {
   return `(${value.value.map(serializeItem).join(' ')})${serializeParams(value.params)}`;
  }

  // 4.1.2.  Serializing a Dictionary
  //
  // Given an ordered Dictionary as input_dictionary (each member having a
  // member_name and a tuple value of (member_value, parameters)), return
  // an ASCII string suitable for use in a HTTP field value.
  //
  // 1.  Let output be an empty string.
  //
  // 2.  For each member_name with a value of (member_value, parameters)
  //     in input_dictionary:
  //
  //     1.  Append the result of running Serializing a Key
  //         (Section 4.1.1.3) with member's member_name to output.
  //
  //     2.  If member_value is Boolean true:
  //
  //         1.  Append the result of running Serializing Parameters
  //             (Section 4.1.1.2) with parameters to output.
  //
  //     3.  Otherwise:
  //
  //         1.  Append "=" to output.
  //
  //         2.  If member_value is an array, append the result of running
  //             Serializing an Inner List (Section 4.1.1.1) with
  //             (member_value, parameters) to output.
  //
  //         3.  Otherwise, append the result of running Serializing an
  //             Item (Section 4.1.3) with (member_value, parameters) to
  //             output.
  //
  //     4.  If more members remain in input_dictionary:
  //
  //         1.  Append "," to output.
  //
  //         2.  Append a single SP to output.
  //
  // 3.  Return output.
  function serializeDict(
   dict,
   options = {
    whitespace: true,
   },
  ) {
   if (typeof dict !== 'object' || dict == null) {
    throw serializeError(dict, DICT);
   }
   const entries = dict instanceof Map ? dict.entries() : Object.entries(dict);
   const optionalWhiteSpace = (options === null || options === void 0 ? void 0 : options.whitespace) ? ' ' : '';
   return Array.from(entries)
    .map(([key, item]) => {
     if (item instanceof SfItem === false) {
      item = new SfItem(item);
     }
     let output = serializeKey(key);
     if (item.value === true) {
      output += serializeParams(item.params);
     } else {
      output += '=';
      if (Array.isArray(item.value)) {
       output += serializeInnerList(item);
      } else {
       output += serializeItem(item);
      }
     }
     return output;
    })
    .join(`,${optionalWhiteSpace}`);
  }

  /**
   * Encode an object into a structured field dictionary
   *
   * @param value - The structured field dictionary to encode
   * @param options - Encoding options
   *
   * @returns The structured field string
   *
   * @group Structured Field
   *
   * @beta
   */
  function encodeSfDict(value, options) {
   return serializeDict(value, options);
  }

  /**
   * CMCD object header name.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_OBJECT = 'CMCD-Object';

  /**
   * CMCD request header name.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_REQUEST = 'CMCD-Request';

  /**
   * CMCD session header name.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_SESSION = 'CMCD-Session';

  /**
   * CMCD status header name.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_STATUS = 'CMCD-Status';

  /**
   * The map of CMCD keys to their appropriate header shard.
   *
   * @group CMCD
   *
   * @internal
   */
  const CMCD_HEADER_MAP = {
   // Object
   br: CMCD_OBJECT,
   ab: CMCD_OBJECT,
   d: CMCD_OBJECT,
   ot: CMCD_OBJECT,
   tb: CMCD_OBJECT,
   tpb: CMCD_OBJECT,
   lb: CMCD_OBJECT,
   tab: CMCD_OBJECT,
   lab: CMCD_OBJECT,
   url: CMCD_OBJECT,
   // Request
   pb: CMCD_REQUEST,
   bl: CMCD_REQUEST,
   tbl: CMCD_REQUEST,
   dl: CMCD_REQUEST,
   ltc: CMCD_REQUEST,
   mtp: CMCD_REQUEST,
   nor: CMCD_REQUEST,
   nrr: CMCD_REQUEST,
   rc: CMCD_REQUEST,
   sn: CMCD_REQUEST,
   sta: CMCD_REQUEST,
   su: CMCD_REQUEST,
   ttfb: CMCD_REQUEST,
   ttfbb: CMCD_REQUEST,
   ttlb: CMCD_REQUEST,
   cmsdd: CMCD_REQUEST,
   cmsds: CMCD_REQUEST,
   smrt: CMCD_REQUEST,
   df: CMCD_REQUEST,
   cs: CMCD_REQUEST,
   // TODO: Which header to put the `ts` field is not defined yet.
   ts: CMCD_REQUEST,
   // Session
   cid: CMCD_SESSION,
   pr: CMCD_SESSION,
   sf: CMCD_SESSION,
   sid: CMCD_SESSION,
   st: CMCD_SESSION,
   v: CMCD_SESSION,
   msd: CMCD_SESSION,
   // Status
   bs: CMCD_STATUS,
   bsd: CMCD_STATUS,
   cdn: CMCD_STATUS,
   rtp: CMCD_STATUS,
   bg: CMCD_STATUS,
   pt: CMCD_STATUS,
   ec: CMCD_STATUS,
   e: CMCD_STATUS,
  };

  /**
   * CMCD header fields.
   *
   * @group CMCD
   *
   * @enum
   *
   * @beta
   */
  const CmcdHeaderField = {
   /**
    * keys whose values vary with each request.
    */
   REQUEST: CMCD_REQUEST,
  };

  function createHeaderMap(headerMap) {
   return Object.keys(headerMap).reduce((acc, field) => {
    var _a;
    (_a = headerMap[field]) === null || _a === void 0 ? void 0 : _a.forEach((key) => (acc[key] = field));
    return acc;
   }, {});
  }
  /**
   * Group a CMCD data object into header shards
   *
   * @param cmcd - The CMCD data object to convert.
   * @param customHeaderMap - A map of CMCD header fields to custom CMCD keys.
   *
   * @returns The CMCD header shards.
   *
   * @group CMCD
   *
   * @beta
   */
  function groupCmcdHeaders(cmcd, customHeaderMap) {
   const result = {};
   if (!cmcd) {
    return result;
   }
   const keys = Object.keys(cmcd);
   const custom = customHeaderMap ? createHeaderMap(customHeaderMap) : {};
   return keys.reduce((acc, key) => {
    var _a;
    const field = CMCD_HEADER_MAP[key] || custom[key] || CmcdHeaderField.REQUEST;
    const data = (_a = acc[field]) !== null && _a !== void 0 ? _a : (acc[field] = {});
    data[key] = cmcd[key];
    return acc;
   }, result);
  }

  /**
   * Checks if the given key is a token field.
   *
   * @param key - The key to check.
   *
   * @returns `true` if the key is a token field.
   *
   * @internal
   */
  function isTokenField(key) {
   return ['ot', 'sf', 'st', 'e', 'sta'].includes(key);
  }

  /**
   * Checks if the given value is valid
   *
   * @param value - The value to check.
   *
   * @returns `true` if the key is a value is valid.
   *
   * @internal
   */
  function isValid(value) {
   if (typeof value === 'number') {
    return isFiniteNumber(value);
   }
   return value != null && value !== '' && value !== false;
  }

  /**
   * CMCD event mode variable name.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_EVENT_MODE = 'event';

  /**
   * Constructs a relative path from a URL.
   *
   * @param url - The destination URL
   * @param base - The base URL
   * @returns The relative path
   *
   * @group Utils
   *
   * @beta
   */
  function urlToRelativePath(url, base) {
   const to = new URL(url);
   const from = new URL(base);
   if (to.origin !== from.origin) {
    return url;
   }
   const toPath = to.pathname.split('/').slice(1);
   const fromPath = from.pathname.split('/').slice(1, -1);
   // remove common parents
   while (toPath[0] === fromPath[0]) {
    toPath.shift();
    fromPath.shift();
   }
   // add back paths
   while (fromPath.length) {
    fromPath.shift();
    toPath.unshift('..');
   }
   const relativePath = toPath.join('/');
   // preserve query parameters and hash of the destination url
   return relativePath + to.search + to.hash;
  }

  const toRounded = (value) => Math.round(value);
  const toUrlSafe = (value, options) => {
   if (Array.isArray(value)) {
    return value.map((item) => toUrlSafe(item, options));
   }
   if (value instanceof SfItem && typeof value.value === 'string') {
    return new SfItem(toUrlSafe(value.value, options), value.params);
   } else {
    if (options.baseUrl) {
     value = urlToRelativePath(value, options.baseUrl);
    }
    return options.version === 1 ? encodeURIComponent(value) : value;
   }
  };
  const toHundred = (value) => toRounded(value / 100) * 100;
  const nor = (value, options) => {
   let norValue = value;
   if (options.version >= 2) {
    if (value instanceof SfItem && typeof value.value === 'string') {
     norValue = new SfItem([value]);
    } else if (typeof value === 'string') {
     norValue = [value];
    }
   }
   return toUrlSafe(norValue, options);
  };
  /**
   * The default formatters for CMCD values.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_FORMATTER_MAP = {
   /**
    * Bitrate (kbps) rounded integer
    */
   br: toRounded,
   /**
    * Duration (milliseconds) rounded integer
    */
   d: toRounded,
   /**
    * Buffer Length (milliseconds) rounded nearest 100ms
    */
   bl: toHundred,
   /**
    * Deadline (milliseconds) rounded nearest 100ms
    */
   dl: toHundred,
   /**
    * Measured Throughput (kbps) rounded nearest 100kbps
    */
   mtp: toHundred,
   /**
    * Next Object Request URL encoded
    */
   nor,
   /**
    * Requested maximum throughput (kbps) rounded nearest 100kbps
    */
   rtp: toHundred,
   /**
    * Top Bitrate (kbps) rounded integer
    */
   tb: toRounded,
  };

  /**
   * CMCD request mode variable name.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_REQUEST_MODE = 'request';

  /**
   * CMCD response mode variable name.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_RESPONSE_MODE = 'response';

  /**
   * Defines the common keys for CMCD (Common Media Client Data) version 2.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_COMMON_KEYS = ['ab', 'bg', 'bl', 'br', 'bs', 'bsd', 'cdn', 'cid', 'cs', 'df', 'ec', 'lab', 'lb', 'ltc', 'msd', 'mtp', 'pb', 'pr', 'pt', 'sf', 'sid', 'sn', 'st', 'sta', 'tab', 'tb', 'tbl', 'tpb', 'ts', 'v'];

  /**
   * Defines the event-specific keys for CMCD (Common Media Client Data) version 2.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_EVENT_KEYS = ['e'];

  const CUSTOM_KEY_REGEX = /^[a-zA-Z0-9-.]+-[a-zA-Z0-9-.]+$/;
  /**
   * Check if a key is a custom key.
   *
   * @param key - The key to check.
   *
   * @returns `true` if the key is a custom key, `false` otherwise.
   *
   * @group CMCD
   *
   * @beta
   */
  function isCmcdCustomKey(key) {
   return CUSTOM_KEY_REGEX.test(key);
  }

  /**
   * Check if a key is a valid CMCD event key.
   *
   * @param key - The key to check.
   *
   * @returns `true` if the key is a valid CMCD event key, `false` otherwise.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/isCmcdEventKey.test.ts#example}
   */
  function isCmcdEventKey(key) {
   return CMCD_COMMON_KEYS.includes(key) || CMCD_EVENT_KEYS.includes(key) || isCmcdCustomKey(key);
  }

  /**
   * Defines the request-specific keys for CMCD (Common Media Client Data) version 2.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_REQUEST_KEYS = ['d', 'dl', 'nor', 'ot', 'rtp', 'su'];

  /**
   * Check if a key is a valid CMCD request key.
   *
   * @param key - The key to check.
   *
   * @returns `true` if the key is a valid CMCD request key, `false` otherwise.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/isCmcdRequestKey.test.ts#example}
   */
  function isCmcdRequestKey(key) {
   return CMCD_COMMON_KEYS.includes(key) || CMCD_REQUEST_KEYS.includes(key) || isCmcdCustomKey(key);
  }

  /**
   * CMCD v2 - Response-only and timing keys.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_RESPONSE_KEYS = ['cmsdd', 'cmsds', 'rc', 'smrt', 'ttfb', 'ttfbb', 'ttlb', 'url'];

  /**
   * Check if a key is a valid CMCD response key.
   *
   * @param key - The key to check.
   *
   * @returns `true` if the key is a valid CMCD request key, `false` otherwise.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/isCmcdResponseKey.test.ts#example}
   */
  function isCmcdResponseKey(key) {
   return CMCD_COMMON_KEYS.includes(key) || CMCD_REQUEST_KEYS.includes(key) || CMCD_RESPONSE_KEYS.includes(key) || isCmcdCustomKey(key);
  }

  /**
   * Defines the keys for CMCD (Common Media Client Data) version 1.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_V1_KEYS = ['bl', 'br', 'bs', 'cid', 'd', 'dl', 'mtp', 'nor', 'nrr', 'ot', 'pr', 'rtp', 'sf', 'sid', 'st', 'su', 'tb', 'v'];

  /**
   * Filter function for CMCD v1 keys.
   *
   * @param key - The CMCD key to filter.
   *
   * @returns `true` if the key should be included, `false` otherwise.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/isCmcdV1Key.test.ts#example}
   */
  function isCmcdV1Key(key) {
   return CMCD_V1_KEYS.includes(key) || isCmcdCustomKey(key);
  }

  const filterMap = {
   [CMCD_RESPONSE_MODE]: isCmcdResponseKey,
   [CMCD_EVENT_MODE]: isCmcdEventKey,
   [CMCD_REQUEST_MODE]: isCmcdRequestKey,
  };
  /**
   * Convert a generic object to CMCD data.
   *
   * @param obj - The CMCD object to process.
   * @param options - Options for encoding.
   *
   * @group CMCD
   *
   * @beta
   */
  function prepareCmcdData(obj, options = {}) {
   const results = {};
   if (obj == null || typeof obj !== 'object') {
    return results;
   }
   const version = options.version || obj['v'] || 1;
   const reportingMode = options.reportingMode || CMCD_REQUEST_MODE;
   const keyFilter = version === 1 ? isCmcdV1Key : filterMap[reportingMode];
   // Filter keys based on the version, reporting mode and options
   let keys = Object.keys(obj).filter(keyFilter);
   const filter = options.filter;
   if (typeof filter === 'function') {
    keys = keys.filter(filter);
   }
   // Ensure all required keys are present before sorting
   const needsTimestamp = reportingMode === CMCD_RESPONSE_MODE || reportingMode === CMCD_EVENT_MODE;
   if (needsTimestamp && !keys.includes('ts')) {
    keys.push('ts');
   }
   if (version > 1 && !keys.includes('v')) {
    keys.push('v');
   }
   const formatters = _extends({}, CMCD_FORMATTER_MAP, options.formatters);
   const formatterOptions = {
    version,
    reportingMode,
    baseUrl: options.baseUrl,
   };
   keys.sort().forEach((key) => {
    let value = obj[key];
    const formatter = formatters[key];
    if (typeof formatter === 'function') {
     value = formatter(value, formatterOptions);
    }
    // Version should only be reported if not equal to 1.
    if (key === 'v') {
     if (version === 1) {
      return;
     } else {
      value = version;
     }
    }
    // Playback rate should only be sent if not equal to 1.
    if (key == 'pr' && value === 1) {
     return;
    }
    // Ensure a timestamp is set for response and event modes
    if (needsTimestamp && key === 'ts' && !isFiniteNumber(value)) {
     value = Date.now();
    }
    // ignore invalid values
    if (!isValid(value)) {
     return;
    }
    if (isTokenField(key) && typeof value === 'string') {
     value = new SfToken(value);
    }
    results[key] = value;
   });
   return results;
  }

  /**
   * Convert a CMCD data object to request headers
   *
   * @param cmcd - The CMCD data object to convert.
   * @param options - Options for encoding the CMCD object.
   *
   * @returns The CMCD header shards.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/toCmcdHeaders.test.ts#example}
   */
  function toCmcdHeaders(cmcd, options = {}) {
   const result = {};
   if (!cmcd) {
    return result;
   }
   const data = prepareCmcdData(cmcd, options);
   const shards = groupCmcdHeaders(data, options === null || options === void 0 ? void 0 : options.customHeaderMap);
   return Object.entries(shards).reduce((acc, [field, value]) => {
    const shard = encodeSfDict(value, {
     whitespace: false,
    });
    if (shard) {
     acc[field] = shard;
    }
    return acc;
   }, result);
  }

  /**
   * Append CMCD query args to a header object.
   *
   * @param headers - The headers to append to.
   * @param cmcd - The CMCD object to append.
   * @param options - Encode options.
   *
   * @returns The headers with the CMCD header shards appended.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/appendCmcdHeaders.test.ts#example}
   */
  function appendCmcdHeaders(headers, cmcd, options) {
   return _extends(headers, toCmcdHeaders(cmcd, options));
  }

  /**
   * CMCD parameter name.
   *
   * @group CMCD
   *
   * @beta
   */
  const CMCD_PARAM = 'CMCD';

  /**
   * Encode a CMCD object to a string.
   *
   * @param cmcd - The CMCD object to encode.
   * @param options - Options for encoding.
   *
   * @returns The encoded CMCD string.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/encodeCmcd.test.ts#example}
   */
  function encodeCmcd(cmcd, options = {}) {
   if (!cmcd) {
    return '';
   }
   return encodeSfDict(prepareCmcdData(cmcd, options), {
    whitespace: false,
   });
  }

  /**
   * Convert a CMCD data object to a URL encoded string.
   *
   * @param cmcd - The CMCD object to convert.
   * @param options - Options for encoding the CMCD object.
   *
   * @returns The URL encoded CMCD data.
   *
   * @group CMCD
   *
   * @beta
   */
  function toCmcdUrl(cmcd, options = {}) {
   if (!cmcd) {
    return '';
   }
   const params = encodeCmcd(cmcd, options);
   return encodeURIComponent(params);
  }

  /**
   * Convert a CMCD data object to a query arg.
   *
   * @param cmcd - The CMCD object to convert.
   * @param options - Options for encoding the CMCD object.
   *
   * @returns The CMCD query arg.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/toCmcdQuery.test.ts#example}
   */
  function toCmcdQuery(cmcd, options = {}) {
   if (!cmcd) {
    return '';
   }
   const value = toCmcdUrl(cmcd, options);
   return `${CMCD_PARAM}=${value}`;
  }

  const REGEX = /CMCD=[^&#]+/;
  /**
   * Append CMCD query args to a URL.
   *
   * @param url - The URL to append to.
   * @param cmcd - The CMCD object to append.
   * @param options - Options for encoding the CMCD object.
   *
   * @returns The URL with the CMCD query args appended.
   *
   * @group CMCD
   *
   * @beta
   *
   * @example
   * {@includeCode ../../test/cmcd/appendCmcdQuery.test.ts#example}
   */
  function appendCmcdQuery(url, cmcd, options) {
   // TODO: Replace with URLSearchParams once we drop Safari < 10.1 & Chrome < 49 support.
   // https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams
   const query = toCmcdQuery(cmcd, options);
   if (!query) {
    return url;
   }
   if (REGEX.test(url)) {
    return url.replace(REGEX, query);
   }
   const separator = url.includes('?') ? '&' : '?';
   return `${url}${separator}${query}`;
  }

  /**
   * Controller to deal with Common Media Client Data (CMCD)
   * @see https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf
   */
  class CMCDController {
   constructor(hls) {
    this.hls = void 0;
    this.config = void 0;
    this.media = void 0;
    this.sid = void 0;
    this.cid = void 0;
    this.useHeaders = false;
    this.includeKeys = void 0;
    this.initialized = false;
    this.starved = false;
    this.buffering = true;
    this.audioBuffer = void 0;
    this.videoBuffer = void 0;
    this.onWaiting = () => {
     if (this.initialized) {
      this.starved = true;
     }
     this.buffering = true;
    };
    this.onPlaying = () => {
     if (!this.initialized) {
      this.initialized = true;
     }
     this.buffering = false;
    };
    /**
     * Apply CMCD data to a manifest request.
     */
    this.applyPlaylistData = (context) => {
     try {
      this.apply(context, {
       ot: CmcdObjectType.MANIFEST,
       su: !this.initialized,
      });
     } catch (error) {
      this.hls.logger.warn('Could not generate manifest CMCD data.', error);
     }
    };
    /**
     * Apply CMCD data to a segment request
     */
    this.applyFragmentData = (context) => {
     try {
      const { frag, part } = context;
      const level = this.hls.levels[frag.level];
      const ot = this.getObjectType(frag);
      const data = {
       d: (part || frag).duration * 1000,
       ot,
      };
      if (ot === CmcdObjectType.VIDEO || ot === CmcdObjectType.AUDIO || ot == CmcdObjectType.MUXED) {
       data.br = level.bitrate / 1000;
       data.tb = this.getTopBandwidth(ot) / 1000;
       data.bl = this.getBufferLength(ot);
      }
      const next = part ? this.getNextPart(part) : this.getNextFrag(frag);
      if (next != null && next.url && next.url !== frag.url) {
       data.nor = next.url;
      }
      this.apply(context, data);
     } catch (error) {
      this.hls.logger.warn('Could not generate segment CMCD data.', error);
     }
    };
    this.hls = hls;
    const config = (this.config = hls.config);
    const { cmcd } = config;
    if (cmcd != null) {
     config.pLoader = this.createPlaylistLoader();
     config.fLoader = this.createFragmentLoader();
     this.sid = cmcd.sessionId || hls.sessionId;
     this.cid = cmcd.contentId;
     this.useHeaders = cmcd.useHeaders === true;
     this.includeKeys = cmcd.includeKeys;
     this.registerListeners();
    }
   }
   registerListeners() {
    const hls = this.hls;
    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    hls.on(Events.MEDIA_DETACHED, this.onMediaDetached, this);
    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);
   }
   unregisterListeners() {
    const hls = this.hls;
    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    hls.off(Events.MEDIA_DETACHED, this.onMediaDetached, this);
    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);
   }
   destroy() {
    this.unregisterListeners();
    this.onMediaDetached();

    // @ts-ignore
    this.hls = this.config = this.audioBuffer = this.videoBuffer = null;
    // @ts-ignore
    this.onWaiting = this.onPlaying = this.media = null;
   }
   onMediaAttached(event, data) {
    this.media = data.media;
    this.media.addEventListener('waiting', this.onWaiting);
    this.media.addEventListener('playing', this.onPlaying);
   }
   onMediaDetached() {
    if (!this.media) {
     return;
    }
    this.media.removeEventListener('waiting', this.onWaiting);
    this.media.removeEventListener('playing', this.onPlaying);

    // @ts-ignore
    this.media = null;
   }
   onBufferCreated(event, data) {
    var _data$tracks$audio, _data$tracks$video;
    this.audioBuffer = (_data$tracks$audio = data.tracks.audio) == null ? void 0 : _data$tracks$audio.buffer;
    this.videoBuffer = (_data$tracks$video = data.tracks.video) == null ? void 0 : _data$tracks$video.buffer;
   }
   /**
    * Create baseline CMCD data
    */
   createData() {
    var _this$media;
    return {
     v: 1,
     sf: CmcdStreamingFormat.HLS,
     sid: this.sid,
     cid: this.cid,
     pr: (_this$media = this.media) == null ? void 0 : _this$media.playbackRate,
     mtp: this.hls.bandwidthEstimate / 1000,
    };
   }

   /**
    * Apply CMCD data to a request.
    */
   apply(context, data = {}) {
    // apply baseline data
    _extends(data, this.createData());
    const isVideo = data.ot === CmcdObjectType.INIT || data.ot === CmcdObjectType.VIDEO || data.ot === CmcdObjectType.MUXED;
    if (this.starved && isVideo) {
     data.bs = true;
     data.su = true;
     this.starved = false;
    }
    if (data.su == null) {
     data.su = this.buffering;
    }

    // TODO: Implement rtp, nrr, dl

    const { includeKeys } = this;
    if (includeKeys) {
     data = Object.keys(data).reduce((acc, key) => {
      includeKeys.includes(key) && (acc[key] = data[key]);
      return acc;
     }, {});
    }
    const options = {
     baseUrl: context.url,
    };
    if (this.useHeaders) {
     if (!context.headers) {
      context.headers = {};
     }
     appendCmcdHeaders(context.headers, data, options);
    } else {
     context.url = appendCmcdQuery(context.url, data, options);
    }
   }
   getNextFrag(fragment) {
    var _this$hls$levels$frag;
    const levelDetails = (_this$hls$levels$frag = this.hls.levels[fragment.level]) == null ? void 0 : _this$hls$levels$frag.details;
    if (levelDetails) {
     const index = fragment.sn - levelDetails.startSN;
     return levelDetails.fragments[index + 1];
    }
    return undefined;
   }
   getNextPart(part) {
    var _this$hls$levels$frag2;
    const { index, fragment } = part;
    const partList = (_this$hls$levels$frag2 = this.hls.levels[fragment.level]) == null || (_this$hls$levels$frag2 = _this$hls$levels$frag2.details) == null ? void 0 : _this$hls$levels$frag2.partList;
    if (partList) {
     const { sn } = fragment;
     for (let i = partList.length - 1; i >= 0; i--) {
      const p = partList[i];
      if (p.index === index && p.fragment.sn === sn) {
       return partList[i + 1];
      }
     }
    }
    return undefined;
   }

   /**
    * The CMCD object type.
    */
   getObjectType(fragment) {
    const { type } = fragment;
    if (type === 'subtitle') {
     return CmcdObjectType.TIMED_TEXT;
    }
    if (fragment.sn === 'initSegment') {
     return CmcdObjectType.INIT;
    }
    if (type === 'audio') {
     return CmcdObjectType.AUDIO;
    }
    if (type === 'main') {
     if (!this.hls.audioTracks.length) {
      return CmcdObjectType.MUXED;
     }
     return CmcdObjectType.VIDEO;
    }
    return undefined;
   }

   /**
    * Get the highest bitrate.
    */
   getTopBandwidth(type) {
    let bitrate = 0;
    let levels;
    const hls = this.hls;
    if (type === CmcdObjectType.AUDIO) {
     levels = hls.audioTracks;
    } else {
     const max = hls.maxAutoLevel;
     const len = max > -1 ? max + 1 : hls.levels.length;
     levels = hls.levels.slice(0, len);
    }
    levels.forEach((level) => {
     if (level.bitrate > bitrate) {
      bitrate = level.bitrate;
     }
    });
    return bitrate > 0 ? bitrate : NaN;
   }

   /**
    * Get the buffer length for a media type in milliseconds
    */
   getBufferLength(type) {
    const media = this.media;
    const buffer = type === CmcdObjectType.AUDIO ? this.audioBuffer : this.videoBuffer;
    if (!buffer || !media) {
     return NaN;
    }
    const info = BufferHelper.bufferInfo(buffer, media.currentTime, this.config.maxBufferHole);
    return info.len * 1000;
   }

   /**
    * Create a playlist loader
    */
   createPlaylistLoader() {
    const { pLoader } = this.config;
    const apply = this.applyPlaylistData;
    const Ctor = pLoader || this.config.loader;
    return class CmcdPlaylistLoader {
     constructor(config) {
      this.loader = void 0;
      this.loader = new Ctor(config);
     }
     get stats() {
      return this.loader.stats;
     }
     get context() {
      return this.loader.context;
     }
     destroy() {
      this.loader.destroy();
     }
     abort() {
      this.loader.abort();
     }
     load(context, config, callbacks) {
      apply(context);
      this.loader.load(context, config, callbacks);
     }
    };
   }

   /**
    * Create a playlist loader
    */
   createFragmentLoader() {
    const { fLoader } = this.config;
    const apply = this.applyFragmentData;
    const Ctor = fLoader || this.config.loader;
    return class CmcdFragmentLoader {
     constructor(config) {
      this.loader = void 0;
      this.loader = new Ctor(config);
     }
     get stats() {
      return this.loader.stats;
     }
     get context() {
      return this.loader.context;
     }
     destroy() {
      this.loader.destroy();
     }
     abort() {
      this.loader.abort();
     }
     load(context, config, callbacks) {
      apply(context);
      this.loader.load(context, config, callbacks);
     }
    };
   }
  }

  const PATHWAY_PENALTY_DURATION_MS = 300000;
  class ContentSteeringController extends Logger {
   constructor(hls) {
    super('content-steering', hls.logger);
    this.hls = void 0;
    this.loader = null;
    this.uri = null;
    this.pathwayId = '.';
    this._pathwayPriority = null;
    this.timeToLoad = 300;
    this.reloadTimer = -1;
    this.updated = 0;
    this.started = false;
    this.enabled = true;
    this.levels = null;
    this.audioTracks = null;
    this.subtitleTracks = null;
    this.penalizedPathways = {};
    this.hls = hls;
    this.registerListeners();
   }
   registerListeners() {
    const hls = this.hls;
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.on(Events.ERROR, this.onError, this);
   }
   unregisterListeners() {
    const hls = this.hls;
    if (!hls) {
     return;
    }
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.off(Events.ERROR, this.onError, this);
   }
   pathways() {
    return (this.levels || []).reduce((pathways, level) => {
     if (pathways.indexOf(level.pathwayId) === -1) {
      pathways.push(level.pathwayId);
     }
     return pathways;
    }, []);
   }
   get pathwayPriority() {
    return this._pathwayPriority;
   }
   set pathwayPriority(pathwayPriority) {
    this.updatePathwayPriority(pathwayPriority);
   }
   startLoad() {
    this.started = true;
    this.clearTimeout();
    if (this.enabled && this.uri) {
     if (this.updated) {
      const ttl = this.timeToLoad * 1000 - (performance.now() - this.updated);
      if (ttl > 0) {
       this.scheduleRefresh(this.uri, ttl);
       return;
      }
     }
     this.loadSteeringManifest(this.uri);
    }
   }
   stopLoad() {
    this.started = false;
    if (this.loader) {
     this.loader.destroy();
     this.loader = null;
    }
    this.clearTimeout();
   }
   clearTimeout() {
    if (this.reloadTimer !== -1) {
     self.clearTimeout(this.reloadTimer);
     this.reloadTimer = -1;
    }
   }
   destroy() {
    this.unregisterListeners();
    this.stopLoad();
    // @ts-ignore
    this.hls = null;
    this.levels = this.audioTracks = this.subtitleTracks = null;
   }
   removeLevel(levelToRemove) {
    const levels = this.levels;
    if (levels) {
     this.levels = levels.filter((level) => level !== levelToRemove);
    }
   }
   onManifestLoading() {
    this.stopLoad();
    this.enabled = true;
    this.timeToLoad = 300;
    this.updated = 0;
    this.uri = null;
    this.pathwayId = '.';
    this.levels = this.audioTracks = this.subtitleTracks = null;
   }
   onManifestLoaded(event, data) {
    const { contentSteering } = data;
    if (contentSteering === null) {
     return;
    }
    this.pathwayId = contentSteering.pathwayId;
    this.uri = contentSteering.uri;
    if (this.started) {
     this.startLoad();
    }
   }
   onManifestParsed(event, data) {
    this.audioTracks = data.audioTracks;
    this.subtitleTracks = data.subtitleTracks;
   }
   onError(event, data) {
    const { errorAction } = data;
    if ((errorAction == null ? void 0 : errorAction.action) === NetworkErrorAction.SendAlternateToPenaltyBox && errorAction.flags === ErrorActionFlags.MoveAllAlternatesMatchingHost) {
     const levels = this.levels;
     let pathwayPriority = this._pathwayPriority;
     let errorPathway = this.pathwayId;
     if (data.context) {
      const { groupId, pathwayId, type } = data.context;
      if (groupId && levels) {
       errorPathway = this.getPathwayForGroupId(groupId, type, errorPathway);
      } else if (pathwayId) {
       errorPathway = pathwayId;
      }
     }
     if (!(errorPathway in this.penalizedPathways)) {
      this.penalizedPathways[errorPathway] = performance.now();
     }
     if (!pathwayPriority && levels) {
      // If PATHWAY-PRIORITY was not provided, list pathways for error handling
      pathwayPriority = this.pathways();
     }
     if (pathwayPriority && pathwayPriority.length > 1) {
      this.updatePathwayPriority(pathwayPriority);
      errorAction.resolved = this.pathwayId !== errorPathway;
     }
     if (data.details === ErrorDetails.BUFFER_APPEND_ERROR && !data.fatal) {
      // Error will become fatal in buffer-controller when reaching `appendErrorMaxRetry`
      // Stream-controllers are expected to reduce buffer length even if this is not deemed a QuotaExceededError
      errorAction.resolved = true;
     } else if (!errorAction.resolved) {
      this.warn(`Could not resolve ${data.details} ("${data.error.message}") with content-steering for Pathway: ${errorPathway} levels: ${levels ? levels.length : levels} priorities: ${stringify(pathwayPriority)} penalized: ${stringify(this.penalizedPathways)}`);
     }
    }
   }
   filterParsedLevels(levels) {
    // Filter levels to only include those that are in the initial pathway
    this.levels = levels;
    let pathwayLevels = this.getLevelsForPathway(this.pathwayId);
    if (pathwayLevels.length === 0) {
     const pathwayId = levels[0].pathwayId;
     this.log(`No levels found in Pathway ${this.pathwayId}. Setting initial Pathway to "${pathwayId}"`);
     pathwayLevels = this.getLevelsForPathway(pathwayId);
     this.pathwayId = pathwayId;
    }
    if (pathwayLevels.length !== levels.length) {
     this.log(`Found ${pathwayLevels.length}/${levels.length} levels in Pathway "${this.pathwayId}"`);
    }
    return pathwayLevels;
   }
   getLevelsForPathway(pathwayId) {
    if (this.levels === null) {
     return [];
    }
    return this.levels.filter((level) => pathwayId === level.pathwayId);
   }
   updatePathwayPriority(pathwayPriority) {
    this._pathwayPriority = pathwayPriority;
    let levels;

    // Evaluate if we should remove the pathway from the penalized list
    const penalizedPathways = this.penalizedPathways;
    const now = performance.now();
    Object.keys(penalizedPathways).forEach((pathwayId) => {
     if (now - penalizedPathways[pathwayId] > PATHWAY_PENALTY_DURATION_MS) {
      delete penalizedPathways[pathwayId];
     }
    });
    for (let i = 0; i < pathwayPriority.length; i++) {
     const pathwayId = pathwayPriority[i];
     if (pathwayId in penalizedPathways) {
      continue;
     }
     if (pathwayId === this.pathwayId) {
      return;
     }
     const selectedIndex = this.hls.nextLoadLevel;
     const selectedLevel = this.hls.levels[selectedIndex];
     levels = this.getLevelsForPathway(pathwayId);
     if (levels.length > 0) {
      this.log(`Setting Pathway to "${pathwayId}"`);
      this.pathwayId = pathwayId;
      reassignFragmentLevelIndexes(levels);
      this.hls.trigger(Events.LEVELS_UPDATED, {
       levels,
      });
      // Set LevelController's level to trigger LEVEL_SWITCHING which loads playlist if needed
      const levelAfterChange = this.hls.levels[selectedIndex];
      if (selectedLevel && levelAfterChange && this.levels) {
       if (levelAfterChange.attrs['STABLE-VARIANT-ID'] !== selectedLevel.attrs['STABLE-VARIANT-ID'] && levelAfterChange.bitrate !== selectedLevel.bitrate) {
        this.log(`Unstable Pathways change from bitrate ${selectedLevel.bitrate} to ${levelAfterChange.bitrate}`);
       }
       this.hls.nextLoadLevel = selectedIndex;
      }
      break;
     }
    }
   }
   getPathwayForGroupId(groupId, type, defaultPathway) {
    const levels = this.getLevelsForPathway(defaultPathway).concat(this.levels || []);
    for (let i = 0; i < levels.length; i++) {
     if ((type === PlaylistContextType.AUDIO_TRACK && levels[i].hasAudioGroup(groupId)) || (type === PlaylistContextType.SUBTITLE_TRACK && levels[i].hasSubtitleGroup(groupId))) {
      return levels[i].pathwayId;
     }
    }
    return defaultPathway;
   }
   clonePathways(pathwayClones) {
    const levels = this.levels;
    if (!levels) {
     return;
    }
    const audioGroupCloneMap = {};
    const subtitleGroupCloneMap = {};
    pathwayClones.forEach((pathwayClone) => {
     const { ID: cloneId, 'BASE-ID': baseId, 'URI-REPLACEMENT': uriReplacement } = pathwayClone;
     if (levels.some((level) => level.pathwayId === cloneId)) {
      return;
     }
     const clonedVariants = this.getLevelsForPathway(baseId).map((baseLevel) => {
      const attributes = new AttrList(baseLevel.attrs);
      attributes['PATHWAY-ID'] = cloneId;
      const clonedAudioGroupId = attributes.AUDIO && `${attributes.AUDIO}_clone_${cloneId}`;
      const clonedSubtitleGroupId = attributes.SUBTITLES && `${attributes.SUBTITLES}_clone_${cloneId}`;
      if (clonedAudioGroupId) {
       audioGroupCloneMap[attributes.AUDIO] = clonedAudioGroupId;
       attributes.AUDIO = clonedAudioGroupId;
      }
      if (clonedSubtitleGroupId) {
       subtitleGroupCloneMap[attributes.SUBTITLES] = clonedSubtitleGroupId;
       attributes.SUBTITLES = clonedSubtitleGroupId;
      }
      const url = performUriReplacement(baseLevel.uri, attributes['STABLE-VARIANT-ID'], 'PER-VARIANT-URIS', uriReplacement);
      const clonedLevel = new Level({
       attrs: attributes,
       audioCodec: baseLevel.audioCodec,
       bitrate: baseLevel.bitrate,
       height: baseLevel.height,
       name: baseLevel.name,
       url,
       videoCodec: baseLevel.videoCodec,
       width: baseLevel.width,
      });
      if (baseLevel.audioGroups) {
       for (let i = 1; i < baseLevel.audioGroups.length; i++) {
        clonedLevel.addGroupId('audio', `${baseLevel.audioGroups[i]}_clone_${cloneId}`);
       }
      }
      if (baseLevel.subtitleGroups) {
       for (let i = 1; i < baseLevel.subtitleGroups.length; i++) {
        clonedLevel.addGroupId('text', `${baseLevel.subtitleGroups[i]}_clone_${cloneId}`);
       }
      }
      return clonedLevel;
     });
     levels.push(...clonedVariants);
     cloneRenditionGroups(this.audioTracks, audioGroupCloneMap, uriReplacement, cloneId);
     cloneRenditionGroups(this.subtitleTracks, subtitleGroupCloneMap, uriReplacement, cloneId);
    });
   }
   loadSteeringManifest(uri) {
    const config = this.hls.config;
    const Loader = config.loader;
    if (this.loader) {
     this.loader.destroy();
    }
    this.loader = new Loader(config);
    let url;
    try {
     url = new self.URL(uri);
    } catch (error) {
     this.enabled = false;
     this.log(`Failed to parse Steering Manifest URI: ${uri}`);
     return;
    }
    if (url.protocol !== 'data:') {
     const throughput = (this.hls.bandwidthEstimate || config.abrEwmaDefaultEstimate) | 0;
     url.searchParams.set('_HLS_pathway', this.pathwayId);
     url.searchParams.set('_HLS_throughput', '' + throughput);
    }
    const context = {
     responseType: 'json',
     url: url.href,
    };
    const loadPolicy = config.steeringManifestLoadPolicy.default;
    const legacyRetryCompatibility = loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};
    const loaderConfig = {
     loadPolicy,
     timeout: loadPolicy.maxLoadTimeMs,
     maxRetry: legacyRetryCompatibility.maxNumRetry || 0,
     retryDelay: legacyRetryCompatibility.retryDelayMs || 0,
     maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0,
    };
    const callbacks = {
     onSuccess: (response, stats, context, networkDetails) => {
      this.log(`Loaded steering manifest: "${url}"`);
      const steeringData = response.data;
      if ((steeringData == null ? void 0 : steeringData.VERSION) !== 1) {
       this.log(`Steering VERSION ${steeringData.VERSION} not supported!`);
       return;
      }
      this.updated = performance.now();
      this.timeToLoad = steeringData.TTL;
      const { 'RELOAD-URI': reloadUri, 'PATHWAY-CLONES': pathwayClones, 'PATHWAY-PRIORITY': pathwayPriority } = steeringData;
      if (reloadUri) {
       try {
        this.uri = new self.URL(reloadUri, url).href;
       } catch (error) {
        this.enabled = false;
        this.log(`Failed to parse Steering Manifest RELOAD-URI: ${reloadUri}`);
        return;
       }
      }
      this.scheduleRefresh(this.uri || context.url);
      if (pathwayClones) {
       this.clonePathways(pathwayClones);
      }
      const loadedSteeringData = {
       steeringManifest: steeringData,
       url: url.toString(),
      };
      this.hls.trigger(Events.STEERING_MANIFEST_LOADED, loadedSteeringData);
      if (pathwayPriority) {
       this.updatePathwayPriority(pathwayPriority);
      }
     },
     onError: (error, context, networkDetails, stats) => {
      this.log(`Error loading steering manifest: ${error.code} ${error.text} (${context.url})`);
      this.stopLoad();
      if (error.code === 410) {
       this.enabled = false;
       this.log(`Steering manifest ${context.url} no longer available`);
       return;
      }
      let ttl = this.timeToLoad * 1000;
      if (error.code === 429) {
       const loader = this.loader;
       if (typeof (loader == null ? void 0 : loader.getResponseHeader) === 'function') {
        const retryAfter = loader.getResponseHeader('Retry-After');
        if (retryAfter) {
         ttl = parseFloat(retryAfter) * 1000;
        }
       }
       this.log(`Steering manifest ${context.url} rate limited`);
       return;
      }
      this.scheduleRefresh(this.uri || context.url, ttl);
     },
     onTimeout: (stats, context, networkDetails) => {
      this.log(`Timeout loading steering manifest (${context.url})`);
      this.scheduleRefresh(this.uri || context.url);
     },
    };
    this.log(`Requesting steering manifest: ${url}`);
    this.loader.load(context, loaderConfig, callbacks);
   }
   scheduleRefresh(uri, ttlMs = this.timeToLoad * 1000) {
    this.clearTimeout();
    this.reloadTimer = self.setTimeout(() => {
     var _this$hls;
     const media = (_this$hls = this.hls) == null ? void 0 : _this$hls.media;
     if (media && !media.ended) {
      this.loadSteeringManifest(uri);
      return;
     }
     this.scheduleRefresh(uri, this.timeToLoad * 1000);
    }, ttlMs);
   }
  }
  function cloneRenditionGroups(tracks, groupCloneMap, uriReplacement, cloneId) {
   if (!tracks) {
    return;
   }
   Object.keys(groupCloneMap).forEach((audioGroupId) => {
    const clonedTracks = tracks
     .filter((track) => track.groupId === audioGroupId)
     .map((track) => {
      const clonedTrack = _extends({}, track);
      clonedTrack.details = undefined;
      clonedTrack.attrs = new AttrList(clonedTrack.attrs);
      clonedTrack.url = clonedTrack.attrs.URI = performUriReplacement(track.url, track.attrs['STABLE-RENDITION-ID'], 'PER-RENDITION-URIS', uriReplacement);
      clonedTrack.groupId = clonedTrack.attrs['GROUP-ID'] = groupCloneMap[audioGroupId];
      clonedTrack.attrs['PATHWAY-ID'] = cloneId;
      return clonedTrack;
     });
    tracks.push(...clonedTracks);
   });
  }
  function performUriReplacement(uri, stableId, perOptionKey, uriReplacement) {
   const { HOST: host, PARAMS: params, [perOptionKey]: perOptionUris } = uriReplacement;
   let perVariantUri;
   if (stableId) {
    perVariantUri = perOptionUris == null ? void 0 : perOptionUris[stableId];
    if (perVariantUri) {
     uri = perVariantUri;
    }
   }
   const url = new self.URL(uri);
   if (host && !perVariantUri) {
    url.host = host;
   }
   if (params) {
    Object.keys(params)
     .sort()
     .forEach((key) => {
      if (key) {
       url.searchParams.set(key, params[key]);
      }
     });
   }
   return url.href;
  }

  function addEventListener(el, type, listener) {
   removeEventListener(el, type, listener);
   el.addEventListener(type, listener);
  }
  function removeEventListener(el, type, listener) {
   el.removeEventListener(type, listener);
  }

  /**
   * Controller to deal with encrypted media extensions (EME)
   * @see https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API
   *
   * @class
   * @constructor
   */
  class EMEController extends Logger {
   constructor(hls) {
    super('eme', hls.logger);
    this.hls = void 0;
    this.config = void 0;
    this.media = null;
    this.keyFormatPromise = null;
    this.keySystemAccessPromises = {};
    this._requestLicenseFailureCount = 0;
    this.mediaKeySessions = [];
    this.keyIdToKeySessionPromise = {};
    this.mediaKeys = null;
    this.setMediaKeysQueue = EMEController.CDMCleanupPromise ? [EMEController.CDMCleanupPromise] : [];
    this.onMediaEncrypted = (event) => {
     const { initDataType, initData } = event;
     const logMessage = `"${event.type}" event: init data type: "${initDataType}"`;
     this.debug(logMessage);

     // Ignore event when initData is null
     if (initData === null) {
      return;
     }
     if (!this.keyFormatPromise) {
      let keySystems = Object.keys(this.keySystemAccessPromises);
      if (!keySystems.length) {
       keySystems = getKeySystemsForConfig(this.config);
      }
      const keyFormats = keySystems.map(keySystemDomainToKeySystemFormat).filter((k) => !!k);
      this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);
     }
     this.keyFormatPromise
      .then((keySystemFormat) => {
       const keySystem = keySystemFormatToKeySystemDomain(keySystemFormat);
       if (initDataType !== 'sinf' || keySystem !== KeySystems.FAIRPLAY) {
        this.log(`Ignoring "${event.type}" event with init data type: "${initDataType}" for selected key-system ${keySystem}`);
        return;
       }

       // Match sinf keyId to playlist skd://keyId=
       let keyId;
       try {
        const json = bin2str(new Uint8Array(initData));
        const sinf = base64Decode(JSON.parse(json).sinf);
        const tenc = parseSinf(sinf);
        if (!tenc) {
         throw new Error(`'schm' box missing or not cbcs/cenc with schi > tenc`);
        }
        keyId = new Uint8Array(tenc.subarray(8, 24));
       } catch (error) {
        this.warn(`${logMessage} Failed to parse sinf: ${error}`);
        return;
       }
       const keyIdHex = Hex.hexDump(keyId);
       const { keyIdToKeySessionPromise, mediaKeySessions } = this;
       let keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex];
       for (let i = 0; i < mediaKeySessions.length; i++) {
        // Match playlist key
        const keyContext = mediaKeySessions[i];
        const decryptdata = keyContext.decryptdata;
        if (!decryptdata.keyId) {
         continue;
        }
        const oldKeyIdHex = Hex.hexDump(decryptdata.keyId);
        if (keyIdHex === oldKeyIdHex || decryptdata.uri.replace(/-/g, '').indexOf(keyIdHex) !== -1) {
         keySessionContextPromise = keyIdToKeySessionPromise[oldKeyIdHex];
         if (!keySessionContextPromise) {
          continue;
         }
         if (decryptdata.pssh) {
          break;
         }
         delete keyIdToKeySessionPromise[oldKeyIdHex];
         decryptdata.pssh = new Uint8Array(initData);
         decryptdata.keyId = keyId;
         keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex] = keySessionContextPromise.then(() => {
          return this.generateRequestWithPreferredKeySession(keyContext, initDataType, initData, 'encrypted-event-key-match');
         });
         keySessionContextPromise.catch((error) => this.handleError(error));
         break;
        }
       }
       if (!keySessionContextPromise) {
        this.handleError(new Error(`Key ID ${keyIdHex} not encountered in playlist. Key-system sessions ${mediaKeySessions.length}.`));
       }
      })
      .catch((error) => this.handleError(error));
    };
    this.onWaitingForKey = (event) => {
     this.log(`"${event.type}" event`);
    };
    this.hls = hls;
    this.config = hls.config;
    this.registerListeners();
   }
   destroy() {
    this.onDestroying();
    this.onMediaDetached();
    // Remove any references that could be held in config options or callbacks
    const config = this.config;
    config.requestMediaKeySystemAccessFunc = null;
    config.licenseXhrSetup = config.licenseResponseCallback = undefined;
    config.drmSystems = config.drmSystemOptions = {};
    // @ts-ignore
    this.hls = this.config = this.keyIdToKeySessionPromise = null;
    // @ts-ignore
    this.onWaitingForKey = null;
   }
   registerListeners() {
    this.hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    this.hls.on(Events.MEDIA_DETACHED, this.onMediaDetached, this);
    this.hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    this.hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    this.hls.on(Events.DESTROYING, this.onDestroying, this);
   }
   unregisterListeners() {
    this.hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    this.hls.off(Events.MEDIA_DETACHED, this.onMediaDetached, this);
    this.hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    this.hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    this.hls.off(Events.DESTROYING, this.onDestroying, this);
   }
   getLicenseServerUrl(keySystem) {
    const { drmSystems, widevineLicenseUrl } = this.config;
    const keySystemConfiguration = drmSystems[keySystem];
    if (keySystemConfiguration) {
     return keySystemConfiguration.licenseUrl;
    }

    // For backward compatibility
    if (keySystem === KeySystems.WIDEVINE && widevineLicenseUrl) {
     return widevineLicenseUrl;
    }
   }
   getLicenseServerUrlOrThrow(keySystem) {
    const url = this.getLicenseServerUrl(keySystem);
    if (url === undefined) {
     throw new Error(`no license server URL configured for key-system "${keySystem}"`);
    }
    return url;
   }
   getServerCertificateUrl(keySystem) {
    const { drmSystems } = this.config;
    const keySystemConfiguration = drmSystems[keySystem];
    if (keySystemConfiguration) {
     return keySystemConfiguration.serverCertificateUrl;
    } else {
     this.log(`No Server Certificate in config.drmSystems["${keySystem}"]`);
    }
   }
   attemptKeySystemAccess(keySystemsToAttempt) {
    const levels = this.hls.levels;
    const uniqueCodec = (value, i, a) => !!value && a.indexOf(value) === i;
    const audioCodecs = levels.map((level) => level.audioCodec).filter(uniqueCodec);
    const videoCodecs = levels.map((level) => level.videoCodec).filter(uniqueCodec);
    if (audioCodecs.length + videoCodecs.length === 0) {
     videoCodecs.push('avc1.42e01e');
    }
    return new Promise((resolve, reject) => {
     const attempt = (keySystems) => {
      const keySystem = keySystems.shift();
      this.getMediaKeysPromise(keySystem, audioCodecs, videoCodecs)
       .then((mediaKeys) =>
        resolve({
         keySystem,
         mediaKeys,
        }),
       )
       .catch((error) => {
        if (keySystems.length) {
         attempt(keySystems);
        } else if (error instanceof EMEKeyError) {
         reject(error);
        } else {
         reject(
          new EMEKeyError(
           {
            type: ErrorTypes.KEY_SYSTEM_ERROR,
            details: ErrorDetails.KEY_SYSTEM_NO_ACCESS,
            error,
            fatal: true,
           },
           error.message,
          ),
         );
        }
       });
     };
     attempt(keySystemsToAttempt);
    });
   }
   requestMediaKeySystemAccess(keySystem, supportedConfigurations) {
    const { requestMediaKeySystemAccessFunc } = this.config;
    if (!(typeof requestMediaKeySystemAccessFunc === 'function')) {
     let errMessage = `Configured requestMediaKeySystemAccess is not a function ${requestMediaKeySystemAccessFunc}`;
     if (requestMediaKeySystemAccess === null && self.location.protocol === 'http:') {
      errMessage = `navigator.requestMediaKeySystemAccess is not available over insecure protocol ${location.protocol}`;
     }
     return Promise.reject(new Error(errMessage));
    }
    return requestMediaKeySystemAccessFunc(keySystem, supportedConfigurations);
   }
   getMediaKeysPromise(keySystem, audioCodecs, videoCodecs) {
    // This can throw, but is caught in event handler callpath
    const mediaKeySystemConfigs = getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, this.config.drmSystemOptions);
    const keySystemAccessPromises = this.keySystemAccessPromises[keySystem];
    let keySystemAccess = keySystemAccessPromises == null ? void 0 : keySystemAccessPromises.keySystemAccess;
    if (!keySystemAccess) {
     this.log(`Requesting encrypted media "${keySystem}" key-system access with config: ${stringify(mediaKeySystemConfigs)}`);
     keySystemAccess = this.requestMediaKeySystemAccess(keySystem, mediaKeySystemConfigs);
     const _keySystemAccessPromises = (this.keySystemAccessPromises[keySystem] = {
      keySystemAccess,
     });
     keySystemAccess.catch((error) => {
      this.log(`Failed to obtain access to key-system "${keySystem}": ${error}`);
     });
     return keySystemAccess.then((mediaKeySystemAccess) => {
      this.log(`Access for key-system "${mediaKeySystemAccess.keySystem}" obtained`);
      const certificateRequest = this.fetchServerCertificate(keySystem);
      this.log(`Create media-keys for "${keySystem}"`);
      _keySystemAccessPromises.mediaKeys = mediaKeySystemAccess.createMediaKeys().then((mediaKeys) => {
       this.log(`Media-keys created for "${keySystem}"`);
       _keySystemAccessPromises.hasMediaKeys = true;
       return certificateRequest.then((certificate) => {
        if (certificate) {
         return this.setMediaKeysServerCertificate(mediaKeys, keySystem, certificate);
        }
        return mediaKeys;
       });
      });
      _keySystemAccessPromises.mediaKeys.catch((error) => {
       this.error(`Failed to create media-keys for "${keySystem}"}: ${error}`);
      });
      return _keySystemAccessPromises.mediaKeys;
     });
    }
    return keySystemAccess.then(() => keySystemAccessPromises.mediaKeys);
   }
   createMediaKeySessionContext({ decryptdata, keySystem, mediaKeys }) {
    this.log(`Creating key-system session "${keySystem}" keyId: ${Hex.hexDump(decryptdata.keyId || [])}`);
    const mediaKeysSession = mediaKeys.createSession();
    const mediaKeySessionContext = {
     decryptdata,
     keySystem,
     mediaKeys,
     mediaKeysSession,
     keyStatus: 'status-pending',
    };
    this.mediaKeySessions.push(mediaKeySessionContext);
    return mediaKeySessionContext;
   }
   renewKeySession(mediaKeySessionContext) {
    const decryptdata = mediaKeySessionContext.decryptdata;
    if (decryptdata.pssh) {
     const keySessionContext = this.createMediaKeySessionContext(mediaKeySessionContext);
     const keyId = this.getKeyIdString(decryptdata);
     const scheme = 'cenc';
     this.keyIdToKeySessionPromise[keyId] = this.generateRequestWithPreferredKeySession(keySessionContext, scheme, decryptdata.pssh.buffer, 'expired');
    } else {
     this.warn(`Could not renew expired session. Missing pssh initData.`);
    }
    this.removeSession(mediaKeySessionContext);
   }
   getKeyIdString(decryptdata) {
    if (!decryptdata) {
     throw new Error('Could not read keyId of undefined decryptdata');
    }
    if (decryptdata.keyId === null) {
     throw new Error('keyId is null');
    }
    return Hex.hexDump(decryptdata.keyId);
   }
   updateKeySession(mediaKeySessionContext, data) {
    var _mediaKeySessionConte;
    const keySession = mediaKeySessionContext.mediaKeysSession;
    this.log(`Updating key-session "${keySession.sessionId}" for keyID ${Hex.hexDump(((_mediaKeySessionConte = mediaKeySessionContext.decryptdata) == null ? void 0 : _mediaKeySessionConte.keyId) || [])}
      } (data length: ${data ? data.byteLength : data})`);
    return keySession.update(data);
   }
   getSelectedKeySystemFormats() {
    return Object.keys(this.keySystemAccessPromises)
     .map((keySystem) => ({
      keySystem,
      hasMediaKeys: this.keySystemAccessPromises[keySystem].hasMediaKeys,
     }))
     .filter(({ hasMediaKeys }) => !!hasMediaKeys)
     .map(({ keySystem }) => keySystemDomainToKeySystemFormat(keySystem))
     .filter((keySystem) => !!keySystem);
   }
   getKeySystemAccess(keySystemsToAttempt) {
    return this.getKeySystemSelectionPromise(keySystemsToAttempt).then(({ keySystem, mediaKeys }) => {
     return this.attemptSetMediaKeys(keySystem, mediaKeys);
    });
   }
   selectKeySystem(keySystemsToAttempt) {
    return new Promise((resolve, reject) => {
     return this.getKeySystemSelectionPromise(keySystemsToAttempt)
      .then(({ keySystem }) => {
       const keySystemFormat = keySystemDomainToKeySystemFormat(keySystem);
       if (keySystemFormat) {
        resolve(keySystemFormat);
       } else {
        reject(new Error(`Unable to find format for key-system "${keySystem}"`));
       }
      })
      .catch(reject);
    });
   }
   selectKeySystemFormat(frag) {
    const keyFormats = Object.keys(frag.levelkeys || {});
    if (!this.keyFormatPromise) {
     this.log(`Selecting key-system from fragment (sn: ${frag.sn} ${frag.type}: ${frag.level}) key formats ${keyFormats.join(', ')}`);
     this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);
    }
    return this.keyFormatPromise;
   }
   getKeyFormatPromise(keyFormats) {
    const keySystemsInConfig = getKeySystemsForConfig(this.config);
    const keySystemsToAttempt = keyFormats.map(keySystemFormatToKeySystemDomain).filter((value) => !!value && keySystemsInConfig.indexOf(value) !== -1);
    return this.selectKeySystem(keySystemsToAttempt);
   }
   loadKey(data) {
    const decryptdata = data.keyInfo.decryptdata;
    const keyId = this.getKeyIdString(decryptdata);
    const keyDetails = `(keyId: ${keyId} format: "${decryptdata.keyFormat}" method: ${decryptdata.method} uri: ${decryptdata.uri})`;
    this.log(`Starting session for key ${keyDetails}`);
    let keyContextPromise = this.keyIdToKeySessionPromise[keyId];
    if (!keyContextPromise) {
     keyContextPromise = this.getKeySystemForKeyPromise(decryptdata).then(({ keySystem, mediaKeys }) => {
      this.throwIfDestroyed();
      this.log(`Handle encrypted media sn: ${data.frag.sn} ${data.frag.type}: ${data.frag.level} using key ${keyDetails}`);
      return this.attemptSetMediaKeys(keySystem, mediaKeys).then(() => {
       this.throwIfDestroyed();
       return this.createMediaKeySessionContext({
        keySystem,
        mediaKeys,
        decryptdata,
       });
      });
     });
     const keySessionContextPromise = (this.keyIdToKeySessionPromise[keyId] = keyContextPromise.then((keySessionContext) => {
      const scheme = 'cenc';
      const initData = decryptdata.pssh ? decryptdata.pssh.buffer : null;
      return this.generateRequestWithPreferredKeySession(keySessionContext, scheme, initData, 'playlist-key');
     }));
     keySessionContextPromise.catch((error) => this.handleError(error));
    }
    return keyContextPromise;
   }
   throwIfDestroyed(message = 'Invalid state') {
    if (!this.hls) {
     throw new Error('invalid state');
    }
   }
   handleError(error) {
    if (!this.hls) {
     return;
    }
    this.error(error.message);
    if (error instanceof EMEKeyError) {
     this.hls.trigger(Events.ERROR, error.data);
    } else {
     this.hls.trigger(Events.ERROR, {
      type: ErrorTypes.KEY_SYSTEM_ERROR,
      details: ErrorDetails.KEY_SYSTEM_NO_KEYS,
      error,
      fatal: true,
     });
    }
   }
   getKeySystemForKeyPromise(decryptdata) {
    const keyId = this.getKeyIdString(decryptdata);
    const mediaKeySessionContext = this.keyIdToKeySessionPromise[keyId];
    if (!mediaKeySessionContext) {
     const keySystem = keySystemFormatToKeySystemDomain(decryptdata.keyFormat);
     const keySystemsToAttempt = keySystem ? [keySystem] : getKeySystemsForConfig(this.config);
     return this.attemptKeySystemAccess(keySystemsToAttempt);
    }
    return mediaKeySessionContext;
   }
   getKeySystemSelectionPromise(keySystemsToAttempt) {
    if (!keySystemsToAttempt.length) {
     keySystemsToAttempt = getKeySystemsForConfig(this.config);
    }
    if (keySystemsToAttempt.length === 0) {
     throw new EMEKeyError(
      {
       type: ErrorTypes.KEY_SYSTEM_ERROR,
       details: ErrorDetails.KEY_SYSTEM_NO_CONFIGURED_LICENSE,
       fatal: true,
      },
      `Missing key-system license configuration options ${stringify({
       drmSystems: this.config.drmSystems,
      })}`,
     );
    }
    return this.attemptKeySystemAccess(keySystemsToAttempt);
   }
   attemptSetMediaKeys(keySystem, mediaKeys) {
    if (this.mediaKeys === mediaKeys) {
     return Promise.resolve();
    }
    const queue = this.setMediaKeysQueue.slice();
    this.log(`Setting media-keys for "${keySystem}"`);
    // Only one setMediaKeys() can run at one time, and multiple setMediaKeys() operations
    // can be queued for execution for multiple key sessions.
    const setMediaKeysPromise = Promise.all(queue).then(() => {
     if (!this.media) {
      this.mediaKeys = null;
      throw new Error('Attempted to set mediaKeys without media element attached');
     }
     return this.media.setMediaKeys(mediaKeys);
    });
    this.mediaKeys = mediaKeys;
    this.setMediaKeysQueue.push(setMediaKeysPromise);
    return setMediaKeysPromise.then(() => {
     this.log(`Media-keys set for "${keySystem}"`);
     queue.push(setMediaKeysPromise);
     this.setMediaKeysQueue = this.setMediaKeysQueue.filter((p) => queue.indexOf(p) === -1);
    });
   }
   generateRequestWithPreferredKeySession(context, initDataType, initData, reason) {
    var _this$config$drmSyste;
    const generateRequestFilter = (_this$config$drmSyste = this.config.drmSystems) == null || (_this$config$drmSyste = _this$config$drmSyste[context.keySystem]) == null ? void 0 : _this$config$drmSyste.generateRequest;
    if (generateRequestFilter) {
     try {
      const mappedInitData = generateRequestFilter.call(this.hls, initDataType, initData, context);
      if (!mappedInitData) {
       throw new Error('Invalid response from configured generateRequest filter');
      }
      initDataType = mappedInitData.initDataType;
      initData = mappedInitData.initData ? mappedInitData.initData : null;
      context.decryptdata.pssh = initData ? new Uint8Array(initData) : null;
     } catch (error) {
      var _this$hls;
      this.warn(error.message);
      if ((_this$hls = this.hls) != null && _this$hls.config.debug) {
       throw error;
      }
     }
    }
    if (initData === null) {
     this.log(`Skipping key-session request for "${reason}" (no initData)`);
     return Promise.resolve(context);
    }
    const keyId = this.getKeyIdString(context.decryptdata);
    this.log(`Generating key-session request for "${reason}": ${keyId} (init data type: ${initDataType} length: ${initData ? initData.byteLength : null})`);
    const licenseStatus = new EventEmitter();
    const onmessage = (context._onmessage = (event) => {
     const keySession = context.mediaKeysSession;
     if (!keySession) {
      licenseStatus.emit('error', new Error('invalid state'));
      return;
     }
     const { messageType, message } = event;
     this.log(`"${messageType}" message event for session "${keySession.sessionId}" message size: ${message.byteLength}`);
     if (messageType === 'license-request' || messageType === 'license-renewal') {
      this.renewLicense(context, message).catch((error) => {
       if (licenseStatus.eventNames().length) {
        licenseStatus.emit('error', error);
       } else {
        this.handleError(error);
       }
      });
     } else if (messageType === 'license-release') {
      if (context.keySystem === KeySystems.FAIRPLAY) {
       this.updateKeySession(context, strToUtf8array('acknowledged'));
       this.removeSession(context);
      }
     } else {
      this.warn(`unhandled media key message type "${messageType}"`);
     }
    });
    const onkeystatuseschange = (context._onkeystatuseschange = (event) => {
     const keySession = context.mediaKeysSession;
     if (!keySession) {
      licenseStatus.emit('error', new Error('invalid state'));
      return;
     }
     this.onKeyStatusChange(context);
     const keyStatus = context.keyStatus;
     licenseStatus.emit('keyStatus', keyStatus);
     if (keyStatus === 'expired') {
      this.warn(`${context.keySystem} expired for key ${keyId}`);
      this.renewKeySession(context);
     }
    });
    addEventListener(context.mediaKeysSession, 'message', onmessage);
    addEventListener(context.mediaKeysSession, 'keystatuseschange', onkeystatuseschange);
    const keyUsablePromise = new Promise((resolve, reject) => {
     licenseStatus.on('error', reject);
     licenseStatus.on('keyStatus', (keyStatus) => {
      if (keyStatus.startsWith('usable')) {
       resolve();
      } else if (keyStatus === 'output-restricted') {
       reject(
        new EMEKeyError(
         {
          type: ErrorTypes.KEY_SYSTEM_ERROR,
          details: ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED,
          fatal: false,
         },
         'HDCP level output restricted',
        ),
       );
      } else if (keyStatus === 'internal-error') {
       reject(
        new EMEKeyError(
         {
          type: ErrorTypes.KEY_SYSTEM_ERROR,
          details: ErrorDetails.KEY_SYSTEM_STATUS_INTERNAL_ERROR,
          fatal: true,
         },
         `key status changed to "${keyStatus}"`,
        ),
       );
      } else if (keyStatus === 'expired') {
       reject(new Error('key expired while generating request'));
      } else {
       this.warn(`unhandled key status change "${keyStatus}"`);
      }
     });
    });
    return context.mediaKeysSession
     .generateRequest(initDataType, initData)
     .then(() => {
      var _context$mediaKeysSes;
      this.log(`Request generated for key-session "${(_context$mediaKeysSes = context.mediaKeysSession) == null ? void 0 : _context$mediaKeysSes.sessionId}" keyId: ${keyId}`);
     })
     .catch((error) => {
      throw new EMEKeyError(
       {
        type: ErrorTypes.KEY_SYSTEM_ERROR,
        details: ErrorDetails.KEY_SYSTEM_NO_SESSION,
        error,
        fatal: false,
       },
       `Error generating key-session request: ${error}`,
      );
     })
     .then(() => keyUsablePromise)
     .catch((error) => {
      licenseStatus.removeAllListeners();
      this.removeSession(context);
      throw error;
     })
     .then(() => {
      licenseStatus.removeAllListeners();
      return context;
     });
   }
   onKeyStatusChange(mediaKeySessionContext) {
    mediaKeySessionContext.mediaKeysSession.keyStatuses.forEach((status, keyId) => {
     // keyStatuses.forEach is not standard API so the callback value looks weird on xboxone
     // xboxone callback(keyId, status) so we need to exchange them
     if (typeof keyId === 'string' && typeof status === 'object') {
      const temp = keyId;
      keyId = status;
      status = temp;
     }
     this.log(`key status change "${status}" for keyStatuses keyId: ${Hex.hexDump('buffer' in keyId ? new Uint8Array(keyId.buffer, keyId.byteOffset, keyId.byteLength) : new Uint8Array(keyId))} session keyId: ${Hex.hexDump(new Uint8Array(mediaKeySessionContext.decryptdata.keyId || []))} uri: ${mediaKeySessionContext.decryptdata.uri}`);
     mediaKeySessionContext.keyStatus = status;
    });
   }
   fetchServerCertificate(keySystem) {
    const config = this.config;
    const Loader = config.loader;
    const certLoader = new Loader(config);
    const url = this.getServerCertificateUrl(keySystem);
    if (!url) {
     return Promise.resolve();
    }
    this.log(`Fetching server certificate for "${keySystem}"`);
    return new Promise((resolve, reject) => {
     const loaderContext = {
      responseType: 'arraybuffer',
      url,
     };
     const loadPolicy = config.certLoadPolicy.default;
     const loaderConfig = {
      loadPolicy,
      timeout: loadPolicy.maxLoadTimeMs,
      maxRetry: 0,
      retryDelay: 0,
      maxRetryDelay: 0,
     };
     const loaderCallbacks = {
      onSuccess: (response, stats, context, networkDetails) => {
       resolve(response.data);
      },
      onError: (response, contex, networkDetails, stats) => {
       reject(
        new EMEKeyError(
         {
          type: ErrorTypes.KEY_SYSTEM_ERROR,
          details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,
          fatal: true,
          networkDetails,
          response: _objectSpread2(
           {
            url: loaderContext.url,
            data: undefined,
           },
           response,
          ),
         },
         `"${keySystem}" certificate request failed (${url}). Status: ${response.code} (${response.text})`,
        ),
       );
      },
      onTimeout: (stats, context, networkDetails) => {
       reject(
        new EMEKeyError(
         {
          type: ErrorTypes.KEY_SYSTEM_ERROR,
          details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,
          fatal: true,
          networkDetails,
          response: {
           url: loaderContext.url,
           data: undefined,
          },
         },
         `"${keySystem}" certificate request timed out (${url})`,
        ),
       );
      },
      onAbort: (stats, context, networkDetails) => {
       reject(new Error('aborted'));
      },
     };
     certLoader.load(loaderContext, loaderConfig, loaderCallbacks);
    });
   }
   setMediaKeysServerCertificate(mediaKeys, keySystem, cert) {
    return new Promise((resolve, reject) => {
     mediaKeys
      .setServerCertificate(cert)
      .then((success) => {
       this.log(`setServerCertificate ${success ? 'success' : 'not supported by CDM'} (${cert == null ? void 0 : cert.byteLength}) on "${keySystem}"`);
       resolve(mediaKeys);
      })
      .catch((error) => {
       reject(
        new EMEKeyError(
         {
          type: ErrorTypes.KEY_SYSTEM_ERROR,
          details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED,
          error,
          fatal: true,
         },
         error.message,
        ),
       );
      });
    });
   }
   renewLicense(context, keyMessage) {
    return this.requestLicense(context, new Uint8Array(keyMessage)).then((data) => {
     return this.updateKeySession(context, new Uint8Array(data)).catch((error) => {
      throw new EMEKeyError(
       {
        type: ErrorTypes.KEY_SYSTEM_ERROR,
        details: ErrorDetails.KEY_SYSTEM_SESSION_UPDATE_FAILED,
        error,
        fatal: true,
       },
       error.message,
      );
     });
    });
   }
   unpackPlayReadyKeyMessage(xhr, licenseChallenge) {
    // On Edge, the raw license message is UTF-16-encoded XML.  We need
    // to unpack the Challenge element (base64-encoded string containing the
    // actual license request) and any HttpHeader elements (sent as request
    // headers).
    // For PlayReady CDMs, we need to dig the Challenge out of the XML.
    const xmlString = String.fromCharCode.apply(null, new Uint16Array(licenseChallenge.buffer));
    if (!xmlString.includes('PlayReadyKeyMessage')) {
     // This does not appear to be a wrapped message as on Edge.  Some
     // clients do not need this unwrapping, so we will assume this is one of
     // them.  Note that "xml" at this point probably looks like random
     // garbage, since we interpreted UTF-8 as UTF-16.
     xhr.setRequestHeader('Content-Type', 'text/xml; charset=utf-8');
     return licenseChallenge;
    }
    const keyMessageXml = new DOMParser().parseFromString(xmlString, 'application/xml');
    // Set request headers.
    const headers = keyMessageXml.querySelectorAll('HttpHeader');
    if (headers.length > 0) {
     let header;
     for (let i = 0, len = headers.length; i < len; i++) {
      var _header$querySelector, _header$querySelector2;
      header = headers[i];
      const name = (_header$querySelector = header.querySelector('name')) == null ? void 0 : _header$querySelector.textContent;
      const value = (_header$querySelector2 = header.querySelector('value')) == null ? void 0 : _header$querySelector2.textContent;
      if (name && value) {
       xhr.setRequestHeader(name, value);
      }
     }
    }
    const challengeElement = keyMessageXml.querySelector('Challenge');
    const challengeText = challengeElement == null ? void 0 : challengeElement.textContent;
    if (!challengeText) {
     throw new Error(`Cannot find <Challenge> in key message`);
    }
    return strToUtf8array(atob(challengeText));
   }
   setupLicenseXHR(xhr, url, keysListItem, licenseChallenge) {
    const licenseXhrSetup = this.config.licenseXhrSetup;
    if (!licenseXhrSetup) {
     xhr.open('POST', url, true);
     return Promise.resolve({
      xhr,
      licenseChallenge,
     });
    }
    return Promise.resolve()
     .then(() => {
      if (!keysListItem.decryptdata) {
       throw new Error('Key removed');
      }
      return licenseXhrSetup.call(this.hls, xhr, url, keysListItem, licenseChallenge);
     })
     .catch((error) => {
      if (!keysListItem.decryptdata) {
       // Key session removed. Cancel license request.
       throw error;
      }
      // let's try to open before running setup
      xhr.open('POST', url, true);
      return licenseXhrSetup.call(this.hls, xhr, url, keysListItem, licenseChallenge);
     })
     .then((licenseXhrSetupResult) => {
      // if licenseXhrSetup did not yet call open, let's do it now
      if (!xhr.readyState) {
       xhr.open('POST', url, true);
      }
      const finalLicenseChallenge = licenseXhrSetupResult ? licenseXhrSetupResult : licenseChallenge;
      return {
       xhr,
       licenseChallenge: finalLicenseChallenge,
      };
     });
   }
   requestLicense(keySessionContext, licenseChallenge) {
    const keyLoadPolicy = this.config.keyLoadPolicy.default;
    return new Promise((resolve, reject) => {
     const url = this.getLicenseServerUrlOrThrow(keySessionContext.keySystem);
     this.log(`Sending license request to URL: ${url}`);
     const xhr = new XMLHttpRequest();
     xhr.responseType = 'arraybuffer';
     xhr.onreadystatechange = () => {
      if (!this.hls || !keySessionContext.mediaKeysSession) {
       return reject(new Error('invalid state'));
      }
      if (xhr.readyState === 4) {
       if (xhr.status === 200) {
        this._requestLicenseFailureCount = 0;
        let data = xhr.response;
        this.log(`License received ${data instanceof ArrayBuffer ? data.byteLength : data}`);
        const licenseResponseCallback = this.config.licenseResponseCallback;
        if (licenseResponseCallback) {
         try {
          data = licenseResponseCallback.call(this.hls, xhr, url, keySessionContext);
         } catch (error) {
          this.error(error);
         }
        }
        resolve(data);
       } else {
        const retryConfig = keyLoadPolicy.errorRetry;
        const maxNumRetry = retryConfig ? retryConfig.maxNumRetry : 0;
        this._requestLicenseFailureCount++;
        if (this._requestLicenseFailureCount > maxNumRetry || (xhr.status >= 400 && xhr.status < 500)) {
         reject(
          new EMEKeyError(
           {
            type: ErrorTypes.KEY_SYSTEM_ERROR,
            details: ErrorDetails.KEY_SYSTEM_LICENSE_REQUEST_FAILED,
            fatal: true,
            networkDetails: xhr,
            response: {
             url,
             data: undefined,
             code: xhr.status,
             text: xhr.statusText,
            },
           },
           `License Request XHR failed (${url}). Status: ${xhr.status} (${xhr.statusText})`,
          ),
         );
        } else {
         const attemptsLeft = maxNumRetry - this._requestLicenseFailureCount + 1;
         this.warn(`Retrying license request, ${attemptsLeft} attempts left`);
         this.requestLicense(keySessionContext, licenseChallenge).then(resolve, reject);
        }
       }
      }
     };
     if (keySessionContext.licenseXhr && keySessionContext.licenseXhr.readyState !== XMLHttpRequest.DONE) {
      keySessionContext.licenseXhr.abort();
     }
     keySessionContext.licenseXhr = xhr;
     this.setupLicenseXHR(xhr, url, keySessionContext, licenseChallenge).then(({ xhr, licenseChallenge }) => {
      if (keySessionContext.keySystem == KeySystems.PLAYREADY) {
       licenseChallenge = this.unpackPlayReadyKeyMessage(xhr, licenseChallenge);
      }
      xhr.send(licenseChallenge);
     });
    });
   }
   onDestroying() {
    this.unregisterListeners();
    this._clear();
   }
   onMediaAttached(event, data) {
    if (!this.config.emeEnabled) {
     return;
    }
    const media = data.media;

    // keep reference of media
    this.media = media;
    addEventListener(media, 'encrypted', this.onMediaEncrypted);
    addEventListener(media, 'waitingforkey', this.onWaitingForKey);
   }
   onMediaDetached() {
    const media = this.media;
    if (media) {
     removeEventListener(media, 'encrypted', this.onMediaEncrypted);
     removeEventListener(media, 'waitingforkey', this.onWaitingForKey);
     this.media = null;
     this.mediaKeys = null;
    }
   }
   _clear() {
    var _media$setMediaKeys;
    this._requestLicenseFailureCount = 0;
    this.keyIdToKeySessionPromise = {};
    if (!this.mediaKeys && !this.mediaKeySessions.length) {
     return;
    }
    const media = this.media;
    const mediaKeysList = this.mediaKeySessions.slice();
    this.mediaKeySessions = [];
    this.mediaKeys = null;
    LevelKey.clearKeyUriToKeyIdMap();

    // Close all sessions and remove media keys from the video element.
    const keySessionCount = mediaKeysList.length;
    EMEController.CDMCleanupPromise = Promise.all(
     mediaKeysList
      .map((mediaKeySessionContext) => this.removeSession(mediaKeySessionContext))
      .concat(
       media == null || (_media$setMediaKeys = media.setMediaKeys(null)) == null
        ? void 0
        : _media$setMediaKeys.catch((error) => {
           var _this$hls2;
           this.log(`Could not clear media keys: ${error}`);
           (_this$hls2 = this.hls) == null ||
            _this$hls2.trigger(Events.ERROR, {
             type: ErrorTypes.OTHER_ERROR,
             details: ErrorDetails.KEY_SYSTEM_DESTROY_MEDIA_KEYS_ERROR,
             fatal: false,
             error: new Error(`Could not clear media keys: ${error}`),
            });
          }),
      ),
    )
     .catch((error) => {
      var _this$hls3;
      this.log(`Could not close sessions and clear media keys: ${error}`);
      (_this$hls3 = this.hls) == null ||
       _this$hls3.trigger(Events.ERROR, {
        type: ErrorTypes.OTHER_ERROR,
        details: ErrorDetails.KEY_SYSTEM_DESTROY_CLOSE_SESSION_ERROR,
        fatal: false,
        error: new Error(`Could not close sessions and clear media keys: ${error}`),
       });
     })
     .then(() => {
      if (keySessionCount) {
       this.log('finished closing key sessions and clearing media keys');
      }
     });
   }
   onManifestLoading() {
    this.keyFormatPromise = null;
   }
   onManifestLoaded(event, { sessionKeys }) {
    if (!sessionKeys || !this.config.emeEnabled) {
     return;
    }
    if (!this.keyFormatPromise) {
     const keyFormats = sessionKeys.reduce((formats, sessionKey) => {
      if (formats.indexOf(sessionKey.keyFormat) === -1) {
       formats.push(sessionKey.keyFormat);
      }
      return formats;
     }, []);
     this.log(`Selecting key-system from session-keys ${keyFormats.join(', ')}`);
     this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);
    }
   }
   removeSession(mediaKeySessionContext) {
    const { mediaKeysSession, licenseXhr } = mediaKeySessionContext;
    if (mediaKeysSession) {
     this.log(`Remove licenses and keys and close session ${mediaKeysSession.sessionId}`);
     if (mediaKeySessionContext._onmessage) {
      mediaKeysSession.removeEventListener('message', mediaKeySessionContext._onmessage);
      mediaKeySessionContext._onmessage = undefined;
     }
     if (mediaKeySessionContext._onkeystatuseschange) {
      mediaKeysSession.removeEventListener('keystatuseschange', mediaKeySessionContext._onkeystatuseschange);
      mediaKeySessionContext._onkeystatuseschange = undefined;
     }
     if (licenseXhr && licenseXhr.readyState !== XMLHttpRequest.DONE) {
      licenseXhr.abort();
     }
     mediaKeySessionContext.mediaKeysSession = mediaKeySessionContext.decryptdata = mediaKeySessionContext.licenseXhr = undefined;
     const index = this.mediaKeySessions.indexOf(mediaKeySessionContext);
     if (index > -1) {
      this.mediaKeySessions.splice(index, 1);
     }
     const { drmSystemOptions } = this.config;
     const removePromise = isPersistentSessionType(drmSystemOptions)
      ? new Promise((resolve, reject) => {
         self.setTimeout(() => reject(new Error(`MediaKeySession.remove() timeout`)), 8000);
         mediaKeysSession.remove().then(resolve);
        })
      : Promise.resolve();
     return removePromise
      .catch((error) => {
       var _this$hls4;
       this.log(`Could not remove session: ${error}`);
       (_this$hls4 = this.hls) == null ||
        _this$hls4.trigger(Events.ERROR, {
         type: ErrorTypes.OTHER_ERROR,
         details: ErrorDetails.KEY_SYSTEM_DESTROY_REMOVE_SESSION_ERROR,
         fatal: false,
         error: new Error(`Could not remove session: ${error}`),
        });
      })
      .then(() => {
       return mediaKeysSession.close();
      })
      .catch((error) => {
       var _this$hls5;
       this.log(`Could not close session: ${error}`);
       (_this$hls5 = this.hls) == null ||
        _this$hls5.trigger(Events.ERROR, {
         type: ErrorTypes.OTHER_ERROR,
         details: ErrorDetails.KEY_SYSTEM_DESTROY_CLOSE_SESSION_ERROR,
         fatal: false,
         error: new Error(`Could not close session: ${error}`),
        });
      });
    }
   }
  }
  EMEController.CDMCleanupPromise = void 0;
  class EMEKeyError extends Error {
   constructor(data, message) {
    super(message);
    this.data = void 0;
    data.error || (data.error = new Error(message));
    this.data = data;
    data.err = data.error;
   }
  }

  class FPSController {
   constructor(hls) {
    this.hls = void 0;
    this.isVideoPlaybackQualityAvailable = false;
    this.timer = void 0;
    this.media = null;
    this.lastTime = void 0;
    this.lastDroppedFrames = 0;
    this.lastDecodedFrames = 0;
    // stream controller must be provided as a dependency!
    this.streamController = void 0;
    this.hls = hls;
    this.registerListeners();
   }
   setStreamController(streamController) {
    this.streamController = streamController;
   }
   registerListeners() {
    this.hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
    this.hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
   }
   unregisterListeners() {
    this.hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
    this.hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
   }
   destroy() {
    if (this.timer) {
     clearInterval(this.timer);
    }
    this.unregisterListeners();
    this.isVideoPlaybackQualityAvailable = false;
    this.media = null;
   }
   onMediaAttaching(event, data) {
    const config = this.hls.config;
    if (config.capLevelOnFPSDrop) {
     const media = data.media instanceof self.HTMLVideoElement ? data.media : null;
     this.media = media;
     if (media && typeof media.getVideoPlaybackQuality === 'function') {
      this.isVideoPlaybackQualityAvailable = true;
     }
     self.clearInterval(this.timer);
     this.timer = self.setInterval(this.checkFPSInterval.bind(this), config.fpsDroppedMonitoringPeriod);
    }
   }
   onMediaDetaching() {
    this.media = null;
   }
   checkFPS(video, decodedFrames, droppedFrames) {
    const currentTime = performance.now();
    if (decodedFrames) {
     if (this.lastTime) {
      const currentPeriod = currentTime - this.lastTime;
      const currentDropped = droppedFrames - this.lastDroppedFrames;
      const currentDecoded = decodedFrames - this.lastDecodedFrames;
      const droppedFPS = (1000 * currentDropped) / currentPeriod;
      const hls = this.hls;
      hls.trigger(Events.FPS_DROP, {
       currentDropped: currentDropped,
       currentDecoded: currentDecoded,
       totalDroppedFrames: droppedFrames,
      });
      if (droppedFPS > 0) {
       // hls.logger.log('checkFPS : droppedFPS/decodedFPS:' + droppedFPS/(1000 * currentDecoded / currentPeriod));
       if (currentDropped > hls.config.fpsDroppedMonitoringThreshold * currentDecoded) {
        let currentLevel = hls.currentLevel;
        hls.logger.warn('drop FPS ratio greater than max allowed value for currentLevel: ' + currentLevel);
        if (currentLevel > 0 && (hls.autoLevelCapping === -1 || hls.autoLevelCapping >= currentLevel)) {
         currentLevel = currentLevel - 1;
         hls.trigger(Events.FPS_DROP_LEVEL_CAPPING, {
          level: currentLevel,
          droppedLevel: hls.currentLevel,
         });
         hls.autoLevelCapping = currentLevel;
         this.streamController.nextLevelSwitch();
        }
       }
      }
     }
     this.lastTime = currentTime;
     this.lastDroppedFrames = droppedFrames;
     this.lastDecodedFrames = decodedFrames;
    }
   }
   checkFPSInterval() {
    const video = this.media;
    if (video) {
     if (this.isVideoPlaybackQualityAvailable) {
      const videoPlaybackQuality = video.getVideoPlaybackQuality();
      this.checkFPS(video, videoPlaybackQuality.totalVideoFrames, videoPlaybackQuality.droppedVideoFrames);
     } else {
      // HTMLVideoElement doesn't include the webkit types
      this.checkFPS(video, video.webkitDecodedFrameCount, video.webkitDroppedFrameCount);
     }
    }
   }
  }

  function sendAddTrackEvent(track, videoEl) {
   let event;
   try {
    event = new Event('addtrack');
   } catch (err) {
    // for IE11
    event = document.createEvent('Event');
    event.initEvent('addtrack', false, false);
   }
   event.track = track;
   videoEl.dispatchEvent(event);
  }
  function addCueToTrack(track, cue) {
   // Sometimes there are cue overlaps on segmented vtts so the same
   // cue can appear more than once in different vtt files.
   // This avoid showing duplicated cues with same timecode and text.
   const mode = track.mode;
   if (mode === 'disabled') {
    track.mode = 'hidden';
   }
   if (track.cues && !track.cues.getCueById(cue.id)) {
    try {
     track.addCue(cue);
     if (!track.cues.getCueById(cue.id)) {
      throw new Error(`addCue is failed for: ${cue}`);
     }
    } catch (err) {
     logger.debug(`[texttrack-utils]: ${err}`);
     try {
      const textTrackCue = new self.TextTrackCue(cue.startTime, cue.endTime, cue.text);
      textTrackCue.id = cue.id;
      track.addCue(textTrackCue);
     } catch (err2) {
      logger.debug(`[texttrack-utils]: Legacy TextTrackCue fallback failed: ${err2}`);
     }
    }
   }
   if (mode === 'disabled') {
    track.mode = mode;
   }
  }
  function clearCurrentCues(track, enterHandler) {
   // When track.mode is disabled, track.cues will be null.
   // To guarantee the removal of cues, we need to temporarily
   // change the mode to hidden
   const mode = track.mode;
   if (mode === 'disabled') {
    track.mode = 'hidden';
   }
   if (track.cues) {
    for (let i = track.cues.length; i--; ) {
     if (enterHandler) {
      track.cues[i].removeEventListener('enter', enterHandler);
     }
     track.removeCue(track.cues[i]);
    }
   }
   if (mode === 'disabled') {
    track.mode = mode;
   }
  }
  function removeCuesInRange(track, start, end, predicate) {
   const mode = track.mode;
   if (mode === 'disabled') {
    track.mode = 'hidden';
   }
   if (track.cues && track.cues.length > 0) {
    const cues = getCuesInRange(track.cues, start, end);
    for (let i = 0; i < cues.length; i++) {
     if (!predicate || predicate(cues[i])) {
      track.removeCue(cues[i]);
     }
    }
   }
   if (mode === 'disabled') {
    track.mode = mode;
   }
  }

  // Find first cue starting at or after given time.
  // Modified version of binary search O(log(n)).
  function getFirstCueIndexFromTime(cues, time) {
   // If first cue starts at or after time, start there
   if (time <= cues[0].startTime) {
    return 0;
   }
   // If the last cue ends before time there is no overlap
   const len = cues.length - 1;
   if (time > cues[len].endTime) {
    return -1;
   }
   let left = 0;
   let right = len;
   let mid;
   while (left <= right) {
    mid = Math.floor((right + left) / 2);
    if (time < cues[mid].startTime) {
     right = mid - 1;
    } else if (time > cues[mid].startTime && left < len) {
     left = mid + 1;
    } else {
     // If it's not lower or higher, it must be equal.
     return mid;
    }
   }
   // At this point, left and right have swapped.
   // No direct match was found, left or right element must be the closest. Check which one has the smallest diff.
   return cues[left].startTime - time < time - cues[right].startTime ? left : right;
  }
  function getCuesInRange(cues, start, end) {
   const cuesFound = [];
   const firstCueInRange = getFirstCueIndexFromTime(cues, start);
   if (firstCueInRange > -1) {
    for (let i = firstCueInRange, len = cues.length; i < len; i++) {
     const cue = cues[i];
     if (cue.startTime >= start && cue.endTime <= end) {
      cuesFound.push(cue);
     } else if (cue.startTime > end) {
      return cuesFound;
     }
    }
   }
   return cuesFound;
  }
  function filterSubtitleTracks(textTrackList) {
   const tracks = [];
   for (let i = 0; i < textTrackList.length; i++) {
    const track = textTrackList[i];
    // Edge adds a track without a label; we don't want to use it
    if ((track.kind === 'subtitles' || track.kind === 'captions') && track.label) {
     tracks.push(textTrackList[i]);
    }
   }
   return tracks;
  }

  class SubtitleTrackController extends BasePlaylistController {
   constructor(hls) {
    super(hls, 'subtitle-track-controller');
    this.media = null;
    this.tracks = [];
    this.groupIds = null;
    this.tracksInGroup = [];
    this.trackId = -1;
    this.currentTrack = null;
    this.selectDefaultTrack = true;
    this.queuedDefaultTrack = -1;
    this.useTextTrackPolling = false;
    this.subtitlePollingInterval = -1;
    this._subtitleDisplay = true;
    this.asyncPollTrackChange = () => this.pollTrackChange(0);
    this.onTextTracksChanged = () => {
     if (!this.useTextTrackPolling) {
      self.clearInterval(this.subtitlePollingInterval);
     }
     // Media is undefined when switching streams via loadSource()
     if (!this.media || !this.hls.config.renderTextTracksNatively) {
      return;
     }
     let textTrack = null;
     const tracks = filterSubtitleTracks(this.media.textTracks);
     for (let i = 0; i < tracks.length; i++) {
      if (tracks[i].mode === 'hidden') {
       // Do not break in case there is a following track with showing.
       textTrack = tracks[i];
      } else if (tracks[i].mode === 'showing') {
       textTrack = tracks[i];
       break;
      }
     }

     // Find internal track index for TextTrack
     const trackId = this.findTrackForTextTrack(textTrack);
     if (this.subtitleTrack !== trackId) {
      this.setSubtitleTrack(trackId);
     }
    };
    this.registerListeners();
   }
   destroy() {
    this.unregisterListeners();
    this.tracks.length = 0;
    this.tracksInGroup.length = 0;
    this.currentTrack = null;
    // @ts-ignore
    this.onTextTracksChanged = this.asyncPollTrackChange = null;
    super.destroy();
   }
   get subtitleDisplay() {
    return this._subtitleDisplay;
   }
   set subtitleDisplay(value) {
    this._subtitleDisplay = value;
    if (this.trackId > -1) {
     this.toggleTrackModes();
    }
   }
   registerListeners() {
    const { hls } = this;
    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);
    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
    hls.on(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
    hls.on(Events.ERROR, this.onError, this);
   }
   unregisterListeners() {
    const { hls } = this;
    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);
    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
    hls.off(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
    hls.off(Events.ERROR, this.onError, this);
   }

   // Listen for subtitle track change, then extract the current track ID.
   onMediaAttached(event, data) {
    this.media = data.media;
    if (!this.media) {
     return;
    }
    if (this.queuedDefaultTrack > -1) {
     this.subtitleTrack = this.queuedDefaultTrack;
     this.queuedDefaultTrack = -1;
    }
    this.useTextTrackPolling = !(this.media.textTracks && 'onchange' in this.media.textTracks);
    if (this.useTextTrackPolling) {
     this.pollTrackChange(500);
    } else {
     this.media.textTracks.addEventListener('change', this.asyncPollTrackChange);
    }
   }
   pollTrackChange(timeout) {
    self.clearInterval(this.subtitlePollingInterval);
    this.subtitlePollingInterval = self.setInterval(this.onTextTracksChanged, timeout);
   }
   onMediaDetaching(event, data) {
    const media = this.media;
    if (!media) {
     return;
    }
    const transferringMedia = !!data.transferMedia;
    self.clearInterval(this.subtitlePollingInterval);
    if (!this.useTextTrackPolling) {
     media.textTracks.removeEventListener('change', this.asyncPollTrackChange);
    }
    if (this.trackId > -1) {
     this.queuedDefaultTrack = this.trackId;
    }

    // Disable all subtitle tracks before detachment so when reattached only tracks in that content are enabled.
    this.subtitleTrack = -1;
    this.media = null;
    if (transferringMedia) {
     return;
    }
    const textTracks = filterSubtitleTracks(media.textTracks);
    // Clear loaded cues on media detachment from tracks
    textTracks.forEach((track) => {
     clearCurrentCues(track);
    });
   }
   onManifestLoading() {
    this.tracks = [];
    this.groupIds = null;
    this.tracksInGroup = [];
    this.trackId = -1;
    this.currentTrack = null;
    this.selectDefaultTrack = true;
   }

   // Fired whenever a new manifest is loaded.
   onManifestParsed(event, data) {
    this.tracks = data.subtitleTracks;
   }
   onSubtitleTrackLoaded(event, data) {
    const { id, groupId, details } = data;
    const trackInActiveGroup = this.tracksInGroup[id];
    if (!trackInActiveGroup || trackInActiveGroup.groupId !== groupId) {
     this.warn(`Subtitle track with id:${id} and group:${groupId} not found in active group ${trackInActiveGroup == null ? void 0 : trackInActiveGroup.groupId}`);
     return;
    }
    const curDetails = trackInActiveGroup.details;
    trackInActiveGroup.details = data.details;
    this.log(`Subtitle track ${id} "${trackInActiveGroup.name}" lang:${trackInActiveGroup.lang} group:${groupId} loaded [${details.startSN}-${details.endSN}]`);
    if (id === this.trackId) {
     this.playlistLoaded(id, data, curDetails);
    }
   }
   onLevelLoading(event, data) {
    this.switchLevel(data.level);
   }
   onLevelSwitching(event, data) {
    this.switchLevel(data.level);
   }
   switchLevel(levelIndex) {
    const levelInfo = this.hls.levels[levelIndex];
    if (!levelInfo) {
     return;
    }
    const subtitleGroups = levelInfo.subtitleGroups || null;
    const currentGroups = this.groupIds;
    let currentTrack = this.currentTrack;
    if (!subtitleGroups || (currentGroups == null ? void 0 : currentGroups.length) !== (subtitleGroups == null ? void 0 : subtitleGroups.length) || (subtitleGroups != null && subtitleGroups.some((groupId) => (currentGroups == null ? void 0 : currentGroups.indexOf(groupId)) === -1))) {
     this.groupIds = subtitleGroups;
     this.trackId = -1;
     this.currentTrack = null;
     const subtitleTracks = this.tracks.filter((track) => !subtitleGroups || subtitleGroups.indexOf(track.groupId) !== -1);
     if (subtitleTracks.length) {
      // Disable selectDefaultTrack if there are no default tracks
      if (this.selectDefaultTrack && !subtitleTracks.some((track) => track.default)) {
       this.selectDefaultTrack = false;
      }
      // track.id should match hls.audioTracks index
      subtitleTracks.forEach((track, i) => {
       track.id = i;
      });
     } else if (!currentTrack && !this.tracksInGroup.length) {
      // Do not dispatch SUBTITLE_TRACKS_UPDATED when there were and are no tracks
      return;
     }
     this.tracksInGroup = subtitleTracks;

     // Find preferred track
     const subtitlePreference = this.hls.config.subtitlePreference;
     if (!currentTrack && subtitlePreference) {
      this.selectDefaultTrack = false;
      const groupIndex = findMatchingOption(subtitlePreference, subtitleTracks);
      if (groupIndex > -1) {
       currentTrack = subtitleTracks[groupIndex];
      } else {
       const allIndex = findMatchingOption(subtitlePreference, this.tracks);
       currentTrack = this.tracks[allIndex];
      }
     }

     // Select initial track
     let trackId = this.findTrackId(currentTrack);
     if (trackId === -1 && currentTrack) {
      trackId = this.findTrackId(null);
     }

     // Dispatch events and load track if needed
     const subtitleTracksUpdated = {
      subtitleTracks,
     };
     this.log(`Updating subtitle tracks, ${subtitleTracks.length} track(s) found in "${subtitleGroups == null ? void 0 : subtitleGroups.join(',')}" group-id`);
     this.hls.trigger(Events.SUBTITLE_TRACKS_UPDATED, subtitleTracksUpdated);
     if (trackId !== -1 && this.trackId === -1) {
      this.setSubtitleTrack(trackId);
     }
    }
   }
   findTrackId(currentTrack) {
    const tracks = this.tracksInGroup;
    const selectDefault = this.selectDefaultTrack;
    for (let i = 0; i < tracks.length; i++) {
     const track = tracks[i];
     if ((selectDefault && !track.default) || (!selectDefault && !currentTrack)) {
      continue;
     }
     if (!currentTrack || matchesOption(track, currentTrack)) {
      return i;
     }
    }
    if (currentTrack) {
     for (let i = 0; i < tracks.length; i++) {
      const track = tracks[i];
      if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE', 'ASSOC-LANGUAGE', 'CHARACTERISTICS'])) {
       return i;
      }
     }
     for (let i = 0; i < tracks.length; i++) {
      const track = tracks[i];
      if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE'])) {
       return i;
      }
     }
    }
    return -1;
   }
   findTrackForTextTrack(textTrack) {
    if (textTrack) {
     const tracks = this.tracksInGroup;
     for (let i = 0; i < tracks.length; i++) {
      const track = tracks[i];
      if (subtitleTrackMatchesTextTrack(track, textTrack)) {
       return i;
      }
     }
    }
    return -1;
   }
   onError(event, data) {
    if (data.fatal || !data.context) {
     return;
    }
    if (data.context.type === PlaylistContextType.SUBTITLE_TRACK && data.context.id === this.trackId && (!this.groupIds || this.groupIds.indexOf(data.context.groupId) !== -1)) {
     this.checkRetry(data);
    }
   }
   get allSubtitleTracks() {
    return this.tracks;
   }

   /** get alternate subtitle tracks list from playlist **/
   get subtitleTracks() {
    return this.tracksInGroup;
   }

   /** get/set index of the selected subtitle track (based on index in subtitle track lists) **/
   get subtitleTrack() {
    return this.trackId;
   }
   set subtitleTrack(newId) {
    this.selectDefaultTrack = false;
    this.setSubtitleTrack(newId);
   }
   setSubtitleOption(subtitleOption) {
    this.hls.config.subtitlePreference = subtitleOption;
    if (subtitleOption) {
     if (subtitleOption.id === -1) {
      this.setSubtitleTrack(-1);
      return null;
     }
     const allSubtitleTracks = this.allSubtitleTracks;
     this.selectDefaultTrack = false;
     if (allSubtitleTracks.length) {
      // First see if current option matches (no switch op)
      const currentTrack = this.currentTrack;
      if (currentTrack && matchesOption(subtitleOption, currentTrack)) {
       return currentTrack;
      }
      // Find option in current group
      const groupIndex = findMatchingOption(subtitleOption, this.tracksInGroup);
      if (groupIndex > -1) {
       const track = this.tracksInGroup[groupIndex];
       this.setSubtitleTrack(groupIndex);
       return track;
      } else if (currentTrack) {
       // If this is not the initial selection return null
       // option should have matched one in active group
       return null;
      } else {
       // Find the option in all tracks for initial selection
       const allIndex = findMatchingOption(subtitleOption, allSubtitleTracks);
       if (allIndex > -1) {
        return allSubtitleTracks[allIndex];
       }
      }
     }
    }
    return null;
   }
   loadPlaylist(hlsUrlParameters) {
    super.loadPlaylist();
    if (this.shouldLoadPlaylist(this.currentTrack)) {
     this.scheduleLoading(this.currentTrack, hlsUrlParameters);
    }
   }
   loadingPlaylist(currentTrack, hlsUrlParameters) {
    super.loadingPlaylist(currentTrack, hlsUrlParameters);
    const id = currentTrack.id;
    const groupId = currentTrack.groupId;
    const url = this.getUrlWithDirectives(currentTrack.url, hlsUrlParameters);
    const details = currentTrack.details;
    const age = details == null ? void 0 : details.age;
    this.log(`Loading subtitle ${id} "${currentTrack.name}" lang:${currentTrack.lang} group:${groupId}${(hlsUrlParameters == null ? void 0 : hlsUrlParameters.msn) !== undefined ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : ''}${age && details.live ? ' age ' + age.toFixed(1) + (details.type ? ' ' + details.type || 0 : '') : ''} ${url}`);
    this.hls.trigger(Events.SUBTITLE_TRACK_LOADING, {
     url,
     id,
     groupId,
     deliveryDirectives: hlsUrlParameters || null,
     track: currentTrack,
    });
   }

   /**
    * Disables the old subtitleTrack and sets current mode on the next subtitleTrack.
    * This operates on the DOM textTracks.
    * A value of -1 will disable all subtitle tracks.
    */
   toggleTrackModes() {
    const { media } = this;
    if (!media) {
     return;
    }
    const textTracks = filterSubtitleTracks(media.textTracks);
    const currentTrack = this.currentTrack;
    let nextTrack;
    if (currentTrack) {
     nextTrack = textTracks.filter((textTrack) => subtitleTrackMatchesTextTrack(currentTrack, textTrack))[0];
     if (!nextTrack) {
      this.warn(`Unable to find subtitle TextTrack with name "${currentTrack.name}" and language "${currentTrack.lang}"`);
     }
    }
    [].slice.call(textTracks).forEach((track) => {
     if (track.mode !== 'disabled' && track !== nextTrack) {
      track.mode = 'disabled';
     }
    });
    if (nextTrack) {
     const mode = this.subtitleDisplay ? 'showing' : 'hidden';
     if (nextTrack.mode !== mode) {
      nextTrack.mode = mode;
     }
    }
   }

   /**
    * This method is responsible for validating the subtitle index and periodically reloading if live.
    * Dispatches the SUBTITLE_TRACK_SWITCH event, which instructs the subtitle-stream-controller to load the selected track.
    */
   setSubtitleTrack(newId) {
    const tracks = this.tracksInGroup;

    // setting this.subtitleTrack will trigger internal logic
    // if media has not been attached yet, it will fail
    // we keep a reference to the default track id
    // and we'll set subtitleTrack when onMediaAttached is triggered
    if (!this.media) {
     this.queuedDefaultTrack = newId;
     return;
    }

    // exit if track id as already set or invalid
    if (newId < -1 || newId >= tracks.length || !isFiniteNumber(newId)) {
     this.warn(`Invalid subtitle track id: ${newId}`);
     return;
    }
    this.selectDefaultTrack = false;
    const lastTrack = this.currentTrack;
    const track = tracks[newId] || null;
    this.trackId = newId;
    this.currentTrack = track;
    this.toggleTrackModes();
    if (!track) {
     // switch to -1
     this.hls.trigger(Events.SUBTITLE_TRACK_SWITCH, {
      id: newId,
     });
     return;
    }
    const trackLoaded = !!track.details && !track.details.live;
    if (newId === this.trackId && track === lastTrack && trackLoaded) {
     return;
    }
    this.log(`Switching to subtitle-track ${newId}` + (track ? ` "${track.name}" lang:${track.lang} group:${track.groupId}` : ''));
    const { id, groupId = '', name, type, url } = track;
    this.hls.trigger(Events.SUBTITLE_TRACK_SWITCH, {
     id,
     groupId,
     name,
     type,
     url,
    });
    const hlsUrlParameters = this.switchParams(track.url, lastTrack == null ? void 0 : lastTrack.details, track.details);
    this.loadPlaylist(hlsUrlParameters);
   }
  }

  /**
   * Generate a random v4 UUID
   *
   * @returns A random v4 UUID
   *
   * @group Utils
   *
   * @beta
   */
  function uuid() {
   try {
    return crypto.randomUUID();
   } catch (error) {
    try {
     const url = URL.createObjectURL(new Blob());
     const uuid = url.toString();
     URL.revokeObjectURL(url);
     return uuid.slice(uuid.lastIndexOf('/') + 1);
    } catch (error) {
     let dt = new Date().getTime();
     const uuid = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {
      const r = (dt + Math.random() * 16) % 16 | 0;
      dt = Math.floor(dt / 16);
      return (c == 'x' ? r : (r & 0x3) | 0x8).toString(16);
     });
     return uuid;
    }
   }
  }

  // From https://github.com/darkskyapp/string-hash
  function hash(text) {
   let hash = 5381;
   let i = text.length;
   while (i) {
    hash = (hash * 33) ^ text.charCodeAt(--i);
   }
   return (hash >>> 0).toString();
  }

  const ALIGNED_END_THRESHOLD_SECONDS = 0.025;
  let TimelineOccupancy = /*#__PURE__*/ (function (TimelineOccupancy) {
   TimelineOccupancy[(TimelineOccupancy['Point'] = 0)] = 'Point';
   TimelineOccupancy[(TimelineOccupancy['Range'] = 1)] = 'Range';
   return TimelineOccupancy;
  })({});
  function generateAssetIdentifier(interstitial, uri, assetListIndex) {
   return `${interstitial.identifier}-${assetListIndex + 1}-${hash(uri)}`;
  }
  class InterstitialEvent {
   constructor(dateRange, base) {
    this.base = void 0;
    this._duration = null;
    this._timelineStart = null;
    this.appendInPlaceDisabled = void 0;
    this.appendInPlaceStarted = void 0;
    this.dateRange = void 0;
    this.hasPlayed = false;
    this.cumulativeDuration = 0;
    this.resumeOffset = NaN;
    this.playoutLimit = NaN;
    this.restrictions = {
     skip: false,
     jump: false,
    };
    this.snapOptions = {
     out: false,
     in: false,
    };
    this.assetList = [];
    this.assetListLoader = void 0;
    this.assetListResponse = null;
    this.resumeAnchor = void 0;
    this.error = void 0;
    this.resetOnResume = void 0;
    this.base = base;
    this.dateRange = dateRange;
    this.setDateRange(dateRange);
   }
   setDateRange(dateRange) {
    this.dateRange = dateRange;
    this.resumeOffset = dateRange.attr.optionalFloat('X-RESUME-OFFSET', this.resumeOffset);
    this.playoutLimit = dateRange.attr.optionalFloat('X-PLAYOUT-LIMIT', this.playoutLimit);
    this.restrictions = dateRange.attr.enumeratedStringList('X-RESTRICT', this.restrictions);
    this.snapOptions = dateRange.attr.enumeratedStringList('X-SNAP', this.snapOptions);
   }
   reset() {
    var _this$assetListLoader;
    this.appendInPlaceStarted = false;
    (_this$assetListLoader = this.assetListLoader) == null || _this$assetListLoader.destroy();
    this.assetListLoader = undefined;
    if (!this.supplementsPrimary) {
     this.assetListResponse = null;
     this.assetList = [];
     this._duration = null;
    }
    // `error?` is reset when seeking back over interstitial `startOffset`
    //  using `schedule.resetErrorsInRange(start, end)`.
   }
   isAssetPastPlayoutLimit(assetIndex) {
    var _this$assetList$asset;
    if (assetIndex > 0 && assetIndex >= this.assetList.length) {
     return true;
    }
    const playoutLimit = this.playoutLimit;
    if (assetIndex <= 0 || isNaN(playoutLimit)) {
     return false;
    }
    if (playoutLimit === 0) {
     return true;
    }
    const assetOffset = ((_this$assetList$asset = this.assetList[assetIndex]) == null ? void 0 : _this$assetList$asset.startOffset) || 0;
    return assetOffset > playoutLimit;
   }
   findAssetIndex(asset) {
    const index = this.assetList.indexOf(asset);
    return index;
   }
   get identifier() {
    return this.dateRange.id;
   }
   get startDate() {
    return this.dateRange.startDate;
   }
   get startTime() {
    // Primary media timeline start time
    const startTime = this.dateRange.startTime;
    if (this.snapOptions.out) {
     const frag = this.dateRange.tagAnchor;
     if (frag) {
      return getSnapToFragmentTime(startTime, frag);
     }
    }
    return startTime;
   }
   get startOffset() {
    return this.cue.pre ? 0 : this.startTime;
   }
   get startIsAligned() {
    if (this.startTime === 0 || this.snapOptions.out) {
     return true;
    }
    const frag = this.dateRange.tagAnchor;
    if (frag) {
     const startTime = this.dateRange.startTime;
     const snappedStart = getSnapToFragmentTime(startTime, frag);
     return startTime - snappedStart < 0.1;
    }
    return false;
   }
   get resumptionOffset() {
    const resumeOffset = this.resumeOffset;
    const offset = isFiniteNumber(resumeOffset) ? resumeOffset : this.duration;
    return this.cumulativeDuration + offset;
   }
   get resumeTime() {
    // Primary media timeline resumption time
    const resumeTime = this.startOffset + this.resumptionOffset;
    if (this.snapOptions.in) {
     const frag = this.resumeAnchor;
     if (frag) {
      return getSnapToFragmentTime(resumeTime, frag);
     }
    }
    return resumeTime;
   }
   get appendInPlace() {
    if (this.appendInPlaceStarted) {
     return true;
    }
    if (this.appendInPlaceDisabled) {
     return false;
    }
    if (
     !this.cue.once &&
     !this.cue.pre &&
     // preroll starts at startPosition before startPosition is known (live)
     this.startIsAligned &&
     ((isNaN(this.playoutLimit) && isNaN(this.resumeOffset)) || (this.resumeOffset && this.duration && Math.abs(this.resumeOffset - this.duration) < ALIGNED_END_THRESHOLD_SECONDS))
    ) {
     return true;
    }
    return false;
   }
   set appendInPlace(value) {
    if (this.appendInPlaceStarted) {
     this.resetOnResume = !value;
     return;
    }
    this.appendInPlaceDisabled = !value;
   }

   // Extended timeline start time
   get timelineStart() {
    if (this._timelineStart !== null) {
     return this._timelineStart;
    }
    return this.startTime;
   }
   set timelineStart(value) {
    this._timelineStart = value;
   }
   get duration() {
    const playoutLimit = this.playoutLimit;
    let duration;
    if (this._duration !== null) {
     duration = this._duration;
    } else if (this.dateRange.duration) {
     duration = this.dateRange.duration;
    } else {
     duration = this.dateRange.plannedDuration || 0;
    }
    if (!isNaN(playoutLimit) && playoutLimit < duration) {
     duration = playoutLimit;
    }
    return duration;
   }
   set duration(value) {
    this._duration = value;
   }
   get cue() {
    return this.dateRange.cue;
   }
   get timelineOccupancy() {
    if (this.dateRange.attr['X-TIMELINE-OCCUPIES'] === 'RANGE') {
     return TimelineOccupancy.Range;
    }
    return TimelineOccupancy.Point;
   }
   get supplementsPrimary() {
    return this.dateRange.attr['X-TIMELINE-STYLE'] === 'PRIMARY';
   }
   get contentMayVary() {
    return this.dateRange.attr['X-CONTENT-MAY-VARY'] !== 'NO';
   }
   get assetUrl() {
    return this.dateRange.attr['X-ASSET-URI'];
   }
   get assetListUrl() {
    return this.dateRange.attr['X-ASSET-LIST'];
   }
   get baseUrl() {
    return this.base.url;
   }
   get assetListLoaded() {
    return this.assetList.length > 0 || this.assetListResponse !== null;
   }
   toString() {
    return eventToString(this);
   }
  }
  function getSnapToFragmentTime(time, frag) {
   return time - frag.start < frag.duration / 2 && !(Math.abs(time - (frag.start + frag.duration)) < ALIGNED_END_THRESHOLD_SECONDS) ? frag.start : frag.start + frag.duration;
  }
  function getInterstitialUrl(uri, sessionId, baseUrl) {
   const url = new self.URL(uri, baseUrl);
   if (url.protocol !== 'data:') {
    url.searchParams.set('_HLS_primary_id', sessionId);
   }
   return url;
  }
  function getNextAssetIndex(interstitial, assetListIndex) {
   while ((_interstitial$assetLi = interstitial.assetList[++assetListIndex]) != null && _interstitial$assetLi.error) {
    var _interstitial$assetLi;
   } /* no-op */
   return assetListIndex;
  }
  function eventToString(interstitial) {
   return `["${interstitial.identifier}" ${interstitial.cue.pre ? '<pre>' : interstitial.cue.post ? '<post>' : ''}${interstitial.timelineStart.toFixed(2)}-${interstitial.resumeTime.toFixed(2)}]`;
  }
  function eventAssetToString(asset) {
   const start = asset.timelineStart;
   const duration = asset.duration || 0;
   return `["${asset.identifier}" ${start.toFixed(2)}-${(start + duration).toFixed(2)}]`;
  }

  class HlsAssetPlayer {
   constructor(HlsPlayerClass, userConfig, interstitial, assetItem) {
    this.hls = void 0;
    this.interstitial = void 0;
    this.assetItem = void 0;
    this.tracks = null;
    this.hasDetails = false;
    this.mediaAttached = null;
    this._currentTime = void 0;
    this._bufferedEosTime = void 0;
    this.checkPlayout = () => {
     if (this.reachedPlayout(this.currentTime) && this.hls) {
      this.hls.trigger(Events.PLAYOUT_LIMIT_REACHED, {});
     }
    };
    const hls = (this.hls = new HlsPlayerClass(userConfig));
    this.interstitial = interstitial;
    this.assetItem = assetItem;
    const detailsLoaded = () => {
     this.hasDetails = true;
    };
    hls.once(Events.LEVEL_LOADED, detailsLoaded);
    hls.once(Events.AUDIO_TRACK_LOADED, detailsLoaded);
    hls.once(Events.SUBTITLE_TRACK_LOADED, detailsLoaded);
    hls.on(Events.MEDIA_ATTACHING, (name, { media }) => {
     this.removeMediaListeners();
     this.mediaAttached = media;
     const event = this.interstitial;
     if (event.playoutLimit) {
      media.addEventListener('timeupdate', this.checkPlayout);
      if (this.appendInPlace) {
       hls.on(Events.BUFFER_APPENDED, () => {
        const bufferedEnd = this.bufferedEnd;
        if (this.reachedPlayout(bufferedEnd)) {
         this._bufferedEosTime = bufferedEnd;
         hls.trigger(Events.BUFFERED_TO_END, undefined);
        }
       });
      }
     }
    });
   }
   get appendInPlace() {
    return this.interstitial.appendInPlace;
   }
   loadSource() {
    const hls = this.hls;
    if (!hls) {
     return;
    }
    if (!hls.url) {
     let uri = this.assetItem.uri;
     try {
      uri = getInterstitialUrl(uri, hls.config.primarySessionId || '').href;
     } catch (error) {
      // Ignore error parsing ASSET_URI or adding _HLS_primary_id to it. The
      // issue should surface as an INTERSTITIAL_ASSET_ERROR loading the asset.
     }
     hls.loadSource(uri);
    } else if (hls.levels.length && !hls.started) {
     hls.startLoad(-1, true);
    }
   }
   bufferedInPlaceToEnd(media) {
    var _this$hls;
    if (!this.appendInPlace) {
     return false;
    }
    if ((_this$hls = this.hls) != null && _this$hls.bufferedToEnd) {
     return true;
    }
    if (!media) {
     return false;
    }
    const duration = Math.min(this._bufferedEosTime || Infinity, this.duration);
    const start = this.timelineOffset;
    const bufferInfo = BufferHelper.bufferInfo(media, start, 0);
    const bufferedEnd = this.getAssetTime(bufferInfo.end);
    return bufferedEnd >= duration - 0.02;
   }
   reachedPlayout(time) {
    const interstitial = this.interstitial;
    const playoutLimit = interstitial.playoutLimit;
    return this.startOffset + time >= playoutLimit;
   }
   get destroyed() {
    var _this$hls2;
    return !((_this$hls2 = this.hls) != null && _this$hls2.userConfig);
   }
   get assetId() {
    return this.assetItem.identifier;
   }
   get interstitialId() {
    return this.assetItem.parentIdentifier;
   }
   get media() {
    var _this$hls3;
    return ((_this$hls3 = this.hls) == null ? void 0 : _this$hls3.media) || null;
   }
   get bufferedEnd() {
    const media = this.media || this.mediaAttached;
    if (!media) {
     if (this._bufferedEosTime) {
      return this._bufferedEosTime;
     }
     return this.currentTime;
    }
    const bufferInfo = BufferHelper.bufferInfo(media, media.currentTime, 0.001);
    return this.getAssetTime(bufferInfo.end);
   }
   get currentTime() {
    const media = this.media || this.mediaAttached;
    if (!media) {
     return this._currentTime || 0;
    }
    return this.getAssetTime(media.currentTime);
   }
   get duration() {
    const duration = this.assetItem.duration;
    if (!duration) {
     return 0;
    }
    const playoutLimit = this.interstitial.playoutLimit;
    if (playoutLimit) {
     const assetPlayout = playoutLimit - this.startOffset;
     if (assetPlayout > 0 && assetPlayout < duration) {
      return assetPlayout;
     }
    }
    return duration;
   }
   get remaining() {
    const duration = this.duration;
    if (!duration) {
     return 0;
    }
    return Math.max(0, duration - this.currentTime);
   }
   get startOffset() {
    return this.assetItem.startOffset;
   }
   get timelineOffset() {
    var _this$hls4;
    return ((_this$hls4 = this.hls) == null ? void 0 : _this$hls4.config.timelineOffset) || 0;
   }
   set timelineOffset(value) {
    const timelineOffset = this.timelineOffset;
    if (value !== timelineOffset) {
     const diff = value - timelineOffset;
     if (Math.abs(diff) > 1 / 90000 && this.hls) {
      if (this.hasDetails) {
       throw new Error(`Cannot set timelineOffset after playlists are loaded`);
      }
      this.hls.config.timelineOffset = value;
     }
    }
   }
   getAssetTime(time) {
    const timelineOffset = this.timelineOffset;
    const duration = this.duration;
    return Math.min(Math.max(0, time - timelineOffset), duration);
   }
   removeMediaListeners() {
    const media = this.mediaAttached;
    if (media) {
     this._currentTime = media.currentTime;
     this.bufferSnapShot();
     media.removeEventListener('timeupdate', this.checkPlayout);
    }
   }
   bufferSnapShot() {
    if (this.mediaAttached) {
     var _this$hls5;
     if ((_this$hls5 = this.hls) != null && _this$hls5.bufferedToEnd) {
      this._bufferedEosTime = this.bufferedEnd;
     }
    }
   }
   destroy() {
    this.removeMediaListeners();
    if (this.hls) {
     this.hls.destroy();
    }
    this.hls = null;
    // @ts-ignore
    this.tracks = this.mediaAttached = this.checkPlayout = null;
   }
   attachMedia(data) {
    var _this$hls6;
    this.loadSource();
    (_this$hls6 = this.hls) == null || _this$hls6.attachMedia(data);
   }
   detachMedia() {
    var _this$hls7;
    this.removeMediaListeners();
    this.mediaAttached = null;
    (_this$hls7 = this.hls) == null || _this$hls7.detachMedia();
   }
   resumeBuffering() {
    var _this$hls8;
    (_this$hls8 = this.hls) == null || _this$hls8.resumeBuffering();
   }
   pauseBuffering() {
    var _this$hls9;
    (_this$hls9 = this.hls) == null || _this$hls9.pauseBuffering();
   }
   transferMedia() {
    var _this$hls0;
    this.bufferSnapShot();
    return ((_this$hls0 = this.hls) == null ? void 0 : _this$hls0.transferMedia()) || null;
   }
   resetDetails() {
    const hls = this.hls;
    if (hls && this.hasDetails) {
     hls.stopLoad();
     const deleteDetails = (obj) => delete obj.details;
     hls.levels.forEach(deleteDetails);
     hls.allAudioTracks.forEach(deleteDetails);
     hls.allSubtitleTracks.forEach(deleteDetails);
     this.hasDetails = false;
    }
   }
   on(event, listener, context) {
    var _this$hls1;
    (_this$hls1 = this.hls) == null || _this$hls1.on(event, listener);
   }
   once(event, listener, context) {
    var _this$hls10;
    (_this$hls10 = this.hls) == null || _this$hls10.once(event, listener);
   }
   off(event, listener, context) {
    var _this$hls11;
    (_this$hls11 = this.hls) == null || _this$hls11.off(event, listener);
   }
   toString() {
    var _this$hls12;
    return `HlsAssetPlayer: ${eventAssetToString(this.assetItem)} ${(_this$hls12 = this.hls) == null ? void 0 : _this$hls12.sessionId} ${this.appendInPlace ? 'append-in-place' : ''}`;
   }
  }

  const ABUTTING_THRESHOLD_SECONDS = 0.033;
  class InterstitialsSchedule extends Logger {
   constructor(onScheduleUpdate, logger) {
    super('interstitials-sched', logger);
    this.onScheduleUpdate = void 0;
    this.eventMap = {};
    this.events = null;
    this.items = null;
    this.durations = {
     primary: 0,
     playout: 0,
     integrated: 0,
    };
    this.onScheduleUpdate = onScheduleUpdate;
   }
   destroy() {
    this.reset();
    // @ts-ignore
    this.onScheduleUpdate = null;
   }
   reset() {
    this.eventMap = {};
    this.setDurations(0, 0, 0);
    if (this.events) {
     this.events.forEach((interstitial) => interstitial.reset());
    }
    this.events = this.items = null;
   }
   resetErrorsInRange(start, end) {
    if (this.events) {
     return this.events.reduce((count, interstitial) => {
      if (start <= interstitial.startOffset && end > interstitial.startOffset) {
       delete interstitial.error;
       return count + 1;
      }
      return count;
     }, 0);
    }
    return 0;
   }
   get duration() {
    const items = this.items;
    return items ? items[items.length - 1].end : 0;
   }
   get length() {
    return this.items ? this.items.length : 0;
   }
   getEvent(identifier) {
    return identifier ? this.eventMap[identifier] || null : null;
   }
   hasEvent(identifier) {
    return identifier in this.eventMap;
   }
   findItemIndex(item, time) {
    if (item.event) {
     // Find Event Item
     return this.findEventIndex(item.event.identifier);
    }
    // Find Primary Item
    let index = -1;
    if (item.nextEvent) {
     index = this.findEventIndex(item.nextEvent.identifier) - 1;
    } else if (item.previousEvent) {
     index = this.findEventIndex(item.previousEvent.identifier) + 1;
    }
    const items = this.items;
    if (items) {
     if (!items[index]) {
      if (time === undefined) {
       time = item.start;
      }
      index = this.findItemIndexAtTime(time);
     }
     // Only return index of a Primary Item
     while (index >= 0 && (_items$index = items[index]) != null && _items$index.event) {
      var _items$index;
      // If index found is an interstitial it is not a valid result as it should have been matched up top
      // decrement until result is negative (not found) or a primary segment
      index--;
     }
    }
    return index;
   }
   findItemIndexAtTime(timelinePos, timelineType) {
    const items = this.items;
    if (items) {
     for (let i = 0; i < items.length; i++) {
      let timeRange = items[i];
      if (timelineType && timelineType !== 'primary') {
       timeRange = timeRange[timelineType];
      }
      if (timelinePos === timeRange.start || (timelinePos > timeRange.start && timelinePos < timeRange.end)) {
       return i;
      }
     }
    }
    return -1;
   }
   findJumpRestrictedIndex(startIndex, endIndex) {
    const items = this.items;
    if (items) {
     for (let i = startIndex; i <= endIndex; i++) {
      if (!items[i]) {
       break;
      }
      const event = items[i].event;
      if (event != null && event.restrictions.jump && !event.appendInPlace) {
       return i;
      }
     }
    }
    return -1;
   }
   findEventIndex(identifier) {
    const items = this.items;
    if (items) {
     for (let i = items.length; i--; ) {
      var _items$i$event;
      if (((_items$i$event = items[i].event) == null ? void 0 : _items$i$event.identifier) === identifier) {
       return i;
      }
     }
    }
    return -1;
   }
   findAssetIndex(event, timelinePos) {
    const assetList = event.assetList;
    const length = assetList.length;
    if (length > 1) {
     for (let i = 0; i < length; i++) {
      const asset = assetList[i];
      if (!asset.error) {
       const timelineStart = asset.timelineStart;
       if (timelinePos === timelineStart || (timelinePos > timelineStart && (timelinePos < timelineStart + (asset.duration || 0) || i === length - 1))) {
        return i;
       }
      }
     }
    }
    return 0;
   }
   get assetIdAtEnd() {
    var _this$items;
    const interstitialAtEnd = (_this$items = this.items) == null || (_this$items = _this$items[this.length - 1]) == null ? void 0 : _this$items.event;
    if (interstitialAtEnd) {
     const assetList = interstitialAtEnd.assetList;
     const assetAtEnd = assetList[assetList.length - 1];
     if (assetAtEnd) {
      return assetAtEnd.identifier;
     }
    }
    return null;
   }
   parseInterstitialDateRanges(mediaSelection, enableAppendInPlace) {
    const details = mediaSelection.main.details;
    const { dateRanges } = details;
    const previousInterstitialEvents = this.events;
    const interstitialEvents = this.parseDateRanges(
     dateRanges,
     {
      url: details.url,
     },
     enableAppendInPlace,
    );
    const ids = Object.keys(dateRanges);
    const removedInterstitials = previousInterstitialEvents ? previousInterstitialEvents.filter((event) => !ids.includes(event.identifier)) : [];
    if (interstitialEvents.length) {
     // pre-rolls, post-rolls, and events with the same start time are played in playlist tag order
     // all other events are ordered by start time
     interstitialEvents.sort((a, b) => {
      const aPre = a.cue.pre;
      const aPost = a.cue.post;
      const bPre = b.cue.pre;
      const bPost = b.cue.post;
      if (aPre && !bPre) {
       return -1;
      }
      if (bPre && !aPre) {
       return 1;
      }
      if (aPost && !bPost) {
       return 1;
      }
      if (bPost && !aPost) {
       return -1;
      }
      if (!aPre && !bPre && !aPost && !bPost) {
       const startA = a.startTime;
       const startB = b.startTime;
       if (startA !== startB) {
        return startA - startB;
       }
      }
      return a.dateRange.tagOrder - b.dateRange.tagOrder;
     });
    }
    this.events = interstitialEvents;

    // Clear removed DateRanges from buffered list (kills playback of active Interstitials)
    removedInterstitials.forEach((interstitial) => {
     this.removeEvent(interstitial);
    });
    this.updateSchedule(mediaSelection, removedInterstitials);
   }
   updateSchedule(mediaSelection, removedInterstitials = [], forceUpdate = false) {
    const events = this.events || [];
    if (events.length || removedInterstitials.length || this.length < 2) {
     const currentItems = this.items;
     const updatedItems = this.parseSchedule(events, mediaSelection);
     const updated =
      forceUpdate ||
      removedInterstitials.length ||
      (currentItems == null ? void 0 : currentItems.length) !== updatedItems.length ||
      updatedItems.some((item, i) => {
       return Math.abs(item.playout.start - currentItems[i].playout.start) > 0.005 || Math.abs(item.playout.end - currentItems[i].playout.end) > 0.005;
      });
     if (updated) {
      this.items = updatedItems;
      // call interstitials-controller onScheduleUpdated()
      this.onScheduleUpdate(removedInterstitials, currentItems);
     }
    }
   }
   parseDateRanges(dateRanges, baseData, enableAppendInPlace) {
    const interstitialEvents = [];
    const ids = Object.keys(dateRanges);
    for (let i = 0; i < ids.length; i++) {
     const id = ids[i];
     const dateRange = dateRanges[id];
     if (dateRange.isInterstitial) {
      let interstitial = this.eventMap[id];
      if (interstitial) {
       // Update InterstitialEvent already parsed and mapped
       // This retains already loaded duration and loaded asset list info
       interstitial.setDateRange(dateRange);
      } else {
       interstitial = new InterstitialEvent(dateRange, baseData);
       this.eventMap[id] = interstitial;
       if (enableAppendInPlace === false) {
        interstitial.appendInPlace = enableAppendInPlace;
       }
      }
      interstitialEvents.push(interstitial);
     }
    }
    return interstitialEvents;
   }
   parseSchedule(interstitialEvents, mediaSelection) {
    const schedule = [];
    const details = mediaSelection.main.details;
    const primaryDuration = details.live ? Infinity : details.edge;
    let playoutDuration = 0;

    // Filter events that have errored from the schedule (Primary fallback)
    interstitialEvents = interstitialEvents.filter((event) => !event.error && !(event.cue.once && event.hasPlayed));
    if (interstitialEvents.length) {
     // Update Schedule
     this.resolveOffsets(interstitialEvents, mediaSelection);

     // Populate Schedule with Interstitial Event and Primary Segment Items
     let primaryPosition = 0;
     let integratedTime = 0;
     interstitialEvents.forEach((interstitial, i) => {
      const preroll = interstitial.cue.pre;
      const postroll = interstitial.cue.post;
      const previousEvent = interstitialEvents[i - 1] || null;
      const appendInPlace = interstitial.appendInPlace;
      const eventStart = postroll ? primaryDuration : interstitial.startOffset;
      const interstitialDuration = interstitial.duration;
      const timelineDuration = interstitial.timelineOccupancy === TimelineOccupancy.Range ? interstitialDuration : 0;
      const resumptionOffset = interstitial.resumptionOffset;
      const inSameStartTimeSequence = (previousEvent == null ? void 0 : previousEvent.startTime) === eventStart;
      const start = eventStart + interstitial.cumulativeDuration;
      let end = appendInPlace ? start + interstitialDuration : eventStart + resumptionOffset;
      if (preroll || (!postroll && eventStart <= 0)) {
       // preroll or in-progress midroll
       const integratedStart = integratedTime;
       integratedTime += timelineDuration;
       interstitial.timelineStart = start;
       const playoutStart = playoutDuration;
       playoutDuration += interstitialDuration;
       schedule.push({
        event: interstitial,
        start,
        end,
        playout: {
         start: playoutStart,
         end: playoutDuration,
        },
        integrated: {
         start: integratedStart,
         end: integratedTime,
        },
       });
      } else if (eventStart <= primaryDuration) {
       if (!inSameStartTimeSequence) {
        const segmentDuration = eventStart - primaryPosition;
        // Do not schedule a primary segment if interstitials are abutting by less than ABUTTING_THRESHOLD_SECONDS
        if (segmentDuration > ABUTTING_THRESHOLD_SECONDS) {
         // primary segment
         const timelineStart = primaryPosition;
         const _integratedStart = integratedTime;
         integratedTime += segmentDuration;
         const _playoutStart = playoutDuration;
         playoutDuration += segmentDuration;
         const primarySegment = {
          previousEvent: interstitialEvents[i - 1] || null,
          nextEvent: interstitial,
          start: timelineStart,
          end: timelineStart + segmentDuration,
          playout: {
           start: _playoutStart,
           end: playoutDuration,
          },
          integrated: {
           start: _integratedStart,
           end: integratedTime,
          },
         };
         schedule.push(primarySegment);
        } else if (segmentDuration > 0 && previousEvent) {
         // Add previous event `resumeTime` (based on duration or resumeOffset) so that it ends aligned with this one
         previousEvent.cumulativeDuration += segmentDuration;
         schedule[schedule.length - 1].end = eventStart;
        }
       }
       // midroll / postroll
       if (postroll) {
        end = start;
       }
       interstitial.timelineStart = start;
       const integratedStart = integratedTime;
       integratedTime += timelineDuration;
       const playoutStart = playoutDuration;
       playoutDuration += interstitialDuration;
       schedule.push({
        event: interstitial,
        start,
        end,
        playout: {
         start: playoutStart,
         end: playoutDuration,
        },
        integrated: {
         start: integratedStart,
         end: integratedTime,
        },
       });
      } else {
       // Interstitial starts after end of primary VOD - not included in schedule
       return;
      }
      const resumeTime = interstitial.resumeTime;
      if (postroll || resumeTime > primaryDuration) {
       primaryPosition = primaryDuration;
      } else {
       primaryPosition = resumeTime;
      }
     });
     if (primaryPosition < primaryDuration) {
      var _schedule;
      // last primary segment
      const timelineStart = primaryPosition;
      const integratedStart = integratedTime;
      const segmentDuration = primaryDuration - primaryPosition;
      integratedTime += segmentDuration;
      const playoutStart = playoutDuration;
      playoutDuration += segmentDuration;
      schedule.push({
       previousEvent: ((_schedule = schedule[schedule.length - 1]) == null ? void 0 : _schedule.event) || null,
       nextEvent: null,
       start: primaryPosition,
       end: timelineStart + segmentDuration,
       playout: {
        start: playoutStart,
        end: playoutDuration,
       },
       integrated: {
        start: integratedStart,
        end: integratedTime,
       },
      });
     }
     this.setDurations(primaryDuration, playoutDuration, integratedTime);
    } else {
     // no interstials - schedule is one primary segment
     const start = 0;
     schedule.push({
      previousEvent: null,
      nextEvent: null,
      start,
      end: primaryDuration,
      playout: {
       start,
       end: primaryDuration,
      },
      integrated: {
       start,
       end: primaryDuration,
      },
     });
     this.setDurations(primaryDuration, primaryDuration, primaryDuration);
    }
    return schedule;
   }
   setDurations(primary, playout, integrated) {
    this.durations = {
     primary,
     playout,
     integrated,
    };
   }
   resolveOffsets(interstitialEvents, mediaSelection) {
    const details = mediaSelection.main.details;
    const primaryDuration = details.live ? Infinity : details.edge;

    // First resolve cumulative resumption offsets for Interstitials that start at the same DateTime
    let cumulativeDuration = 0;
    let lastScheduledStart = -1;
    interstitialEvents.forEach((interstitial, i) => {
     const preroll = interstitial.cue.pre;
     const postroll = interstitial.cue.post;
     const eventStart = preroll ? 0 : postroll ? primaryDuration : interstitial.startTime;
     this.updateAssetDurations(interstitial);

     // X-RESUME-OFFSET values of interstitials scheduled at the same time are cumulative
     const inSameStartTimeSequence = lastScheduledStart === eventStart;
     if (inSameStartTimeSequence) {
      interstitial.cumulativeDuration = cumulativeDuration;
     } else {
      cumulativeDuration = 0;
      lastScheduledStart = eventStart;
     }
     if (!postroll && interstitial.snapOptions.in) {
      // FIXME: Include audio playlist in snapping
      interstitial.resumeAnchor = findFragmentByPTS(null, details.fragments, interstitial.startOffset + interstitial.resumptionOffset, 0, 0) || undefined;
     }
     // Check if primary fragments align with resumption offset and disable appendInPlace if they do not
     if (interstitial.appendInPlace && !interstitial.appendInPlaceStarted) {
      const alignedSegmentStart = this.primaryCanResumeInPlaceAt(interstitial, mediaSelection);
      if (!alignedSegmentStart) {
       interstitial.appendInPlace = false;
      }
     }
     if (!interstitial.appendInPlace && i + 1 < interstitialEvents.length) {
      // abutting Interstitials must use the same MediaSource strategy, this applies to all whether or not they are back to back:
      const timeBetween = interstitialEvents[i + 1].startTime - interstitialEvents[i].resumeTime;
      if (timeBetween < ABUTTING_THRESHOLD_SECONDS) {
       interstitialEvents[i + 1].appendInPlace = false;
       if (interstitialEvents[i + 1].appendInPlace) {
        this.warn(`Could not change append strategy for abutting event ${interstitial}`);
       }
      }
     }
     // Update cumulativeDuration for next abutting interstitial with the same start date
     const resumeOffset = isFiniteNumber(interstitial.resumeOffset) ? interstitial.resumeOffset : interstitial.duration;
     cumulativeDuration += resumeOffset;
    });
   }
   primaryCanResumeInPlaceAt(interstitial, mediaSelection) {
    const resumeTime = interstitial.resumeTime;
    const resumesInPlaceAt = interstitial.startTime + interstitial.resumptionOffset;
    if (Math.abs(resumeTime - resumesInPlaceAt) > ALIGNED_END_THRESHOLD_SECONDS) {
     this.log(`"${interstitial.identifier}" resumption ${resumeTime} not aligned with estimated timeline end ${resumesInPlaceAt}`);
     return false;
    }
    const playlists = Object.keys(mediaSelection);
    return !playlists.some((playlistType) => {
     const details = mediaSelection[playlistType].details;
     const playlistEnd = details.edge;
     if (resumeTime >= playlistEnd) {
      // Live playback - resumption segments are not yet available
      this.log(`"${interstitial.identifier}" resumption ${resumeTime} past ${playlistType} playlist end ${playlistEnd}`);
      // Assume alignment is possible (or reset can take place)
      return false;
     }
     const startFragment = findFragmentByPTS(null, details.fragments, resumeTime);
     if (!startFragment) {
      this.log(`"${interstitial.identifier}" resumption ${resumeTime} does not align with any fragments in ${playlistType} playlist (${details.fragStart}-${details.fragmentEnd})`);
      return true;
     }
     const allowance = playlistType === 'audio' ? 0.175 : 0;
     const alignedWithSegment = Math.abs(startFragment.start - resumeTime) < ALIGNED_END_THRESHOLD_SECONDS + allowance || Math.abs(startFragment.end - resumeTime) < ALIGNED_END_THRESHOLD_SECONDS + allowance;
     if (!alignedWithSegment) {
      this.log(`"${interstitial.identifier}" resumption ${resumeTime} not aligned with ${playlistType} fragment bounds (${startFragment.start}-${startFragment.end} sn: ${startFragment.sn} cc: ${startFragment.cc})`);
      return true;
     }
     return false;
    });
   }
   updateAssetDurations(interstitial) {
    if (!interstitial.assetListLoaded) {
     return;
    }
    const eventStart = interstitial.timelineStart;
    let sumDuration = 0;
    let hasUnknownDuration = false;
    let hasErrors = false;
    for (let i = 0; i < interstitial.assetList.length; i++) {
     const asset = interstitial.assetList[i];
     const timelineStart = eventStart + sumDuration;
     asset.startOffset = sumDuration;
     asset.timelineStart = timelineStart;
     hasUnknownDuration || (hasUnknownDuration = asset.duration === null);
     hasErrors || (hasErrors = !!asset.error);
     const duration = asset.error ? 0 : asset.duration || 0;
     sumDuration += duration;
    }
    // Use the sum of known durations when it is greater than the stated duration
    if (hasUnknownDuration && !hasErrors) {
     interstitial.duration = Math.max(sumDuration, interstitial.duration);
    } else {
     interstitial.duration = sumDuration;
    }
   }
   removeEvent(interstitial) {
    interstitial.reset();
    delete this.eventMap[interstitial.identifier];
   }
  }
  function segmentToString(segment) {
   return `[${segment.event ? '"' + segment.event.identifier + '"' : 'primary'}: ${segment.start.toFixed(2)}-${segment.end.toFixed(2)}]`;
  }

  class AssetListLoader {
   constructor(hls) {
    this.hls = void 0;
    this.hls = hls;
   }
   destroy() {
    // @ts-ignore
    this.hls = null;
   }
   loadAssetList(interstitial, hlsStartOffset) {
    const assetListUrl = interstitial.assetListUrl;
    let url;
    try {
     url = getInterstitialUrl(assetListUrl, this.hls.sessionId, interstitial.baseUrl);
    } catch (error) {
     const errorData = this.assignAssetListError(interstitial, ErrorDetails.ASSET_LIST_LOAD_ERROR, error, assetListUrl);
     this.hls.trigger(Events.ERROR, errorData);
     return;
    }
    if (hlsStartOffset && url.protocol !== 'data:') {
     url.searchParams.set('_HLS_start_offset', '' + hlsStartOffset);
    }
    const config = this.hls.config;
    const Loader = config.loader;
    const loader = new Loader(config);
    const context = {
     responseType: 'json',
     url: url.href,
    };
    const loadPolicy = config.interstitialAssetListLoadPolicy.default;
    const loaderConfig = {
     loadPolicy,
     timeout: loadPolicy.maxLoadTimeMs,
     maxRetry: 0,
     retryDelay: 0,
     maxRetryDelay: 0,
    };
    const callbacks = {
     onSuccess: (response, stats, context, networkDetails) => {
      const assetListResponse = response.data;
      const assets = assetListResponse == null ? void 0 : assetListResponse.ASSETS;
      if (!Array.isArray(assets)) {
       const errorData = this.assignAssetListError(interstitial, ErrorDetails.ASSET_LIST_PARSING_ERROR, new Error(`Invalid interstitial asset list`), context.url, stats, networkDetails);
       this.hls.trigger(Events.ERROR, errorData);
       return;
      }
      interstitial.assetListResponse = assetListResponse;
      this.hls.trigger(Events.ASSET_LIST_LOADED, {
       event: interstitial,
       assetListResponse,
       networkDetails,
      });
     },
     onError: (error, context, networkDetails, stats) => {
      const errorData = this.assignAssetListError(interstitial, ErrorDetails.ASSET_LIST_LOAD_ERROR, new Error(`Error loading X-ASSET-LIST: HTTP status ${error.code} ${error.text} (${context.url})`), context.url, stats, networkDetails);
      this.hls.trigger(Events.ERROR, errorData);
     },
     onTimeout: (stats, context, networkDetails) => {
      const errorData = this.assignAssetListError(interstitial, ErrorDetails.ASSET_LIST_LOAD_TIMEOUT, new Error(`Timeout loading X-ASSET-LIST (${context.url})`), context.url, stats, networkDetails);
      this.hls.trigger(Events.ERROR, errorData);
     },
    };
    loader.load(context, loaderConfig, callbacks);
    this.hls.trigger(Events.ASSET_LIST_LOADING, {
     event: interstitial,
    });
    return loader;
   }
   assignAssetListError(interstitial, details, error, url, stats, networkDetails) {
    interstitial.error = error;
    return {
     type: ErrorTypes.NETWORK_ERROR,
     details,
     fatal: false,
     interstitial,
     url,
     error,
     networkDetails,
     stats,
    };
   }
  }

  function playWithCatch(media) {
   media == null ||
    media.play().catch(() => {
     /* no-op */
    });
  }
  class InterstitialsController extends Logger {
   constructor(hls, HlsPlayerClass) {
    super('interstitials', hls.logger);
    this.HlsPlayerClass = void 0;
    this.hls = void 0;
    this.assetListLoader = void 0;
    // Last updated LevelDetails
    this.mediaSelection = null;
    this.altSelection = null;
    // Media and MediaSource/SourceBuffers
    this.media = null;
    this.detachedData = null;
    this.requiredTracks = null;
    // Public Interface for Interstitial playback state and control
    this.manager = null;
    // Interstitial Asset Players
    this.playerQueue = [];
    // Timeline position tracking
    this.bufferedPos = -1;
    this.timelinePos = -1;
    // Schedule
    this.schedule = void 0;
    // Schedule playback and buffering state
    this.playingItem = null;
    this.bufferingItem = null;
    this.waitingItem = null;
    this.endedItem = null;
    this.playingAsset = null;
    this.endedAsset = null;
    this.bufferingAsset = null;
    this.shouldPlay = false;
    this.onPlay = () => {
     this.shouldPlay = true;
    };
    this.onPause = () => {
     this.shouldPlay = false;
    };
    this.onSeeking = () => {
     const currentTime = this.currentTime;
     if (currentTime === undefined || this.playbackDisabled || !this.schedule) {
      return;
     }
     const diff = currentTime - this.timelinePos;
     const roundingError = Math.abs(diff) < 1 / 705600000; // one flick
     if (roundingError) {
      return;
     }
     const backwardSeek = diff <= -0.01;
     this.timelinePos = currentTime;
     this.bufferedPos = currentTime;

     // Check if seeking out of an item
     const playingItem = this.playingItem;
     if (!playingItem) {
      this.checkBuffer();
      return;
     }
     if (backwardSeek) {
      const resetCount = this.schedule.resetErrorsInRange(currentTime, currentTime - diff);
      if (resetCount) {
       this.updateSchedule(true);
      }
     }
     this.checkBuffer();
     if ((backwardSeek && currentTime < playingItem.start) || currentTime >= playingItem.end) {
      var _this$media;
      const playingIndex = this.findItemIndex(playingItem);
      let scheduleIndex = this.schedule.findItemIndexAtTime(currentTime);
      if (scheduleIndex === -1) {
       scheduleIndex = playingIndex + (backwardSeek ? -1 : 1);
       this.log(`seeked ${backwardSeek ? 'back ' : ''}to position not covered by schedule ${currentTime} (resolving from ${playingIndex} to ${scheduleIndex})`);
      }
      if (!this.isInterstitial(playingItem) && (_this$media = this.media) != null && _this$media.paused) {
       this.shouldPlay = false;
      }
      if (!backwardSeek) {
       // check if an Interstitial between the current item and target item has an X-RESTRICT JUMP restriction
       if (scheduleIndex > playingIndex) {
        const jumpIndex = this.schedule.findJumpRestrictedIndex(playingIndex + 1, scheduleIndex);
        if (jumpIndex > playingIndex) {
         this.setSchedulePosition(jumpIndex);
         return;
        }
       }
      }
      this.setSchedulePosition(scheduleIndex);
      return;
     }
     // Check if seeking out of an asset (assumes same item following above check)
     const playingAsset = this.playingAsset;
     if (!playingAsset) {
      // restart Interstitial at end
      if (this.playingLastItem && this.isInterstitial(playingItem)) {
       const restartAsset = playingItem.event.assetList[0];
       // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
       if (restartAsset) {
        this.endedItem = this.playingItem;
        this.playingItem = null;
        this.setScheduleToAssetAtTime(currentTime, restartAsset);
       }
      }
      return;
     }
     const start = playingAsset.timelineStart;
     const duration = playingAsset.duration || 0;
     if ((backwardSeek && currentTime < start) || currentTime >= start + duration) {
      var _playingItem$event;
      if ((_playingItem$event = playingItem.event) != null && _playingItem$event.appendInPlace) {
       this.clearInterstitial(playingItem.event, playingItem);
       this.flushFrontBuffer(currentTime);
      }
      this.setScheduleToAssetAtTime(currentTime, playingAsset);
     }
    };
    this.onTimeupdate = () => {
     const currentTime = this.currentTime;
     if (currentTime === undefined || this.playbackDisabled) {
      return;
     }

     // Only allow timeupdate to advance primary position, seeking is used for jumping back
     // this prevents primaryPos from being reset to 0 after re-attach
     if (currentTime > this.timelinePos) {
      this.timelinePos = currentTime;
      if (currentTime > this.bufferedPos) {
       this.checkBuffer();
      }
     } else {
      return;
     }

     // Check if playback has entered the next item
     const playingItem = this.playingItem;
     if (!playingItem || this.playingLastItem) {
      return;
     }
     if (currentTime >= playingItem.end) {
      this.timelinePos = playingItem.end;
      const playingIndex = this.findItemIndex(playingItem);
      this.setSchedulePosition(playingIndex + 1);
     }
     // Check if playback has entered the next asset
     const playingAsset = this.playingAsset;
     if (!playingAsset) {
      return;
     }
     const end = playingAsset.timelineStart + (playingAsset.duration || 0);
     if (currentTime >= end) {
      this.setScheduleToAssetAtTime(currentTime, playingAsset);
     }
    };
    // Schedule update callback
    this.onScheduleUpdate = (removedInterstitials, previousItems) => {
     const schedule = this.schedule;
     if (!schedule) {
      return;
     }
     const playingItem = this.playingItem;
     const interstitialEvents = schedule.events || [];
     const scheduleItems = schedule.items || [];
     const durations = schedule.durations;
     const removedIds = removedInterstitials.map((interstitial) => interstitial.identifier);
     const interstitialsUpdated = !!(interstitialEvents.length || removedIds.length);
     if (interstitialsUpdated || previousItems) {
      this.log(`INTERSTITIALS_UPDATED (${interstitialEvents.length}): ${interstitialEvents}
Schedule: ${scheduleItems.map((seg) => segmentToString(seg))} pos: ${this.timelinePos}`);
     }
     if (removedIds.length) {
      this.log(`Removed events ${removedIds}`);
     }

     // Update schedule item references
     // Do not replace Interstitial playingItem without a match - used for INTERSTITIAL_ASSET_ENDED and INTERSTITIAL_ENDED
     let updatedPlayingItem = null;
     let updatedBufferingItem = null;
     if (playingItem) {
      updatedPlayingItem = this.updateItem(playingItem, this.timelinePos);
      if (this.itemsMatch(playingItem, updatedPlayingItem)) {
       this.playingItem = updatedPlayingItem;
      } else {
       this.waitingItem = this.endedItem = null;
      }
     }
     // Clear waitingItem if it has been removed from the schedule
     this.waitingItem = this.updateItem(this.waitingItem);
     this.endedItem = this.updateItem(this.endedItem);
     // Do not replace Interstitial bufferingItem without a match - used for transfering media element or source
     const bufferingItem = this.bufferingItem;
     if (bufferingItem) {
      updatedBufferingItem = this.updateItem(bufferingItem, this.bufferedPos);
      if (this.itemsMatch(bufferingItem, updatedBufferingItem)) {
       this.bufferingItem = updatedBufferingItem;
      } else if (bufferingItem.event) {
       // Interstitial removed from schedule (Live -> VOD or other scenario where Start Date is outside the range of VOD Playlist)
       this.bufferingItem = this.playingItem;
       this.clearInterstitial(bufferingItem.event, null);
      }
     }
     removedInterstitials.forEach((interstitial) => {
      interstitial.assetList.forEach((asset) => {
       this.clearAssetPlayer(asset.identifier, null);
      });
     });
     this.playerQueue.forEach((player) => {
      if (player.interstitial.appendInPlace) {
       const timelineStart = player.assetItem.timelineStart;
       const diff = player.timelineOffset - timelineStart;
       if (diff) {
        try {
         player.timelineOffset = timelineStart;
        } catch (e) {
         if (Math.abs(diff) > ALIGNED_END_THRESHOLD_SECONDS) {
          this.warn(`${e} ("${player.assetId}" ${player.timelineOffset}->${timelineStart})`);
         }
        }
       }
      }
     });
     if (interstitialsUpdated || previousItems) {
      this.hls.trigger(Events.INTERSTITIALS_UPDATED, {
       events: interstitialEvents.slice(0),
       schedule: scheduleItems.slice(0),
       durations,
       removedIds,
      });
      if (this.isInterstitial(playingItem) && removedIds.includes(playingItem.event.identifier)) {
       this.warn(`Interstitial "${playingItem.event.identifier}" removed while playing`);
       this.primaryFallback(playingItem.event);
       return;
      }
      if (playingItem) {
       this.trimInPlace(updatedPlayingItem, playingItem);
      }
      if (bufferingItem) {
       this.trimInPlace(updatedBufferingItem, bufferingItem);
      }

      // Check is buffered to new Interstitial event boundary
      // (Live update publishes Interstitial with new segment)
      this.checkBuffer();
     }
    };
    this.hls = hls;
    this.HlsPlayerClass = HlsPlayerClass;
    this.assetListLoader = new AssetListLoader(hls);
    this.schedule = new InterstitialsSchedule(this.onScheduleUpdate, hls.logger);
    this.registerListeners();
   }
   registerListeners() {
    const hls = this.hls;
    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
    if (hls) {
     hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
     hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
     hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
     hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
     hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
     hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
     hls.on(Events.AUDIO_TRACK_UPDATED, this.onAudioTrackUpdated, this);
     hls.on(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);
     hls.on(Events.SUBTITLE_TRACK_UPDATED, this.onSubtitleTrackUpdated, this);
     hls.on(Events.EVENT_CUE_ENTER, this.onInterstitialCueEnter, this);
     hls.on(Events.ASSET_LIST_LOADED, this.onAssetListLoaded, this);
     hls.on(Events.BUFFER_APPENDED, this.onBufferAppended, this);
     hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
     hls.on(Events.BUFFERED_TO_END, this.onBufferedToEnd, this);
     hls.on(Events.MEDIA_ENDED, this.onMediaEnded, this);
     hls.on(Events.ERROR, this.onError, this);
     hls.on(Events.DESTROYING, this.onDestroying, this);
    }
   }
   unregisterListeners() {
    const hls = this.hls;
    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
    if (hls) {
     hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
     hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
     hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
     hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
     hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
     hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
     hls.off(Events.AUDIO_TRACK_UPDATED, this.onAudioTrackUpdated, this);
     hls.off(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);
     hls.off(Events.SUBTITLE_TRACK_UPDATED, this.onSubtitleTrackUpdated, this);
     hls.off(Events.EVENT_CUE_ENTER, this.onInterstitialCueEnter, this);
     hls.off(Events.ASSET_LIST_LOADED, this.onAssetListLoaded, this);
     hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);
     hls.off(Events.BUFFER_APPENDED, this.onBufferAppended, this);
     hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
     hls.off(Events.BUFFERED_TO_END, this.onBufferedToEnd, this);
     hls.off(Events.MEDIA_ENDED, this.onMediaEnded, this);
     hls.off(Events.ERROR, this.onError, this);
     hls.off(Events.DESTROYING, this.onDestroying, this);
    }
   }
   startLoad() {
    // TODO: startLoad - check for waitingItem and retry by resetting schedule
    this.resumeBuffering();
   }
   stopLoad() {
    // TODO: stopLoad - stop all scheule.events[].assetListLoader?.abort() then delete the loaders
    this.pauseBuffering();
   }
   resumeBuffering() {
    var _this$getBufferingPla;
    (_this$getBufferingPla = this.getBufferingPlayer()) == null || _this$getBufferingPla.resumeBuffering();
   }
   pauseBuffering() {
    var _this$getBufferingPla2;
    (_this$getBufferingPla2 = this.getBufferingPlayer()) == null || _this$getBufferingPla2.pauseBuffering();
   }
   destroy() {
    this.unregisterListeners();
    this.stopLoad();
    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
    if (this.assetListLoader) {
     this.assetListLoader.destroy();
    }
    this.emptyPlayerQueue();
    this.clearScheduleState();
    if (this.schedule) {
     this.schedule.destroy();
    }
    this.media = this.detachedData = this.mediaSelection = this.requiredTracks = this.altSelection = this.schedule = this.manager = null;
    // @ts-ignore
    this.hls = this.HlsPlayerClass = this.log = null;
    // @ts-ignore
    this.assetListLoader = null;
    // @ts-ignore
    this.onPlay = this.onPause = this.onSeeking = this.onTimeupdate = null;
    // @ts-ignore
    this.onScheduleUpdate = null;
   }
   onDestroying() {
    const media = this.primaryMedia || this.media;
    if (media) {
     this.removeMediaListeners(media);
    }
   }
   removeMediaListeners(media) {
    removeEventListener(media, 'play', this.onPlay);
    removeEventListener(media, 'pause', this.onPause);
    removeEventListener(media, 'seeking', this.onSeeking);
    removeEventListener(media, 'timeupdate', this.onTimeupdate);
   }
   onMediaAttaching(event, data) {
    const media = (this.media = data.media);
    addEventListener(media, 'seeking', this.onSeeking);
    addEventListener(media, 'timeupdate', this.onTimeupdate);
    addEventListener(media, 'play', this.onPlay);
    addEventListener(media, 'pause', this.onPause);
   }
   onMediaAttached(event, data) {
    const playingItem = this.effectivePlayingItem;
    const detachedMedia = this.detachedData;
    this.detachedData = null;
    if (playingItem === null) {
     this.checkStart();
    } else if (!detachedMedia) {
     // Resume schedule after detached externally
     this.clearScheduleState();
     const playingIndex = this.findItemIndex(playingItem);
     this.setSchedulePosition(playingIndex);
    }
   }
   clearScheduleState() {
    this.playingItem = this.bufferingItem = this.waitingItem = this.endedItem = this.playingAsset = this.endedAsset = this.bufferingAsset = null;
   }
   onMediaDetaching(event, data) {
    const transferringMedia = !!data.transferMedia;
    const media = this.media;
    this.media = null;
    if (transferringMedia) {
     return;
    }
    if (media) {
     this.removeMediaListeners(media);
    }
    // If detachMedia is called while in an Interstitial, detach the asset player as well and reset the schedule position
    if (this.detachedData) {
     const player = this.getBufferingPlayer();
     if (player) {
      this.playingAsset = this.endedAsset = this.bufferingAsset = this.bufferingItem = this.waitingItem = this.detachedData = null;
      player.detachMedia();
     }
     this.shouldPlay = false;
    }
   }
   get interstitialsManager() {
    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
    if (!this.hls) {
     return null;
    }
    if (this.manager) {
     return this.manager;
    }
    const c = this;
    const effectiveBufferingItem = () => c.bufferingItem || c.waitingItem;
    const getAssetPlayer = (asset) => (asset ? c.getAssetPlayer(asset.identifier) : asset);
    const getMappedTime = (item, timelineType, asset, controllerField, assetPlayerField) => {
     if (item) {
      let time = item[timelineType].start;
      const interstitial = item.event;
      if (interstitial) {
       if (timelineType === 'playout' || interstitial.timelineOccupancy !== TimelineOccupancy.Point) {
        const assetPlayer = getAssetPlayer(asset);
        if ((assetPlayer == null ? void 0 : assetPlayer.interstitial) === interstitial) {
         time += assetPlayer.assetItem.startOffset + assetPlayer[assetPlayerField];
        }
       }
      } else {
       const value = controllerField === 'bufferedPos' ? getBufferedEnd() : c[controllerField];
       time += value - item.start;
      }
      return time;
     }
     return 0;
    };
    const findMappedTime = (primaryTime, timelineType) => {
     var _c$schedule;
     if (primaryTime !== 0 && timelineType !== 'primary' && (_c$schedule = c.schedule) != null && _c$schedule.length) {
      var _c$schedule$items;
      const index = c.schedule.findItemIndexAtTime(primaryTime);
      const item = (_c$schedule$items = c.schedule.items) == null ? void 0 : _c$schedule$items[index];
      if (item) {
       const diff = item[timelineType].start - item.start;
       return primaryTime + diff;
      }
     }
     return primaryTime;
    };
    const getBufferedEnd = () => {
     const value = c.bufferedPos;
     if (value === Number.MAX_VALUE) {
      return getMappedDuration('primary');
     }
     return Math.max(value, 0);
    };
    const getMappedDuration = (timelineType) => {
     var _c$primaryDetails, _c$schedule2;
     if ((_c$primaryDetails = c.primaryDetails) != null && _c$primaryDetails.live) {
      // return end of last event item or playlist
      return c.primaryDetails.edge;
     }
     return ((_c$schedule2 = c.schedule) == null ? void 0 : _c$schedule2.durations[timelineType]) || 0;
    };
    const seekTo = (time, timelineType) => {
     var _item$event, _c$schedule$items2;
     const item = c.effectivePlayingItem;
     if ((item != null && (_item$event = item.event) != null && _item$event.restrictions.skip) || !c.schedule) {
      return;
     }
     c.log(`seek to ${time} "${timelineType}"`);
     const playingItem = c.effectivePlayingItem;
     const targetIndex = c.schedule.findItemIndexAtTime(time, timelineType);
     const targetItem = (_c$schedule$items2 = c.schedule.items) == null ? void 0 : _c$schedule$items2[targetIndex];
     const bufferingPlayer = c.getBufferingPlayer();
     const bufferingInterstitial = bufferingPlayer == null ? void 0 : bufferingPlayer.interstitial;
     const appendInPlace = bufferingInterstitial == null ? void 0 : bufferingInterstitial.appendInPlace;
     const seekInItem = playingItem && c.itemsMatch(playingItem, targetItem);
     if (playingItem && (appendInPlace || seekInItem)) {
      // seek in asset player or primary media (appendInPlace)
      const assetPlayer = getAssetPlayer(c.playingAsset);
      const media = (assetPlayer == null ? void 0 : assetPlayer.media) || c.primaryMedia;
      if (media) {
       const currentTime = timelineType === 'primary' ? media.currentTime : getMappedTime(playingItem, timelineType, c.playingAsset, 'timelinePos', 'currentTime');
       const diff = time - currentTime;
       const seekToTime = (appendInPlace ? currentTime : media.currentTime) + diff;
       if (seekToTime >= 0 && (!assetPlayer || appendInPlace || seekToTime <= assetPlayer.duration)) {
        media.currentTime = seekToTime;
        return;
       }
      }
     }
     // seek out of item or asset
     if (targetItem) {
      let seekToTime = time;
      if (timelineType !== 'primary') {
       const primarySegmentStart = targetItem[timelineType].start;
       const diff = time - primarySegmentStart;
       seekToTime = targetItem.start + diff;
      }
      const targetIsPrimary = !c.isInterstitial(targetItem);
      if ((!c.isInterstitial(playingItem) || playingItem.event.appendInPlace) && (targetIsPrimary || targetItem.event.appendInPlace)) {
       const media = c.media || (appendInPlace ? (bufferingPlayer == null ? void 0 : bufferingPlayer.media) : null);
       if (media) {
        media.currentTime = seekToTime;
       }
      } else if (playingItem) {
       // check if an Interstitial between the current item and target item has an X-RESTRICT JUMP restriction
       const playingIndex = c.findItemIndex(playingItem);
       if (targetIndex > playingIndex) {
        const jumpIndex = c.schedule.findJumpRestrictedIndex(playingIndex + 1, targetIndex);
        if (jumpIndex > playingIndex) {
         c.setSchedulePosition(jumpIndex);
         return;
        }
       }
       let assetIndex = 0;
       if (targetIsPrimary) {
        c.timelinePos = seekToTime;
        c.checkBuffer();
       } else {
        const assetList = targetItem.event.assetList;
        const eventTime = time - (targetItem[timelineType] || targetItem).start;
        for (let i = assetList.length; i--; ) {
         const asset = assetList[i];
         if (asset.duration && eventTime >= asset.startOffset && eventTime < asset.startOffset + asset.duration) {
          assetIndex = i;
          break;
         }
        }
       }
       c.setSchedulePosition(targetIndex, assetIndex);
      }
     }
    };
    const getActiveInterstitial = () => {
     const playingItem = c.effectivePlayingItem;
     if (c.isInterstitial(playingItem)) {
      return playingItem;
     }
     const bufferingItem = effectiveBufferingItem();
     if (c.isInterstitial(bufferingItem)) {
      return bufferingItem;
     }
     return null;
    };
    const interstitialPlayer = {
     get bufferedEnd() {
      const interstitialItem = effectiveBufferingItem();
      const bufferingItem = c.bufferingItem;
      if (bufferingItem && bufferingItem === interstitialItem) {
       var _c$bufferingAsset;
       return getMappedTime(bufferingItem, 'playout', c.bufferingAsset, 'bufferedPos', 'bufferedEnd') - bufferingItem.playout.start || ((_c$bufferingAsset = c.bufferingAsset) == null ? void 0 : _c$bufferingAsset.startOffset) || 0;
      }
      return 0;
     },
     get currentTime() {
      const interstitialItem = getActiveInterstitial();
      const playingItem = c.effectivePlayingItem;
      if (playingItem && playingItem === interstitialItem) {
       return getMappedTime(playingItem, 'playout', c.effectivePlayingAsset, 'timelinePos', 'currentTime') - playingItem.playout.start;
      }
      return 0;
     },
     set currentTime(time) {
      const interstitialItem = getActiveInterstitial();
      const playingItem = c.effectivePlayingItem;
      if (playingItem && playingItem === interstitialItem) {
       seekTo(time + playingItem.playout.start, 'playout');
      }
     },
     get duration() {
      const interstitialItem = getActiveInterstitial();
      if (interstitialItem) {
       return interstitialItem.playout.end - interstitialItem.playout.start;
      }
      return 0;
     },
     get assetPlayers() {
      var _getActiveInterstitia;
      const assetList = (_getActiveInterstitia = getActiveInterstitial()) == null ? void 0 : _getActiveInterstitia.event.assetList;
      if (assetList) {
       return assetList.map((asset) => c.getAssetPlayer(asset.identifier));
      }
      return [];
     },
     get playingIndex() {
      var _getActiveInterstitia2;
      const interstitial = (_getActiveInterstitia2 = getActiveInterstitial()) == null ? void 0 : _getActiveInterstitia2.event;
      if (interstitial && c.effectivePlayingAsset) {
       return interstitial.findAssetIndex(c.effectivePlayingAsset);
      }
      return -1;
     },
     get scheduleItem() {
      return getActiveInterstitial();
     },
    };
    return (this.manager = {
     get events() {
      var _c$schedule3;
      // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
      return ((_c$schedule3 = c.schedule) == null || (_c$schedule3 = _c$schedule3.events) == null ? void 0 : _c$schedule3.slice(0)) || [];
     },
     get schedule() {
      var _c$schedule4;
      // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
      return ((_c$schedule4 = c.schedule) == null || (_c$schedule4 = _c$schedule4.items) == null ? void 0 : _c$schedule4.slice(0)) || [];
     },
     get interstitialPlayer() {
      if (getActiveInterstitial()) {
       return interstitialPlayer;
      }
      return null;
     },
     get playerQueue() {
      return c.playerQueue.slice(0);
     },
     get bufferingAsset() {
      return c.bufferingAsset;
     },
     get bufferingItem() {
      return effectiveBufferingItem();
     },
     get bufferingIndex() {
      const item = effectiveBufferingItem();
      return c.findItemIndex(item);
     },
     get playingAsset() {
      return c.effectivePlayingAsset;
     },
     get playingItem() {
      return c.effectivePlayingItem;
     },
     get playingIndex() {
      const item = c.effectivePlayingItem;
      return c.findItemIndex(item);
     },
     primary: {
      get bufferedEnd() {
       return getBufferedEnd();
      },
      get currentTime() {
       const timelinePos = c.timelinePos;
       return timelinePos > 0 ? timelinePos : 0;
      },
      set currentTime(time) {
       seekTo(time, 'primary');
      },
      get duration() {
       return getMappedDuration('primary');
      },
      get seekableStart() {
       var _c$primaryDetails2;
       return ((_c$primaryDetails2 = c.primaryDetails) == null ? void 0 : _c$primaryDetails2.fragmentStart) || 0;
      },
     },
     integrated: {
      get bufferedEnd() {
       return getMappedTime(effectiveBufferingItem(), 'integrated', c.bufferingAsset, 'bufferedPos', 'bufferedEnd');
      },
      get currentTime() {
       return getMappedTime(c.effectivePlayingItem, 'integrated', c.effectivePlayingAsset, 'timelinePos', 'currentTime');
      },
      set currentTime(time) {
       seekTo(time, 'integrated');
      },
      get duration() {
       return getMappedDuration('integrated');
      },
      get seekableStart() {
       var _c$primaryDetails3;
       return findMappedTime(((_c$primaryDetails3 = c.primaryDetails) == null ? void 0 : _c$primaryDetails3.fragmentStart) || 0, 'integrated');
      },
     },
     skip: () => {
      const item = c.effectivePlayingItem;
      const event = item == null ? void 0 : item.event;
      if (event && !event.restrictions.skip) {
       const index = c.findItemIndex(item);
       if (event.appendInPlace) {
        const time = item.playout.start + item.event.duration;
        seekTo(time + 0.001, 'playout');
       } else {
        c.advanceAfterAssetEnded(event, index, Infinity);
       }
      }
     },
    });
   }

   // Schedule getters
   get effectivePlayingItem() {
    return this.waitingItem || this.playingItem || this.endedItem;
   }
   get effectivePlayingAsset() {
    return this.playingAsset || this.endedAsset;
   }
   get playingLastItem() {
    var _this$schedule;
    const playingItem = this.playingItem;
    const items = (_this$schedule = this.schedule) == null ? void 0 : _this$schedule.items;
    if (!this.playbackStarted || !playingItem || !items) {
     return false;
    }
    return this.findItemIndex(playingItem) === items.length - 1;
   }
   get playbackStarted() {
    return this.effectivePlayingItem !== null;
   }

   // Media getters and event callbacks
   get currentTime() {
    var _this$bufferingItem, _media;
    if (this.mediaSelection === null) {
     // Do not advance before schedule is known
     return undefined;
    }
    // Ignore currentTime when detached for Interstitial playback with source reset
    const queuedForPlayback = this.waitingItem || this.playingItem;
    if (this.isInterstitial(queuedForPlayback) && !queuedForPlayback.event.appendInPlace) {
     return undefined;
    }
    let media = this.media;
    if (!media && (_this$bufferingItem = this.bufferingItem) != null && (_this$bufferingItem = _this$bufferingItem.event) != null && _this$bufferingItem.appendInPlace) {
     // Observe detached media currentTime when appending in place
     media = this.primaryMedia;
    }
    const currentTime = (_media = media) == null ? void 0 : _media.currentTime;
    if (currentTime === undefined || !isFiniteNumber(currentTime)) {
     return undefined;
    }
    return currentTime;
   }
   get primaryMedia() {
    var _this$detachedData;
    return this.media || ((_this$detachedData = this.detachedData) == null ? void 0 : _this$detachedData.media) || null;
   }
   isInterstitial(item) {
    return !!(item != null && item.event);
   }
   retreiveMediaSource(assetId, toSegment) {
    const player = this.getAssetPlayer(assetId);
    if (player) {
     this.transferMediaFromPlayer(player, toSegment);
    }
   }
   transferMediaFromPlayer(player, toSegment) {
    const appendInPlace = player.interstitial.appendInPlace;
    const playerMedia = player.media;
    if (appendInPlace && playerMedia === this.primaryMedia) {
     this.bufferingAsset = null;
     if (!toSegment || (this.isInterstitial(toSegment) && !toSegment.event.appendInPlace)) {
      // MediaSource cannot be transfered back to an Interstitial that requires a source reset
      // no-op when toSegment is undefined
      if (toSegment && playerMedia) {
       this.detachedData = {
        media: playerMedia,
       };
       return;
      }
     }
     const attachMediaSourceData = player.transferMedia();
     this.log(`transfer MediaSource from ${player} ${stringify(attachMediaSourceData)}`);
     this.detachedData = attachMediaSourceData;
    } else if (toSegment && playerMedia) {
     this.shouldPlay || (this.shouldPlay = !playerMedia.paused);
    }
   }
   transferMediaTo(player, media) {
    var _this$detachedData2, _attachMediaSourceDat;
    if (player.media === media) {
     return;
    }
    let attachMediaSourceData = null;
    const primaryPlayer = this.hls;
    const isAssetPlayer = player !== primaryPlayer;
    const appendInPlace = isAssetPlayer && player.interstitial.appendInPlace;
    const detachedMediaSource = (_this$detachedData2 = this.detachedData) == null ? void 0 : _this$detachedData2.mediaSource;
    let logFromSource;
    if (primaryPlayer.media) {
     if (appendInPlace) {
      attachMediaSourceData = primaryPlayer.transferMedia();
      this.detachedData = attachMediaSourceData;
     }
     logFromSource = `Primary`;
    } else if (detachedMediaSource) {
     const bufferingPlayer = this.getBufferingPlayer();
     if (bufferingPlayer) {
      attachMediaSourceData = bufferingPlayer.transferMedia();
      logFromSource = `${bufferingPlayer}`;
     } else {
      logFromSource = `detached MediaSource`;
     }
    } else {
     logFromSource = `detached media`;
    }
    if (!attachMediaSourceData) {
     if (detachedMediaSource) {
      attachMediaSourceData = this.detachedData;
      this.log(`using detachedData: MediaSource ${stringify(attachMediaSourceData)}`);
     } else if (!this.detachedData || primaryPlayer.media === media) {
      // Keep interstitial media transition consistent
      const playerQueue = this.playerQueue;
      if (playerQueue.length > 1) {
       playerQueue.forEach((queuedPlayer) => {
        if (isAssetPlayer && queuedPlayer.interstitial.appendInPlace !== appendInPlace) {
         const interstitial = queuedPlayer.interstitial;
         this.clearInterstitial(queuedPlayer.interstitial, null);
         interstitial.appendInPlace = false; // setter may be a no-op;
         // `appendInPlace` getter may still return `true` after insterstitial streaming has begun in that mode.
         if (interstitial.appendInPlace) {
          this.warn(`Could not change append strategy for queued assets ${interstitial}`);
         }
        }
       });
      }
      this.hls.detachMedia();
      this.detachedData = {
       media,
      };
     }
    }
    const transferring = attachMediaSourceData && 'mediaSource' in attachMediaSourceData && ((_attachMediaSourceDat = attachMediaSourceData.mediaSource) == null ? void 0 : _attachMediaSourceDat.readyState) !== 'closed';
    const dataToAttach = transferring && attachMediaSourceData ? attachMediaSourceData : media;
    this.log(`${transferring ? 'transfering MediaSource' : 'attaching media'} to ${isAssetPlayer ? player : 'Primary'} from ${logFromSource} (media.currentTime: ${media.currentTime})`);
    const schedule = this.schedule;
    if (dataToAttach === attachMediaSourceData && schedule) {
     const isAssetAtEndOfSchedule = isAssetPlayer && player.assetId === schedule.assetIdAtEnd;
     // Prevent asset players from marking EoS on transferred MediaSource
     dataToAttach.overrides = {
      duration: schedule.duration,
      endOfStream: !isAssetPlayer || isAssetAtEndOfSchedule,
      cueRemoval: !isAssetPlayer,
     };
    }
    player.attachMedia(dataToAttach);
   }
   onInterstitialCueEnter() {
    this.onTimeupdate();
   }
   // Scheduling methods
   checkStart() {
    const schedule = this.schedule;
    const interstitialEvents = schedule == null ? void 0 : schedule.events;
    if (!interstitialEvents || this.playbackDisabled || !this.media) {
     return;
    }
    // Check buffered to pre-roll
    if (this.bufferedPos === -1) {
     this.bufferedPos = 0;
    }
    // Start stepping through schedule when playback begins for the first time and we have a pre-roll
    const timelinePos = this.timelinePos;
    const effectivePlayingItem = this.effectivePlayingItem;
    if (timelinePos === -1) {
     const startPosition = this.hls.startPosition;
     this.timelinePos = startPosition;
     if (interstitialEvents.length && interstitialEvents[0].cue.pre) {
      const index = schedule.findEventIndex(interstitialEvents[0].identifier);
      this.setSchedulePosition(index);
     } else if (startPosition >= 0 || !this.primaryLive) {
      const start = (this.timelinePos = startPosition > 0 ? startPosition : 0);
      const index = schedule.findItemIndexAtTime(start);
      this.setSchedulePosition(index);
     }
    } else if (effectivePlayingItem && !this.playingItem) {
     const index = schedule.findItemIndex(effectivePlayingItem);
     this.setSchedulePosition(index);
    }
   }
   advanceAssetBuffering(item, assetItem) {
    const interstitial = item.event;
    const assetListIndex = interstitial.findAssetIndex(assetItem);
    const nextAssetIndex = getNextAssetIndex(interstitial, assetListIndex);
    if (!interstitial.isAssetPastPlayoutLimit(nextAssetIndex)) {
     this.bufferedToEvent(item, nextAssetIndex);
    } else if (this.schedule) {
     var _this$schedule$items;
     const nextItem = (_this$schedule$items = this.schedule.items) == null ? void 0 : _this$schedule$items[this.findItemIndex(item) + 1];
     if (nextItem) {
      this.bufferedToItem(nextItem);
     }
    }
   }
   advanceAfterAssetEnded(interstitial, index, assetListIndex) {
    const nextAssetIndex = getNextAssetIndex(interstitial, assetListIndex);
    if (!interstitial.isAssetPastPlayoutLimit(nextAssetIndex)) {
     // Advance to next asset list item
     if (interstitial.appendInPlace) {
      const assetItem = interstitial.assetList[nextAssetIndex];
      if (assetItem) {
       this.advanceInPlace(assetItem.timelineStart);
      }
     }
     this.setSchedulePosition(index, nextAssetIndex);
    } else if (this.schedule) {
     // Advance to next schedule segment
     // check if we've reached the end of the program
     const scheduleItems = this.schedule.items;
     if (scheduleItems) {
      const nextIndex = index + 1;
      const scheduleLength = scheduleItems.length;
      if (nextIndex >= scheduleLength) {
       this.setSchedulePosition(-1);
       return;
      }
      const resumptionTime = interstitial.resumeTime;
      if (this.timelinePos < resumptionTime) {
       this.timelinePos = resumptionTime;
       if (interstitial.appendInPlace) {
        this.advanceInPlace(resumptionTime);
       }
       this.checkBuffer(this.bufferedPos < resumptionTime);
      }
      this.setSchedulePosition(nextIndex);
     }
    }
   }
   setScheduleToAssetAtTime(time, playingAsset) {
    const schedule = this.schedule;
    if (!schedule) {
     return;
    }
    const parentIdentifier = playingAsset.parentIdentifier;
    const interstitial = schedule.getEvent(parentIdentifier);
    if (interstitial) {
     const itemIndex = schedule.findEventIndex(parentIdentifier);
     const assetListIndex = schedule.findAssetIndex(interstitial, time);
     this.advanceAfterAssetEnded(interstitial, itemIndex, assetListIndex - 1);
    }
   }
   setSchedulePosition(index, assetListIndex) {
    var _this$schedule2;
    const scheduleItems = (_this$schedule2 = this.schedule) == null ? void 0 : _this$schedule2.items;
    if (!scheduleItems || this.playbackDisabled) {
     return;
    }
    const scheduledItem = index >= 0 ? scheduleItems[index] : null;
    this.log(`setSchedulePosition ${index}, ${assetListIndex} (${scheduledItem ? segmentToString(scheduledItem) : scheduledItem})`);
    // Cleanup current item / asset
    const currentItem = this.waitingItem || this.playingItem;
    const playingLastItem = this.playingLastItem;
    if (this.isInterstitial(currentItem)) {
     const interstitial = currentItem.event;
     const playingAsset = this.playingAsset;
     const assetId = playingAsset == null ? void 0 : playingAsset.identifier;
     const player = assetId ? this.getAssetPlayer(assetId) : null;
     if (player && assetId && (!this.eventItemsMatch(currentItem, scheduledItem) || (assetListIndex !== undefined && assetId !== interstitial.assetList[assetListIndex].identifier))) {
      var _this$detachedData3;
      const playingAssetListIndex = interstitial.findAssetIndex(playingAsset);
      this.log(`INTERSTITIAL_ASSET_ENDED ${playingAssetListIndex + 1}/${interstitial.assetList.length} ${eventAssetToString(playingAsset)}`);
      this.endedAsset = playingAsset;
      this.playingAsset = null;
      this.hls.trigger(Events.INTERSTITIAL_ASSET_ENDED, {
       asset: playingAsset,
       assetListIndex: playingAssetListIndex,
       event: interstitial,
       schedule: scheduleItems.slice(0),
       scheduleIndex: index,
       player,
      });
      if (currentItem !== this.playingItem) {
       // Schedule change occured on INTERSTITIAL_ASSET_ENDED
       if (
        this.itemsMatch(currentItem, this.playingItem) &&
        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
        !this.playingAsset // INTERSTITIAL_ASSET_ENDED side-effect
       ) {
        this.advanceAfterAssetEnded(interstitial, this.findItemIndex(this.playingItem), playingAssetListIndex);
       }
       // Navigation occured on INTERSTITIAL_ASSET_ENDED
       return;
      }
      this.retreiveMediaSource(assetId, scheduledItem);
      if (player.media && !((_this$detachedData3 = this.detachedData) != null && _this$detachedData3.mediaSource)) {
       player.detachMedia();
      }
     }
     if (!this.eventItemsMatch(currentItem, scheduledItem)) {
      this.endedItem = currentItem;
      this.playingItem = null;
      this.log(`INTERSTITIAL_ENDED ${interstitial} ${segmentToString(currentItem)}`);
      interstitial.hasPlayed = true;
      this.hls.trigger(Events.INTERSTITIAL_ENDED, {
       event: interstitial,
       schedule: scheduleItems.slice(0),
       scheduleIndex: index,
      });
      // Exiting an Interstitial
      if (interstitial.cue.once) {
       var _this$schedule3;
       // Remove interstitial with CUE attribute value of ONCE after it has played
       this.updateSchedule();
       const updatedScheduleItems = (_this$schedule3 = this.schedule) == null ? void 0 : _this$schedule3.items;
       if (scheduledItem && updatedScheduleItems) {
        const updatedIndex = this.findItemIndex(scheduledItem);
        this.advanceSchedule(updatedIndex, updatedScheduleItems, assetListIndex, currentItem, playingLastItem);
       }
       return;
      }
     }
    }
    this.advanceSchedule(index, scheduleItems, assetListIndex, currentItem, playingLastItem);
   }
   advanceSchedule(index, scheduleItems, assetListIndex, currentItem, playedLastItem) {
    const schedule = this.schedule;
    if (!schedule) {
     return;
    }
    const scheduledItem = index >= 0 ? scheduleItems[index] : null;
    const media = this.primaryMedia;
    // Cleanup out of range Interstitials
    const playerQueue = this.playerQueue;
    if (playerQueue.length) {
     playerQueue.forEach((player) => {
      const interstitial = player.interstitial;
      const queuedIndex = schedule.findEventIndex(interstitial.identifier);
      if (queuedIndex < index || queuedIndex > index + 1) {
       this.clearInterstitial(interstitial, scheduledItem);
      }
     });
    }
    // Setup scheduled item
    if (this.isInterstitial(scheduledItem)) {
     this.timelinePos = Math.min(Math.max(this.timelinePos, scheduledItem.start), scheduledItem.end);
     // Handle Interstitial
     const interstitial = scheduledItem.event;
     // find asset index
     if (assetListIndex === undefined) {
      assetListIndex = schedule.findAssetIndex(interstitial, this.timelinePos);
      const assetIndexCandidate = getNextAssetIndex(interstitial, assetListIndex - 1);
      if (interstitial.isAssetPastPlayoutLimit(assetIndexCandidate) || (interstitial.appendInPlace && this.timelinePos === scheduledItem.end)) {
       this.advanceAfterAssetEnded(interstitial, index, assetListIndex);
       return;
      }
      assetListIndex = assetIndexCandidate;
     }
     // Ensure Interstitial is enqueued
     const waitingItem = this.waitingItem;
     if (!this.assetsBuffered(scheduledItem, media)) {
      this.setBufferingItem(scheduledItem);
     }
     let player = this.preloadAssets(interstitial, assetListIndex);
     if (!this.eventItemsMatch(scheduledItem, waitingItem || currentItem)) {
      this.waitingItem = scheduledItem;
      this.log(`INTERSTITIAL_STARTED ${segmentToString(scheduledItem)} ${interstitial.appendInPlace ? 'append in place' : ''}`);
      this.hls.trigger(Events.INTERSTITIAL_STARTED, {
       event: interstitial,
       schedule: scheduleItems.slice(0),
       scheduleIndex: index,
      });
     }
     if (!interstitial.assetListLoaded) {
      // Waiting at end of primary content segment
      // Expect setSchedulePosition to be called again once ASSET-LIST is loaded
      this.log(`Waiting for ASSET-LIST to complete loading ${interstitial}`);
      return;
     }
     if (interstitial.assetListLoader) {
      interstitial.assetListLoader.destroy();
      interstitial.assetListLoader = undefined;
     }
     if (!media) {
      this.log(`Waiting for attachMedia to start Interstitial ${interstitial}`);
      return;
     }
     // Update schedule and asset list position now that it can start
     this.waitingItem = this.endedItem = null;
     this.playingItem = scheduledItem;

     // If asset-list is empty or missing asset index, advance to next item
     const assetItem = interstitial.assetList[assetListIndex];
     if (!assetItem) {
      this.advanceAfterAssetEnded(interstitial, index, assetListIndex || 0);
      return;
     }

     // Start Interstitial Playback
     if (!player) {
      player = this.getAssetPlayer(assetItem.identifier);
     }
     if (player === null || player.destroyed) {
      const assetListLength = interstitial.assetList.length;
      this.warn(`asset ${assetListIndex + 1}/${assetListLength} player destroyed ${interstitial}`);
      player = this.createAssetPlayer(interstitial, assetItem, assetListIndex);
      player.loadSource();
     }
     if (!this.eventItemsMatch(scheduledItem, this.bufferingItem)) {
      if (interstitial.appendInPlace && this.isAssetBuffered(assetItem)) {
       return;
      }
     }
     this.startAssetPlayer(player, assetListIndex, scheduleItems, index, media);
     if (this.shouldPlay) {
      playWithCatch(player.media);
     }
    } else if (scheduledItem !== null) {
     this.resumePrimary(scheduledItem, index, currentItem);
     if (this.shouldPlay) {
      playWithCatch(this.hls.media);
     }
    } else if (playedLastItem && this.isInterstitial(currentItem)) {
     // Maintain playingItem state at end of schedule (setSchedulePosition(-1) called to end program)
     // this allows onSeeking handler to update schedule position
     this.endedItem = null;
     this.playingItem = currentItem;
     if (!currentItem.event.appendInPlace) {
      // Media must be re-attached to resume primary schedule if not sharing source
      this.attachPrimary(schedule.durations.primary, null);
     }
    }
   }
   get playbackDisabled() {
    return this.hls.config.enableInterstitialPlayback === false;
   }
   get primaryDetails() {
    var _this$mediaSelection;
    return (_this$mediaSelection = this.mediaSelection) == null ? void 0 : _this$mediaSelection.main.details;
   }
   get primaryLive() {
    var _this$primaryDetails;
    return !!((_this$primaryDetails = this.primaryDetails) != null && _this$primaryDetails.live);
   }
   resumePrimary(scheduledItem, index, fromItem) {
    var _this$detachedData4, _this$schedule4;
    this.playingItem = scheduledItem;
    this.playingAsset = this.endedAsset = null;
    this.waitingItem = this.endedItem = null;
    this.bufferedToItem(scheduledItem);
    this.log(`resuming ${segmentToString(scheduledItem)}`);
    if (!((_this$detachedData4 = this.detachedData) != null && _this$detachedData4.mediaSource)) {
     let timelinePos = this.timelinePos;
     if (timelinePos < scheduledItem.start || timelinePos >= scheduledItem.end) {
      timelinePos = this.getPrimaryResumption(scheduledItem, index);
      this.timelinePos = timelinePos;
     }
     this.attachPrimary(timelinePos, scheduledItem);
    }
    if (!fromItem) {
     return;
    }
    const scheduleItems = (_this$schedule4 = this.schedule) == null ? void 0 : _this$schedule4.items;
    if (!scheduleItems) {
     return;
    }
    this.log(`INTERSTITIALS_PRIMARY_RESUMED ${segmentToString(scheduledItem)}`);
    this.hls.trigger(Events.INTERSTITIALS_PRIMARY_RESUMED, {
     schedule: scheduleItems.slice(0),
     scheduleIndex: index,
    });
    this.checkBuffer();
   }
   getPrimaryResumption(scheduledItem, index) {
    const itemStart = scheduledItem.start;
    if (this.primaryLive) {
     const details = this.primaryDetails;
     if (index === 0) {
      return this.hls.startPosition;
     } else if (details && (itemStart < details.fragmentStart || itemStart > details.edge)) {
      return this.hls.liveSyncPosition || -1;
     }
    }
    return itemStart;
   }
   isAssetBuffered(asset) {
    const player = this.getAssetPlayer(asset.identifier);
    if (player != null && player.hls) {
     return player.hls.bufferedToEnd;
    }
    const bufferInfo = BufferHelper.bufferInfo(this.primaryMedia, this.timelinePos, 0);
    return bufferInfo.end + 1 >= asset.timelineStart + (asset.duration || 0);
   }
   attachPrimary(timelinePos, item, skipSeekToStartPosition) {
    if (item) {
     this.setBufferingItem(item);
    } else {
     this.bufferingItem = this.playingItem;
    }
    this.bufferingAsset = null;
    const media = this.primaryMedia;
    if (!media) {
     return;
    }
    const hls = this.hls;
    if (hls.media) {
     this.checkBuffer();
    } else {
     this.transferMediaTo(hls, media);
     if (skipSeekToStartPosition) {
      this.startLoadingPrimaryAt(timelinePos, skipSeekToStartPosition);
     }
    }
    if (!skipSeekToStartPosition) {
     // Set primary position to resume time
     this.timelinePos = timelinePos;
     this.startLoadingPrimaryAt(timelinePos, skipSeekToStartPosition);
    }
   }
   startLoadingPrimaryAt(timelinePos, skipSeekToStartPosition) {
    var _hls$mainForwardBuffe;
    const hls = this.hls;
    if (!hls.loadingEnabled || !hls.media || Math.abs((((_hls$mainForwardBuffe = hls.mainForwardBufferInfo) == null ? void 0 : _hls$mainForwardBuffe.start) || hls.media.currentTime) - timelinePos) > 0.5) {
     hls.startLoad(timelinePos, skipSeekToStartPosition);
    } else if (!hls.bufferingEnabled) {
     hls.resumeBuffering();
    }
   }

   // HLS.js event callbacks
   onManifestLoading() {
    var _this$schedule5;
    this.stopLoad();
    (_this$schedule5 = this.schedule) == null || _this$schedule5.reset();
    this.emptyPlayerQueue();
    this.clearScheduleState();
    this.shouldPlay = false;
    this.bufferedPos = this.timelinePos = -1;
    this.mediaSelection = this.altSelection = this.manager = this.requiredTracks = null;
    // BUFFER_CODECS listener added here for buffer-controller to handle it first where it adds tracks
    this.hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);
    this.hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);
   }
   onLevelUpdated(event, data) {
    if (data.level === -1 || !this.schedule) {
     // level was removed
     return;
    }
    const main = this.hls.levels[data.level];
    const currentSelection = _objectSpread2(
     _objectSpread2({}, this.mediaSelection || this.altSelection),
     {},
     {
      main,
     },
    );
    this.mediaSelection = currentSelection;
    this.schedule.parseInterstitialDateRanges(currentSelection, this.hls.config.interstitialAppendInPlace);
    if (!this.effectivePlayingItem && this.schedule.items) {
     this.checkStart();
    }
   }
   onAudioTrackUpdated(event, data) {
    const audio = this.hls.audioTracks[data.id];
    const previousSelection = this.mediaSelection;
    if (!previousSelection) {
     this.altSelection = _objectSpread2(
      _objectSpread2({}, this.altSelection),
      {},
      {
       audio,
      },
     );
     return;
    }
    const currentSelection = _objectSpread2(
     _objectSpread2({}, previousSelection),
     {},
     {
      audio,
     },
    );
    this.mediaSelection = currentSelection;
   }
   onSubtitleTrackUpdated(event, data) {
    const subtitles = this.hls.subtitleTracks[data.id];
    const previousSelection = this.mediaSelection;
    if (!previousSelection) {
     this.altSelection = _objectSpread2(
      _objectSpread2({}, this.altSelection),
      {},
      {
       subtitles,
      },
     );
     return;
    }
    const currentSelection = _objectSpread2(
     _objectSpread2({}, previousSelection),
     {},
     {
      subtitles,
     },
    );
    this.mediaSelection = currentSelection;
   }
   onAudioTrackSwitching(event, data) {
    const audioOption = getBasicSelectionOption(data);
    this.playerQueue.forEach(({ hls }) => hls && (hls.setAudioOption(data) || hls.setAudioOption(audioOption)));
   }
   onSubtitleTrackSwitch(event, data) {
    const subtitleOption = getBasicSelectionOption(data);
    this.playerQueue.forEach(({ hls }) => hls && (hls.setSubtitleOption(data) || (data.id !== -1 && hls.setSubtitleOption(subtitleOption))));
   }
   onBufferCodecs(event, data) {
    const requiredTracks = data.tracks;
    if (requiredTracks) {
     this.requiredTracks = requiredTracks;
    }
   }
   onBufferAppended(event, data) {
    this.checkBuffer();
   }
   onBufferFlushed(event, data) {
    const playingItem = this.playingItem;
    if (playingItem && !this.itemsMatch(playingItem, this.bufferingItem) && !this.isInterstitial(playingItem)) {
     const timelinePos = this.timelinePos;
     this.bufferedPos = timelinePos;
     this.checkBuffer();
    }
   }
   onBufferedToEnd(event) {
    if (!this.schedule) {
     return;
    }
    // Buffered to post-roll
    const interstitialEvents = this.schedule.events;
    if (this.bufferedPos < Number.MAX_VALUE && interstitialEvents) {
     for (let i = 0; i < interstitialEvents.length; i++) {
      const interstitial = interstitialEvents[i];
      if (interstitial.cue.post) {
       var _this$schedule$items2;
       const scheduleIndex = this.schedule.findEventIndex(interstitial.identifier);
       const item = (_this$schedule$items2 = this.schedule.items) == null ? void 0 : _this$schedule$items2[scheduleIndex];
       if (this.isInterstitial(item) && this.eventItemsMatch(item, this.bufferingItem)) {
        this.bufferedToItem(item, 0);
       }
       break;
      }
     }
     this.bufferedPos = Number.MAX_VALUE;
    }
   }
   onMediaEnded(event) {
    const playingItem = this.playingItem;
    if (!this.playingLastItem && playingItem) {
     const playingIndex = this.findItemIndex(playingItem);
     this.setSchedulePosition(playingIndex + 1);
    } else {
     this.shouldPlay = false;
    }
   }
   updateItem(previousItem, time) {
    var _this$schedule6;
    // find item in this.schedule.items;
    const items = (_this$schedule6 = this.schedule) == null ? void 0 : _this$schedule6.items;
    if (previousItem && items) {
     const index = this.findItemIndex(previousItem, time);
     return items[index] || null;
    }
    return null;
   }
   trimInPlace(updatedItem, itemBeforeUpdate) {
    if (this.isInterstitial(updatedItem) && updatedItem.event.appendInPlace && itemBeforeUpdate.end - updatedItem.end > 0.25) {
     updatedItem.event.assetList.forEach((asset, index) => {
      if (updatedItem.event.isAssetPastPlayoutLimit(index)) {
       this.clearAssetPlayer(asset.identifier, null);
      }
     });
     const flushStart = updatedItem.end + 0.25;
     const bufferInfo = BufferHelper.bufferInfo(this.primaryMedia, flushStart, 0);
     if (bufferInfo.end > flushStart || (bufferInfo.nextStart || 0) > flushStart) {
      this.attachPrimary(flushStart, null);
      this.flushFrontBuffer(flushStart);
     }
    }
   }
   itemsMatch(a, b) {
    return !!b && (a === b || (a.event && b.event && this.eventItemsMatch(a, b)) || (!a.event && !b.event && this.findItemIndex(a) === this.findItemIndex(b)));
   }
   eventItemsMatch(a, b) {
    var _b$event;
    return !!b && (a === b || a.event.identifier === ((_b$event = b.event) == null ? void 0 : _b$event.identifier));
   }
   findItemIndex(item, time) {
    return item && this.schedule ? this.schedule.findItemIndex(item, time) : -1;
   }
   updateSchedule(forceUpdate = false) {
    var _this$schedule7;
    const mediaSelection = this.mediaSelection;
    if (!mediaSelection) {
     return;
    }
    (_this$schedule7 = this.schedule) == null || _this$schedule7.updateSchedule(mediaSelection, [], forceUpdate);
   }

   // Schedule buffer control
   checkBuffer(starved) {
    var _this$schedule8;
    const items = (_this$schedule8 = this.schedule) == null ? void 0 : _this$schedule8.items;
    if (!items) {
     return;
    }
    // Find when combined forward buffer change reaches next schedule segment
    const bufferInfo = BufferHelper.bufferInfo(this.primaryMedia, this.timelinePos, 0);
    if (starved) {
     this.bufferedPos = this.timelinePos;
    }
    starved || (starved = bufferInfo.len < 1);
    this.updateBufferedPos(bufferInfo.end, items, starved);
   }
   updateBufferedPos(bufferEnd, items, bufferIsEmpty) {
    const schedule = this.schedule;
    const bufferingItem = this.bufferingItem;
    if (this.bufferedPos > bufferEnd || !schedule) {
     return;
    }
    if (items.length === 1 && this.itemsMatch(items[0], bufferingItem)) {
     this.bufferedPos = bufferEnd;
     return;
    }
    const playingItem = this.playingItem;
    const playingIndex = this.findItemIndex(playingItem);
    let bufferEndIndex = schedule.findItemIndexAtTime(bufferEnd);
    if (this.bufferedPos < bufferEnd) {
     var _nextItemToBuffer$eve;
     const bufferingIndex = this.findItemIndex(bufferingItem);
     const nextToBufferIndex = Math.min(bufferingIndex + 1, items.length - 1);
     const nextItemToBuffer = items[nextToBufferIndex];
     if ((bufferEndIndex === -1 && bufferingItem && bufferEnd >= bufferingItem.end) || ((_nextItemToBuffer$eve = nextItemToBuffer.event) != null && _nextItemToBuffer$eve.appendInPlace && bufferEnd + 0.01 >= nextItemToBuffer.start)) {
      bufferEndIndex = nextToBufferIndex;
     }
     if (this.isInterstitial(bufferingItem)) {
      const interstitial = bufferingItem.event;
      if (nextToBufferIndex - playingIndex > 1 && interstitial.appendInPlace === false) {
       // do not advance buffering item past Interstitial that requires source reset
       return;
      }
      if (interstitial.assetList.length === 0 && interstitial.assetListLoader) {
       // do not advance buffering item past Interstitial loading asset-list
       return;
      }
     }
     this.bufferedPos = bufferEnd;
     if (bufferEndIndex > bufferingIndex && bufferEndIndex > playingIndex) {
      this.bufferedToItem(nextItemToBuffer);
     } else {
      // allow more time than distance from edge for assets to load
      const details = this.primaryDetails;
      if (this.primaryLive && details && bufferEnd > details.edge - details.targetduration && nextItemToBuffer.start < details.edge + this.hls.config.interstitialLiveLookAhead && this.isInterstitial(nextItemToBuffer)) {
       this.preloadAssets(nextItemToBuffer.event, 0);
      }
     }
    } else if (bufferIsEmpty && playingItem && !this.itemsMatch(playingItem, bufferingItem)) {
     if (bufferEndIndex === playingIndex) {
      this.bufferedToItem(playingItem);
     } else if (bufferEndIndex === playingIndex + 1) {
      this.bufferedToItem(items[bufferEndIndex]);
     }
    }
   }
   assetsBuffered(item, media) {
    const assetList = item.event.assetList;
    if (assetList.length === 0) {
     return false;
    }
    return !item.event.assetList.some((asset) => {
     const player = this.getAssetPlayer(asset.identifier);
     return !(player != null && player.bufferedInPlaceToEnd(media));
    });
   }
   setBufferingItem(item) {
    const bufferingLast = this.bufferingItem;
    const schedule = this.schedule;
    if (!this.itemsMatch(item, bufferingLast) && schedule) {
     const { items, events } = schedule;
     if (!items || !events) {
      return bufferingLast;
     }
     const isInterstitial = this.isInterstitial(item);
     const bufferingPlayer = this.getBufferingPlayer();
     this.bufferingItem = item;
     this.bufferedPos = Math.max(item.start, Math.min(item.end, this.timelinePos));
     const timeRemaining = bufferingPlayer ? bufferingPlayer.remaining : bufferingLast ? bufferingLast.end - this.timelinePos : 0;
     this.log(`INTERSTITIALS_BUFFERED_TO_BOUNDARY ${segmentToString(item)}` + (bufferingLast ? ` (${timeRemaining.toFixed(2)} remaining)` : ''));
     if (!this.playbackDisabled) {
      if (isInterstitial) {
       const bufferIndex = schedule.findAssetIndex(item.event, this.bufferedPos);
       // primary fragment loading will exit early in base-stream-controller while `bufferingItem` is set to an Interstitial block
       item.event.assetList.forEach((asset, i) => {
        const player = this.getAssetPlayer(asset.identifier);
        if (player) {
         if (i === bufferIndex) {
          player.loadSource();
         }
         player.resumeBuffering();
        }
       });
      } else {
       this.hls.resumeBuffering();
       this.playerQueue.forEach((player) => player.pauseBuffering());
      }
     }
     this.hls.trigger(Events.INTERSTITIALS_BUFFERED_TO_BOUNDARY, {
      events: events.slice(0),
      schedule: items.slice(0),
      bufferingIndex: this.findItemIndex(item),
      playingIndex: this.findItemIndex(this.playingItem),
     });
    } else if (this.bufferingItem !== item) {
     this.bufferingItem = item;
    }
    return bufferingLast;
   }
   bufferedToItem(item, assetListIndex = 0) {
    const bufferingLast = this.setBufferingItem(item);
    if (this.playbackDisabled) {
     return;
    }
    if (this.isInterstitial(item)) {
     // Ensure asset list is loaded
     this.bufferedToEvent(item, assetListIndex);
    } else if (bufferingLast !== null) {
     // If primary player is detached, it is also stopped, restart loading at primary position
     this.bufferingAsset = null;
     const detachedData = this.detachedData;
     if (detachedData) {
      if (detachedData.mediaSource) {
       const skipSeekToStartPosition = true;
       this.attachPrimary(item.start, item, skipSeekToStartPosition);
      } else {
       this.preloadPrimary(item);
      }
     } else {
      // If not detached seek to resumption point
      this.preloadPrimary(item);
     }
    }
   }
   preloadPrimary(item) {
    const index = this.findItemIndex(item);
    const timelinePos = this.getPrimaryResumption(item, index);
    this.startLoadingPrimaryAt(timelinePos);
   }
   bufferedToEvent(item, assetListIndex) {
    const interstitial = item.event;
    const neverLoaded = interstitial.assetList.length === 0 && !interstitial.assetListLoader;
    const playOnce = interstitial.cue.once;
    if (neverLoaded || !playOnce) {
     // Buffered to Interstitial boundary
     const player = this.preloadAssets(interstitial, assetListIndex);
     if (player != null && player.interstitial.appendInPlace) {
      const media = this.primaryMedia;
      if (media) {
       this.bufferAssetPlayer(player, media);
      }
     }
    }
   }
   preloadAssets(interstitial, assetListIndex) {
    const uri = interstitial.assetUrl;
    const assetListLength = interstitial.assetList.length;
    const neverLoaded = assetListLength === 0 && !interstitial.assetListLoader;
    const playOnce = interstitial.cue.once;
    if (neverLoaded) {
     const timelineStart = interstitial.timelineStart;
     if (interstitial.appendInPlace) {
      var _playingItem$nextEven;
      const playingItem = this.playingItem;
      if (!this.isInterstitial(playingItem) && (playingItem == null || (_playingItem$nextEven = playingItem.nextEvent) == null ? void 0 : _playingItem$nextEven.identifier) === interstitial.identifier) {
       this.flushFrontBuffer(timelineStart + 0.25);
      }
     }
     let hlsStartOffset;
     let liveStartPosition = 0;
     if (!this.playingItem && this.primaryLive) {
      liveStartPosition = this.hls.startPosition;
      if (liveStartPosition === -1) {
       liveStartPosition = this.hls.liveSyncPosition || 0;
      }
     }
     if (liveStartPosition && !(interstitial.cue.pre || interstitial.cue.post)) {
      const startOffset = liveStartPosition - timelineStart;
      if (startOffset > 0) {
       hlsStartOffset = Math.round(startOffset * 1000) / 1000;
      }
     }
     this.log(`Load interstitial asset ${assetListIndex + 1}/${uri ? 1 : assetListLength} ${interstitial}${hlsStartOffset ? ` live-start: ${liveStartPosition} start-offset: ${hlsStartOffset}` : ''}`);
     if (uri) {
      return this.createAsset(interstitial, 0, 0, timelineStart, interstitial.duration, uri);
     }
     const assetListLoader = this.assetListLoader.loadAssetList(interstitial, hlsStartOffset);
     if (assetListLoader) {
      interstitial.assetListLoader = assetListLoader;
     }
    } else if (!playOnce && assetListLength) {
     // Re-buffered to Interstitial boundary, re-create asset player(s)
     for (let i = assetListIndex; i < assetListLength; i++) {
      const _asset = interstitial.assetList[i];
      const playerIndex = this.getAssetPlayerQueueIndex(_asset.identifier);
      if ((playerIndex === -1 || this.playerQueue[playerIndex].destroyed) && !_asset.error) {
       this.createAssetPlayer(interstitial, _asset, i);
      }
     }
     const asset = interstitial.assetList[assetListIndex];
     // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
     if (asset) {
      const player = this.getAssetPlayer(asset.identifier);
      if (player) {
       player.loadSource();
      }
      return player;
     }
    }
    return null;
   }
   flushFrontBuffer(startOffset) {
    // Force queued flushing of all buffers
    const requiredTracks = this.requiredTracks;
    if (!requiredTracks) {
     return;
    }
    this.log(`Removing front buffer starting at ${startOffset}`);
    const sourceBufferNames = Object.keys(requiredTracks);
    sourceBufferNames.forEach((type) => {
     this.hls.trigger(Events.BUFFER_FLUSHING, {
      startOffset,
      endOffset: Infinity,
      type,
     });
    });
   }

   // Interstitial Asset Player control
   getAssetPlayerQueueIndex(assetId) {
    const playerQueue = this.playerQueue;
    for (let i = 0; i < playerQueue.length; i++) {
     if (assetId === playerQueue[i].assetId) {
      return i;
     }
    }
    return -1;
   }
   getAssetPlayer(assetId) {
    const index = this.getAssetPlayerQueueIndex(assetId);
    return this.playerQueue[index] || null;
   }
   getBufferingPlayer() {
    const { playerQueue, primaryMedia } = this;
    if (primaryMedia) {
     for (let i = 0; i < playerQueue.length; i++) {
      if (playerQueue[i].media === primaryMedia) {
       return playerQueue[i];
      }
     }
    }
    return null;
   }
   createAsset(interstitial, assetListIndex, startOffset, timelineStart, duration, uri) {
    const assetItem = {
     parentIdentifier: interstitial.identifier,
     identifier: generateAssetIdentifier(interstitial, uri, assetListIndex),
     duration,
     startOffset,
     timelineStart,
     uri,
    };
    return this.createAssetPlayer(interstitial, assetItem, assetListIndex);
   }
   createAssetPlayer(interstitial, assetItem, assetListIndex) {
    const primary = this.hls;
    const userConfig = primary.userConfig;
    let videoPreference = userConfig.videoPreference;
    const currentLevel = primary.loadLevelObj || primary.levels[primary.currentLevel];
    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
    if (videoPreference || currentLevel) {
     videoPreference = _extends({}, videoPreference);
     if (currentLevel.videoCodec) {
      videoPreference.videoCodec = currentLevel.videoCodec;
     }
     // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
     if (currentLevel.videoRange) {
      videoPreference.allowedVideoRanges = [currentLevel.videoRange];
     }
    }
    const selectedAudio = primary.audioTracks[primary.audioTrack];
    const selectedSubtitle = primary.subtitleTracks[primary.subtitleTrack];
    let startPosition = 0;
    if (this.primaryLive || interstitial.appendInPlace) {
     const timePastStart = this.timelinePos - assetItem.timelineStart;
     if (timePastStart > 1) {
      const duration = assetItem.duration;
      if (duration && timePastStart < duration) {
       startPosition = timePastStart;
      }
     }
    }
    const assetId = assetItem.identifier;
    const playerConfig = _objectSpread2(
     _objectSpread2({}, userConfig),
     {},
     {
      maxMaxBufferLength: Math.min(180, primary.config.maxMaxBufferLength),
      autoStartLoad: true,
      startFragPrefetch: true,
      primarySessionId: primary.sessionId,
      assetPlayerId: assetId,
      abrEwmaDefaultEstimate: primary.bandwidthEstimate,
      interstitialsController: undefined,
      startPosition,
      liveDurationInfinity: false,
      testBandwidth: false,
      videoPreference,
      audioPreference: selectedAudio || userConfig.audioPreference,
      subtitlePreference: selectedSubtitle || userConfig.subtitlePreference,
     },
    );
    // TODO: limit maxMaxBufferLength in asset players to prevent QEE
    if (interstitial.appendInPlace) {
     interstitial.appendInPlaceStarted = true;
     if (assetItem.timelineStart) {
      playerConfig.timelineOffset = assetItem.timelineStart;
     }
    }
    const cmcd = playerConfig.cmcd;
    if (cmcd != null && cmcd.sessionId && cmcd.contentId) {
     playerConfig.cmcd = _extends({}, cmcd, {
      contentId: hash(assetItem.uri),
     });
    }
    if (this.getAssetPlayer(assetId)) {
     this.warn(`Duplicate date range identifier ${interstitial} and asset ${assetId}`);
    }
    const player = new HlsAssetPlayer(this.HlsPlayerClass, playerConfig, interstitial, assetItem);
    this.playerQueue.push(player);
    interstitial.assetList[assetListIndex] = assetItem;
    // Listen for LevelDetails and PTS change to update duration
    let initialDuration = true;
    const updateAssetPlayerDetails = (details) => {
     if (details.live) {
      var _this$schedule9;
      const error = new Error(`Interstitials MUST be VOD assets ${interstitial}`);
      const errorData = {
       fatal: true,
       type: ErrorTypes.OTHER_ERROR,
       details: ErrorDetails.INTERSTITIAL_ASSET_ITEM_ERROR,
       error,
      };
      const scheduleIndex = ((_this$schedule9 = this.schedule) == null ? void 0 : _this$schedule9.findEventIndex(interstitial.identifier)) || -1;
      this.handleAssetItemError(errorData, interstitial, scheduleIndex, assetListIndex, error.message);
      return;
     }
     // Get time at end of last fragment
     const duration = details.edge - details.fragmentStart;
     const currentAssetDuration = assetItem.duration;
     if (initialDuration || currentAssetDuration === null || duration > currentAssetDuration) {
      initialDuration = false;
      this.log(`Interstitial asset "${assetId}" duration change ${currentAssetDuration} > ${duration}`);
      assetItem.duration = duration;
      // Update schedule with new event and asset duration
      this.updateSchedule();
     }
    };
    player.on(Events.LEVEL_UPDATED, (event, { details }) => updateAssetPlayerDetails(details));
    player.on(Events.LEVEL_PTS_UPDATED, (event, { details }) => updateAssetPlayerDetails(details));
    player.on(Events.EVENT_CUE_ENTER, () => this.onInterstitialCueEnter());
    const onBufferCodecs = (event, data) => {
     const inQueuPlayer = this.getAssetPlayer(assetId);
     if (inQueuPlayer && data.tracks) {
      inQueuPlayer.off(Events.BUFFER_CODECS, onBufferCodecs);
      inQueuPlayer.tracks = data.tracks;
      const media = this.primaryMedia;
      if (this.bufferingAsset === inQueuPlayer.assetItem && media && !inQueuPlayer.media) {
       this.bufferAssetPlayer(inQueuPlayer, media);
      }
     }
    };
    player.on(Events.BUFFER_CODECS, onBufferCodecs);
    const bufferedToEnd = () => {
     var _this$schedule$items3;
     const inQueuPlayer = this.getAssetPlayer(assetId);
     this.log(`buffered to end of asset ${inQueuPlayer}`);
     if (!inQueuPlayer || !this.schedule) {
      return;
     }
     // Preload at end of asset
     const scheduleIndex = this.schedule.findEventIndex(interstitial.identifier);
     const item = (_this$schedule$items3 = this.schedule.items) == null ? void 0 : _this$schedule$items3[scheduleIndex];
     if (this.isInterstitial(item)) {
      this.advanceAssetBuffering(item, assetItem);
     }
    };
    player.on(Events.BUFFERED_TO_END, bufferedToEnd);
    const endedWithAssetIndex = (assetIndex) => {
     return () => {
      const inQueuPlayer = this.getAssetPlayer(assetId);
      if (!inQueuPlayer || !this.schedule) {
       return;
      }
      this.shouldPlay = true;
      const scheduleIndex = this.schedule.findEventIndex(interstitial.identifier);
      this.advanceAfterAssetEnded(interstitial, scheduleIndex, assetIndex);
     };
    };
    player.once(Events.MEDIA_ENDED, endedWithAssetIndex(assetListIndex));
    player.once(Events.PLAYOUT_LIMIT_REACHED, endedWithAssetIndex(Infinity));
    player.on(Events.ERROR, (event, data) => {
     if (!this.schedule) {
      return;
     }
     const inQueuPlayer = this.getAssetPlayer(assetId);
     if (data.details === ErrorDetails.BUFFER_STALLED_ERROR) {
      if (inQueuPlayer != null && inQueuPlayer.appendInPlace) {
       this.handleInPlaceStall(interstitial);
       return;
      }
      this.onTimeupdate();
      this.checkBuffer(true);
      return;
     }
     this.handleAssetItemError(data, interstitial, this.schedule.findEventIndex(interstitial.identifier), assetListIndex, `Asset player error ${data.error} ${interstitial}`);
    });
    player.on(Events.DESTROYING, () => {
     const inQueuPlayer = this.getAssetPlayer(assetId);
     if (!inQueuPlayer || !this.schedule) {
      return;
     }
     const error = new Error(`Asset player destroyed unexpectedly ${assetId}`);
     const errorData = {
      fatal: true,
      type: ErrorTypes.OTHER_ERROR,
      details: ErrorDetails.INTERSTITIAL_ASSET_ITEM_ERROR,
      error,
     };
     this.handleAssetItemError(errorData, interstitial, this.schedule.findEventIndex(interstitial.identifier), assetListIndex, error.message);
    });
    this.log(`INTERSTITIAL_ASSET_PLAYER_CREATED ${eventAssetToString(assetItem)}`);
    this.hls.trigger(Events.INTERSTITIAL_ASSET_PLAYER_CREATED, {
     asset: assetItem,
     assetListIndex,
     event: interstitial,
     player,
    });
    return player;
   }
   clearInterstitial(interstitial, toSegment) {
    interstitial.assetList.forEach((asset) => {
     this.clearAssetPlayer(asset.identifier, toSegment);
    });
    // Remove asset list and resolved duration
    interstitial.reset();
   }
   resetAssetPlayer(assetId) {
    // Reset asset player so that it's timeline can be adjusted without reloading the MVP
    const playerIndex = this.getAssetPlayerQueueIndex(assetId);
    if (playerIndex !== -1) {
     this.log(`reset asset player "${assetId}" after error`);
     const player = this.playerQueue[playerIndex];
     this.transferMediaFromPlayer(player, null);
     player.resetDetails();
    }
   }
   clearAssetPlayer(assetId, toSegment) {
    const playerIndex = this.getAssetPlayerQueueIndex(assetId);
    if (playerIndex !== -1) {
     this.log(`clear asset player "${assetId}" toSegment: ${toSegment ? segmentToString(toSegment) : toSegment}`);
     const player = this.playerQueue[playerIndex];
     this.transferMediaFromPlayer(player, toSegment);
     this.playerQueue.splice(playerIndex, 1);
     player.destroy();
    }
   }
   emptyPlayerQueue() {
    let player;
    while ((player = this.playerQueue.pop())) {
     player.destroy();
    }
    this.playerQueue = [];
   }
   startAssetPlayer(player, assetListIndex, scheduleItems, scheduleIndex, media) {
    const { interstitial, assetItem, assetId } = player;
    const assetListLength = interstitial.assetList.length;
    const playingAsset = this.playingAsset;
    this.endedAsset = null;
    this.playingAsset = assetItem;
    if (!playingAsset || playingAsset.identifier !== assetId) {
     if (playingAsset) {
      // Exiting another Interstitial asset
      this.clearAssetPlayer(playingAsset.identifier, scheduleItems[scheduleIndex]);
      delete playingAsset.error;
     }
     this.log(`INTERSTITIAL_ASSET_STARTED ${assetListIndex + 1}/${assetListLength} ${eventAssetToString(assetItem)}`);
     this.hls.trigger(Events.INTERSTITIAL_ASSET_STARTED, {
      asset: assetItem,
      assetListIndex,
      event: interstitial,
      schedule: scheduleItems.slice(0),
      scheduleIndex,
      player,
     });
    }

    // detach media and attach to interstitial player if it does not have another element attached
    this.bufferAssetPlayer(player, media);
   }
   bufferAssetPlayer(player, media) {
    var _this$schedule$items4, _this$detachedData5;
    if (!this.schedule) {
     return;
    }
    const { interstitial, assetItem } = player;
    const scheduleIndex = this.schedule.findEventIndex(interstitial.identifier);
    const item = (_this$schedule$items4 = this.schedule.items) == null ? void 0 : _this$schedule$items4[scheduleIndex];
    if (!item) {
     return;
    }
    player.loadSource();
    this.setBufferingItem(item);
    this.bufferingAsset = assetItem;
    const bufferingPlayer = this.getBufferingPlayer();
    if (bufferingPlayer === player) {
     return;
    }
    const appendInPlaceNext = interstitial.appendInPlace;
    if (appendInPlaceNext && (bufferingPlayer == null ? void 0 : bufferingPlayer.interstitial.appendInPlace) === false) {
     // Media is detached and not available to append in place
     return;
    }
    const activeTracks = (bufferingPlayer == null ? void 0 : bufferingPlayer.tracks) || ((_this$detachedData5 = this.detachedData) == null ? void 0 : _this$detachedData5.tracks) || this.requiredTracks;
    if (appendInPlaceNext && assetItem !== this.playingAsset) {
     // Do not buffer another item if tracks are unknown or incompatible
     if (!player.tracks) {
      this.log(`Waiting for track info before buffering ${player}`);
      return;
     }
     if (activeTracks && !isCompatibleTrackChange(activeTracks, player.tracks)) {
      const error = new Error(`Asset ${eventAssetToString(assetItem)} SourceBuffer tracks ('${Object.keys(player.tracks)}') are not compatible with primary content tracks ('${Object.keys(activeTracks)}')`);
      const errorData = {
       fatal: true,
       type: ErrorTypes.OTHER_ERROR,
       details: ErrorDetails.INTERSTITIAL_ASSET_ITEM_ERROR,
       error,
      };
      const assetListIndex = interstitial.findAssetIndex(assetItem);
      this.handleAssetItemError(errorData, interstitial, scheduleIndex, assetListIndex, error.message);
      return;
     }
    }
    this.transferMediaTo(player, media);
   }
   handleInPlaceStall(interstitial) {
    const schedule = this.schedule;
    const media = this.primaryMedia;
    if (!schedule || !media) {
     return;
    }
    const currentTime = media.currentTime;
    const foundAssetIndex = schedule.findAssetIndex(interstitial, currentTime);
    const stallingAsset = interstitial.assetList[foundAssetIndex];
    if (stallingAsset) {
     const player = this.getAssetPlayer(stallingAsset.identifier);
     if (player) {
      const assetCurrentTime = player.currentTime || currentTime - stallingAsset.timelineStart;
      const distanceFromEnd = player.duration - assetCurrentTime;
      this.warn(`Stalled at ${assetCurrentTime} of ${assetCurrentTime + distanceFromEnd} in ${player} ${interstitial} (media.currentTime: ${currentTime})`);
      if (assetCurrentTime && (distanceFromEnd / media.playbackRate < 0.5 || player.bufferedInPlaceToEnd(media)) && player.hls) {
       const scheduleIndex = schedule.findEventIndex(interstitial.identifier);
       this.advanceAfterAssetEnded(interstitial, scheduleIndex, foundAssetIndex);
      }
     }
    }
   }
   advanceInPlace(time) {
    const media = this.primaryMedia;
    if (media && media.currentTime < time) {
     media.currentTime = time;
    }
   }
   handleAssetItemError(data, interstitial, scheduleIndex, assetListIndex, errorMessage) {
    if (data.details === ErrorDetails.BUFFER_STALLED_ERROR) {
     return;
    }
    const assetItem = interstitial.assetList[assetListIndex] || null;
    this.warn(`INTERSTITIAL_ASSET_ERROR ${assetItem ? eventAssetToString(assetItem) : assetItem} ${data.error}`);
    if (!this.schedule) {
     return;
    }
    const assetId = (assetItem == null ? void 0 : assetItem.identifier) || '';
    const playerIndex = this.getAssetPlayerQueueIndex(assetId);
    const player = this.playerQueue[playerIndex] || null;
    const items = this.schedule.items;
    const interstitialAssetError = _extends({}, data, {
     fatal: false,
     errorAction: createDoNothingErrorAction(true),
     asset: assetItem,
     assetListIndex,
     event: interstitial,
     schedule: items,
     scheduleIndex,
     player,
    });
    this.hls.trigger(Events.INTERSTITIAL_ASSET_ERROR, interstitialAssetError);
    if (!data.fatal) {
     return;
    }
    const playingAsset = this.playingAsset;
    const bufferingAsset = this.bufferingAsset;
    const error = new Error(errorMessage);
    if (assetItem) {
     this.clearAssetPlayer(assetId, null);
     assetItem.error = error;
    }

    // If all assets in interstitial fail, mark the interstitial with an error
    if (!interstitial.assetList.some((asset) => !asset.error)) {
     interstitial.error = error;
    } else {
     // Reset level details and reload/parse media playlists to align with updated schedule
     for (let i = assetListIndex; i < interstitial.assetList.length; i++) {
      this.resetAssetPlayer(interstitial.assetList[i].identifier);
     }
    }
    this.updateSchedule(true);
    if (interstitial.error) {
     this.primaryFallback(interstitial);
    } else if (playingAsset && playingAsset.identifier === assetId) {
     this.advanceAfterAssetEnded(interstitial, scheduleIndex, assetListIndex);
    } else if (bufferingAsset && bufferingAsset.identifier === assetId && this.isInterstitial(this.bufferingItem)) {
     this.advanceAssetBuffering(this.bufferingItem, bufferingAsset);
    }
   }
   primaryFallback(interstitial) {
    // Fallback to Primary by on current or future events by updating schedule to skip errored interstitials/assets
    const flushStart = interstitial.timelineStart;
    const playingItem = this.effectivePlayingItem;
    // Update schedule now that interstitial/assets are flagged with `error` for fallback
    if (playingItem) {
     this.log(`Fallback to primary from event "${interstitial.identifier}" start: ${flushStart} pos: ${this.timelinePos} playing: ${segmentToString(playingItem)} error: ${interstitial.error}`);
     let timelinePos = this.timelinePos;
     if (timelinePos === -1) {
      timelinePos = this.hls.startPosition;
     }
     const newPlayingItem = this.updateItem(playingItem, timelinePos);
     if (this.itemsMatch(playingItem, newPlayingItem)) {
      this.clearInterstitial(interstitial, null);
     }
     if (interstitial.appendInPlace) {
      this.attachPrimary(flushStart, null);
      this.flushFrontBuffer(flushStart);
     }
     if (!this.schedule) {
      return;
     }
     const scheduleIndex = this.schedule.findItemIndexAtTime(timelinePos);
     this.setSchedulePosition(scheduleIndex);
    } else {
     this.checkStart();
    }
   }

   // Asset List loading
   onAssetListLoaded(event, data) {
    var _this$schedule0, _this$bufferingItem2;
    const interstitial = data.event;
    const interstitialId = interstitial.identifier;
    const assets = data.assetListResponse.ASSETS;
    if (!((_this$schedule0 = this.schedule) != null && _this$schedule0.hasEvent(interstitialId))) {
     // Interstitial with id was removed
     return;
    }
    const eventStart = interstitial.timelineStart;
    const previousDuration = interstitial.duration;
    let sumDuration = 0;
    assets.forEach((asset, assetListIndex) => {
     const duration = parseFloat(asset.DURATION);
     this.createAsset(interstitial, assetListIndex, sumDuration, eventStart + sumDuration, duration, asset.URI);
     sumDuration += duration;
    });
    interstitial.duration = sumDuration;
    this.log(`Loaded asset-list with duration: ${sumDuration} (was: ${previousDuration}) ${interstitial}`);
    const waitingItem = this.waitingItem;
    const waitingForItem = (waitingItem == null ? void 0 : waitingItem.event.identifier) === interstitialId;

    // Update schedule now that asset.DURATION(s) are parsed
    this.updateSchedule();
    const bufferingEvent = (_this$bufferingItem2 = this.bufferingItem) == null ? void 0 : _this$bufferingItem2.event;

    // If buffer reached Interstitial, start buffering first asset
    if (waitingForItem) {
     var _this$schedule$items5;
     // Advance schedule when waiting for asset list data to play
     const scheduleIndex = this.schedule.findEventIndex(interstitialId);
     const item = (_this$schedule$items5 = this.schedule.items) == null ? void 0 : _this$schedule$items5[scheduleIndex];
     if (item) {
      if (!this.playingItem && this.timelinePos > item.end) {
       // Abandon if new duration is reduced enough to land playback in primary start
       const index = this.schedule.findItemIndexAtTime(this.timelinePos);
       if (index !== scheduleIndex) {
        interstitial.error = new Error(`Interstitial no longer within playback range ${this.timelinePos} ${interstitial}`);
        this.updateSchedule(true);
        this.primaryFallback(interstitial);
        return;
       }
      }
      this.setBufferingItem(item);
     }
     this.setSchedulePosition(scheduleIndex);
    } else if ((bufferingEvent == null ? void 0 : bufferingEvent.identifier) === interstitialId) {
     const assetItem = interstitial.assetList[0];
     // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition
     if (assetItem) {
      const player = this.getAssetPlayer(assetItem.identifier);
      if (bufferingEvent.appendInPlace) {
       // If buffering (but not playback) has reached this item transfer media-source
       const media = this.primaryMedia;
       if (player && media) {
        this.bufferAssetPlayer(player, media);
       }
      } else if (player) {
       player.loadSource();
      }
     }
    }
   }
   onError(event, data) {
    if (!this.schedule) {
     return;
    }
    switch (data.details) {
     case ErrorDetails.ASSET_LIST_PARSING_ERROR:
     case ErrorDetails.ASSET_LIST_LOAD_ERROR:
     case ErrorDetails.ASSET_LIST_LOAD_TIMEOUT: {
      const interstitial = data.interstitial;
      if (interstitial) {
       this.updateSchedule(true);
       this.primaryFallback(interstitial);
      }
      break;
     }
     case ErrorDetails.BUFFER_STALLED_ERROR: {
      const stallingItem = this.endedItem || this.waitingItem || this.playingItem;
      if (this.isInterstitial(stallingItem) && stallingItem.event.appendInPlace) {
       this.handleInPlaceStall(stallingItem.event);
       return;
      }
      this.log(`Primary player stall @${this.timelinePos} bufferedPos: ${this.bufferedPos}`);
      this.onTimeupdate();
      this.checkBuffer(true);
      break;
     }
    }
   }
  }

  const TICK_INTERVAL$2 = 500; // how often to tick in ms

  class SubtitleStreamController extends BaseStreamController {
   constructor(hls, fragmentTracker, keyLoader) {
    super(hls, fragmentTracker, keyLoader, 'subtitle-stream-controller', PlaylistLevelType.SUBTITLE);
    this.currentTrackId = -1;
    this.tracksBuffered = [];
    this.mainDetails = null;
    this.registerListeners();
   }
   onHandlerDestroying() {
    this.unregisterListeners();
    super.onHandlerDestroying();
    this.mainDetails = null;
   }
   registerListeners() {
    super.registerListeners();
    const { hls } = this;
    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.on(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
    hls.on(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);
    hls.on(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
    hls.on(Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);
    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
   }
   unregisterListeners() {
    super.unregisterListeners();
    const { hls } = this;
    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.off(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
    hls.off(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);
    hls.off(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
    hls.off(Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);
    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
   }
   startLoad(startPosition, skipSeekToStartPosition) {
    this.stopLoad();
    this.state = State.IDLE;
    this.setInterval(TICK_INTERVAL$2);
    this.nextLoadPosition = this.lastCurrentTime = startPosition + this.timelineOffset;
    this.startPosition = skipSeekToStartPosition ? -1 : startPosition;
    this.tick();
   }
   onManifestLoading() {
    super.onManifestLoading();
    this.mainDetails = null;
   }
   onMediaDetaching(event, data) {
    this.tracksBuffered = [];
    super.onMediaDetaching(event, data);
   }
   onLevelLoaded(event, data) {
    this.mainDetails = data.details;
   }
   onSubtitleFragProcessed(event, data) {
    const { frag, success } = data;
    if (!this.fragContextChanged(frag)) {
     if (isMediaFragment(frag)) {
      this.fragPrevious = frag;
     }
     this.state = State.IDLE;
    }
    if (!success) {
     return;
    }
    const buffered = this.tracksBuffered[this.currentTrackId];
    if (!buffered) {
     return;
    }

    // Create/update a buffered array matching the interface used by BufferHelper.bufferedInfo
    // so we can re-use the logic used to detect how much has been buffered
    let timeRange;
    const fragStart = frag.start;
    for (let i = 0; i < buffered.length; i++) {
     if (fragStart >= buffered[i].start && fragStart <= buffered[i].end) {
      timeRange = buffered[i];
      break;
     }
    }
    const fragEnd = frag.start + frag.duration;
    if (timeRange) {
     timeRange.end = fragEnd;
    } else {
     timeRange = {
      start: fragStart,
      end: fragEnd,
     };
     buffered.push(timeRange);
    }
    this.fragmentTracker.fragBuffered(frag);
    this.fragBufferedComplete(frag, null);
    if (this.media) {
     this.tick();
    }
   }
   onBufferFlushing(event, data) {
    const { startOffset, endOffset } = data;
    if (startOffset === 0 && endOffset !== Number.POSITIVE_INFINITY) {
     const endOffsetSubtitles = endOffset - 1;
     if (endOffsetSubtitles <= 0) {
      return;
     }
     data.endOffsetSubtitles = Math.max(0, endOffsetSubtitles);
     this.tracksBuffered.forEach((buffered) => {
      for (let i = 0; i < buffered.length; ) {
       if (buffered[i].end <= endOffsetSubtitles) {
        buffered.shift();
        continue;
       } else if (buffered[i].start < endOffsetSubtitles) {
        buffered[i].start = endOffsetSubtitles;
       } else {
        break;
       }
       i++;
      }
     });
     this.fragmentTracker.removeFragmentsInRange(startOffset, endOffsetSubtitles, PlaylistLevelType.SUBTITLE);
    }
   }

   // If something goes wrong, proceed to next frag, if we were processing one.
   onError(event, data) {
    const frag = data.frag;
    if ((frag == null ? void 0 : frag.type) === PlaylistLevelType.SUBTITLE) {
     if (data.details === ErrorDetails.FRAG_GAP) {
      this.fragmentTracker.fragBuffered(frag, true);
     }
     if (this.fragCurrent) {
      this.fragCurrent.abortRequests();
     }
     if (this.state !== State.STOPPED) {
      this.state = State.IDLE;
     }
    }
   }

   // Got all new subtitle levels.
   onSubtitleTracksUpdated(event, { subtitleTracks }) {
    if (this.levels && subtitleOptionsIdentical(this.levels, subtitleTracks)) {
     this.levels = subtitleTracks.map((mediaPlaylist) => new Level(mediaPlaylist));
     return;
    }
    this.tracksBuffered = [];
    this.levels = subtitleTracks.map((mediaPlaylist) => {
     const level = new Level(mediaPlaylist);
     this.tracksBuffered[level.id] = [];
     return level;
    });
    this.fragmentTracker.removeFragmentsInRange(0, Number.POSITIVE_INFINITY, PlaylistLevelType.SUBTITLE);
    this.fragPrevious = null;
    this.mediaBuffer = null;
   }
   onSubtitleTrackSwitch(event, data) {
    var _this$levels;
    this.currentTrackId = data.id;
    if (!((_this$levels = this.levels) != null && _this$levels.length) || this.currentTrackId === -1) {
     this.clearInterval();
     return;
    }

    // Check if track has the necessary details to load fragments
    const currentTrack = this.levels[this.currentTrackId];
    if (currentTrack != null && currentTrack.details) {
     this.mediaBuffer = this.mediaBufferTimeRanges;
    } else {
     this.mediaBuffer = null;
    }
    if (currentTrack && this.state !== State.STOPPED) {
     this.setInterval(TICK_INTERVAL$2);
    }
   }

   // Got a new set of subtitle fragments.
   onSubtitleTrackLoaded(event, data) {
    var _track$details;
    const { currentTrackId, levels } = this;
    const { details: newDetails, id: trackId } = data;
    if (!levels) {
     this.warn(`Subtitle tracks were reset while loading level ${trackId}`);
     return;
    }
    const track = levels[trackId];
    if (trackId >= levels.length || !track) {
     return;
    }
    this.log(`Subtitle track ${trackId} loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''},duration:${newDetails.totalduration}`);
    this.mediaBuffer = this.mediaBufferTimeRanges;
    let sliding = 0;
    if (newDetails.live || ((_track$details = track.details) != null && _track$details.live)) {
     if (newDetails.deltaUpdateFailed) {
      return;
     }
     const mainDetails = this.mainDetails;
     if (!mainDetails) {
      this.startFragRequested = false;
      return;
     }
     const mainSlidingStartFragment = mainDetails.fragments[0];
     if (!track.details) {
      if (newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {
       alignMediaPlaylistByPDT(newDetails, mainDetails);
       sliding = newDetails.fragmentStart;
      } else if (mainSlidingStartFragment) {
       // line up live playlist with main so that fragments in range are loaded
       sliding = mainSlidingStartFragment.start;
       addSliding(newDetails, sliding);
      }
     } else {
      var _this$levelLastLoaded;
      sliding = this.alignPlaylists(newDetails, track.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);
      if (sliding === 0 && mainSlidingStartFragment) {
       // realign with main when there is no overlap with last refresh
       sliding = mainSlidingStartFragment.start;
       addSliding(newDetails, sliding);
      }
     }
     // compute start position if we are aligned with the main playlist
     if (mainDetails && !this.startFragRequested) {
      this.setStartPosition(mainDetails, sliding);
     }
    }
    track.details = newDetails;
    this.levelLastLoaded = track;
    if (trackId !== currentTrackId) {
     return;
    }
    this.hls.trigger(Events.SUBTITLE_TRACK_UPDATED, {
     details: newDetails,
     id: trackId,
     groupId: data.groupId,
    });

    // trigger handler right now
    this.tick();

    // If playlist is misaligned because of bad PDT or drift, delete details to resync with main on reload
    if (newDetails.live && !this.fragCurrent && this.media && this.state === State.IDLE) {
     const foundFrag = findFragmentByPTS(null, newDetails.fragments, this.media.currentTime, 0);
     if (!foundFrag) {
      this.warn('Subtitle playlist not aligned with playback');
      track.details = undefined;
     }
    }
   }
   _handleFragmentLoadComplete(fragLoadedData) {
    const { frag, payload } = fragLoadedData;
    const decryptData = frag.decryptdata;
    const hls = this.hls;
    if (this.fragContextChanged(frag)) {
     return;
    }
    // check to see if the payload needs to be decrypted
    if (payload && payload.byteLength > 0 && decryptData != null && decryptData.key && decryptData.iv && isFullSegmentEncryption(decryptData.method)) {
     const startTime = performance.now();
     // decrypt the subtitles
     this.decrypter
      .decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer, getAesModeFromFullSegmentMethod(decryptData.method))
      .catch((err) => {
       hls.trigger(Events.ERROR, {
        type: ErrorTypes.MEDIA_ERROR,
        details: ErrorDetails.FRAG_DECRYPT_ERROR,
        fatal: false,
        error: err,
        reason: err.message,
        frag,
       });
       throw err;
      })
      .then((decryptedData) => {
       const endTime = performance.now();
       hls.trigger(Events.FRAG_DECRYPTED, {
        frag,
        payload: decryptedData,
        stats: {
         tstart: startTime,
         tdecrypt: endTime,
        },
       });
      })
      .catch((err) => {
       this.warn(`${err.name}: ${err.message}`);
       this.state = State.IDLE;
      });
    }
   }
   doTick() {
    if (!this.media) {
     this.state = State.IDLE;
     return;
    }
    if (this.state === State.IDLE) {
     const { currentTrackId, levels } = this;
     const track = levels == null ? void 0 : levels[currentTrackId];
     if (!track || !levels.length || !track.details) {
      return;
     }
     if (this.waitForLive(track)) {
      return;
     }
     const { config } = this;
     const currentTime = this.getLoadPosition();
     const bufferedInfo = BufferHelper.bufferedInfo(this.tracksBuffered[this.currentTrackId] || [], currentTime, config.maxBufferHole);
     const { end: targetBufferTime, len: bufferLen } = bufferedInfo;
     const trackDetails = track.details;
     const maxBufLen = this.hls.maxBufferLength + trackDetails.levelTargetDuration;
     if (bufferLen > maxBufLen) {
      return;
     }
     const fragments = trackDetails.fragments;
     const fragLen = fragments.length;
     const end = trackDetails.edge;
     let foundFrag = null;
     const fragPrevious = this.fragPrevious;
     if (targetBufferTime < end) {
      const tolerance = config.maxFragLookUpTolerance;
      const lookupTolerance = targetBufferTime > end - tolerance ? 0 : tolerance;
      foundFrag = findFragmentByPTS(fragPrevious, fragments, Math.max(fragments[0].start, targetBufferTime), lookupTolerance);
      if (!foundFrag && fragPrevious && fragPrevious.start < fragments[0].start) {
       foundFrag = fragments[0];
      }
     } else {
      foundFrag = fragments[fragLen - 1];
     }
     foundFrag = this.filterReplacedPrimary(foundFrag, track.details);
     if (!foundFrag) {
      return;
     }
     // Load earlier fragment in same discontinuity to make up for misaligned playlists and cues that extend beyond end of segment
     const curSNIdx = foundFrag.sn - trackDetails.startSN;
     const prevFrag = fragments[curSNIdx - 1];
     if (prevFrag && prevFrag.cc === foundFrag.cc && this.fragmentTracker.getState(prevFrag) === FragmentState.NOT_LOADED) {
      foundFrag = prevFrag;
     }
     if (this.fragmentTracker.getState(foundFrag) === FragmentState.NOT_LOADED) {
      // only load if fragment is not loaded
      const fragToLoad = this.mapToInitFragWhenRequired(foundFrag);
      if (fragToLoad) {
       this.loadFragment(fragToLoad, track, targetBufferTime);
      }
     }
    }
   }
   loadFragment(frag, level, targetBufferTime) {
    if (!isMediaFragment(frag)) {
     this._loadInitSegment(frag, level);
    } else {
     super.loadFragment(frag, level, targetBufferTime);
    }
   }
   get mediaBufferTimeRanges() {
    return new BufferableInstance(this.tracksBuffered[this.currentTrackId] || []);
   }
  }
  class BufferableInstance {
   constructor(timeranges) {
    this.buffered = void 0;
    const getRange = (name, index, length) => {
     index = index >>> 0;
     if (index > length - 1) {
      throw new DOMException(`Failed to execute '${name}' on 'TimeRanges': The index provided (${index}) is greater than the maximum bound (${length})`);
     }
     return timeranges[index][name];
    };
    this.buffered = {
     get length() {
      return timeranges.length;
     },
     end(index) {
      return getRange('end', index, timeranges.length);
     },
     start(index) {
      return getRange('start', index, timeranges.length);
     },
    };
   }
  }

  /**
   *
   * This code was ported from the dash.js project at:
   *   https://github.com/Dash-Industry-Forum/dash.js/blob/development/externals/cea608-parser.js
   *   https://github.com/Dash-Industry-Forum/dash.js/commit/8269b26a761e0853bb21d78780ed945144ecdd4d#diff-71bc295a2d6b6b7093a1d3290d53a4b2
   *
   * The original copyright appears below:
   *
   * The copyright in this software is being made available under the BSD License,
   * included below. This software may be subject to other third party and contributor
   * rights, including patent rights, and no such rights are granted under this license.
   *
   * Copyright (c) 2015-2016, DASH Industry Forum.
   * All rights reserved.
   *
   * Redistribution and use in source and binary forms, with or without modification,
   * are permitted provided that the following conditions are met:
   *  1. Redistributions of source code must retain the above copyright notice, this
   *  list of conditions and the following disclaimer.
   *  * Redistributions in binary form must reproduce the above copyright notice,
   *  this list of conditions and the following disclaimer in the documentation and/or
   *  other materials provided with the distribution.
   *  2. Neither the name of Dash Industry Forum nor the names of its
   *  contributors may be used to endorse or promote products derived from this software
   *  without specific prior written permission.
   *
   *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS AS IS AND ANY
   *  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
   *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
   *  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
   *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
   *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
   *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
   *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
   *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
   *  POSSIBILITY OF SUCH DAMAGE.
   */
  /**
   *  Exceptions from regular ASCII. CodePoints are mapped to UTF-16 codes
   */

  const specialCea608CharsCodes = {
   0x2a: 0xe1,
   // lowercase a, acute accent
   0x5c: 0xe9,
   // lowercase e, acute accent
   0x5e: 0xed,
   // lowercase i, acute accent
   0x5f: 0xf3,
   // lowercase o, acute accent
   0x60: 0xfa,
   // lowercase u, acute accent
   0x7b: 0xe7,
   // lowercase c with cedilla
   0x7c: 0xf7,
   // division symbol
   0x7d: 0xd1,
   // uppercase N tilde
   0x7e: 0xf1,
   // lowercase n tilde
   0x7f: 0x2588,
   // Full block
   // THIS BLOCK INCLUDES THE 16 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
   // THAT COME FROM HI BYTE=0x11 AND LOW BETWEEN 0x30 AND 0x3F
   // THIS MEANS THAT \x50 MUST BE ADDED TO THE VALUES
   0x80: 0xae,
   // Registered symbol (R)
   0x81: 0xb0,
   // degree sign
   0x82: 0xbd,
   // 1/2 symbol
   0x83: 0xbf,
   // Inverted (open) question mark
   0x84: 0x2122,
   // Trademark symbol (TM)
   0x85: 0xa2,
   // Cents symbol
   0x86: 0xa3,
   // Pounds sterling
   0x87: 0x266a,
   // Music 8'th note
   0x88: 0xe0,
   // lowercase a, grave accent
   0x89: 0x20,
   // transparent space (regular)
   0x8a: 0xe8,
   // lowercase e, grave accent
   0x8b: 0xe2,
   // lowercase a, circumflex accent
   0x8c: 0xea,
   // lowercase e, circumflex accent
   0x8d: 0xee,
   // lowercase i, circumflex accent
   0x8e: 0xf4,
   // lowercase o, circumflex accent
   0x8f: 0xfb,
   // lowercase u, circumflex accent
   // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
   // THAT COME FROM HI BYTE=0x12 AND LOW BETWEEN 0x20 AND 0x3F
   0x90: 0xc1,
   // capital letter A with acute
   0x91: 0xc9,
   // capital letter E with acute
   0x92: 0xd3,
   // capital letter O with acute
   0x93: 0xda,
   // capital letter U with acute
   0x94: 0xdc,
   // capital letter U with diaresis
   0x95: 0xfc,
   // lowercase letter U with diaeresis
   0x96: 0x2018,
   // opening single quote
   0x97: 0xa1,
   // inverted exclamation mark
   0x98: 0x2a,
   // asterisk
   0x99: 0x2019,
   // closing single quote
   0x9a: 0x2501,
   // box drawings heavy horizontal
   0x9b: 0xa9,
   // copyright sign
   0x9c: 0x2120,
   // Service mark
   0x9d: 0x2022,
   // (round) bullet
   0x9e: 0x201c,
   // Left double quotation mark
   0x9f: 0x201d,
   // Right double quotation mark
   0xa0: 0xc0,
   // uppercase A, grave accent
   0xa1: 0xc2,
   // uppercase A, circumflex
   0xa2: 0xc7,
   // uppercase C with cedilla
   0xa3: 0xc8,
   // uppercase E, grave accent
   0xa4: 0xca,
   // uppercase E, circumflex
   0xa5: 0xcb,
   // capital letter E with diaresis
   0xa6: 0xeb,
   // lowercase letter e with diaresis
   0xa7: 0xce,
   // uppercase I, circumflex
   0xa8: 0xcf,
   // uppercase I, with diaresis
   0xa9: 0xef,
   // lowercase i, with diaresis
   0xaa: 0xd4,
   // uppercase O, circumflex
   0xab: 0xd9,
   // uppercase U, grave accent
   0xac: 0xf9,
   // lowercase u, grave accent
   0xad: 0xdb,
   // uppercase U, circumflex
   0xae: 0xab,
   // left-pointing double angle quotation mark
   0xaf: 0xbb,
   // right-pointing double angle quotation mark
   // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
   // THAT COME FROM HI BYTE=0x13 AND LOW BETWEEN 0x20 AND 0x3F
   0xb0: 0xc3,
   // Uppercase A, tilde
   0xb1: 0xe3,
   // Lowercase a, tilde
   0xb2: 0xcd,
   // Uppercase I, acute accent
   0xb3: 0xcc,
   // Uppercase I, grave accent
   0xb4: 0xec,
   // Lowercase i, grave accent
   0xb5: 0xd2,
   // Uppercase O, grave accent
   0xb6: 0xf2,
   // Lowercase o, grave accent
   0xb7: 0xd5,
   // Uppercase O, tilde
   0xb8: 0xf5,
   // Lowercase o, tilde
   0xb9: 0x7b,
   // Open curly brace
   0xba: 0x7d,
   // Closing curly brace
   0xbb: 0x5c,
   // Backslash
   0xbc: 0x5e,
   // Caret
   0xbd: 0x5f,
   // Underscore
   0xbe: 0x7c,
   // Pipe (vertical line)
   0xbf: 0x223c,
   // Tilde operator
   0xc0: 0xc4,
   // Uppercase A, umlaut
   0xc1: 0xe4,
   // Lowercase A, umlaut
   0xc2: 0xd6,
   // Uppercase O, umlaut
   0xc3: 0xf6,
   // Lowercase o, umlaut
   0xc4: 0xdf,
   // Esszett (sharp S)
   0xc5: 0xa5,
   // Yen symbol
   0xc6: 0xa4,
   // Generic currency sign
   0xc7: 0x2503,
   // Box drawings heavy vertical
   0xc8: 0xc5,
   // Uppercase A, ring
   0xc9: 0xe5,
   // Lowercase A, ring
   0xca: 0xd8,
   // Uppercase O, stroke
   0xcb: 0xf8,
   // Lowercase o, strok
   0xcc: 0x250f,
   // Box drawings heavy down and right
   0xcd: 0x2513,
   // Box drawings heavy down and left
   0xce: 0x2517,
   // Box drawings heavy up and right
   0xcf: 0x251b, // Box drawings heavy up and left
  };

  /**
   * Utils
   */
  const getCharForByte = (byte) => String.fromCharCode(specialCea608CharsCodes[byte] || byte);
  const NR_ROWS = 15;
  const NR_COLS = 100;
  // Tables to look up row from PAC data
  const rowsLowCh1 = {
   0x11: 1,
   0x12: 3,
   0x15: 5,
   0x16: 7,
   0x17: 9,
   0x10: 11,
   0x13: 12,
   0x14: 14,
  };
  const rowsHighCh1 = {
   0x11: 2,
   0x12: 4,
   0x15: 6,
   0x16: 8,
   0x17: 10,
   0x13: 13,
   0x14: 15,
  };
  const rowsLowCh2 = {
   0x19: 1,
   0x1a: 3,
   0x1d: 5,
   0x1e: 7,
   0x1f: 9,
   0x18: 11,
   0x1b: 12,
   0x1c: 14,
  };
  const rowsHighCh2 = {
   0x19: 2,
   0x1a: 4,
   0x1d: 6,
   0x1e: 8,
   0x1f: 10,
   0x1b: 13,
   0x1c: 15,
  };
  const backgroundColors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'black', 'transparent'];
  class CaptionsLogger {
   constructor() {
    this.time = null;
    this.verboseLevel = 0;
   }
   log(severity, msg) {
    if (this.verboseLevel >= severity) {
     const m = typeof msg === 'function' ? msg() : msg;
     logger.log(`${this.time} [${severity}] ${m}`);
    }
   }
  }
  const numArrayToHexArray = function numArrayToHexArray(numArray) {
   const hexArray = [];
   for (let j = 0; j < numArray.length; j++) {
    hexArray.push(numArray[j].toString(16));
   }
   return hexArray;
  };
  class PenState {
   constructor() {
    this.foreground = 'white';
    this.underline = false;
    this.italics = false;
    this.background = 'black';
    this.flash = false;
   }
   reset() {
    this.foreground = 'white';
    this.underline = false;
    this.italics = false;
    this.background = 'black';
    this.flash = false;
   }
   setStyles(styles) {
    const attribs = ['foreground', 'underline', 'italics', 'background', 'flash'];
    for (let i = 0; i < attribs.length; i++) {
     const style = attribs[i];
     if (styles.hasOwnProperty(style)) {
      this[style] = styles[style];
     }
    }
   }
   isDefault() {
    return this.foreground === 'white' && !this.underline && !this.italics && this.background === 'black' && !this.flash;
   }
   equals(other) {
    return this.foreground === other.foreground && this.underline === other.underline && this.italics === other.italics && this.background === other.background && this.flash === other.flash;
   }
   copy(newPenState) {
    this.foreground = newPenState.foreground;
    this.underline = newPenState.underline;
    this.italics = newPenState.italics;
    this.background = newPenState.background;
    this.flash = newPenState.flash;
   }
   toString() {
    return 'color=' + this.foreground + ', underline=' + this.underline + ', italics=' + this.italics + ', background=' + this.background + ', flash=' + this.flash;
   }
  }

  /**
   * Unicode character with styling and background.
   * @constructor
   */
  class StyledUnicodeChar {
   constructor() {
    this.uchar = ' ';
    this.penState = new PenState();
   }
   reset() {
    this.uchar = ' ';
    this.penState.reset();
   }
   setChar(uchar, newPenState) {
    this.uchar = uchar;
    this.penState.copy(newPenState);
   }
   setPenState(newPenState) {
    this.penState.copy(newPenState);
   }
   equals(other) {
    return this.uchar === other.uchar && this.penState.equals(other.penState);
   }
   copy(newChar) {
    this.uchar = newChar.uchar;
    this.penState.copy(newChar.penState);
   }
   isEmpty() {
    return this.uchar === ' ' && this.penState.isDefault();
   }
  }

  /**
   * CEA-608 row consisting of NR_COLS instances of StyledUnicodeChar.
   * @constructor
   */
  class Row {
   constructor(logger) {
    this.chars = [];
    this.pos = 0;
    this.currPenState = new PenState();
    this.cueStartTime = null;
    this.logger = void 0;
    for (let i = 0; i < NR_COLS; i++) {
     this.chars.push(new StyledUnicodeChar());
    }
    this.logger = logger;
   }
   equals(other) {
    for (let i = 0; i < NR_COLS; i++) {
     if (!this.chars[i].equals(other.chars[i])) {
      return false;
     }
    }
    return true;
   }
   copy(other) {
    for (let i = 0; i < NR_COLS; i++) {
     this.chars[i].copy(other.chars[i]);
    }
   }
   isEmpty() {
    let empty = true;
    for (let i = 0; i < NR_COLS; i++) {
     if (!this.chars[i].isEmpty()) {
      empty = false;
      break;
     }
    }
    return empty;
   }

   /**
    *  Set the cursor to a valid column.
    */
   setCursor(absPos) {
    if (this.pos !== absPos) {
     this.pos = absPos;
    }
    if (this.pos < 0) {
     this.logger.log(3, 'Negative cursor position ' + this.pos);
     this.pos = 0;
    } else if (this.pos > NR_COLS) {
     this.logger.log(3, 'Too large cursor position ' + this.pos);
     this.pos = NR_COLS;
    }
   }

   /**
    * Move the cursor relative to current position.
    */
   moveCursor(relPos) {
    const newPos = this.pos + relPos;
    if (relPos > 1) {
     for (let i = this.pos + 1; i < newPos + 1; i++) {
      this.chars[i].setPenState(this.currPenState);
     }
    }
    this.setCursor(newPos);
   }

   /**
    * Backspace, move one step back and clear character.
    */
   backSpace() {
    this.moveCursor(-1);
    this.chars[this.pos].setChar(' ', this.currPenState);
   }
   insertChar(byte) {
    if (byte >= 0x90) {
     // Extended char
     this.backSpace();
    }
    const char = getCharForByte(byte);
    if (this.pos >= NR_COLS) {
     this.logger.log(0, () => 'Cannot insert ' + byte.toString(16) + ' (' + char + ') at position ' + this.pos + '. Skipping it!');
     return;
    }
    this.chars[this.pos].setChar(char, this.currPenState);
    this.moveCursor(1);
   }
   clearFromPos(startPos) {
    let i;
    for (i = startPos; i < NR_COLS; i++) {
     this.chars[i].reset();
    }
   }
   clear() {
    this.clearFromPos(0);
    this.pos = 0;
    this.currPenState.reset();
   }
   clearToEndOfRow() {
    this.clearFromPos(this.pos);
   }
   getTextString() {
    const chars = [];
    let empty = true;
    for (let i = 0; i < NR_COLS; i++) {
     const char = this.chars[i].uchar;
     if (char !== ' ') {
      empty = false;
     }
     chars.push(char);
    }
    if (empty) {
     return '';
    } else {
     return chars.join('');
    }
   }
   setPenStyles(styles) {
    this.currPenState.setStyles(styles);
    const currChar = this.chars[this.pos];
    currChar.setPenState(this.currPenState);
   }
  }

  /**
   * Keep a CEA-608 screen of 32x15 styled characters
   * @constructor
   */
  class CaptionScreen {
   constructor(logger) {
    this.rows = [];
    this.currRow = NR_ROWS - 1;
    this.nrRollUpRows = null;
    this.lastOutputScreen = null;
    this.logger = void 0;
    for (let i = 0; i < NR_ROWS; i++) {
     this.rows.push(new Row(logger));
    }
    this.logger = logger;
   }
   reset() {
    for (let i = 0; i < NR_ROWS; i++) {
     this.rows[i].clear();
    }
    this.currRow = NR_ROWS - 1;
   }
   equals(other) {
    let equal = true;
    for (let i = 0; i < NR_ROWS; i++) {
     if (!this.rows[i].equals(other.rows[i])) {
      equal = false;
      break;
     }
    }
    return equal;
   }
   copy(other) {
    for (let i = 0; i < NR_ROWS; i++) {
     this.rows[i].copy(other.rows[i]);
    }
   }
   isEmpty() {
    let empty = true;
    for (let i = 0; i < NR_ROWS; i++) {
     if (!this.rows[i].isEmpty()) {
      empty = false;
      break;
     }
    }
    return empty;
   }
   backSpace() {
    const row = this.rows[this.currRow];
    row.backSpace();
   }
   clearToEndOfRow() {
    const row = this.rows[this.currRow];
    row.clearToEndOfRow();
   }

   /**
    * Insert a character (without styling) in the current row.
    */
   insertChar(char) {
    const row = this.rows[this.currRow];
    row.insertChar(char);
   }
   setPen(styles) {
    const row = this.rows[this.currRow];
    row.setPenStyles(styles);
   }
   moveCursor(relPos) {
    const row = this.rows[this.currRow];
    row.moveCursor(relPos);
   }
   setCursor(absPos) {
    this.logger.log(2, 'setCursor: ' + absPos);
    const row = this.rows[this.currRow];
    row.setCursor(absPos);
   }
   setPAC(pacData) {
    this.logger.log(2, () => 'pacData = ' + stringify(pacData));
    let newRow = pacData.row - 1;
    if (this.nrRollUpRows && newRow < this.nrRollUpRows - 1) {
     newRow = this.nrRollUpRows - 1;
    }

    // Make sure this only affects Roll-up Captions by checking this.nrRollUpRows
    if (this.nrRollUpRows && this.currRow !== newRow) {
     // clear all rows first
     for (let i = 0; i < NR_ROWS; i++) {
      this.rows[i].clear();
     }

     // Copy this.nrRollUpRows rows from lastOutputScreen and place it in the newRow location
     // topRowIndex - the start of rows to copy (inclusive index)
     const topRowIndex = this.currRow + 1 - this.nrRollUpRows;
     // We only copy if the last position was already shown.
     // We use the cueStartTime value to check this.
     const lastOutputScreen = this.lastOutputScreen;
     if (lastOutputScreen) {
      const prevLineTime = lastOutputScreen.rows[topRowIndex].cueStartTime;
      const time = this.logger.time;
      if (prevLineTime !== null && time !== null && prevLineTime < time) {
       for (let i = 0; i < this.nrRollUpRows; i++) {
        this.rows[newRow - this.nrRollUpRows + i + 1].copy(lastOutputScreen.rows[topRowIndex + i]);
       }
      }
     }
    }
    this.currRow = newRow;
    const row = this.rows[this.currRow];
    if (pacData.indent !== null) {
     const indent = pacData.indent;
     const prevPos = Math.max(indent - 1, 0);
     row.setCursor(pacData.indent);
     pacData.color = row.chars[prevPos].penState.foreground;
    }
    const styles = {
     foreground: pacData.color,
     underline: pacData.underline,
     italics: pacData.italics,
     background: 'black',
     flash: false,
    };
    this.setPen(styles);
   }

   /**
    * Set background/extra foreground, but first do back_space, and then insert space (backwards compatibility).
    */
   setBkgData(bkgData) {
    this.logger.log(2, () => 'bkgData = ' + stringify(bkgData));
    this.backSpace();
    this.setPen(bkgData);
    this.insertChar(0x20); // Space
   }
   setRollUpRows(nrRows) {
    this.nrRollUpRows = nrRows;
   }
   rollUp() {
    if (this.nrRollUpRows === null) {
     this.logger.log(3, 'roll_up but nrRollUpRows not set yet');
     return; // Not properly setup
    }
    this.logger.log(1, () => this.getDisplayText());
    const topRowIndex = this.currRow + 1 - this.nrRollUpRows;
    const topRow = this.rows.splice(topRowIndex, 1)[0];
    topRow.clear();
    this.rows.splice(this.currRow, 0, topRow);
    this.logger.log(2, 'Rolling up');
    // this.logger.log(VerboseLevel.TEXT, this.get_display_text())
   }

   /**
    * Get all non-empty rows with as unicode text.
    */
   getDisplayText(asOneRow) {
    asOneRow = asOneRow || false;
    const displayText = [];
    let text = '';
    let rowNr = -1;
    for (let i = 0; i < NR_ROWS; i++) {
     const rowText = this.rows[i].getTextString();
     if (rowText) {
      rowNr = i + 1;
      if (asOneRow) {
       displayText.push('Row ' + rowNr + ": '" + rowText + "'");
      } else {
       displayText.push(rowText.trim());
      }
     }
    }
    if (displayText.length > 0) {
     if (asOneRow) {
      text = '[' + displayText.join(' | ') + ']';
     } else {
      text = displayText.join('\n');
     }
    }
    return text;
   }
   getTextAndFormat() {
    return this.rows;
   }
  }

  // var modes = ['MODE_ROLL-UP', 'MODE_POP-ON', 'MODE_PAINT-ON', 'MODE_TEXT'];

  class Cea608Channel {
   constructor(channelNumber, outputFilter, logger) {
    this.chNr = void 0;
    this.outputFilter = void 0;
    this.mode = void 0;
    this.verbose = void 0;
    this.displayedMemory = void 0;
    this.nonDisplayedMemory = void 0;
    this.lastOutputScreen = void 0;
    this.currRollUpRow = void 0;
    this.writeScreen = void 0;
    this.cueStartTime = void 0;
    this.logger = void 0;
    this.chNr = channelNumber;
    this.outputFilter = outputFilter;
    this.mode = null;
    this.verbose = 0;
    this.displayedMemory = new CaptionScreen(logger);
    this.nonDisplayedMemory = new CaptionScreen(logger);
    this.lastOutputScreen = new CaptionScreen(logger);
    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];
    this.writeScreen = this.displayedMemory;
    this.mode = null;
    this.cueStartTime = null; // Keeps track of where a cue started.
    this.logger = logger;
   }
   reset() {
    this.mode = null;
    this.displayedMemory.reset();
    this.nonDisplayedMemory.reset();
    this.lastOutputScreen.reset();
    this.outputFilter.reset();
    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];
    this.writeScreen = this.displayedMemory;
    this.mode = null;
    this.cueStartTime = null;
   }
   getHandler() {
    return this.outputFilter;
   }
   setHandler(newHandler) {
    this.outputFilter = newHandler;
   }
   setPAC(pacData) {
    this.writeScreen.setPAC(pacData);
   }
   setBkgData(bkgData) {
    this.writeScreen.setBkgData(bkgData);
   }
   setMode(newMode) {
    if (newMode === this.mode) {
     return;
    }
    this.mode = newMode;
    this.logger.log(2, () => 'MODE=' + newMode);
    if (this.mode === 'MODE_POP-ON') {
     this.writeScreen = this.nonDisplayedMemory;
    } else {
     this.writeScreen = this.displayedMemory;
     this.writeScreen.reset();
    }
    if (this.mode !== 'MODE_ROLL-UP') {
     this.displayedMemory.nrRollUpRows = null;
     this.nonDisplayedMemory.nrRollUpRows = null;
    }
    this.mode = newMode;
   }
   insertChars(chars) {
    for (let i = 0; i < chars.length; i++) {
     this.writeScreen.insertChar(chars[i]);
    }
    const screen = this.writeScreen === this.displayedMemory ? 'DISP' : 'NON_DISP';
    this.logger.log(2, () => screen + ': ' + this.writeScreen.getDisplayText(true));
    if (this.mode === 'MODE_PAINT-ON' || this.mode === 'MODE_ROLL-UP') {
     this.logger.log(1, () => 'DISPLAYED: ' + this.displayedMemory.getDisplayText(true));
     this.outputDataUpdate();
    }
   }
   ccRCL() {
    // Resume Caption Loading (switch mode to Pop On)
    this.logger.log(2, 'RCL - Resume Caption Loading');
    this.setMode('MODE_POP-ON');
   }
   ccBS() {
    // BackSpace
    this.logger.log(2, 'BS - BackSpace');
    if (this.mode === 'MODE_TEXT') {
     return;
    }
    this.writeScreen.backSpace();
    if (this.writeScreen === this.displayedMemory) {
     this.outputDataUpdate();
    }
   }
   ccAOF() {
    // Reserved (formerly Alarm Off)
   }
   ccAON() {
    // Reserved (formerly Alarm On)
   }
   ccDER() {
    // Delete to End of Row
    this.logger.log(2, 'DER- Delete to End of Row');
    this.writeScreen.clearToEndOfRow();
    this.outputDataUpdate();
   }
   ccRU(nrRows) {
    // Roll-Up Captions-2,3,or 4 Rows
    this.logger.log(2, 'RU(' + nrRows + ') - Roll Up');
    this.writeScreen = this.displayedMemory;
    this.setMode('MODE_ROLL-UP');
    this.writeScreen.setRollUpRows(nrRows);
   }
   ccFON() {
    // Flash On
    this.logger.log(2, 'FON - Flash On');
    this.writeScreen.setPen({
     flash: true,
    });
   }
   ccRDC() {
    // Resume Direct Captioning (switch mode to PaintOn)
    this.logger.log(2, 'RDC - Resume Direct Captioning');
    this.setMode('MODE_PAINT-ON');
   }
   ccTR() {
    // Text Restart in text mode (not supported, however)
    this.logger.log(2, 'TR');
    this.setMode('MODE_TEXT');
   }
   ccRTD() {
    // Resume Text Display in Text mode (not supported, however)
    this.logger.log(2, 'RTD');
    this.setMode('MODE_TEXT');
   }
   ccEDM() {
    // Erase Displayed Memory
    this.logger.log(2, 'EDM - Erase Displayed Memory');
    this.displayedMemory.reset();
    this.outputDataUpdate(true);
   }
   ccCR() {
    // Carriage Return
    this.logger.log(2, 'CR - Carriage Return');
    this.writeScreen.rollUp();
    this.outputDataUpdate(true);
   }
   ccENM() {
    // Erase Non-Displayed Memory
    this.logger.log(2, 'ENM - Erase Non-displayed Memory');
    this.nonDisplayedMemory.reset();
   }
   ccEOC() {
    // End of Caption (Flip Memories)
    this.logger.log(2, 'EOC - End Of Caption');
    if (this.mode === 'MODE_POP-ON') {
     const tmp = this.displayedMemory;
     this.displayedMemory = this.nonDisplayedMemory;
     this.nonDisplayedMemory = tmp;
     this.writeScreen = this.nonDisplayedMemory;
     this.logger.log(1, () => 'DISP: ' + this.displayedMemory.getDisplayText());
    }
    this.outputDataUpdate(true);
   }
   ccTO(nrCols) {
    // Tab Offset 1,2, or 3 columns
    this.logger.log(2, 'TO(' + nrCols + ') - Tab Offset');
    this.writeScreen.moveCursor(nrCols);
   }
   ccMIDROW(secondByte) {
    // Parse MIDROW command
    const styles = {
     flash: false,
    };
    styles.underline = secondByte % 2 === 1;
    styles.italics = secondByte >= 0x2e;
    if (!styles.italics) {
     const colorIndex = Math.floor(secondByte / 2) - 0x10;
     const colors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta'];
     styles.foreground = colors[colorIndex];
    } else {
     styles.foreground = 'white';
    }
    this.logger.log(2, 'MIDROW: ' + stringify(styles));
    this.writeScreen.setPen(styles);
   }
   outputDataUpdate(dispatch = false) {
    const time = this.logger.time;
    if (time === null) {
     return;
    }
    if (this.outputFilter) {
     if (this.cueStartTime === null && !this.displayedMemory.isEmpty()) {
      // Start of a new cue
      this.cueStartTime = time;
     } else {
      if (!this.displayedMemory.equals(this.lastOutputScreen)) {
       this.outputFilter.newCue(this.cueStartTime, time, this.lastOutputScreen);
       if (dispatch && this.outputFilter.dispatchCue) {
        this.outputFilter.dispatchCue();
       }
       this.cueStartTime = this.displayedMemory.isEmpty() ? null : time;
      }
     }
     this.lastOutputScreen.copy(this.displayedMemory);
    }
   }
   cueSplitAtTime(t) {
    if (this.outputFilter) {
     if (!this.displayedMemory.isEmpty()) {
      if (this.outputFilter.newCue) {
       this.outputFilter.newCue(this.cueStartTime, t, this.displayedMemory);
      }
      this.cueStartTime = t;
     }
    }
   }
  }

  // Will be 1 or 2 when parsing captions

  class Cea608Parser {
   constructor(field, out1, out2) {
    this.channels = void 0;
    this.currentChannel = 0;
    this.cmdHistory = createCmdHistory();
    this.logger = void 0;
    const logger = (this.logger = new CaptionsLogger());
    this.channels = [null, new Cea608Channel(field, out1, logger), new Cea608Channel(field + 1, out2, logger)];
   }
   getHandler(channel) {
    return this.channels[channel].getHandler();
   }
   setHandler(channel, newHandler) {
    this.channels[channel].setHandler(newHandler);
   }

   /**
    * Add data for time t in forms of list of bytes (unsigned ints). The bytes are treated as pairs.
    */
   addData(time, byteList) {
    this.logger.time = time;
    for (let i = 0; i < byteList.length; i += 2) {
     const a = byteList[i] & 0x7f;
     const b = byteList[i + 1] & 0x7f;
     let cmdFound = false;
     let charsFound = null;
     if (a === 0 && b === 0) {
      continue;
     } else {
      this.logger.log(3, () => '[' + numArrayToHexArray([byteList[i], byteList[i + 1]]) + '] -> (' + numArrayToHexArray([a, b]) + ')');
     }
     const cmdHistory = this.cmdHistory;
     const isControlCode = a >= 0x10 && a <= 0x1f;
     if (isControlCode) {
      // Skip redundant control codes
      if (hasCmdRepeated(a, b, cmdHistory)) {
       setLastCmd(null, null, cmdHistory);
       this.logger.log(3, () => 'Repeated command (' + numArrayToHexArray([a, b]) + ') is dropped');
       continue;
      }
      setLastCmd(a, b, this.cmdHistory);
      cmdFound = this.parseCmd(a, b);
      if (!cmdFound) {
       cmdFound = this.parseMidrow(a, b);
      }
      if (!cmdFound) {
       cmdFound = this.parsePAC(a, b);
      }
      if (!cmdFound) {
       cmdFound = this.parseBackgroundAttributes(a, b);
      }
     } else {
      setLastCmd(null, null, cmdHistory);
     }
     if (!cmdFound) {
      charsFound = this.parseChars(a, b);
      if (charsFound) {
       const currChNr = this.currentChannel;
       if (currChNr && currChNr > 0) {
        const channel = this.channels[currChNr];
        channel.insertChars(charsFound);
       } else {
        this.logger.log(2, 'No channel found yet. TEXT-MODE?');
       }
      }
     }
     if (!cmdFound && !charsFound) {
      this.logger.log(2, () => "Couldn't parse cleaned data " + numArrayToHexArray([a, b]) + ' orig: ' + numArrayToHexArray([byteList[i], byteList[i + 1]]));
     }
    }
   }

   /**
    * Parse Command.
    * @returns True if a command was found
    */
   parseCmd(a, b) {
    const cond1 = (a === 0x14 || a === 0x1c || a === 0x15 || a === 0x1d) && b >= 0x20 && b <= 0x2f;
    const cond2 = (a === 0x17 || a === 0x1f) && b >= 0x21 && b <= 0x23;
    if (!(cond1 || cond2)) {
     return false;
    }
    const chNr = a === 0x14 || a === 0x15 || a === 0x17 ? 1 : 2;
    const channel = this.channels[chNr];
    if (a === 0x14 || a === 0x15 || a === 0x1c || a === 0x1d) {
     if (b === 0x20) {
      channel.ccRCL();
     } else if (b === 0x21) {
      channel.ccBS();
     } else if (b === 0x22) {
      channel.ccAOF();
     } else if (b === 0x23) {
      channel.ccAON();
     } else if (b === 0x24) {
      channel.ccDER();
     } else if (b === 0x25) {
      channel.ccRU(2);
     } else if (b === 0x26) {
      channel.ccRU(3);
     } else if (b === 0x27) {
      channel.ccRU(4);
     } else if (b === 0x28) {
      channel.ccFON();
     } else if (b === 0x29) {
      channel.ccRDC();
     } else if (b === 0x2a) {
      channel.ccTR();
     } else if (b === 0x2b) {
      channel.ccRTD();
     } else if (b === 0x2c) {
      channel.ccEDM();
     } else if (b === 0x2d) {
      channel.ccCR();
     } else if (b === 0x2e) {
      channel.ccENM();
     } else if (b === 0x2f) {
      channel.ccEOC();
     }
    } else {
     // a == 0x17 || a == 0x1F
     channel.ccTO(b - 0x20);
    }
    this.currentChannel = chNr;
    return true;
   }

   /**
    * Parse midrow styling command
    */
   parseMidrow(a, b) {
    let chNr = 0;
    if ((a === 0x11 || a === 0x19) && b >= 0x20 && b <= 0x2f) {
     if (a === 0x11) {
      chNr = 1;
     } else {
      chNr = 2;
     }
     if (chNr !== this.currentChannel) {
      this.logger.log(0, 'Mismatch channel in midrow parsing');
      return false;
     }
     const channel = this.channels[chNr];
     if (!channel) {
      return false;
     }
     channel.ccMIDROW(b);
     this.logger.log(3, () => 'MIDROW (' + numArrayToHexArray([a, b]) + ')');
     return true;
    }
    return false;
   }

   /**
    * Parse Preable Access Codes (Table 53).
    * @returns {Boolean} Tells if PAC found
    */
   parsePAC(a, b) {
    let row;
    const case1 = ((a >= 0x11 && a <= 0x17) || (a >= 0x19 && a <= 0x1f)) && b >= 0x40 && b <= 0x7f;
    const case2 = (a === 0x10 || a === 0x18) && b >= 0x40 && b <= 0x5f;
    if (!(case1 || case2)) {
     return false;
    }
    const chNr = a <= 0x17 ? 1 : 2;
    if (b >= 0x40 && b <= 0x5f) {
     row = chNr === 1 ? rowsLowCh1[a] : rowsLowCh2[a];
    } else {
     // 0x60 <= b <= 0x7F
     row = chNr === 1 ? rowsHighCh1[a] : rowsHighCh2[a];
    }
    const channel = this.channels[chNr];
    if (!channel) {
     return false;
    }
    channel.setPAC(this.interpretPAC(row, b));
    this.currentChannel = chNr;
    return true;
   }

   /**
    * Interpret the second byte of the pac, and return the information.
    * @returns pacData with style parameters
    */
   interpretPAC(row, byte) {
    let pacIndex;
    const pacData = {
     color: null,
     italics: false,
     indent: null,
     underline: false,
     row: row,
    };
    if (byte > 0x5f) {
     pacIndex = byte - 0x60;
    } else {
     pacIndex = byte - 0x40;
    }
    pacData.underline = (pacIndex & 1) === 1;
    if (pacIndex <= 0xd) {
     pacData.color = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'white'][Math.floor(pacIndex / 2)];
    } else if (pacIndex <= 0xf) {
     pacData.italics = true;
     pacData.color = 'white';
    } else {
     pacData.indent = Math.floor((pacIndex - 0x10) / 2) * 4;
    }
    return pacData; // Note that row has zero offset. The spec uses 1.
   }

   /**
    * Parse characters.
    * @returns An array with 1 to 2 codes corresponding to chars, if found. null otherwise.
    */
   parseChars(a, b) {
    let channelNr;
    let charCodes = null;
    let charCode1 = null;
    if (a >= 0x19) {
     channelNr = 2;
     charCode1 = a - 8;
    } else {
     channelNr = 1;
     charCode1 = a;
    }
    if (charCode1 >= 0x11 && charCode1 <= 0x13) {
     // Special character
     let oneCode;
     if (charCode1 === 0x11) {
      oneCode = b + 0x50;
     } else if (charCode1 === 0x12) {
      oneCode = b + 0x70;
     } else {
      oneCode = b + 0x90;
     }
     this.logger.log(2, () => "Special char '" + getCharForByte(oneCode) + "' in channel " + channelNr);
     charCodes = [oneCode];
    } else if (a >= 0x20 && a <= 0x7f) {
     charCodes = b === 0 ? [a] : [a, b];
    }
    if (charCodes) {
     this.logger.log(3, () => 'Char codes =  ' + numArrayToHexArray(charCodes).join(','));
    }
    return charCodes;
   }

   /**
    * Parse extended background attributes as well as new foreground color black.
    * @returns True if background attributes are found
    */
   parseBackgroundAttributes(a, b) {
    const case1 = (a === 0x10 || a === 0x18) && b >= 0x20 && b <= 0x2f;
    const case2 = (a === 0x17 || a === 0x1f) && b >= 0x2d && b <= 0x2f;
    if (!(case1 || case2)) {
     return false;
    }
    let index;
    const bkgData = {};
    if (a === 0x10 || a === 0x18) {
     index = Math.floor((b - 0x20) / 2);
     bkgData.background = backgroundColors[index];
     if (b % 2 === 1) {
      bkgData.background = bkgData.background + '_semi';
     }
    } else if (b === 0x2d) {
     bkgData.background = 'transparent';
    } else {
     bkgData.foreground = 'black';
     if (b === 0x2f) {
      bkgData.underline = true;
     }
    }
    const chNr = a <= 0x17 ? 1 : 2;
    const channel = this.channels[chNr];
    channel.setBkgData(bkgData);
    return true;
   }

   /**
    * Reset state of parser and its channels.
    */
   reset() {
    for (let i = 0; i < Object.keys(this.channels).length; i++) {
     const channel = this.channels[i];
     if (channel) {
      channel.reset();
     }
    }
    setLastCmd(null, null, this.cmdHistory);
   }

   /**
    * Trigger the generation of a cue, and the start of a new one if displayScreens are not empty.
    */
   cueSplitAtTime(t) {
    for (let i = 0; i < this.channels.length; i++) {
     const channel = this.channels[i];
     if (channel) {
      channel.cueSplitAtTime(t);
     }
    }
   }
  }
  function setLastCmd(a, b, cmdHistory) {
   cmdHistory.a = a;
   cmdHistory.b = b;
  }
  function hasCmdRepeated(a, b, cmdHistory) {
   return cmdHistory.a === a && cmdHistory.b === b;
  }
  function createCmdHistory() {
   return {
    a: null,
    b: null,
   };
  }

  /**
   * Copyright 2013 vtt.js Contributors
   *
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   */

  var VTTCue = (function () {
   if (optionalSelf != null && optionalSelf.VTTCue) {
    return self.VTTCue;
   }
   const AllowedDirections = ['', 'lr', 'rl'];
   const AllowedAlignments = ['start', 'middle', 'end', 'left', 'right'];
   function isAllowedValue(allowed, value) {
    if (typeof value !== 'string') {
     return false;
    }
    // necessary for assuring the generic conforms to the Array interface
    if (!Array.isArray(allowed)) {
     return false;
    }
    // reset the type so that the next narrowing works well
    const lcValue = value.toLowerCase();
    // use the allow list to narrow the type to a specific subset of strings
    if (~allowed.indexOf(lcValue)) {
     return lcValue;
    }
    return false;
   }
   function findDirectionSetting(value) {
    return isAllowedValue(AllowedDirections, value);
   }
   function findAlignSetting(value) {
    return isAllowedValue(AllowedAlignments, value);
   }
   function extend(obj, ...rest) {
    let i = 1;
    for (; i < arguments.length; i++) {
     const cobj = arguments[i];
     for (const p in cobj) {
      obj[p] = cobj[p];
     }
    }
    return obj;
   }
   function VTTCue(startTime, endTime, text) {
    const cue = this;
    const baseObj = {
     enumerable: true,
    };
    /**
     * Shim implementation specific properties. These properties are not in
     * the spec.
     */

    // Lets us know when the VTTCue's data has changed in such a way that we need
    // to recompute its display state. This lets us compute its display state
    // lazily.
    cue.hasBeenReset = false;

    /**
     * VTTCue and TextTrackCue properties
     * http://dev.w3.org/html5/webvtt/#vttcue-interface
     */

    let _id = '';
    let _pauseOnExit = false;
    let _startTime = startTime;
    let _endTime = endTime;
    let _text = text;
    let _region = null;
    let _vertical = '';
    let _snapToLines = true;
    let _line = 'auto';
    let _lineAlign = 'start';
    let _position = 50;
    let _positionAlign = 'middle';
    let _size = 50;
    let _align = 'middle';
    Object.defineProperty(
     cue,
     'id',
     extend({}, baseObj, {
      get: function () {
       return _id;
      },
      set: function (value) {
       _id = '' + value;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'pauseOnExit',
     extend({}, baseObj, {
      get: function () {
       return _pauseOnExit;
      },
      set: function (value) {
       _pauseOnExit = !!value;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'startTime',
     extend({}, baseObj, {
      get: function () {
       return _startTime;
      },
      set: function (value) {
       if (typeof value !== 'number') {
        throw new TypeError('Start time must be set to a number.');
       }
       _startTime = value;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'endTime',
     extend({}, baseObj, {
      get: function () {
       return _endTime;
      },
      set: function (value) {
       if (typeof value !== 'number') {
        throw new TypeError('End time must be set to a number.');
       }
       _endTime = value;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'text',
     extend({}, baseObj, {
      get: function () {
       return _text;
      },
      set: function (value) {
       _text = '' + value;
       this.hasBeenReset = true;
      },
     }),
    );

    // todo: implement VTTRegion polyfill?
    Object.defineProperty(
     cue,
     'region',
     extend({}, baseObj, {
      get: function () {
       return _region;
      },
      set: function (value) {
       _region = value;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'vertical',
     extend({}, baseObj, {
      get: function () {
       return _vertical;
      },
      set: function (value) {
       const setting = findDirectionSetting(value);
       // Have to check for false because the setting an be an empty string.
       if (setting === false) {
        throw new SyntaxError('An invalid or illegal string was specified.');
       }
       _vertical = setting;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'snapToLines',
     extend({}, baseObj, {
      get: function () {
       return _snapToLines;
      },
      set: function (value) {
       _snapToLines = !!value;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'line',
     extend({}, baseObj, {
      get: function () {
       return _line;
      },
      set: function (value) {
       if (typeof value !== 'number' && value !== 'auto') {
        throw new SyntaxError('An invalid number or illegal string was specified.');
       }
       _line = value;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'lineAlign',
     extend({}, baseObj, {
      get: function () {
       return _lineAlign;
      },
      set: function (value) {
       const setting = findAlignSetting(value);
       if (!setting) {
        throw new SyntaxError('An invalid or illegal string was specified.');
       }
       _lineAlign = setting;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'position',
     extend({}, baseObj, {
      get: function () {
       return _position;
      },
      set: function (value) {
       if (value < 0 || value > 100) {
        throw new Error('Position must be between 0 and 100.');
       }
       _position = value;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'positionAlign',
     extend({}, baseObj, {
      get: function () {
       return _positionAlign;
      },
      set: function (value) {
       const setting = findAlignSetting(value);
       if (!setting) {
        throw new SyntaxError('An invalid or illegal string was specified.');
       }
       _positionAlign = setting;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'size',
     extend({}, baseObj, {
      get: function () {
       return _size;
      },
      set: function (value) {
       if (value < 0 || value > 100) {
        throw new Error('Size must be between 0 and 100.');
       }
       _size = value;
       this.hasBeenReset = true;
      },
     }),
    );
    Object.defineProperty(
     cue,
     'align',
     extend({}, baseObj, {
      get: function () {
       return _align;
      },
      set: function (value) {
       const setting = findAlignSetting(value);
       if (!setting) {
        throw new SyntaxError('An invalid or illegal string was specified.');
       }
       _align = setting;
       this.hasBeenReset = true;
      },
     }),
    );

    /**
     * Other <track> spec defined properties
     */

    // http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#text-track-cue-display-state
    cue.displayState = undefined;
   }

   /**
    * VTTCue methods
    */

   VTTCue.prototype.getCueAsHTML = function () {
    // Assume WebVTT.convertCueToDOMTree is on the global.
    const WebVTT = self.WebVTT;
    return WebVTT.convertCueToDOMTree(self, this.text);
   };
   // this is a polyfill hack
   return VTTCue;
  })();

  /*
   * Source: https://github.com/mozilla/vtt.js/blob/master/dist/vtt.js
   */

  class StringDecoder {
   decode(data, options) {
    if (!data) {
     return '';
    }
    if (typeof data !== 'string') {
     throw new Error('Error - expected string data.');
    }
    return decodeURIComponent(encodeURIComponent(data));
   }
  }

  // Try to parse input as a time stamp.
  function parseTimeStamp(input) {
   function computeSeconds(h, m, s, f) {
    return (h | 0) * 3600 + (m | 0) * 60 + (s | 0) + parseFloat(f || 0);
   }
   const m = input.match(/^(?:(\d+):)?(\d{2}):(\d{2})(\.\d+)?/);
   if (!m) {
    return null;
   }
   if (parseFloat(m[2]) > 59) {
    // Timestamp takes the form of [hours]:[minutes].[milliseconds]
    // First position is hours as it's over 59.
    return computeSeconds(m[2], m[3], 0, m[4]);
   }
   // Timestamp takes the form of [hours (optional)]:[minutes]:[seconds].[milliseconds]
   return computeSeconds(m[1], m[2], m[3], m[4]);
  }

  // A settings object holds key/value pairs and will ignore anything but the first
  // assignment to a specific key.
  class Settings {
   constructor() {
    this.values = Object.create(null);
   }
   // Only accept the first assignment to any key.
   set(k, v) {
    if (!this.get(k) && v !== '') {
     this.values[k] = v;
    }
   }
   // Return the value for a key, or a default value.
   // If 'defaultKey' is passed then 'dflt' is assumed to be an object with
   // a number of possible default values as properties where 'defaultKey' is
   // the key of the property that will be chosen; otherwise it's assumed to be
   // a single value.
   get(k, dflt, defaultKey) {
    if (defaultKey) {
     return this.has(k) ? this.values[k] : dflt[defaultKey];
    }
    return this.has(k) ? this.values[k] : dflt;
   }
   // Check whether we have a value for a key.
   has(k) {
    return k in this.values;
   }
   // Accept a setting if its one of the given alternatives.
   alt(k, v, a) {
    for (let n = 0; n < a.length; ++n) {
     if (v === a[n]) {
      this.set(k, v);
      break;
     }
    }
   }
   // Accept a setting if its a valid (signed) integer.
   integer(k, v) {
    if (/^-?\d+$/.test(v)) {
     // integer
     this.set(k, parseInt(v, 10));
    }
   }
   // Accept a setting if its a valid percentage.
   percent(k, v) {
    if (/^([\d]{1,3})(\.[\d]*)?%$/.test(v)) {
     const percent = parseFloat(v);
     if (percent >= 0 && percent <= 100) {
      this.set(k, percent);
      return true;
     }
    }
    return false;
   }
  }

  // Helper function to parse input into groups separated by 'groupDelim', and
  // interpret each group as a key/value pair separated by 'keyValueDelim'.
  function parseOptions(input, callback, keyValueDelim, groupDelim) {
   const groups = groupDelim ? input.split(groupDelim) : [input];
   for (const i in groups) {
    if (typeof groups[i] !== 'string') {
     continue;
    }
    const kv = groups[i].split(keyValueDelim);
    if (kv.length !== 2) {
     continue;
    }
    const k = kv[0];
    const v = kv[1];
    callback(k, v);
   }
  }
  const defaults = new VTTCue(0, 0, '');
  // 'middle' was changed to 'center' in the spec: https://github.com/w3c/webvtt/pull/244
  //  Safari doesn't yet support this change, but FF and Chrome do.
  const center = defaults.align === 'middle' ? 'middle' : 'center';
  function parseCue(input, cue, regionList) {
   // Remember the original input if we need to throw an error.
   const oInput = input;
   // 4.1 WebVTT timestamp
   function consumeTimeStamp() {
    const ts = parseTimeStamp(input);
    if (ts === null) {
     throw new Error('Malformed timestamp: ' + oInput);
    }

    // Remove time stamp from input.
    input = input.replace(/^[^\sa-zA-Z-]+/, '');
    return ts;
   }

   // 4.4.2 WebVTT cue settings
   function consumeCueSettings(input, cue) {
    const settings = new Settings();
    parseOptions(
     input,
     function (k, v) {
      let vals;
      switch (k) {
       case 'region':
        // Find the last region we parsed with the same region id.
        for (let i = regionList.length - 1; i >= 0; i--) {
         if (regionList[i].id === v) {
          settings.set(k, regionList[i].region);
          break;
         }
        }
        break;
       case 'vertical':
        settings.alt(k, v, ['rl', 'lr']);
        break;
       case 'line':
        vals = v.split(',');
        settings.integer(k, vals[0]);
        if (settings.percent(k, vals[0])) {
         settings.set('snapToLines', false);
        }
        settings.alt(k, vals[0], ['auto']);
        if (vals.length === 2) {
         settings.alt('lineAlign', vals[1], ['start', center, 'end']);
        }
        break;
       case 'position':
        vals = v.split(',');
        settings.percent(k, vals[0]);
        if (vals.length === 2) {
         settings.alt('positionAlign', vals[1], ['start', center, 'end', 'line-left', 'line-right', 'auto']);
        }
        break;
       case 'size':
        settings.percent(k, v);
        break;
       case 'align':
        settings.alt(k, v, ['start', center, 'end', 'left', 'right']);
        break;
      }
     },
     /:/,
     /\s/,
    );

    // Apply default values for any missing fields.
    cue.region = settings.get('region', null);
    cue.vertical = settings.get('vertical', '');
    let line = settings.get('line', 'auto');
    if (line === 'auto' && defaults.line === -1) {
     // set numeric line number for Safari
     line = -1;
    }
    cue.line = line;
    cue.lineAlign = settings.get('lineAlign', 'start');
    cue.snapToLines = settings.get('snapToLines', true);
    cue.size = settings.get('size', 100);
    cue.align = settings.get('align', center);
    let position = settings.get('position', 'auto');
    if (position === 'auto' && defaults.position === 50) {
     // set numeric position for Safari
     position = cue.align === 'start' || cue.align === 'left' ? 0 : cue.align === 'end' || cue.align === 'right' ? 100 : 50;
    }
    cue.position = position;
   }
   function skipWhitespace() {
    input = input.replace(/^\s+/, '');
   }

   // 4.1 WebVTT cue timings.
   skipWhitespace();
   cue.startTime = consumeTimeStamp(); // (1) collect cue start time
   skipWhitespace();
   if (input.slice(0, 3) !== '-->') {
    // (3) next characters must match '-->'
    throw new Error("Malformed time stamp (time stamps must be separated by '-->'): " + oInput);
   }
   input = input.slice(3);
   skipWhitespace();
   cue.endTime = consumeTimeStamp(); // (5) collect cue end time

   // 4.1 WebVTT cue settings list.
   skipWhitespace();
   consumeCueSettings(input, cue);
  }
  function fixLineBreaks(input) {
   return input.replace(/<br(?: \/)?>/gi, '\n');
  }
  class VTTParser {
   constructor() {
    this.state = 'INITIAL';
    this.buffer = '';
    this.decoder = new StringDecoder();
    this.regionList = [];
    this.cue = null;
    this.oncue = void 0;
    this.onparsingerror = void 0;
    this.onflush = void 0;
   }
   parse(data) {
    const _this = this;

    // If there is no data then we won't decode it, but will just try to parse
    // whatever is in buffer already. This may occur in circumstances, for
    // example when flush() is called.
    if (data) {
     // Try to decode the data that we received.
     _this.buffer += _this.decoder.decode(data, {
      stream: true,
     });
    }
    function collectNextLine() {
     let buffer = _this.buffer;
     let pos = 0;
     buffer = fixLineBreaks(buffer);
     while (pos < buffer.length && buffer[pos] !== '\r' && buffer[pos] !== '\n') {
      ++pos;
     }
     const line = buffer.slice(0, pos);
     // Advance the buffer early in case we fail below.
     if (buffer[pos] === '\r') {
      ++pos;
     }
     if (buffer[pos] === '\n') {
      ++pos;
     }
     _this.buffer = buffer.slice(pos);
     return line;
    }

    // 3.2 WebVTT metadata header syntax
    function parseHeader(input) {
     parseOptions(
      input,
      function (k, v) {
       // switch (k) {
       // case 'region':
       // 3.3 WebVTT region metadata header syntax
       // console.log('parse region', v);
       // parseRegion(v);
       // break;
       // }
      },
      /:/,
     );
    }

    // 5.1 WebVTT file parsing.
    try {
     let line = '';
     if (_this.state === 'INITIAL') {
      // We can't start parsing until we have the first line.
      if (!/\r\n|\n/.test(_this.buffer)) {
       return this;
      }
      line = collectNextLine();
      // strip of UTF-8 BOM if any
      // https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8
      const m = line.match(/^()?WEBVTT([ \t].*)?$/);
      if (!(m != null && m[0])) {
       throw new Error('Malformed WebVTT signature.');
      }
      _this.state = 'HEADER';
     }
     let alreadyCollectedLine = false;
     while (_this.buffer) {
      // We can't parse a line until we have the full line.
      if (!/\r\n|\n/.test(_this.buffer)) {
       return this;
      }
      if (!alreadyCollectedLine) {
       line = collectNextLine();
      } else {
       alreadyCollectedLine = false;
      }
      switch (_this.state) {
       case 'HEADER':
        // 13-18 - Allow a header (metadata) under the WEBVTT line.
        if (/:/.test(line)) {
         parseHeader(line);
        } else if (!line) {
         // An empty line terminates the header and starts the body (cues).
         _this.state = 'ID';
        }
        continue;
       case 'NOTE':
        // Ignore NOTE blocks.
        if (!line) {
         _this.state = 'ID';
        }
        continue;
       case 'ID':
        // Check for the start of NOTE blocks.
        if (/^NOTE($|[ \t])/.test(line)) {
         _this.state = 'NOTE';
         break;
        }
        // 19-29 - Allow any number of line terminators, then initialize new cue values.
        if (!line) {
         continue;
        }
        _this.cue = new VTTCue(0, 0, '');
        _this.state = 'CUE';
        // 30-39 - Check if self line contains an optional identifier or timing data.
        if (line.indexOf('-->') === -1) {
         _this.cue.id = line;
         continue;
        }
       // Process line as start of a cue.
       /* falls through */
       case 'CUE':
        // 40 - Collect cue timings and settings.
        if (!_this.cue) {
         _this.state = 'BADCUE';
         continue;
        }
        try {
         parseCue(line, _this.cue, _this.regionList);
        } catch (e) {
         // In case of an error ignore rest of the cue.
         _this.cue = null;
         _this.state = 'BADCUE';
         continue;
        }
        _this.state = 'CUETEXT';
        continue;
       case 'CUETEXT':
        {
         const hasSubstring = line.indexOf('-->') !== -1;
         // 34 - If we have an empty line then report the cue.
         // 35 - If we have the special substring '-->' then report the cue,
         // but do not collect the line as we need to process the current
         // one as a new cue.
         if (!line || (hasSubstring && (alreadyCollectedLine = true))) {
          // We are done parsing self cue.
          if (_this.oncue && _this.cue) {
           _this.oncue(_this.cue);
          }
          _this.cue = null;
          _this.state = 'ID';
          continue;
         }
         if (_this.cue === null) {
          continue;
         }
         if (_this.cue.text) {
          _this.cue.text += '\n';
         }
         _this.cue.text += line;
        }
        continue;
       case 'BADCUE':
        // 54-62 - Collect and discard the remaining cue.
        if (!line) {
         _this.state = 'ID';
        }
      }
     }
    } catch (e) {
     // If we are currently parsing a cue, report what we have.
     if (_this.state === 'CUETEXT' && _this.cue && _this.oncue) {
      _this.oncue(_this.cue);
     }
     _this.cue = null;
     // Enter BADWEBVTT state if header was not parsed correctly otherwise
     // another exception occurred so enter BADCUE state.
     _this.state = _this.state === 'INITIAL' ? 'BADWEBVTT' : 'BADCUE';
    }
    return this;
   }
   flush() {
    const _this = this;
    try {
     // Finish decoding the stream.
     // _this.buffer += _this.decoder.decode();
     // Synthesize the end of the current cue or region.
     if (_this.cue || _this.state === 'HEADER') {
      _this.buffer += '\n\n';
      _this.parse();
     }
     // If we've flushed, parsed, and we're still on the INITIAL state then
     // that means we don't have enough of the stream to parse the first
     // line.
     if (_this.state === 'INITIAL' || _this.state === 'BADWEBVTT') {
      throw new Error('Malformed WebVTT signature.');
     }
    } catch (e) {
     if (_this.onparsingerror) {
      _this.onparsingerror(e);
     }
    }
    if (_this.onflush) {
     _this.onflush();
    }
    return this;
   }
  }

  const LINEBREAKS = /\r\n|\n\r|\n|\r/g;

  // String.prototype.startsWith is not supported in IE11
  const startsWith = function startsWith(inputString, searchString, position = 0) {
   return inputString.slice(position, position + searchString.length) === searchString;
  };
  const cueString2millis = function cueString2millis(timeString) {
   let ts = parseInt(timeString.slice(-3));
   const secs = parseInt(timeString.slice(-6, -4));
   const mins = parseInt(timeString.slice(-9, -7));
   const hours = timeString.length > 9 ? parseInt(timeString.substring(0, timeString.indexOf(':'))) : 0;
   if (!isFiniteNumber(ts) || !isFiniteNumber(secs) || !isFiniteNumber(mins) || !isFiniteNumber(hours)) {
    throw Error(`Malformed X-TIMESTAMP-MAP: Local:${timeString}`);
   }
   ts += 1000 * secs;
   ts += 60 * 1000 * mins;
   ts += 60 * 60 * 1000 * hours;
   return ts;
  };

  // Create a unique hash id for a cue based on start/end times and text.
  // This helps timeline-controller to avoid showing repeated captions.
  function generateCueId(startTime, endTime, text) {
   return hash(startTime.toString()) + hash(endTime.toString()) + hash(text);
  }
  const calculateOffset = function calculateOffset(vttCCs, cc, presentationTime) {
   let currCC = vttCCs[cc];
   let prevCC = vttCCs[currCC.prevCC];

   // This is the first discontinuity or cues have been processed since the last discontinuity
   // Offset = current discontinuity time
   if (!prevCC || (!prevCC.new && currCC.new)) {
    vttCCs.ccOffset = vttCCs.presentationOffset = currCC.start;
    currCC.new = false;
    return;
   }

   // There have been discontinuities since cues were last parsed.
   // Offset = time elapsed
   while ((_prevCC = prevCC) != null && _prevCC.new) {
    var _prevCC;
    vttCCs.ccOffset += currCC.start - prevCC.start;
    currCC.new = false;
    currCC = prevCC;
    prevCC = vttCCs[currCC.prevCC];
   }
   vttCCs.presentationOffset = presentationTime;
  };
  function parseWebVTT(vttByteArray, initPTS, vttCCs, cc, timeOffset, callBack, errorCallBack) {
   const parser = new VTTParser();
   // Convert byteArray into string, replacing any somewhat exotic linefeeds with "\n", then split on that character.
   // Uint8Array.prototype.reduce is not implemented in IE11
   const vttLines = utf8ArrayToStr(new Uint8Array(vttByteArray)).trim().replace(LINEBREAKS, '\n').split('\n');
   const cues = [];
   const init90kHz = initPTS ? toMpegTsClockFromTimescale(initPTS.baseTime, initPTS.timescale) : 0;
   let cueTime = '00:00.000';
   let timestampMapMPEGTS = 0;
   let timestampMapLOCAL = 0;
   let parsingError;
   let inHeader = true;
   parser.oncue = function (cue) {
    // Adjust cue timing; clamp cues to start no earlier than - and drop cues that don't end after - 0 on timeline.
    const currCC = vttCCs[cc];
    let cueOffset = vttCCs.ccOffset;

    // Calculate subtitle PTS offset
    const webVttMpegTsMapOffset = (timestampMapMPEGTS - init90kHz) / 90000;

    // Update offsets for new discontinuities
    if (currCC != null && currCC.new) {
     if (timestampMapLOCAL !== undefined) {
      // When local time is provided, offset = discontinuity start time - local time
      cueOffset = vttCCs.ccOffset = currCC.start;
     } else {
      calculateOffset(vttCCs, cc, webVttMpegTsMapOffset);
     }
    }
    if (webVttMpegTsMapOffset) {
     if (!initPTS) {
      parsingError = new Error('Missing initPTS for VTT MPEGTS');
      return;
     }
     // If we have MPEGTS, offset = presentation time + discontinuity offset
     cueOffset = webVttMpegTsMapOffset - vttCCs.presentationOffset;
    }
    const duration = cue.endTime - cue.startTime;
    const startTime = normalizePts((cue.startTime + cueOffset - timestampMapLOCAL) * 90000, timeOffset * 90000) / 90000;
    cue.startTime = Math.max(startTime, 0);
    cue.endTime = Math.max(startTime + duration, 0);

    //trim trailing webvtt block whitespaces
    const text = cue.text.trim();

    // Fix encoding of special characters
    cue.text = decodeURIComponent(encodeURIComponent(text));

    // If the cue was not assigned an id from the VTT file (line above the content), create one.
    if (!cue.id) {
     cue.id = generateCueId(cue.startTime, cue.endTime, text);
    }
    if (cue.endTime > 0) {
     cues.push(cue);
    }
   };
   parser.onparsingerror = function (error) {
    parsingError = error;
   };
   parser.onflush = function () {
    if (parsingError) {
     errorCallBack(parsingError);
     return;
    }
    callBack(cues);
   };

   // Go through contents line by line.
   vttLines.forEach((line) => {
    if (inHeader) {
     // Look for X-TIMESTAMP-MAP in header.
     if (startsWith(line, 'X-TIMESTAMP-MAP=')) {
      // Once found, no more are allowed anyway, so stop searching.
      inHeader = false;
      // Extract LOCAL and MPEGTS.
      line
       .slice(16)
       .split(',')
       .forEach((timestamp) => {
        if (startsWith(timestamp, 'LOCAL:')) {
         cueTime = timestamp.slice(6);
        } else if (startsWith(timestamp, 'MPEGTS:')) {
         timestampMapMPEGTS = parseInt(timestamp.slice(7));
        }
       });
      try {
       // Convert cue time to seconds
       timestampMapLOCAL = cueString2millis(cueTime) / 1000;
      } catch (error) {
       parsingError = error;
      }
      // Return without parsing X-TIMESTAMP-MAP line.
      return;
     } else if (line === '') {
      inHeader = false;
     }
    }
    // Parse line by default.
    parser.parse(line + '\n');
   });
   parser.flush();
  }

  const IMSC1_CODEC = 'stpp.ttml.im1t';

  // Time format: h:m:s:frames(.subframes)
  const HMSF_REGEX = /^(\d{2,}):(\d{2}):(\d{2}):(\d{2})\.?(\d+)?$/;

  // Time format: hours, minutes, seconds, milliseconds, frames, ticks
  const TIME_UNIT_REGEX = /^(\d*(?:\.\d*)?)(h|m|s|ms|f|t)$/;
  const textAlignToLineAlign = {
   left: 'start',
   center: 'center',
   right: 'end',
   start: 'start',
   end: 'end',
  };
  function parseIMSC1(payload, initPTS, callBack, errorCallBack) {
   const results = findBox(new Uint8Array(payload), ['mdat']);
   if (results.length === 0) {
    errorCallBack(new Error('Could not parse IMSC1 mdat'));
    return;
   }
   const ttmlList = results.map((mdat) => utf8ArrayToStr(mdat));
   const syncTime = toTimescaleFromScale(initPTS.baseTime, 1, initPTS.timescale);
   try {
    ttmlList.forEach((ttml) => callBack(parseTTML(ttml, syncTime)));
   } catch (error) {
    errorCallBack(error);
   }
  }
  function parseTTML(ttml, syncTime) {
   const parser = new DOMParser();
   const xmlDoc = parser.parseFromString(ttml, 'text/xml');
   const tt = xmlDoc.getElementsByTagName('tt')[0];
   if (!tt) {
    throw new Error('Invalid ttml');
   }
   const defaultRateInfo = {
    frameRate: 30,
    subFrameRate: 1,
    frameRateMultiplier: 0,
    tickRate: 0,
   };
   const rateInfo = Object.keys(defaultRateInfo).reduce((result, key) => {
    result[key] = tt.getAttribute(`ttp:${key}`) || defaultRateInfo[key];
    return result;
   }, {});
   const trim = tt.getAttribute('xml:space') !== 'preserve';
   const styleElements = collectionToDictionary(getElementCollection(tt, 'styling', 'style'));
   const regionElements = collectionToDictionary(getElementCollection(tt, 'layout', 'region'));
   const cueElements = getElementCollection(tt, 'body', '[begin]');
   return [].map
    .call(cueElements, (cueElement) => {
     const cueText = getTextContent(cueElement, trim);
     if (!cueText || !cueElement.hasAttribute('begin')) {
      return null;
     }
     const startTime = parseTtmlTime(cueElement.getAttribute('begin'), rateInfo);
     const duration = parseTtmlTime(cueElement.getAttribute('dur'), rateInfo);
     let endTime = parseTtmlTime(cueElement.getAttribute('end'), rateInfo);
     if (startTime === null) {
      throw timestampParsingError(cueElement);
     }
     if (endTime === null) {
      if (duration === null) {
       throw timestampParsingError(cueElement);
      }
      endTime = startTime + duration;
     }
     const cue = new VTTCue(startTime - syncTime, endTime - syncTime, cueText);
     cue.id = generateCueId(cue.startTime, cue.endTime, cue.text);
     const region = regionElements[cueElement.getAttribute('region')];
     const style = styleElements[cueElement.getAttribute('style')];

     // Apply styles to cue
     const styles = getTtmlStyles(region, style, styleElements);
     const { textAlign } = styles;
     if (textAlign) {
      // cue.positionAlign not settable in FF~2016
      const lineAlign = textAlignToLineAlign[textAlign];
      if (lineAlign) {
       cue.lineAlign = lineAlign;
      }
      cue.align = textAlign;
     }
     _extends(cue, styles);
     return cue;
    })
    .filter((cue) => cue !== null);
  }
  function getElementCollection(fromElement, parentName, childName) {
   const parent = fromElement.getElementsByTagName(parentName)[0];
   if (parent) {
    return [].slice.call(parent.querySelectorAll(childName));
   }
   return [];
  }
  function collectionToDictionary(elementsWithId) {
   return elementsWithId.reduce((dict, element) => {
    const id = element.getAttribute('xml:id');
    if (id) {
     dict[id] = element;
    }
    return dict;
   }, {});
  }
  function getTextContent(element, trim) {
   return [].slice.call(element.childNodes).reduce((str, node, i) => {
    var _node$childNodes;
    if (node.nodeName === 'br' && i) {
     return str + '\n';
    }
    if ((_node$childNodes = node.childNodes) != null && _node$childNodes.length) {
     return getTextContent(node, trim);
    } else if (trim) {
     return str + node.textContent.trim().replace(/\s+/g, ' ');
    }
    return str + node.textContent;
   }, '');
  }
  function getTtmlStyles(region, style, styleElements) {
   const ttsNs = 'http://www.w3.org/ns/ttml#styling';
   let regionStyle = null;
   const styleAttributes = [
    'displayAlign',
    'textAlign',
    'color',
    'backgroundColor',
    'fontSize',
    'fontFamily',
    // 'fontWeight',
    // 'lineHeight',
    // 'wrapOption',
    // 'fontStyle',
    // 'direction',
    // 'writingMode'
   ];
   const regionStyleName = region != null && region.hasAttribute('style') ? region.getAttribute('style') : null;
   if (regionStyleName && styleElements.hasOwnProperty(regionStyleName)) {
    regionStyle = styleElements[regionStyleName];
   }
   return styleAttributes.reduce((styles, name) => {
    const value = getAttributeNS(style, ttsNs, name) || getAttributeNS(region, ttsNs, name) || getAttributeNS(regionStyle, ttsNs, name);
    if (value) {
     styles[name] = value;
    }
    return styles;
   }, {});
  }
  function getAttributeNS(element, ns, name) {
   if (!element) {
    return null;
   }
   return element.hasAttributeNS(ns, name) ? element.getAttributeNS(ns, name) : null;
  }
  function timestampParsingError(node) {
   return new Error(`Could not parse ttml timestamp ${node}`);
  }
  function parseTtmlTime(timeAttributeValue, rateInfo) {
   if (!timeAttributeValue) {
    return null;
   }
   let seconds = parseTimeStamp(timeAttributeValue);
   if (seconds === null) {
    if (HMSF_REGEX.test(timeAttributeValue)) {
     seconds = parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo);
    } else if (TIME_UNIT_REGEX.test(timeAttributeValue)) {
     seconds = parseTimeUnits(timeAttributeValue, rateInfo);
    }
   }
   return seconds;
  }
  function parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo) {
   const m = HMSF_REGEX.exec(timeAttributeValue);
   const frames = (m[4] | 0) + (m[5] | 0) / rateInfo.subFrameRate;
   return (m[1] | 0) * 3600 + (m[2] | 0) * 60 + (m[3] | 0) + frames / rateInfo.frameRate;
  }
  function parseTimeUnits(timeAttributeValue, rateInfo) {
   const m = TIME_UNIT_REGEX.exec(timeAttributeValue);
   const value = Number(m[1]);
   const unit = m[2];
   switch (unit) {
    case 'h':
     return value * 3600;
    case 'm':
     return value * 60;
    case 'ms':
     return value * 1000;
    case 'f':
     return value / rateInfo.frameRate;
    case 't':
     return value / rateInfo.tickRate;
   }
   return value;
  }

  class OutputFilter {
   constructor(timelineController, trackName) {
    this.timelineController = void 0;
    this.cueRanges = [];
    this.trackName = void 0;
    this.startTime = null;
    this.endTime = null;
    this.screen = null;
    this.timelineController = timelineController;
    this.trackName = trackName;
   }
   dispatchCue() {
    if (this.startTime === null) {
     return;
    }
    this.timelineController.addCues(this.trackName, this.startTime, this.endTime, this.screen, this.cueRanges);
    this.startTime = null;
   }
   newCue(startTime, endTime, screen) {
    if (this.startTime === null || this.startTime > startTime) {
     this.startTime = startTime;
    }
    this.endTime = endTime;
    this.screen = screen;
    this.timelineController.createCaptionsTrack(this.trackName);
   }
   reset() {
    this.cueRanges = [];
    this.startTime = null;
   }
  }

  class TimelineController {
   constructor(hls) {
    this.hls = void 0;
    this.media = null;
    this.config = void 0;
    this.enabled = true;
    this.Cues = void 0;
    this.textTracks = [];
    this.tracks = [];
    this.initPTS = [];
    this.unparsedVttFrags = [];
    this.captionsTracks = {};
    this.nonNativeCaptionsTracks = {};
    this.cea608Parser1 = void 0;
    this.cea608Parser2 = void 0;
    this.lastCc = -1;
    // Last video (CEA-608) fragment CC
    this.lastSn = -1;
    // Last video (CEA-608) fragment MSN
    this.lastPartIndex = -1;
    // Last video (CEA-608) fragment Part Index
    this.prevCC = -1;
    // Last subtitle fragment CC
    this.vttCCs = newVTTCCs();
    this.captionsProperties = void 0;
    this.hls = hls;
    this.config = hls.config;
    this.Cues = hls.config.cueHandler;
    this.captionsProperties = {
     textTrack1: {
      label: this.config.captionsTextTrack1Label,
      languageCode: this.config.captionsTextTrack1LanguageCode,
     },
     textTrack2: {
      label: this.config.captionsTextTrack2Label,
      languageCode: this.config.captionsTextTrack2LanguageCode,
     },
     textTrack3: {
      label: this.config.captionsTextTrack3Label,
      languageCode: this.config.captionsTextTrack3LanguageCode,
     },
     textTrack4: {
      label: this.config.captionsTextTrack4Label,
      languageCode: this.config.captionsTextTrack4LanguageCode,
     },
    };
    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    hls.on(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);
    hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);
    hls.on(Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);
    hls.on(Events.FRAG_DECRYPTED, this.onFragDecrypted, this);
    hls.on(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);
    hls.on(Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);
    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
   }
   destroy() {
    const { hls } = this;
    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    hls.off(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);
    hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);
    hls.off(Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);
    hls.off(Events.FRAG_DECRYPTED, this.onFragDecrypted, this);
    hls.off(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);
    hls.off(Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);
    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
    // @ts-ignore
    this.hls = this.config = this.media = null;
    this.cea608Parser1 = this.cea608Parser2 = undefined;
   }
   initCea608Parsers() {
    const channel1 = new OutputFilter(this, 'textTrack1');
    const channel2 = new OutputFilter(this, 'textTrack2');
    const channel3 = new OutputFilter(this, 'textTrack3');
    const channel4 = new OutputFilter(this, 'textTrack4');
    this.cea608Parser1 = new Cea608Parser(1, channel1, channel2);
    this.cea608Parser2 = new Cea608Parser(3, channel3, channel4);
   }
   addCues(trackName, startTime, endTime, screen, cueRanges) {
    // skip cues which overlap more than 50% with previously parsed time ranges
    let merged = false;
    for (let i = cueRanges.length; i--; ) {
     const cueRange = cueRanges[i];
     const overlap = intersection(cueRange[0], cueRange[1], startTime, endTime);
     if (overlap >= 0) {
      cueRange[0] = Math.min(cueRange[0], startTime);
      cueRange[1] = Math.max(cueRange[1], endTime);
      merged = true;
      if (overlap / (endTime - startTime) > 0.5) {
       return;
      }
     }
    }
    if (!merged) {
     cueRanges.push([startTime, endTime]);
    }
    if (this.config.renderTextTracksNatively) {
     const track = this.captionsTracks[trackName];
     this.Cues.newCue(track, startTime, endTime, screen);
    } else {
     const cues = this.Cues.newCue(null, startTime, endTime, screen);
     this.hls.trigger(Events.CUES_PARSED, {
      type: 'captions',
      cues,
      track: trackName,
     });
    }
   }

   // Triggered when an initial PTS is found; used for synchronisation of WebVTT.
   onInitPtsFound(event, { frag, id, initPTS, timescale, trackId }) {
    const { unparsedVttFrags } = this;
    if (id === PlaylistLevelType.MAIN) {
     this.initPTS[frag.cc] = {
      baseTime: initPTS,
      timescale,
      trackId,
     };
    }

    // Due to asynchronous processing, initial PTS may arrive later than the first VTT fragments are loaded.
    // Parse any unparsed fragments upon receiving the initial PTS.
    if (unparsedVttFrags.length) {
     this.unparsedVttFrags = [];
     unparsedVttFrags.forEach((data) => {
      if (this.initPTS[data.frag.cc]) {
       this.onFragLoaded(Events.FRAG_LOADED, data);
      } else {
       this.hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {
        success: false,
        frag: data.frag,
        error: new Error('Subtitle discontinuity domain does not match main'),
       });
      }
     });
    }
   }
   getExistingTrack(label, language) {
    const { media } = this;
    if (media) {
     for (let i = 0; i < media.textTracks.length; i++) {
      const textTrack = media.textTracks[i];
      if (
       canReuseVttTextTrack(textTrack, {
        name: label,
        lang: language,
        characteristics: 'transcribes-spoken-dialog,describes-music-and-sound',
       })
      ) {
       return textTrack;
      }
     }
    }
    return null;
   }
   createCaptionsTrack(trackName) {
    if (this.config.renderTextTracksNatively) {
     this.createNativeTrack(trackName);
    } else {
     this.createNonNativeTrack(trackName);
    }
   }
   createNativeTrack(trackName) {
    if (this.captionsTracks[trackName]) {
     return;
    }
    const { captionsProperties, captionsTracks, media } = this;
    const { label, languageCode } = captionsProperties[trackName];
    // Enable reuse of existing text track.
    const existingTrack = this.getExistingTrack(label, languageCode);
    if (!existingTrack) {
     const textTrack = this.createTextTrack('captions', label, languageCode);
     if (textTrack) {
      // Set a special property on the track so we know it's managed by Hls.js
      textTrack[trackName] = true;
      captionsTracks[trackName] = textTrack;
     }
    } else {
     captionsTracks[trackName] = existingTrack;
     clearCurrentCues(captionsTracks[trackName]);
     sendAddTrackEvent(captionsTracks[trackName], media);
    }
   }
   createNonNativeTrack(trackName) {
    if (this.nonNativeCaptionsTracks[trackName]) {
     return;
    }
    // Create a list of a single track for the provider to consume
    const trackProperties = this.captionsProperties[trackName];
    if (!trackProperties) {
     return;
    }
    const label = trackProperties.label;
    const track = {
     _id: trackName,
     label,
     kind: 'captions',
     default: trackProperties.media ? !!trackProperties.media.default : false,
     closedCaptions: trackProperties.media,
    };
    this.nonNativeCaptionsTracks[trackName] = track;
    this.hls.trigger(Events.NON_NATIVE_TEXT_TRACKS_FOUND, {
     tracks: [track],
    });
   }
   createTextTrack(kind, label, lang) {
    const media = this.media;
    if (!media) {
     return;
    }
    return media.addTextTrack(kind, label, lang);
   }
   onMediaAttaching(event, data) {
    this.media = data.media;
    if (!data.mediaSource) {
     this._cleanTracks();
    }
   }
   onMediaDetaching(event, data) {
    const transferringMedia = !!data.transferMedia;
    this.media = null;
    if (transferringMedia) {
     return;
    }
    const { captionsTracks } = this;
    Object.keys(captionsTracks).forEach((trackName) => {
     clearCurrentCues(captionsTracks[trackName]);
     delete captionsTracks[trackName];
    });
    this.nonNativeCaptionsTracks = {};
   }
   onManifestLoading() {
    // Detect discontinuity in video fragment (CEA-608) parsing
    this.lastCc = -1;
    this.lastSn = -1;
    this.lastPartIndex = -1;
    // Detect discontinuity in subtitle manifests
    this.prevCC = -1;
    this.vttCCs = newVTTCCs();
    // Reset tracks
    this._cleanTracks();
    this.tracks = [];
    this.captionsTracks = {};
    this.nonNativeCaptionsTracks = {};
    this.textTracks = [];
    this.unparsedVttFrags = [];
    this.initPTS = [];
    if (this.cea608Parser1 && this.cea608Parser2) {
     this.cea608Parser1.reset();
     this.cea608Parser2.reset();
    }
   }
   _cleanTracks() {
    // clear outdated subtitles
    const { media } = this;
    if (!media) {
     return;
    }
    const textTracks = media.textTracks;
    if (textTracks) {
     for (let i = 0; i < textTracks.length; i++) {
      clearCurrentCues(textTracks[i]);
     }
    }
   }
   onSubtitleTracksUpdated(event, data) {
    const tracks = data.subtitleTracks || [];
    const hasIMSC1 = tracks.some((track) => track.textCodec === IMSC1_CODEC);
    if (this.config.enableWebVTT || (hasIMSC1 && this.config.enableIMSC1)) {
     const listIsIdentical = subtitleOptionsIdentical(this.tracks, tracks);
     if (listIsIdentical) {
      this.tracks = tracks;
      return;
     }
     this.textTracks = [];
     this.tracks = tracks;
     if (this.config.renderTextTracksNatively) {
      const media = this.media;
      const inUseTracks = media ? filterSubtitleTracks(media.textTracks) : null;
      this.tracks.forEach((track, index) => {
       // Reuse tracks with the same label and lang, but do not reuse 608/708 tracks
       let textTrack;
       if (inUseTracks) {
        let inUseTrack = null;
        for (let i = 0; i < inUseTracks.length; i++) {
         if (inUseTracks[i] && canReuseVttTextTrack(inUseTracks[i], track)) {
          inUseTrack = inUseTracks[i];
          inUseTracks[i] = null;
          break;
         }
        }
        if (inUseTrack) {
         textTrack = inUseTrack;
        }
       }
       if (textTrack) {
        clearCurrentCues(textTrack);
       } else {
        const textTrackKind = captionsOrSubtitlesFromCharacteristics(track);
        textTrack = this.createTextTrack(textTrackKind, track.name, track.lang);
        if (textTrack) {
         textTrack.mode = 'disabled';
        }
       }
       if (textTrack) {
        this.textTracks.push(textTrack);
       }
      });
      // Warn when video element has captions or subtitle TextTracks carried over from another source
      if (inUseTracks != null && inUseTracks.length) {
       const unusedTextTracks = inUseTracks.filter((t) => t !== null).map((t) => t.label);
       if (unusedTextTracks.length) {
        this.hls.logger.warn(`Media element contains unused subtitle tracks: ${unusedTextTracks.join(', ')}. Replace media element for each source to clear TextTracks and captions menu.`);
       }
      }
     } else if (this.tracks.length) {
      // Create a list of tracks for the provider to consume
      const tracksList = this.tracks.map((track) => {
       return {
        label: track.name,
        kind: track.type.toLowerCase(),
        default: track.default,
        subtitleTrack: track,
       };
      });
      this.hls.trigger(Events.NON_NATIVE_TEXT_TRACKS_FOUND, {
       tracks: tracksList,
      });
     }
    }
   }
   onManifestLoaded(event, data) {
    if (this.config.enableCEA708Captions && data.captions) {
     data.captions.forEach((captionsTrack) => {
      const instreamIdMatch = /(?:CC|SERVICE)([1-4])/.exec(captionsTrack.instreamId);
      if (!instreamIdMatch) {
       return;
      }
      const trackName = `textTrack${instreamIdMatch[1]}`;
      const trackProperties = this.captionsProperties[trackName];
      if (!trackProperties) {
       return;
      }
      trackProperties.label = captionsTrack.name;
      if (captionsTrack.lang) {
       // optional attribute
       trackProperties.languageCode = captionsTrack.lang;
      }
      trackProperties.media = captionsTrack;
     });
    }
   }
   closedCaptionsForLevel(frag) {
    const level = this.hls.levels[frag.level];
    return level == null ? void 0 : level.attrs['CLOSED-CAPTIONS'];
   }
   onFragLoading(event, data) {
    // if this frag isn't contiguous, clear the parser so cues with bad start/end times aren't added to the textTrack
    if (this.enabled && data.frag.type === PlaylistLevelType.MAIN) {
     var _data$part$index, _data$part;
     const { cea608Parser1, cea608Parser2, lastSn } = this;
     const { cc, sn } = data.frag;
     const partIndex = (_data$part$index = (_data$part = data.part) == null ? void 0 : _data$part.index) != null ? _data$part$index : -1;
     if (cea608Parser1 && cea608Parser2) {
      if (sn !== lastSn + 1 || (sn === lastSn && partIndex !== this.lastPartIndex + 1) || cc !== this.lastCc) {
       cea608Parser1.reset();
       cea608Parser2.reset();
      }
     }
     this.lastCc = cc;
     this.lastSn = sn;
     this.lastPartIndex = partIndex;
    }
   }
   onFragLoaded(event, data) {
    const { frag, payload } = data;
    if (frag.type === PlaylistLevelType.SUBTITLE) {
     // If fragment is subtitle type, parse as WebVTT.
     if (payload.byteLength) {
      const decryptData = frag.decryptdata;
      // fragment after decryption has a stats object
      const decrypted = 'stats' in data;
      // If the subtitles are not encrypted, parse VTTs now. Otherwise, we need to wait.
      if (decryptData == null || !decryptData.encrypted || decrypted) {
       const trackPlaylistMedia = this.tracks[frag.level];
       const vttCCs = this.vttCCs;
       if (!vttCCs[frag.cc]) {
        vttCCs[frag.cc] = {
         start: frag.start,
         prevCC: this.prevCC,
         new: true,
        };
        this.prevCC = frag.cc;
       }
       if (trackPlaylistMedia && trackPlaylistMedia.textCodec === IMSC1_CODEC) {
        this._parseIMSC1(frag, payload);
       } else {
        this._parseVTTs(data);
       }
      }
     } else {
      // In case there is no payload, finish unsuccessfully.
      this.hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {
       success: false,
       frag,
       error: new Error('Empty subtitle payload'),
      });
     }
    }
   }
   _parseIMSC1(frag, payload) {
    const hls = this.hls;
    parseIMSC1(
     payload,
     this.initPTS[frag.cc],
     (cues) => {
      this._appendCues(cues, frag.level);
      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {
       success: true,
       frag: frag,
      });
     },
     (error) => {
      hls.logger.log(`Failed to parse IMSC1: ${error}`);
      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {
       success: false,
       frag: frag,
       error,
      });
     },
    );
   }
   _parseVTTs(data) {
    var _frag$initSegment;
    const { frag, payload } = data;
    // We need an initial synchronisation PTS. Store fragments as long as none has arrived
    const { initPTS, unparsedVttFrags } = this;
    const maxAvCC = initPTS.length - 1;
    if (!initPTS[frag.cc] && maxAvCC === -1) {
     unparsedVttFrags.push(data);
     return;
    }
    const hls = this.hls;
    // Parse the WebVTT file contents.
    const payloadWebVTT = (_frag$initSegment = frag.initSegment) != null && _frag$initSegment.data ? appendUint8Array(frag.initSegment.data, new Uint8Array(payload)).buffer : payload;
    parseWebVTT(
     payloadWebVTT,
     this.initPTS[frag.cc],
     this.vttCCs,
     frag.cc,
     frag.start,
     (cues) => {
      this._appendCues(cues, frag.level);
      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {
       success: true,
       frag: frag,
      });
     },
     (error) => {
      const missingInitPTS = error.message === 'Missing initPTS for VTT MPEGTS';
      if (missingInitPTS) {
       unparsedVttFrags.push(data);
      } else {
       this._fallbackToIMSC1(frag, payload);
      }
      // Something went wrong while parsing. Trigger event with success false.
      hls.logger.log(`Failed to parse VTT cue: ${error}`);
      if (missingInitPTS && maxAvCC > frag.cc) {
       return;
      }
      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {
       success: false,
       frag: frag,
       error,
      });
     },
    );
   }
   _fallbackToIMSC1(frag, payload) {
    // If textCodec is unknown, try parsing as IMSC1. Set textCodec based on the result
    const trackPlaylistMedia = this.tracks[frag.level];
    if (!trackPlaylistMedia.textCodec) {
     parseIMSC1(
      payload,
      this.initPTS[frag.cc],
      () => {
       trackPlaylistMedia.textCodec = IMSC1_CODEC;
       this._parseIMSC1(frag, payload);
      },
      () => {
       trackPlaylistMedia.textCodec = 'wvtt';
      },
     );
    }
   }
   _appendCues(cues, fragLevel) {
    const hls = this.hls;
    if (this.config.renderTextTracksNatively) {
     const textTrack = this.textTracks[fragLevel];
     // WebVTTParser.parse is an async method and if the currently selected text track mode is set to "disabled"
     // before parsing is done then don't try to access currentTrack.cues.getCueById as cues will be null
     // and trying to access getCueById method of cues will throw an exception
     // Because we check if the mode is disabled, we can force check `cues` below. They can't be null.
     if (!textTrack || textTrack.mode === 'disabled') {
      return;
     }
     cues.forEach((cue) => addCueToTrack(textTrack, cue));
    } else {
     const currentTrack = this.tracks[fragLevel];
     if (!currentTrack) {
      return;
     }
     const track = currentTrack.default ? 'default' : 'subtitles' + fragLevel;
     hls.trigger(Events.CUES_PARSED, {
      type: 'subtitles',
      cues,
      track,
     });
    }
   }
   onFragDecrypted(event, data) {
    const { frag } = data;
    if (frag.type === PlaylistLevelType.SUBTITLE) {
     this.onFragLoaded(Events.FRAG_LOADED, data);
    }
   }
   onSubtitleTracksCleared() {
    this.tracks = [];
    this.captionsTracks = {};
   }
   onFragParsingUserdata(event, data) {
    if (!this.enabled || !this.config.enableCEA708Captions) {
     return;
    }
    const { frag, samples } = data;
    if (frag.type === PlaylistLevelType.MAIN && this.closedCaptionsForLevel(frag) === 'NONE') {
     return;
    }
    // If the event contains captions (found in the bytes property), push all bytes into the parser immediately
    // It will create the proper timestamps based on the PTS value
    for (let i = 0; i < samples.length; i++) {
     const ccBytes = samples[i].bytes;
     if (ccBytes) {
      if (!this.cea608Parser1) {
       this.initCea608Parsers();
      }
      const ccdatas = this.extractCea608Data(ccBytes);
      this.cea608Parser1.addData(samples[i].pts, ccdatas[0]);
      this.cea608Parser2.addData(samples[i].pts, ccdatas[1]);
     }
    }
   }
   onBufferFlushing(event, { startOffset, endOffset, endOffsetSubtitles, type }) {
    const { media } = this;
    if (!media || media.currentTime < endOffset) {
     return;
    }
    // Clear 608 caption cues from the captions TextTracks when the video back buffer is flushed
    // Forward cues are never removed because we can loose streamed 608 content from recent fragments
    if (!type || type === 'video') {
     const { captionsTracks } = this;
     Object.keys(captionsTracks).forEach((trackName) => removeCuesInRange(captionsTracks[trackName], startOffset, endOffset));
    }
    if (this.config.renderTextTracksNatively) {
     // Clear VTT/IMSC1 subtitle cues from the subtitle TextTracks when the back buffer is flushed
     if (startOffset === 0 && endOffsetSubtitles !== undefined) {
      const { textTracks } = this;
      Object.keys(textTracks).forEach((trackName) => removeCuesInRange(textTracks[trackName], startOffset, endOffsetSubtitles));
     }
    }
   }
   extractCea608Data(byteArray) {
    const actualCCBytes = [[], []];
    const count = byteArray[0] & 0x1f;
    let position = 2;
    for (let j = 0; j < count; j++) {
     const tmpByte = byteArray[position++];
     const ccbyte1 = 0x7f & byteArray[position++];
     const ccbyte2 = 0x7f & byteArray[position++];
     if (ccbyte1 === 0 && ccbyte2 === 0) {
      continue;
     }
     const ccValid = (0x04 & tmpByte) !== 0; // Support all four channels
     if (ccValid) {
      const ccType = 0x03 & tmpByte;
      if (0x00 /* CEA608 field1*/ === ccType || 0x01 /* CEA608 field2*/ === ccType) {
       // Exclude CEA708 CC data.
       actualCCBytes[ccType].push(ccbyte1);
       actualCCBytes[ccType].push(ccbyte2);
      }
     }
    }
    return actualCCBytes;
   }
  }
  function captionsOrSubtitlesFromCharacteristics(track) {
   if (track.characteristics) {
    if (/transcribes-spoken-dialog/gi.test(track.characteristics) && /describes-music-and-sound/gi.test(track.characteristics)) {
     return 'captions';
    }
   }
   return 'subtitles';
  }
  function canReuseVttTextTrack(inUseTrack, manifestTrack) {
   return !!inUseTrack && inUseTrack.kind === captionsOrSubtitlesFromCharacteristics(manifestTrack) && subtitleTrackMatchesTextTrack(manifestTrack, inUseTrack);
  }
  function intersection(x1, x2, y1, y2) {
   return Math.min(x2, y2) - Math.max(x1, y1);
  }
  function newVTTCCs() {
   return {
    ccOffset: 0,
    presentationOffset: 0,
    0: {
     start: 0,
     prevCC: -1,
     new: true,
    },
   };
  }

  const WHITESPACE_CHAR = /\s/;
  const Cues = {
   newCue(track, startTime, endTime, captionScreen) {
    const result = [];
    let row;
    // the type data states this is VTTCue, but it can potentially be a TextTrackCue on old browsers
    let cue;
    let indenting;
    let indent;
    let text;
    const Cue = self.VTTCue || self.TextTrackCue;
    for (let r = 0; r < captionScreen.rows.length; r++) {
     row = captionScreen.rows[r];
     indenting = true;
     indent = 0;
     text = '';
     if (!row.isEmpty()) {
      var _track$cues;
      for (let c = 0; c < row.chars.length; c++) {
       if (WHITESPACE_CHAR.test(row.chars[c].uchar) && indenting) {
        indent++;
       } else {
        text += row.chars[c].uchar;
        indenting = false;
       }
      }
      // To be used for cleaning-up orphaned roll-up captions
      row.cueStartTime = startTime;

      // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE
      if (startTime === endTime) {
       endTime += 0.0001;
      }
      if (indent >= 16) {
       indent--;
      } else {
       indent++;
      }
      const cueText = fixLineBreaks(text.trim());
      const id = generateCueId(startTime, endTime, cueText);

      // If this cue already exists in the track do not push it
      if (!(track != null && (_track$cues = track.cues) != null && _track$cues.getCueById(id))) {
       cue = new Cue(startTime, endTime, cueText);
       cue.id = id;
       cue.line = r + 1;
       cue.align = 'left';
       // Clamp the position between 10 and 80 percent (CEA-608 PAC indent code)
       // https://dvcs.w3.org/hg/text-tracks/raw-file/default/608toVTT/608toVTT.html#positioning-in-cea-608
       // Firefox throws an exception and captions break with out of bounds 0-100 values
       cue.position = 10 + Math.min(80, Math.floor((indent * 8) / 32) * 10);
       result.push(cue);
      }
     }
    }
    if (track && result.length) {
     // Sort bottom cues in reverse order so that they render in line order when overlapping in Chrome
     result.sort((cueA, cueB) => {
      if (cueA.line === 'auto' || cueB.line === 'auto') {
       return 0;
      }
      if (cueA.line > 8 && cueB.line > 8) {
       return cueB.line - cueA.line;
      }
      return cueA.line - cueB.line;
     });
     result.forEach((cue) => addCueToTrack(track, cue));
    }
    return result;
   },
  };

  function fetchSupported() {
   if (
    // @ts-ignore
    self.fetch &&
    self.AbortController &&
    self.ReadableStream &&
    self.Request
   ) {
    try {
     new self.ReadableStream({}); // eslint-disable-line no-new
     return true;
    } catch (e) {
     /* noop */
    }
   }
   return false;
  }
  const BYTERANGE = /(\d+)-(\d+)\/(\d+)/;
  class FetchLoader {
   constructor(config) {
    this.fetchSetup = void 0;
    this.requestTimeout = void 0;
    this.request = null;
    this.response = null;
    this.controller = void 0;
    this.context = null;
    this.config = null;
    this.callbacks = null;
    this.stats = void 0;
    this.loader = null;
    this.fetchSetup = config.fetchSetup || getRequest;
    this.controller = new self.AbortController();
    this.stats = new LoadStats();
   }
   destroy() {
    this.loader = this.callbacks = this.context = this.config = this.request = null;
    this.abortInternal();
    this.response = null;
    // @ts-ignore
    this.fetchSetup = this.controller = this.stats = null;
   }
   abortInternal() {
    if (this.controller && !this.stats.loading.end) {
     this.stats.aborted = true;
     this.controller.abort();
    }
   }
   abort() {
    var _this$callbacks;
    this.abortInternal();
    if ((_this$callbacks = this.callbacks) != null && _this$callbacks.onAbort) {
     this.callbacks.onAbort(this.stats, this.context, this.response);
    }
   }
   load(context, config, callbacks) {
    const stats = this.stats;
    if (stats.loading.start) {
     throw new Error('Loader can only be used once.');
    }
    stats.loading.start = self.performance.now();
    const initParams = getRequestParameters(context, this.controller.signal);
    const isArrayBuffer = context.responseType === 'arraybuffer';
    const LENGTH = isArrayBuffer ? 'byteLength' : 'length';
    const { maxTimeToFirstByteMs, maxLoadTimeMs } = config.loadPolicy;
    this.context = context;
    this.config = config;
    this.callbacks = callbacks;
    this.request = this.fetchSetup(context, initParams);
    self.clearTimeout(this.requestTimeout);
    config.timeout = maxTimeToFirstByteMs && isFiniteNumber(maxTimeToFirstByteMs) ? maxTimeToFirstByteMs : maxLoadTimeMs;
    this.requestTimeout = self.setTimeout(() => {
     if (this.callbacks) {
      this.abortInternal();
      this.callbacks.onTimeout(stats, context, this.response);
     }
    }, config.timeout);
    const fetchPromise = isPromise(this.request) ? this.request.then(self.fetch) : self.fetch(this.request);
    fetchPromise
     .then((response) => {
      var _this$callbacks2;
      this.response = this.loader = response;
      const first = Math.max(self.performance.now(), stats.loading.start);
      self.clearTimeout(this.requestTimeout);
      config.timeout = maxLoadTimeMs;
      this.requestTimeout = self.setTimeout(
       () => {
        if (this.callbacks) {
         this.abortInternal();
         this.callbacks.onTimeout(stats, context, this.response);
        }
       },
       maxLoadTimeMs - (first - stats.loading.start),
      );
      if (!response.ok) {
       const { status, statusText } = response;
       throw new FetchError(statusText || 'fetch, bad network response', status, response);
      }
      stats.loading.first = first;
      stats.total = getContentLength(response.headers) || stats.total;
      const onProgress = (_this$callbacks2 = this.callbacks) == null ? void 0 : _this$callbacks2.onProgress;
      if (onProgress && isFiniteNumber(config.highWaterMark)) {
       return this.loadProgressively(response, stats, context, config.highWaterMark, onProgress);
      }
      if (isArrayBuffer) {
       return response.arrayBuffer();
      }
      if (context.responseType === 'json') {
       return response.json();
      }
      return response.text();
     })
     .then((responseData) => {
      var _this$callbacks3, _this$callbacks4;
      const response = this.response;
      if (!response) {
       throw new Error('loader destroyed');
      }
      self.clearTimeout(this.requestTimeout);
      stats.loading.end = Math.max(self.performance.now(), stats.loading.first);
      const total = responseData[LENGTH];
      if (total) {
       stats.loaded = stats.total = total;
      }
      const loaderResponse = {
       url: response.url,
       data: responseData,
       code: response.status,
      };
      const onProgress = (_this$callbacks3 = this.callbacks) == null ? void 0 : _this$callbacks3.onProgress;
      if (onProgress && !isFiniteNumber(config.highWaterMark)) {
       onProgress(stats, context, responseData, response);
      }
      (_this$callbacks4 = this.callbacks) == null || _this$callbacks4.onSuccess(loaderResponse, stats, context, response);
     })
     .catch((error) => {
      var _this$callbacks5;
      self.clearTimeout(this.requestTimeout);
      if (stats.aborted) {
       return;
      }
      // CORS errors result in an undefined code. Set it to 0 here to align with XHR's behavior
      // when destroying, 'error' itself can be undefined
      const code = !error ? 0 : error.code || 0;
      const text = !error ? null : error.message;
      (_this$callbacks5 = this.callbacks) == null ||
       _this$callbacks5.onError(
        {
         code,
         text,
        },
        context,
        error ? error.details : null,
        stats,
       );
     });
   }
   getCacheAge() {
    let result = null;
    if (this.response) {
     const ageHeader = this.response.headers.get('age');
     result = ageHeader ? parseFloat(ageHeader) : null;
    }
    return result;
   }
   getResponseHeader(name) {
    return this.response ? this.response.headers.get(name) : null;
   }
   loadProgressively(response, stats, context, highWaterMark = 0, onProgress) {
    const chunkCache = new ChunkCache();
    const reader = response.body.getReader();
    const pump = () => {
     return reader
      .read()
      .then((data) => {
       if (data.done) {
        if (chunkCache.dataLength) {
         onProgress(stats, context, chunkCache.flush().buffer, response);
        }
        return Promise.resolve(new ArrayBuffer(0));
       }
       const chunk = data.value;
       const len = chunk.length;
       stats.loaded += len;
       if (len < highWaterMark || chunkCache.dataLength) {
        // The current chunk is too small to to be emitted or the cache already has data
        // Push it to the cache
        chunkCache.push(chunk);
        if (chunkCache.dataLength >= highWaterMark) {
         // flush in order to join the typed arrays
         onProgress(stats, context, chunkCache.flush().buffer, response);
        }
       } else {
        // If there's nothing cached already, and the chache is large enough
        // just emit the progress event
        onProgress(stats, context, chunk.buffer, response);
       }
       return pump();
      })
      .catch(() => {
       /* aborted */
       return Promise.reject();
      });
    };
    return pump();
   }
  }
  function getRequestParameters(context, signal) {
   const initParams = {
    method: 'GET',
    mode: 'cors',
    credentials: 'same-origin',
    signal,
    headers: new self.Headers(_extends({}, context.headers)),
   };
   if (context.rangeEnd) {
    initParams.headers.set('Range', 'bytes=' + context.rangeStart + '-' + String(context.rangeEnd - 1));
   }
   return initParams;
  }
  function getByteRangeLength(byteRangeHeader) {
   const result = BYTERANGE.exec(byteRangeHeader);
   if (result) {
    return parseInt(result[2]) - parseInt(result[1]) + 1;
   }
  }
  function getContentLength(headers) {
   const contentRange = headers.get('Content-Range');
   if (contentRange) {
    const byteRangeLength = getByteRangeLength(contentRange);
    if (isFiniteNumber(byteRangeLength)) {
     return byteRangeLength;
    }
   }
   const contentLength = headers.get('Content-Length');
   if (contentLength) {
    return parseInt(contentLength);
   }
  }
  function getRequest(context, initParams) {
   return new self.Request(context.url, initParams);
  }
  class FetchError extends Error {
   constructor(message, code, details) {
    super(message);
    this.code = void 0;
    this.details = void 0;
    this.code = code;
    this.details = details;
   }
  }

  const AGE_HEADER_LINE_REGEX = /^age:\s*[\d.]+\s*$/im;
  class XhrLoader {
   constructor(config) {
    this.xhrSetup = void 0;
    this.requestTimeout = void 0;
    this.retryTimeout = void 0;
    this.retryDelay = void 0;
    this.config = null;
    this.callbacks = null;
    this.context = null;
    this.loader = null;
    this.stats = void 0;
    this.xhrSetup = config ? config.xhrSetup || null : null;
    this.stats = new LoadStats();
    this.retryDelay = 0;
   }
   destroy() {
    this.callbacks = null;
    this.abortInternal();
    this.loader = null;
    this.config = null;
    this.context = null;
    this.xhrSetup = null;
   }
   abortInternal() {
    const loader = this.loader;
    self.clearTimeout(this.requestTimeout);
    self.clearTimeout(this.retryTimeout);
    if (loader) {
     loader.onreadystatechange = null;
     loader.onprogress = null;
     if (loader.readyState !== 4) {
      this.stats.aborted = true;
      loader.abort();
     }
    }
   }
   abort() {
    var _this$callbacks;
    this.abortInternal();
    if ((_this$callbacks = this.callbacks) != null && _this$callbacks.onAbort) {
     this.callbacks.onAbort(this.stats, this.context, this.loader);
    }
   }
   load(context, config, callbacks) {
    if (this.stats.loading.start) {
     throw new Error('Loader can only be used once.');
    }
    this.stats.loading.start = self.performance.now();
    this.context = context;
    this.config = config;
    this.callbacks = callbacks;
    this.loadInternal();
   }
   loadInternal() {
    const { config, context } = this;
    if (!config || !context) {
     return;
    }
    const xhr = (this.loader = new self.XMLHttpRequest());
    const stats = this.stats;
    stats.loading.first = 0;
    stats.loaded = 0;
    stats.aborted = false;
    const xhrSetup = this.xhrSetup;
    if (xhrSetup) {
     Promise.resolve()
      .then(() => {
       if (this.loader !== xhr || this.stats.aborted) return;
       return xhrSetup(xhr, context.url);
      })
      .catch((error) => {
       if (this.loader !== xhr || this.stats.aborted) return;
       xhr.open('GET', context.url, true);
       return xhrSetup(xhr, context.url);
      })
      .then(() => {
       if (this.loader !== xhr || this.stats.aborted) return;
       this.openAndSendXhr(xhr, context, config);
      })
      .catch((error) => {
       var _this$callbacks2;
       // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS
       (_this$callbacks2 = this.callbacks) == null ||
        _this$callbacks2.onError(
         {
          code: xhr.status,
          text: error.message,
         },
         context,
         xhr,
         stats,
        );
       return;
      });
    } else {
     this.openAndSendXhr(xhr, context, config);
    }
   }
   openAndSendXhr(xhr, context, config) {
    if (!xhr.readyState) {
     xhr.open('GET', context.url, true);
    }
    const headers = context.headers;
    const { maxTimeToFirstByteMs, maxLoadTimeMs } = config.loadPolicy;
    if (headers) {
     for (const header in headers) {
      xhr.setRequestHeader(header, headers[header]);
     }
    }
    if (context.rangeEnd) {
     xhr.setRequestHeader('Range', 'bytes=' + context.rangeStart + '-' + (context.rangeEnd - 1));
    }
    xhr.onreadystatechange = this.readystatechange.bind(this);
    xhr.onprogress = this.loadprogress.bind(this);
    xhr.responseType = context.responseType;
    // setup timeout before we perform request
    self.clearTimeout(this.requestTimeout);
    config.timeout = maxTimeToFirstByteMs && isFiniteNumber(maxTimeToFirstByteMs) ? maxTimeToFirstByteMs : maxLoadTimeMs;
    this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.timeout);
    xhr.send();
   }
   readystatechange() {
    const { context, loader: xhr, stats } = this;
    if (!context || !xhr) {
     return;
    }
    const readyState = xhr.readyState;
    const config = this.config;

    // don't proceed if xhr has been aborted
    if (stats.aborted) {
     return;
    }

    // >= HEADERS_RECEIVED
    if (readyState >= 2) {
     if (stats.loading.first === 0) {
      stats.loading.first = Math.max(self.performance.now(), stats.loading.start);
      // readyState >= 2 AND readyState !==4 (readyState = HEADERS_RECEIVED || LOADING) rearm timeout as xhr not finished yet
      if (config.timeout !== config.loadPolicy.maxLoadTimeMs) {
       self.clearTimeout(this.requestTimeout);
       config.timeout = config.loadPolicy.maxLoadTimeMs;
       this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.loadPolicy.maxLoadTimeMs - (stats.loading.first - stats.loading.start));
      }
     }
     if (readyState === 4) {
      self.clearTimeout(this.requestTimeout);
      xhr.onreadystatechange = null;
      xhr.onprogress = null;
      const status = xhr.status;
      // http status between 200 to 299 are all successful
      const useResponseText = xhr.responseType === 'text' ? xhr.responseText : null;
      if (status >= 200 && status < 300) {
       const data = useResponseText != null ? useResponseText : xhr.response;
       if (data != null) {
        var _this$callbacks3, _this$callbacks4;
        stats.loading.end = Math.max(self.performance.now(), stats.loading.first);
        const len = xhr.responseType === 'arraybuffer' ? data.byteLength : data.length;
        stats.loaded = stats.total = len;
        stats.bwEstimate = (stats.total * 8000) / (stats.loading.end - stats.loading.first);
        const onProgress = (_this$callbacks3 = this.callbacks) == null ? void 0 : _this$callbacks3.onProgress;
        if (onProgress) {
         onProgress(stats, context, data, xhr);
        }
        const _response = {
         url: xhr.responseURL,
         data: data,
         code: status,
        };
        (_this$callbacks4 = this.callbacks) == null || _this$callbacks4.onSuccess(_response, stats, context, xhr);
        return;
       }
      }

      // Handle bad status or nullish response
      const retryConfig = config.loadPolicy.errorRetry;
      const retryCount = stats.retry;
      // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error
      const response = {
       url: context.url,
       data: undefined,
       code: status,
      };
      if (shouldRetry(retryConfig, retryCount, false, response)) {
       this.retry(retryConfig);
      } else {
       var _this$callbacks5;
       logger.error(`${status} while loading ${context.url}`);
       (_this$callbacks5 = this.callbacks) == null ||
        _this$callbacks5.onError(
         {
          code: status,
          text: xhr.statusText,
         },
         context,
         xhr,
         stats,
        );
      }
     }
    }
   }
   loadtimeout() {
    if (!this.config) return;
    const retryConfig = this.config.loadPolicy.timeoutRetry;
    const retryCount = this.stats.retry;
    if (shouldRetry(retryConfig, retryCount, true)) {
     this.retry(retryConfig);
    } else {
     var _this$context;
     logger.warn(`timeout while loading ${(_this$context = this.context) == null ? void 0 : _this$context.url}`);
     const callbacks = this.callbacks;
     if (callbacks) {
      this.abortInternal();
      callbacks.onTimeout(this.stats, this.context, this.loader);
     }
    }
   }
   retry(retryConfig) {
    const { context, stats } = this;
    this.retryDelay = getRetryDelay(retryConfig, stats.retry);
    stats.retry++;
    logger.warn(`${status ? 'HTTP Status ' + status : 'Timeout'} while loading ${context == null ? void 0 : context.url}, retrying ${stats.retry}/${retryConfig.maxNumRetry} in ${this.retryDelay}ms`);
    // abort and reset internal state
    this.abortInternal();
    this.loader = null;
    // schedule retry
    self.clearTimeout(this.retryTimeout);
    this.retryTimeout = self.setTimeout(this.loadInternal.bind(this), this.retryDelay);
   }
   loadprogress(event) {
    const stats = this.stats;
    stats.loaded = event.loaded;
    if (event.lengthComputable) {
     stats.total = event.total;
    }
   }
   getCacheAge() {
    let result = null;
    if (this.loader && AGE_HEADER_LINE_REGEX.test(this.loader.getAllResponseHeaders())) {
     const ageHeader = this.loader.getResponseHeader('age');
     result = ageHeader ? parseFloat(ageHeader) : null;
    }
    return result;
   }
   getResponseHeader(name) {
    if (this.loader && new RegExp(`^${name}:\\s*[\\d.]+\\s*$`, 'im').test(this.loader.getAllResponseHeaders())) {
     return this.loader.getResponseHeader(name);
    }
    return null;
   }
  }

  /**
   * @deprecated use fragLoadPolicy.default
   */

  /**
   * @deprecated use manifestLoadPolicy.default and playlistLoadPolicy.default
   */

  const defaultLoadPolicy = {
   maxTimeToFirstByteMs: 8000,
   maxLoadTimeMs: 20000,
   timeoutRetry: null,
   errorRetry: null,
  };

  /**
   * @ignore
   * If possible, keep hlsDefaultConfig shallow
   * It is cloned whenever a new Hls instance is created, by keeping the config
   * shallow the properties are cloned, and we don't end up manipulating the default
   */
  const hlsDefaultConfig = _objectSpread2(
   _objectSpread2(
    {
     autoStartLoad: true,
     // used by stream-controller
     startPosition: -1,
     // used by stream-controller
     defaultAudioCodec: undefined,
     // used by stream-controller
     debug: false,
     // used by logger
     capLevelOnFPSDrop: false,
     // used by fps-controller
     capLevelToPlayerSize: false,
     // used by cap-level-controller
     ignoreDevicePixelRatio: false,
     // used by cap-level-controller
     maxDevicePixelRatio: Number.POSITIVE_INFINITY,
     // used by cap-level-controller
     preferManagedMediaSource: true,
     initialLiveManifestSize: 1,
     // used by stream-controller
     maxBufferLength: 30,
     // used by stream-controller
     backBufferLength: Infinity,
     // used by buffer-controller
     frontBufferFlushThreshold: Infinity,
     startOnSegmentBoundary: false,
     // used by stream-controller
     maxBufferSize: 60 * 1000 * 1000,
     // used by stream-controller
     maxFragLookUpTolerance: 0.25,
     // used by stream-controller
     maxBufferHole: 0.1,
     // used by stream-controller and gap-controller
     detectStallWithCurrentTimeMs: 1250,
     // used by gap-controller
     highBufferWatchdogPeriod: 2,
     // used by gap-controller
     nudgeOffset: 0.1,
     // used by gap-controller
     nudgeMaxRetry: 3,
     // used by gap-controller
     nudgeOnVideoHole: true,
     // used by gap-controller
     liveSyncMode: 'edge',
     // used by stream-controller
     liveSyncDurationCount: 3,
     // used by latency-controller
     liveSyncOnStallIncrease: 1,
     // used by latency-controller
     liveMaxLatencyDurationCount: Infinity,
     // used by latency-controller
     liveSyncDuration: undefined,
     // used by latency-controller
     liveMaxLatencyDuration: undefined,
     // used by latency-controller
     maxLiveSyncPlaybackRate: 1,
     // used by latency-controller
     liveDurationInfinity: false,
     // used by buffer-controller
     /**
      * @deprecated use backBufferLength
      */
     liveBackBufferLength: null,
     // used by buffer-controller
     maxMaxBufferLength: 600,
     // used by stream-controller
     enableWorker: true,
     // used by transmuxer
     workerPath: null,
     // used by transmuxer
     enableSoftwareAES: true,
     // used by decrypter
     startLevel: undefined,
     // used by level-controller
     startFragPrefetch: false,
     // used by stream-controller
     fpsDroppedMonitoringPeriod: 5000,
     // used by fps-controller
     fpsDroppedMonitoringThreshold: 0.2,
     // used by fps-controller
     appendErrorMaxRetry: 3,
     // used by buffer-controller
     ignorePlaylistParsingErrors: false,
     loader: XhrLoader,
     // loader: FetchLoader,
     fLoader: undefined,
     // used by fragment-loader
     pLoader: undefined,
     // used by playlist-loader
     xhrSetup: undefined,
     // used by xhr-loader
     licenseXhrSetup: undefined,
     // used by eme-controller
     licenseResponseCallback: undefined,
     // used by eme-controller
     abrController: AbrController,
     bufferController: BufferController,
     capLevelController: CapLevelController,
     errorController: ErrorController,
     fpsController: FPSController,
     stretchShortVideoTrack: false,
     // used by mp4-remuxer
     maxAudioFramesDrift: 1,
     // used by mp4-remuxer
     forceKeyFrameOnDiscontinuity: true,
     // used by ts-demuxer
     abrEwmaFastLive: 3,
     // used by abr-controller
     abrEwmaSlowLive: 9,
     // used by abr-controller
     abrEwmaFastVoD: 3,
     // used by abr-controller
     abrEwmaSlowVoD: 9,
     // used by abr-controller
     abrEwmaDefaultEstimate: 5e5,
     // 500 kbps  // used by abr-controller
     abrEwmaDefaultEstimateMax: 5e6,
     // 5 mbps
     abrBandWidthFactor: 0.95,
     // used by abr-controller
     abrBandWidthUpFactor: 0.7,
     // used by abr-controller
     abrMaxWithRealBitrate: false,
     // used by abr-controller
     maxStarvationDelay: 4,
     // used by abr-controller
     maxLoadingDelay: 4,
     // used by abr-controller
     minAutoBitrate: 0,
     // used by hls
     emeEnabled: false,
     // used by eme-controller
     widevineLicenseUrl: undefined,
     // used by eme-controller
     drmSystems: {},
     // used by eme-controller
     drmSystemOptions: {},
     // used by eme-controller
     requestMediaKeySystemAccessFunc: requestMediaKeySystemAccess,
     // used by eme-controller
     requireKeySystemAccessOnStart: false,
     // used by eme-controller
     testBandwidth: true,
     progressive: false,
     lowLatencyMode: true,
     cmcd: undefined,
     enableDateRangeMetadataCues: true,
     enableEmsgMetadataCues: true,
     enableEmsgKLVMetadata: false,
     enableID3MetadataCues: true,
     enableInterstitialPlayback: true,
     interstitialAppendInPlace: true,
     interstitialLiveLookAhead: 10,
     useMediaCapabilities: true,
     preserveManualLevelOnError: false,
     certLoadPolicy: {
      default: defaultLoadPolicy,
     },
     keyLoadPolicy: {
      default: {
       maxTimeToFirstByteMs: 8000,
       maxLoadTimeMs: 20000,
       timeoutRetry: {
        maxNumRetry: 1,
        retryDelayMs: 1000,
        maxRetryDelayMs: 20000,
        backoff: 'linear',
       },
       errorRetry: {
        maxNumRetry: 8,
        retryDelayMs: 1000,
        maxRetryDelayMs: 20000,
        backoff: 'linear',
       },
      },
     },
     manifestLoadPolicy: {
      default: {
       maxTimeToFirstByteMs: Infinity,
       maxLoadTimeMs: 20000,
       timeoutRetry: {
        maxNumRetry: 2,
        retryDelayMs: 0,
        maxRetryDelayMs: 0,
       },
       errorRetry: {
        maxNumRetry: 1,
        retryDelayMs: 1000,
        maxRetryDelayMs: 8000,
       },
      },
     },
     playlistLoadPolicy: {
      default: {
       maxTimeToFirstByteMs: 10000,
       maxLoadTimeMs: 20000,
       timeoutRetry: {
        maxNumRetry: 2,
        retryDelayMs: 0,
        maxRetryDelayMs: 0,
       },
       errorRetry: {
        maxNumRetry: 2,
        retryDelayMs: 1000,
        maxRetryDelayMs: 8000,
       },
      },
     },
     fragLoadPolicy: {
      default: {
       maxTimeToFirstByteMs: 10000,
       maxLoadTimeMs: 120000,
       timeoutRetry: {
        maxNumRetry: 4,
        retryDelayMs: 0,
        maxRetryDelayMs: 0,
       },
       errorRetry: {
        maxNumRetry: 6,
        retryDelayMs: 1000,
        maxRetryDelayMs: 8000,
       },
      },
     },
     steeringManifestLoadPolicy: {
      default: {
       maxTimeToFirstByteMs: 10000,
       maxLoadTimeMs: 20000,
       timeoutRetry: {
        maxNumRetry: 2,
        retryDelayMs: 0,
        maxRetryDelayMs: 0,
       },
       errorRetry: {
        maxNumRetry: 1,
        retryDelayMs: 1000,
        maxRetryDelayMs: 8000,
       },
      },
     },
     interstitialAssetListLoadPolicy: {
      default: {
       maxTimeToFirstByteMs: 10000,
       maxLoadTimeMs: 30000,
       timeoutRetry: {
        maxNumRetry: 0,
        retryDelayMs: 0,
        maxRetryDelayMs: 0,
       },
       errorRetry: {
        maxNumRetry: 0,
        retryDelayMs: 1000,
        maxRetryDelayMs: 8000,
       },
      },
     },
     // These default settings are deprecated in favor of the above policies
     // and are maintained for backwards compatibility
     manifestLoadingTimeOut: 10000,
     manifestLoadingMaxRetry: 1,
     manifestLoadingRetryDelay: 1000,
     manifestLoadingMaxRetryTimeout: 64000,
     levelLoadingTimeOut: 10000,
     levelLoadingMaxRetry: 4,
     levelLoadingRetryDelay: 1000,
     levelLoadingMaxRetryTimeout: 64000,
     fragLoadingTimeOut: 20000,
     fragLoadingMaxRetry: 6,
     fragLoadingRetryDelay: 1000,
     fragLoadingMaxRetryTimeout: 64000,
    },
    timelineConfig(),
   ),
   {},
   {
    subtitleStreamController: SubtitleStreamController,
    subtitleTrackController: SubtitleTrackController,
    timelineController: TimelineController,
    audioStreamController: AudioStreamController,
    audioTrackController: AudioTrackController,
    emeController: EMEController,
    cmcdController: CMCDController,
    contentSteeringController: ContentSteeringController,
    interstitialsController: InterstitialsController,
   },
  );
  function timelineConfig() {
   return {
    cueHandler: Cues,
    // used by timeline-controller
    enableWebVTT: true,
    // used by timeline-controller
    enableIMSC1: true,
    // used by timeline-controller
    enableCEA708Captions: true,
    // used by timeline-controller
    captionsTextTrack1Label: 'English',
    // used by timeline-controller
    captionsTextTrack1LanguageCode: 'en',
    // used by timeline-controller
    captionsTextTrack2Label: 'Spanish',
    // used by timeline-controller
    captionsTextTrack2LanguageCode: 'es',
    // used by timeline-controller
    captionsTextTrack3Label: 'Unknown CC',
    // used by timeline-controller
    captionsTextTrack3LanguageCode: '',
    // used by timeline-controller
    captionsTextTrack4Label: 'Unknown CC',
    // used by timeline-controller
    captionsTextTrack4LanguageCode: '',
    // used by timeline-controller
    renderTextTracksNatively: true,
   };
  }

  /**
   * @ignore
   */
  function mergeConfig(defaultConfig, userConfig, logger) {
   if ((userConfig.liveSyncDurationCount || userConfig.liveMaxLatencyDurationCount) && (userConfig.liveSyncDuration || userConfig.liveMaxLatencyDuration)) {
    throw new Error("Illegal hls.js config: don't mix up liveSyncDurationCount/liveMaxLatencyDurationCount and liveSyncDuration/liveMaxLatencyDuration");
   }
   if (userConfig.liveMaxLatencyDurationCount !== undefined && (userConfig.liveSyncDurationCount === undefined || userConfig.liveMaxLatencyDurationCount <= userConfig.liveSyncDurationCount)) {
    throw new Error('Illegal hls.js config: "liveMaxLatencyDurationCount" must be greater than "liveSyncDurationCount"');
   }
   if (userConfig.liveMaxLatencyDuration !== undefined && (userConfig.liveSyncDuration === undefined || userConfig.liveMaxLatencyDuration <= userConfig.liveSyncDuration)) {
    throw new Error('Illegal hls.js config: "liveMaxLatencyDuration" must be greater than "liveSyncDuration"');
   }
   const defaultsCopy = deepCpy(defaultConfig);

   // Backwards compatibility with deprecated config values
   const deprecatedSettingTypes = ['manifest', 'level', 'frag'];
   const deprecatedSettings = ['TimeOut', 'MaxRetry', 'RetryDelay', 'MaxRetryTimeout'];
   deprecatedSettingTypes.forEach((type) => {
    const policyName = `${type === 'level' ? 'playlist' : type}LoadPolicy`;
    const policyNotSet = userConfig[policyName] === undefined;
    const report = [];
    deprecatedSettings.forEach((setting) => {
     const deprecatedSetting = `${type}Loading${setting}`;
     const value = userConfig[deprecatedSetting];
     if (value !== undefined && policyNotSet) {
      report.push(deprecatedSetting);
      const settings = defaultsCopy[policyName].default;
      userConfig[policyName] = {
       default: settings,
      };
      switch (setting) {
       case 'TimeOut':
        settings.maxLoadTimeMs = value;
        settings.maxTimeToFirstByteMs = value;
        break;
       case 'MaxRetry':
        settings.errorRetry.maxNumRetry = value;
        settings.timeoutRetry.maxNumRetry = value;
        break;
       case 'RetryDelay':
        settings.errorRetry.retryDelayMs = value;
        settings.timeoutRetry.retryDelayMs = value;
        break;
       case 'MaxRetryTimeout':
        settings.errorRetry.maxRetryDelayMs = value;
        settings.timeoutRetry.maxRetryDelayMs = value;
        break;
      }
     }
    });
    if (report.length) {
     logger.warn(`hls.js config: "${report.join('", "')}" setting(s) are deprecated, use "${policyName}": ${stringify(userConfig[policyName])}`);
    }
   });
   return _objectSpread2(_objectSpread2({}, defaultsCopy), userConfig);
  }
  function deepCpy(obj) {
   if (obj && typeof obj === 'object') {
    if (Array.isArray(obj)) {
     return obj.map(deepCpy);
    }
    return Object.keys(obj).reduce((result, key) => {
     result[key] = deepCpy(obj[key]);
     return result;
    }, {});
   }
   return obj;
  }

  /**
   * @ignore
   */
  function enableStreamingMode(config, logger) {
   const currentLoader = config.loader;
   if (currentLoader !== FetchLoader && currentLoader !== XhrLoader) {
    // If a developer has configured their own loader, respect that choice
    logger.log('[config]: Custom loader detected, cannot enable progressive streaming');
    config.progressive = false;
   } else {
    const canStreamProgressively = fetchSupported();
    if (canStreamProgressively) {
     config.loader = FetchLoader;
     config.progressive = true;
     config.enableSoftwareAES = true;
     logger.log('[config]: Progressive streaming enabled, using FetchLoader');
    }
   }
  }

  const MAX_START_GAP_JUMP = 2.0;
  const SKIP_BUFFER_HOLE_STEP_SECONDS = 0.1;
  const SKIP_BUFFER_RANGE_START = 0.05;
  const TICK_INTERVAL$1 = 100;
  class GapController extends TaskLoop {
   constructor(hls, fragmentTracker) {
    super('gap-controller', hls.logger);
    this.hls = void 0;
    this.fragmentTracker = void 0;
    this.media = null;
    this.mediaSource = void 0;
    this.nudgeRetry = 0;
    this.stallReported = false;
    this.stalled = null;
    this.moved = false;
    this.seeking = false;
    this.buffered = {};
    this.lastCurrentTime = 0;
    this.ended = 0;
    this.waiting = 0;
    this.onMediaPlaying = () => {
     this.ended = 0;
     this.waiting = 0;
    };
    this.onMediaWaiting = () => {
     var _this$media;
     if ((_this$media = this.media) != null && _this$media.seeking) {
      return;
     }
     this.waiting = self.performance.now();
     this.tick();
    };
    this.onMediaEnded = () => {
     if (this.hls) {
      var _this$media2;
      // ended is set when triggering MEDIA_ENDED so that we do not trigger it again on stall or on tick with media.ended
      this.ended = ((_this$media2 = this.media) == null ? void 0 : _this$media2.currentTime) || 1;
      this.hls.trigger(Events.MEDIA_ENDED, {
       stalled: false,
      });
     }
    };
    this.hls = hls;
    this.fragmentTracker = fragmentTracker;
    this.registerListeners();
   }
   registerListeners() {
    const { hls } = this;
    if (hls) {
     hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
     hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
     hls.on(Events.BUFFER_APPENDED, this.onBufferAppended, this);
    }
   }
   unregisterListeners() {
    const { hls } = this;
    if (hls) {
     hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
     hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
     hls.off(Events.BUFFER_APPENDED, this.onBufferAppended, this);
    }
   }
   destroy() {
    super.destroy();
    this.unregisterListeners();
    this.media = this.hls = this.fragmentTracker = null;
    this.mediaSource = undefined;
   }
   onMediaAttached(event, data) {
    this.setInterval(TICK_INTERVAL$1);
    this.mediaSource = data.mediaSource;
    const media = (this.media = data.media);
    addEventListener(media, 'playing', this.onMediaPlaying);
    addEventListener(media, 'waiting', this.onMediaWaiting);
    addEventListener(media, 'ended', this.onMediaEnded);
   }
   onMediaDetaching(event, data) {
    this.clearInterval();
    const { media } = this;
    if (media) {
     removeEventListener(media, 'playing', this.onMediaPlaying);
     removeEventListener(media, 'waiting', this.onMediaWaiting);
     removeEventListener(media, 'ended', this.onMediaEnded);
     this.media = null;
    }
    this.mediaSource = undefined;
   }
   onBufferAppended(event, data) {
    this.buffered = data.timeRanges;
   }
   get hasBuffered() {
    return Object.keys(this.buffered).length > 0;
   }
   tick() {
    var _this$media3;
    if (!((_this$media3 = this.media) != null && _this$media3.readyState) || !this.hasBuffered) {
     return;
    }
    const currentTime = this.media.currentTime;
    this.poll(currentTime, this.lastCurrentTime);
    this.lastCurrentTime = currentTime;
   }

   /**
    * Checks if the playhead is stuck within a gap, and if so, attempts to free it.
    * A gap is an unbuffered range between two buffered ranges (or the start and the first buffered range).
    *
    * @param lastCurrentTime - Previously read playhead position
    */
   poll(currentTime, lastCurrentTime) {
    var _this$hls, _this$hls2;
    const config = (_this$hls = this.hls) == null ? void 0 : _this$hls.config;
    if (!config) {
     return;
    }
    const media = this.media;
    if (!media) {
     return;
    }
    const { seeking } = media;
    const seeked = this.seeking && !seeking;
    const beginSeek = !this.seeking && seeking;
    const pausedEndedOrHalted = (media.paused && !seeking) || media.ended || media.playbackRate === 0;
    this.seeking = seeking;

    // The playhead is moving, no-op
    if (currentTime !== lastCurrentTime) {
     if (lastCurrentTime) {
      this.ended = 0;
     }
     this.moved = true;
     if (!seeking) {
      this.nudgeRetry = 0;
      // When crossing between buffered video time ranges, but not audio, flush pipeline with seek (Chrome)
      if (config.nudgeOnVideoHole && !pausedEndedOrHalted && currentTime > lastCurrentTime) {
       this.nudgeOnVideoHole(currentTime, lastCurrentTime);
      }
     }
     if (this.waiting === 0) {
      this.stallResolved(currentTime);
     }
     return;
    }

    // Clear stalled state when beginning or finishing seeking so that we don't report stalls coming out of a seek
    if (beginSeek || seeked) {
     if (seeked) {
      this.stallResolved(currentTime);
     }
     return;
    }

    // The playhead should not be moving
    if (pausedEndedOrHalted) {
     this.nudgeRetry = 0;
     this.stallResolved(currentTime);
     // Fire MEDIA_ENDED to workaround event not being dispatched by browser
     if (!this.ended && media.ended && this.hls) {
      this.ended = currentTime || 1;
      this.hls.trigger(Events.MEDIA_ENDED, {
       stalled: false,
      });
     }
     return;
    }
    if (!BufferHelper.getBuffered(media).length) {
     this.nudgeRetry = 0;
     return;
    }

    // Resolve stalls at buffer holes using the main buffer, whose ranges are the intersections of the A/V sourcebuffers
    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);
    const nextStart = bufferInfo.nextStart || 0;
    const fragmentTracker = this.fragmentTracker;
    if (seeking && fragmentTracker && this.hls) {
     // Is there a fragment loading/parsing/appending before currentTime?
     const inFlightDependency = getInFlightDependency(this.hls.inFlightFragments, currentTime);

     // Waiting for seeking in a buffered range to complete
     const hasEnoughBuffer = bufferInfo.len > MAX_START_GAP_JUMP;
     // Next buffered range is too far ahead to jump to while still seeking
     const noBufferHole = !nextStart || inFlightDependency || (nextStart - currentTime > MAX_START_GAP_JUMP && !fragmentTracker.getPartialFragment(currentTime));
     if (hasEnoughBuffer || noBufferHole) {
      return;
     }
     // Reset moved state when seeking to a point in or before a gap/hole
     this.moved = false;
    }

    // Skip start gaps if we haven't played, but the last poll detected the start of a stall
    // The addition poll gives the browser a chance to jump the gap for us
    const levelDetails = (_this$hls2 = this.hls) == null ? void 0 : _this$hls2.latestLevelDetails;
    if (!this.moved && this.stalled !== null && fragmentTracker) {
     // There is no playable buffer (seeked, waiting for buffer)
     const isBuffered = bufferInfo.len > 0;
     if (!isBuffered && !nextStart) {
      return;
     }
     // Jump start gaps within jump threshold
     const startJump = Math.max(nextStart, bufferInfo.start || 0) - currentTime;

     // When joining a live stream with audio tracks, account for live playlist window sliding by allowing
     // a larger jump over start gaps caused by the audio-stream-controller buffering a start fragment
     // that begins over 1 target duration after the video start position.
     const isLive = !!(levelDetails != null && levelDetails.live);
     const maxStartGapJump = isLive ? levelDetails.targetduration * 2 : MAX_START_GAP_JUMP;
     const appended = appendedFragAtPosition(currentTime, fragmentTracker);
     if (startJump > 0 && (startJump <= maxStartGapJump || appended)) {
      if (!media.paused) {
       this._trySkipBufferHole(appended);
      }
      return;
     }
    }

    // Start tracking stall time
    const detectStallWithCurrentTimeMs = config.detectStallWithCurrentTimeMs;
    const tnow = self.performance.now();
    const tWaiting = this.waiting;
    let stalled = this.stalled;
    if (stalled === null) {
     // Use time of recent "waiting" event
     if (tWaiting > 0 && tnow - tWaiting < detectStallWithCurrentTimeMs) {
      stalled = this.stalled = tWaiting;
     } else {
      this.stalled = tnow;
      return;
     }
    }
    const stalledDuration = tnow - stalled;
    if (!seeking && (stalledDuration >= detectStallWithCurrentTimeMs || tWaiting) && this.hls) {
     var _this$mediaSource;
     // Dispatch MEDIA_ENDED when media.ended/ended event is not signalled at end of stream
     if (((_this$mediaSource = this.mediaSource) == null ? void 0 : _this$mediaSource.readyState) === 'ended' && !(levelDetails != null && levelDetails.live) && Math.abs(currentTime - ((levelDetails == null ? void 0 : levelDetails.edge) || 0)) < 1) {
      if (this.ended) {
       return;
      }
      this.ended = currentTime || 1;
      this.hls.trigger(Events.MEDIA_ENDED, {
       stalled: true,
      });
      return;
     }
     // Report stalling after trying to fix
     this._reportStall(bufferInfo);
     if (!this.media || !this.hls) {
      return;
     }
    }
    const bufferedWithHoles = BufferHelper.bufferInfo(media, currentTime, config.maxBufferHole);
    this._tryFixBufferStall(bufferedWithHoles, stalledDuration, currentTime);
   }
   stallResolved(currentTime) {
    const stalled = this.stalled;
    if (stalled && this.hls) {
     this.stalled = null;
     // The playhead is now moving, but was previously stalled
     if (this.stallReported) {
      const stalledDuration = self.performance.now() - stalled;
      this.log(`playback not stuck anymore @${currentTime}, after ${Math.round(stalledDuration)}ms`);
      this.stallReported = false;
      this.waiting = 0;
      this.hls.trigger(Events.STALL_RESOLVED, {});
     }
    }
   }
   nudgeOnVideoHole(currentTime, lastCurrentTime) {
    var _this$buffered$audio;
    // Chrome will play one second past a hole in video buffered time ranges without rendering any video from the subsequent range and then stall as long as audio is buffered:
    // https://github.com/video-dev/hls.js/issues/5631
    // https://issues.chromium.org/issues/40280613#comment10
    // Detect the potential for this situation and proactively seek to flush the video pipeline once the playhead passes the start of the video hole.
    // When there are audio and video buffers and currentTime is past the end of the first video buffered range...
    const videoSourceBuffered = this.buffered.video;
    if (this.hls && this.media && this.fragmentTracker && (_this$buffered$audio = this.buffered.audio) != null && _this$buffered$audio.length && videoSourceBuffered && videoSourceBuffered.length > 1 && currentTime > videoSourceBuffered.end(0)) {
     // and audio is buffered at the playhead
     const audioBufferInfo = BufferHelper.bufferedInfo(BufferHelper.timeRangesToArray(this.buffered.audio), currentTime, 0);
     if (audioBufferInfo.len > 1 && lastCurrentTime >= audioBufferInfo.start) {
      const videoTimes = BufferHelper.timeRangesToArray(videoSourceBuffered);
      const lastBufferedIndex = BufferHelper.bufferedInfo(videoTimes, lastCurrentTime, 0).bufferedIndex;
      // nudge when crossing into another video buffered range (hole).
      if (lastBufferedIndex > -1 && lastBufferedIndex < videoTimes.length - 1) {
       const bufferedIndex = BufferHelper.bufferedInfo(videoTimes, currentTime, 0).bufferedIndex;
       const holeStart = videoTimes[lastBufferedIndex].end;
       const holeEnd = videoTimes[lastBufferedIndex + 1].start;
       if (
        (bufferedIndex === -1 || bufferedIndex > lastBufferedIndex) &&
        holeEnd - holeStart < 1 &&
        // `maxBufferHole` may be too small and setting it to 0 should not disable this feature
        currentTime - holeStart < 2
       ) {
        const error = new Error(`nudging playhead to flush pipeline after video hole. currentTime: ${currentTime} hole: ${holeStart} -> ${holeEnd} buffered index: ${bufferedIndex}`);
        this.warn(error.message);
        // Magic number to flush the pipeline without interuption to audio playback:
        this.media.currentTime += 0.000001;
        let frag = appendedFragAtPosition(currentTime, this.fragmentTracker);
        if (frag && 'fragment' in frag) {
         frag = frag.fragment;
        } else if (!frag) {
         frag = undefined;
        }
        const bufferInfo = BufferHelper.bufferInfo(this.media, currentTime, 0);
        this.hls.trigger(Events.ERROR, {
         type: ErrorTypes.MEDIA_ERROR,
         details: ErrorDetails.BUFFER_SEEK_OVER_HOLE,
         fatal: false,
         error,
         reason: error.message,
         frag,
         buffer: bufferInfo.len,
         bufferInfo,
        });
       }
      }
     }
    }
   }

   /**
    * Detects and attempts to fix known buffer stalling issues.
    * @param bufferInfo - The properties of the current buffer.
    * @param stalledDurationMs - The amount of time Hls.js has been stalling for.
    * @private
    */
   _tryFixBufferStall(bufferInfo, stalledDurationMs, currentTime) {
    var _this$hls3, _this$hls4;
    const { fragmentTracker, media } = this;
    const config = (_this$hls3 = this.hls) == null ? void 0 : _this$hls3.config;
    if (!media || !fragmentTracker || !config) {
     return;
    }
    const levelDetails = (_this$hls4 = this.hls) == null ? void 0 : _this$hls4.latestLevelDetails;
    const appended = appendedFragAtPosition(currentTime, fragmentTracker);
    if (appended || (levelDetails != null && levelDetails.live && currentTime < levelDetails.fragmentStart)) {
     // Try to skip over the buffer hole caused by a partial fragment
     // This method isn't limited by the size of the gap between buffered ranges
     const targetTime = this._trySkipBufferHole(appended);
     // we return here in this case, meaning
     // the branch below only executes when we haven't seeked to a new position
     if (targetTime || !this.media) {
      return;
     }
    }

    // if we haven't had to skip over a buffer hole of a partial fragment
    // we may just have to "nudge" the playlist as the browser decoding/rendering engine
    // needs to cross some sort of threshold covering all source-buffers content
    // to start playing properly.
    const bufferedRanges = bufferInfo.buffered;
    const adjacentTraversal = this.adjacentTraversal(bufferInfo, currentTime);
    if (((bufferedRanges && bufferedRanges.length > 1 && bufferInfo.len > config.maxBufferHole) || (bufferInfo.nextStart && (bufferInfo.nextStart - currentTime < config.maxBufferHole || adjacentTraversal))) && (stalledDurationMs > config.highBufferWatchdogPeriod * 1000 || this.waiting)) {
     this.warn('Trying to nudge playhead over buffer-hole');
     // Try to nudge currentTime over a buffer hole if we've been stalling for the configured amount of seconds
     // We only try to jump the hole if it's under the configured size
     this._tryNudgeBuffer(bufferInfo);
    }
   }
   adjacentTraversal(bufferInfo, currentTime) {
    const fragmentTracker = this.fragmentTracker;
    const nextStart = bufferInfo.nextStart;
    if (fragmentTracker && nextStart) {
     const current = fragmentTracker.getFragAtPos(currentTime, PlaylistLevelType.MAIN);
     const next = fragmentTracker.getFragAtPos(nextStart, PlaylistLevelType.MAIN);
     if (current && next) {
      return next.sn - current.sn < 2;
     }
    }
    return false;
   }

   /**
    * Triggers a BUFFER_STALLED_ERROR event, but only once per stall period.
    * @param bufferLen - The playhead distance from the end of the current buffer segment.
    * @private
    */
   _reportStall(bufferInfo) {
    const { hls, media, stallReported, stalled } = this;
    if (!stallReported && stalled !== null && media && hls) {
     // Report stalled error once
     this.stallReported = true;
     const error = new Error(`Playback stalling at @${media.currentTime} due to low buffer (${stringify(bufferInfo)})`);
     this.warn(error.message);
     hls.trigger(Events.ERROR, {
      type: ErrorTypes.MEDIA_ERROR,
      details: ErrorDetails.BUFFER_STALLED_ERROR,
      fatal: false,
      error,
      buffer: bufferInfo.len,
      bufferInfo,
      stalled: {
       start: stalled,
      },
     });
    }
   }

   /**
    * Attempts to fix buffer stalls by jumping over known gaps caused by partial fragments
    * @param appended - The fragment or part found at the current time (where playback is stalling).
    * @private
    */
   _trySkipBufferHole(appended) {
    var _this$hls5;
    const { fragmentTracker, media } = this;
    const config = (_this$hls5 = this.hls) == null ? void 0 : _this$hls5.config;
    if (!media || !fragmentTracker || !config) {
     return 0;
    }

    // Check if currentTime is between unbuffered regions of partial fragments
    const currentTime = media.currentTime;
    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);
    const startTime = currentTime < bufferInfo.start ? bufferInfo.start : bufferInfo.nextStart;
    if (startTime && this.hls) {
     const bufferStarved = bufferInfo.len <= config.maxBufferHole;
     const waiting = bufferInfo.len > 0 && bufferInfo.len < 1 && media.readyState < 3;
     const gapLength = startTime - currentTime;
     if (gapLength > 0 && (bufferStarved || waiting)) {
      // Only allow large gaps to be skipped if it is a start gap, or all fragments in skip range are partial
      if (gapLength > config.maxBufferHole) {
       let startGap = false;
       if (currentTime === 0) {
        const startFrag = fragmentTracker.getAppendedFrag(0, PlaylistLevelType.MAIN);
        if (startFrag && startTime < startFrag.end) {
         startGap = true;
        }
       }
       if (!startGap && appended) {
        var _this$hls$loadLevelOb;
        // Do not seek when selected variant playlist is unloaded
        if (!((_this$hls$loadLevelOb = this.hls.loadLevelObj) != null && _this$hls$loadLevelOb.details)) {
         return 0;
        }
        // Do not seek when required fragments are inflight or appending
        const inFlightDependency = getInFlightDependency(this.hls.inFlightFragments, startTime);
        if (inFlightDependency) {
         return 0;
        }
        // Do not seek if we can't walk tracked fragments to end of gap
        let moreToLoad = false;
        let pos = appended.end;
        while (pos < startTime) {
         const provisioned = appendedFragAtPosition(pos, fragmentTracker);
         if (provisioned) {
          pos += provisioned.duration;
         } else {
          moreToLoad = true;
          break;
         }
        }
        if (moreToLoad) {
         return 0;
        }
       }
      }
      const targetTime = Math.max(startTime + SKIP_BUFFER_RANGE_START, currentTime + SKIP_BUFFER_HOLE_STEP_SECONDS);
      this.warn(`skipping hole, adjusting currentTime from ${currentTime} to ${targetTime}`);
      this.moved = true;
      media.currentTime = targetTime;
      if (!(appended != null && appended.gap)) {
       const error = new Error(`fragment loaded with buffer holes, seeking from ${currentTime} to ${targetTime}`);
       const errorData = {
        type: ErrorTypes.MEDIA_ERROR,
        details: ErrorDetails.BUFFER_SEEK_OVER_HOLE,
        fatal: false,
        error,
        reason: error.message,
        buffer: bufferInfo.len,
        bufferInfo,
       };
       if (appended) {
        if ('fragment' in appended) {
         errorData.part = appended;
        } else {
         errorData.frag = appended;
        }
       }
       this.hls.trigger(Events.ERROR, errorData);
      }
      return targetTime;
     }
    }
    return 0;
   }

   /**
    * Attempts to fix buffer stalls by advancing the mediaElement's current time by a small amount.
    * @private
    */
   _tryNudgeBuffer(bufferInfo) {
    const { hls, media, nudgeRetry } = this;
    const config = hls == null ? void 0 : hls.config;
    if (!media || !config) {
     return 0;
    }
    const currentTime = media.currentTime;
    this.nudgeRetry++;
    if (nudgeRetry < config.nudgeMaxRetry) {
     const targetTime = currentTime + (nudgeRetry + 1) * config.nudgeOffset;
     // playback stalled in buffered area ... let's nudge currentTime to try to overcome this
     const error = new Error(`Nudging 'currentTime' from ${currentTime} to ${targetTime}`);
     this.warn(error.message);
     media.currentTime = targetTime;
     hls.trigger(Events.ERROR, {
      type: ErrorTypes.MEDIA_ERROR,
      details: ErrorDetails.BUFFER_NUDGE_ON_STALL,
      error,
      fatal: false,
      buffer: bufferInfo.len,
      bufferInfo,
     });
    } else {
     const error = new Error(`Playhead still not moving while enough data buffered @${currentTime} after ${config.nudgeMaxRetry} nudges`);
     this.error(error.message);
     hls.trigger(Events.ERROR, {
      type: ErrorTypes.MEDIA_ERROR,
      details: ErrorDetails.BUFFER_STALLED_ERROR,
      error,
      fatal: true,
      buffer: bufferInfo.len,
      bufferInfo,
     });
    }
   }
  }
  function getInFlightDependency(inFlightFragments, currentTime) {
   const main = inFlight(inFlightFragments.main);
   if (main && main.start <= currentTime) {
    return main;
   }
   const audio = inFlight(inFlightFragments.audio);
   if (audio && audio.start <= currentTime) {
    return audio;
   }
   return null;
  }
  function inFlight(inFlightData) {
   if (!inFlightData) {
    return null;
   }
   switch (inFlightData.state) {
    case State.IDLE:
    case State.STOPPED:
    case State.ENDED:
    case State.ERROR:
     return null;
   }
   return inFlightData.frag;
  }
  function appendedFragAtPosition(pos, fragmentTracker) {
   return fragmentTracker.getAppendedFrag(pos, PlaylistLevelType.MAIN) || fragmentTracker.getPartialFragment(pos);
  }

  const MIN_CUE_DURATION = 0.25;
  function getCueClass() {
   if (typeof self === 'undefined') return undefined;
   return self.VTTCue || self.TextTrackCue;
  }
  function createCueWithDataFields(Cue, startTime, endTime, data, type) {
   let cue = new Cue(startTime, endTime, '');
   try {
    cue.value = data;
    if (type) {
     cue.type = type;
    }
   } catch (e) {
    cue = new Cue(
     startTime,
     endTime,
     stringify(
      type
       ? _objectSpread2(
          {
           type,
          },
          data,
         )
       : data,
     ),
    );
   }
   return cue;
  }

  // VTTCue latest draft allows an infinite duration, fallback
  // to MAX_VALUE if necessary
  const MAX_CUE_ENDTIME = (() => {
   const Cue = getCueClass();
   try {
    Cue && new Cue(0, Number.POSITIVE_INFINITY, '');
   } catch (e) {
    return Number.MAX_VALUE;
   }
   return Number.POSITIVE_INFINITY;
  })();
  class ID3TrackController {
   constructor(hls) {
    this.hls = void 0;
    this.id3Track = null;
    this.media = null;
    this.dateRangeCuesAppended = {};
    this.removeCues = true;
    this.assetCue = void 0;
    this.onEventCueEnter = () => {
     if (!this.hls) {
      return;
     }
     this.hls.trigger(Events.EVENT_CUE_ENTER, {});
    };
    this.hls = hls;
    this._registerListeners();
   }
   destroy() {
    this._unregisterListeners();
    this.id3Track = null;
    this.media = null;
    this.dateRangeCuesAppended = {};
    // @ts-ignore
    this.hls = this.onEventCueEnter = null;
   }
   _registerListeners() {
    const { hls } = this;
    if (hls) {
     hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
     hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
     hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
     hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
     hls.on(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);
     hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
     hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
     hls.on(Events.LEVEL_PTS_UPDATED, this.onLevelPtsUpdated, this);
    }
   }
   _unregisterListeners() {
    const { hls } = this;
    if (hls) {
     hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
     hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
     hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
     hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
     hls.off(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);
     hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
     hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
     hls.off(Events.LEVEL_PTS_UPDATED, this.onLevelPtsUpdated, this);
    }
   }
   // Add ID3 metatadata text track.
   onMediaAttaching(event, data) {
    var _data$overrides;
    this.media = data.media;
    if (((_data$overrides = data.overrides) == null ? void 0 : _data$overrides.cueRemoval) === false) {
     this.removeCues = false;
    }
   }
   onMediaAttached() {
    var _this$hls;
    const details = (_this$hls = this.hls) == null ? void 0 : _this$hls.latestLevelDetails;
    if (details) {
     this.updateDateRangeCues(details);
    }
   }
   onMediaDetaching(event, data) {
    this.media = null;
    const transferringMedia = !!data.transferMedia;
    if (transferringMedia) {
     return;
    }
    if (this.id3Track) {
     if (this.removeCues) {
      clearCurrentCues(this.id3Track, this.onEventCueEnter);
     }
     this.id3Track = null;
    }
    this.dateRangeCuesAppended = {};
   }
   onManifestLoading() {
    this.dateRangeCuesAppended = {};
   }
   createTrack(media) {
    const track = this.getID3Track(media.textTracks);
    track.mode = 'hidden';
    return track;
   }
   getID3Track(textTracks) {
    if (!this.media) {
     return;
    }
    for (let i = 0; i < textTracks.length; i++) {
     const textTrack = textTracks[i];
     if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {
      // send 'addtrack' when reusing the textTrack for metadata,
      // same as what we do for captions
      sendAddTrackEvent(textTrack, this.media);
      return textTrack;
     }
    }
    return this.media.addTextTrack('metadata', 'id3');
   }
   onFragParsingMetadata(event, data) {
    if (!this.media || !this.hls) {
     return;
    }
    const { enableEmsgMetadataCues, enableID3MetadataCues } = this.hls.config;
    if (!enableEmsgMetadataCues && !enableID3MetadataCues) {
     return;
    }
    const { samples } = data;

    // create track dynamically
    if (!this.id3Track) {
     this.id3Track = this.createTrack(this.media);
    }
    const Cue = getCueClass();
    if (!Cue) {
     return;
    }
    for (let i = 0; i < samples.length; i++) {
     const type = samples[i].type;
     if ((type === MetadataSchema.emsg && !enableEmsgMetadataCues) || !enableID3MetadataCues) {
      continue;
     }
     const frames = getId3Frames(samples[i].data);
     const startTime = samples[i].pts;
     let endTime = startTime + samples[i].duration;
     if (endTime > MAX_CUE_ENDTIME) {
      endTime = MAX_CUE_ENDTIME;
     }
     const timeDiff = endTime - startTime;
     if (timeDiff <= 0) {
      endTime = startTime + MIN_CUE_DURATION;
     }
     for (let j = 0; j < frames.length; j++) {
      const frame = frames[j];
      // Safari doesn't put the timestamp frame in the TextTrack
      if (!isId3TimestampFrame(frame)) {
       // add a bounds to any unbounded cues
       this.updateId3CueEnds(startTime, type);
       const cue = createCueWithDataFields(Cue, startTime, endTime, frame, type);
       if (cue) {
        this.id3Track.addCue(cue);
       }
      }
     }
    }
   }
   updateId3CueEnds(startTime, type) {
    var _this$id3Track;
    const cues = (_this$id3Track = this.id3Track) == null ? void 0 : _this$id3Track.cues;
    if (cues) {
     for (let i = cues.length; i--; ) {
      const cue = cues[i];
      if (cue.type === type && cue.startTime < startTime && cue.endTime === MAX_CUE_ENDTIME) {
       cue.endTime = startTime;
      }
     }
    }
   }
   onBufferFlushing(event, { startOffset, endOffset, type }) {
    const { id3Track, hls } = this;
    if (!hls) {
     return;
    }
    const {
     config: { enableEmsgMetadataCues, enableID3MetadataCues },
    } = hls;
    if (id3Track && (enableEmsgMetadataCues || enableID3MetadataCues)) {
     let predicate;
     if (type === 'audio') {
      predicate = (cue) => cue.type === MetadataSchema.audioId3 && enableID3MetadataCues;
     } else if (type === 'video') {
      predicate = (cue) => cue.type === MetadataSchema.emsg && enableEmsgMetadataCues;
     } else {
      predicate = (cue) => (cue.type === MetadataSchema.audioId3 && enableID3MetadataCues) || (cue.type === MetadataSchema.emsg && enableEmsgMetadataCues);
     }
     removeCuesInRange(id3Track, startOffset, endOffset, predicate);
    }
   }
   onLevelUpdated(event, { details }) {
    this.updateDateRangeCues(details, true);
   }
   onLevelPtsUpdated(event, data) {
    if (Math.abs(data.drift) > 0.01) {
     this.updateDateRangeCues(data.details);
    }
   }
   updateDateRangeCues(details, removeOldCues) {
    if (!this.hls || !this.media) {
     return;
    }
    const { assetPlayerId, timelineOffset, enableDateRangeMetadataCues, interstitialsController } = this.hls.config;
    if (!enableDateRangeMetadataCues) {
     return;
    }
    const Cue = getCueClass();
    if (assetPlayerId && timelineOffset && !interstitialsController) {
     const { fragmentStart, fragmentEnd } = details;
     let cue = this.assetCue;
     if (cue) {
      cue.startTime = fragmentStart;
      cue.endTime = fragmentEnd;
     } else if (Cue) {
      cue = this.assetCue = createCueWithDataFields(
       Cue,
       fragmentStart,
       fragmentEnd,
       {
        assetPlayerId: this.hls.config.assetPlayerId,
       },
       'hlsjs.interstitial.asset',
      );
      if (cue) {
       cue.id = assetPlayerId;
       this.id3Track || (this.id3Track = this.createTrack(this.media));
       this.id3Track.addCue(cue);
       cue.addEventListener('enter', this.onEventCueEnter);
      }
     }
    }
    if (!details.hasProgramDateTime) {
     return;
    }
    const { id3Track } = this;
    const { dateRanges } = details;
    const ids = Object.keys(dateRanges);
    let dateRangeCuesAppended = this.dateRangeCuesAppended;
    // Remove cues from track not found in details.dateRanges
    if (id3Track && removeOldCues) {
     var _id3Track$cues;
     if ((_id3Track$cues = id3Track.cues) != null && _id3Track$cues.length) {
      const idsToRemove = Object.keys(dateRangeCuesAppended).filter((id) => !ids.includes(id));
      for (let i = idsToRemove.length; i--; ) {
       var _dateRangeCuesAppende;
       const id = idsToRemove[i];
       const cues = (_dateRangeCuesAppende = dateRangeCuesAppended[id]) == null ? void 0 : _dateRangeCuesAppende.cues;
       delete dateRangeCuesAppended[id];
       if (cues) {
        Object.keys(cues).forEach((key) => {
         const cue = cues[key];
         if (cue) {
          cue.removeEventListener('enter', this.onEventCueEnter);
          try {
           id3Track.removeCue(cue);
          } catch (e) {
           /* no-op */
          }
         }
        });
       }
      }
     } else {
      dateRangeCuesAppended = this.dateRangeCuesAppended = {};
     }
    }
    // Exit if the playlist does not have Date Ranges or does not have Program Date Time
    const lastFragment = details.fragments[details.fragments.length - 1];
    if (ids.length === 0 || !isFiniteNumber(lastFragment == null ? void 0 : lastFragment.programDateTime)) {
     return;
    }
    this.id3Track || (this.id3Track = this.createTrack(this.media));
    for (let i = 0; i < ids.length; i++) {
     const id = ids[i];
     const dateRange = dateRanges[id];
     const startTime = dateRange.startTime;

     // Process DateRanges to determine end-time (known DURATION, END-DATE, or END-ON-NEXT)
     const appendedDateRangeCues = dateRangeCuesAppended[id];
     const cues = (appendedDateRangeCues == null ? void 0 : appendedDateRangeCues.cues) || {};
     let durationKnown = (appendedDateRangeCues == null ? void 0 : appendedDateRangeCues.durationKnown) || false;
     let endTime = MAX_CUE_ENDTIME;
     const { duration, endDate } = dateRange;
     if (endDate && duration !== null) {
      endTime = startTime + duration;
      durationKnown = true;
     } else if (dateRange.endOnNext && !durationKnown) {
      const nextDateRangeWithSameClass = ids.reduce((candidateDateRange, id) => {
       if (id !== dateRange.id) {
        const otherDateRange = dateRanges[id];
        if (otherDateRange.class === dateRange.class && otherDateRange.startDate > dateRange.startDate && (!candidateDateRange || dateRange.startDate < candidateDateRange.startDate)) {
         return otherDateRange;
        }
       }
       return candidateDateRange;
      }, null);
      if (nextDateRangeWithSameClass) {
       endTime = nextDateRangeWithSameClass.startTime;
       durationKnown = true;
      }
     }

     // Create TextTrack Cues for each MetadataGroup Item (select DateRange attribute)
     // This is to emulate Safari HLS playback handling of DateRange tags
     const attributes = Object.keys(dateRange.attr);
     for (let j = 0; j < attributes.length; j++) {
      const key = attributes[j];
      if (!isDateRangeCueAttribute(key)) {
       continue;
      }
      const cue = cues[key];
      if (cue) {
       if (durationKnown && !(appendedDateRangeCues != null && appendedDateRangeCues.durationKnown)) {
        cue.endTime = endTime;
       } else if (Math.abs(cue.startTime - startTime) > 0.01) {
        cue.startTime = startTime;
        cue.endTime = endTime;
       }
      } else if (Cue) {
       let data = dateRange.attr[key];
       if (isSCTE35Attribute(key)) {
        data = hexToArrayBuffer(data);
       }
       const payload = {
        key,
        data,
       };
       const _cue = createCueWithDataFields(Cue, startTime, endTime, payload, MetadataSchema.dateRange);
       if (_cue) {
        _cue.id = id;
        this.id3Track.addCue(_cue);
        cues[key] = _cue;
        if (interstitialsController) {
         if (key === 'X-ASSET-LIST' || key === 'X-ASSET-URL') {
          _cue.addEventListener('enter', this.onEventCueEnter);
         }
        }
       }
      }
     }

     // Keep track of processed DateRanges by ID for updating cues with new DateRange tag attributes
     dateRangeCuesAppended[id] = {
      cues,
      dateRange,
      durationKnown,
     };
    }
   }
  }

  class LatencyController {
   constructor(hls) {
    this.hls = void 0;
    this.config = void 0;
    this.media = null;
    this.currentTime = 0;
    this.stallCount = 0;
    this._latency = null;
    this._targetLatencyUpdated = false;
    this.onTimeupdate = () => {
     const { media } = this;
     const levelDetails = this.levelDetails;
     if (!media || !levelDetails) {
      return;
     }
     this.currentTime = media.currentTime;
     const latency = this.computeLatency();
     if (latency === null) {
      return;
     }
     this._latency = latency;

     // Adapt playbackRate to meet target latency in low-latency mode
     const { lowLatencyMode, maxLiveSyncPlaybackRate } = this.config;
     if (!lowLatencyMode || maxLiveSyncPlaybackRate === 1 || !levelDetails.live) {
      return;
     }
     const targetLatency = this.targetLatency;
     if (targetLatency === null) {
      return;
     }
     const distanceFromTarget = latency - targetLatency;
     // Only adjust playbackRate when within one target duration of targetLatency
     // and more than one second from under-buffering.
     // Playback further than one target duration from target can be considered DVR playback.
     const liveMinLatencyDuration = Math.min(this.maxLatency, targetLatency + levelDetails.targetduration);
     const inLiveRange = distanceFromTarget < liveMinLatencyDuration;
     if (inLiveRange && distanceFromTarget > 0.05 && this.forwardBufferLength > 1) {
      const max = Math.min(2, Math.max(1.0, maxLiveSyncPlaybackRate));
      const rate = Math.round((2 / (1 + Math.exp(-0.75 * distanceFromTarget - this.edgeStalled))) * 20) / 20;
      const playbackRate = Math.min(max, Math.max(1, rate));
      this.changeMediaPlaybackRate(media, playbackRate);
     } else if (media.playbackRate !== 1 && media.playbackRate !== 0) {
      this.changeMediaPlaybackRate(media, 1);
     }
    };
    this.hls = hls;
    this.config = hls.config;
    this.registerListeners();
   }
   get levelDetails() {
    var _this$hls;
    return ((_this$hls = this.hls) == null ? void 0 : _this$hls.latestLevelDetails) || null;
   }
   get latency() {
    return this._latency || 0;
   }
   get maxLatency() {
    const { config } = this;
    if (config.liveMaxLatencyDuration !== undefined) {
     return config.liveMaxLatencyDuration;
    }
    const levelDetails = this.levelDetails;
    return levelDetails ? config.liveMaxLatencyDurationCount * levelDetails.targetduration : 0;
   }
   get targetLatency() {
    const levelDetails = this.levelDetails;
    if (levelDetails === null || this.hls === null) {
     return null;
    }
    const { holdBack, partHoldBack, targetduration } = levelDetails;
    const { liveSyncDuration, liveSyncDurationCount, lowLatencyMode } = this.config;
    const userConfig = this.hls.userConfig;
    let targetLatency = lowLatencyMode ? partHoldBack || holdBack : holdBack;
    if (this._targetLatencyUpdated || userConfig.liveSyncDuration || userConfig.liveSyncDurationCount || targetLatency === 0) {
     targetLatency = liveSyncDuration !== undefined ? liveSyncDuration : liveSyncDurationCount * targetduration;
    }
    const maxLiveSyncOnStallIncrease = targetduration;
    return targetLatency + Math.min(this.stallCount * this.config.liveSyncOnStallIncrease, maxLiveSyncOnStallIncrease);
   }
   set targetLatency(latency) {
    this.stallCount = 0;
    this.config.liveSyncDuration = latency;
    this._targetLatencyUpdated = true;
   }
   get liveSyncPosition() {
    const liveEdge = this.estimateLiveEdge();
    const targetLatency = this.targetLatency;
    if (liveEdge === null || targetLatency === null) {
     return null;
    }
    const levelDetails = this.levelDetails;
    if (levelDetails === null) {
     return null;
    }
    const edge = levelDetails.edge;
    const syncPosition = liveEdge - targetLatency - this.edgeStalled;
    const min = edge - levelDetails.totalduration;
    const max = edge - ((this.config.lowLatencyMode && levelDetails.partTarget) || levelDetails.targetduration);
    return Math.min(Math.max(min, syncPosition), max);
   }
   get drift() {
    const levelDetails = this.levelDetails;
    if (levelDetails === null) {
     return 1;
    }
    return levelDetails.drift;
   }
   get edgeStalled() {
    const levelDetails = this.levelDetails;
    if (levelDetails === null) {
     return 0;
    }
    const maxLevelUpdateAge = ((this.config.lowLatencyMode && levelDetails.partTarget) || levelDetails.targetduration) * 3;
    return Math.max(levelDetails.age - maxLevelUpdateAge, 0);
   }
   get forwardBufferLength() {
    const { media } = this;
    const levelDetails = this.levelDetails;
    if (!media || !levelDetails) {
     return 0;
    }
    const bufferedRanges = media.buffered.length;
    return (bufferedRanges ? media.buffered.end(bufferedRanges - 1) : levelDetails.edge) - this.currentTime;
   }
   destroy() {
    this.unregisterListeners();
    this.onMediaDetaching();
    this.hls = null;
   }
   registerListeners() {
    const { hls } = this;
    if (!hls) {
     return;
    }
    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
    hls.on(Events.ERROR, this.onError, this);
   }
   unregisterListeners() {
    const { hls } = this;
    if (!hls) {
     return;
    }
    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);
    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);
    hls.off(Events.ERROR, this.onError, this);
   }
   onMediaAttached(event, data) {
    this.media = data.media;
    this.media.addEventListener('timeupdate', this.onTimeupdate);
   }
   onMediaDetaching() {
    if (this.media) {
     this.media.removeEventListener('timeupdate', this.onTimeupdate);
     this.media = null;
    }
   }
   onManifestLoading() {
    this._latency = null;
    this.stallCount = 0;
   }
   onLevelUpdated(event, { details }) {
    if (details.advanced) {
     this.onTimeupdate();
    }
    if (!details.live && this.media) {
     this.media.removeEventListener('timeupdate', this.onTimeupdate);
    }
   }
   onError(event, data) {
    var _this$levelDetails;
    if (data.details !== ErrorDetails.BUFFER_STALLED_ERROR) {
     return;
    }
    this.stallCount++;
    if (this.hls && (_this$levelDetails = this.levelDetails) != null && _this$levelDetails.live) {
     this.hls.logger.warn('[latency-controller]: Stall detected, adjusting target latency');
    }
   }
   changeMediaPlaybackRate(media, playbackRate) {
    var _this$hls2, _this$targetLatency;
    if (media.playbackRate === playbackRate) {
     return;
    }
    (_this$hls2 = this.hls) == null || _this$hls2.logger.debug(`[latency-controller]: latency=${this.latency.toFixed(3)}, targetLatency=${(_this$targetLatency = this.targetLatency) == null ? void 0 : _this$targetLatency.toFixed(3)}, forwardBufferLength=${this.forwardBufferLength.toFixed(3)}: adjusting playback rate from ${media.playbackRate} to ${playbackRate}`);
    media.playbackRate = playbackRate;
   }
   estimateLiveEdge() {
    const levelDetails = this.levelDetails;
    if (levelDetails === null) {
     return null;
    }
    return levelDetails.edge + levelDetails.age;
   }
   computeLatency() {
    const liveEdge = this.estimateLiveEdge();
    if (liveEdge === null) {
     return null;
    }
    return liveEdge - this.currentTime;
   }
  }

  class LevelController extends BasePlaylistController {
   constructor(hls, contentSteeringController) {
    super(hls, 'level-controller');
    this._levels = [];
    this._firstLevel = -1;
    this._maxAutoLevel = -1;
    this._startLevel = void 0;
    this.currentLevel = null;
    this.currentLevelIndex = -1;
    this.manualLevelIndex = -1;
    this.steering = void 0;
    this.onParsedComplete = void 0;
    this.steering = contentSteeringController;
    this._registerListeners();
   }
   _registerListeners() {
    const { hls } = this;
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);
    hls.on(Events.ERROR, this.onError, this);
   }
   _unregisterListeners() {
    const { hls } = this;
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);
    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);
    hls.off(Events.ERROR, this.onError, this);
   }
   destroy() {
    this._unregisterListeners();
    this.steering = null;
    this.resetLevels();
    super.destroy();
   }
   stopLoad() {
    const levels = this._levels;

    // clean up live level details to force reload them, and reset load errors
    levels.forEach((level) => {
     level.loadError = 0;
     level.fragmentError = 0;
    });
    super.stopLoad();
   }
   resetLevels() {
    this._startLevel = undefined;
    this.manualLevelIndex = -1;
    this.currentLevelIndex = -1;
    this.currentLevel = null;
    this._levels = [];
    this._maxAutoLevel = -1;
   }
   onManifestLoading(event, data) {
    this.resetLevels();
   }
   onManifestLoaded(event, data) {
    const preferManagedMediaSource = this.hls.config.preferManagedMediaSource;
    const levels = [];
    const redundantSet = {};
    const generatePathwaySet = {};
    let resolutionFound = false;
    let videoCodecFound = false;
    let audioCodecFound = false;
    data.levels.forEach((levelParsed) => {
     const attributes = levelParsed.attrs;
     let { audioCodec, videoCodec } = levelParsed;
     if (audioCodec) {
      // Returns empty and set to undefined for 'mp4a.40.34' with fallback to 'audio/mpeg' SourceBuffer
      levelParsed.audioCodec = audioCodec = getCodecCompatibleName(audioCodec, preferManagedMediaSource) || undefined;
     }
     if (videoCodec) {
      videoCodec = levelParsed.videoCodec = convertAVC1ToAVCOTI(videoCodec);
     }

     // only keep levels with supported audio/video codecs
     const { width, height, unknownCodecs } = levelParsed;
     let unknownUnsupportedCodecCount = unknownCodecs ? unknownCodecs.length : 0;
     if (unknownCodecs) {
      // Treat unknown codec as audio or video codec based on passing `isTypeSupported` check
      // (allows for playback of any supported codec even if not indexed in utils/codecs)
      for (let i = unknownUnsupportedCodecCount; i--; ) {
       const unknownCodec = unknownCodecs[i];
       if (this.isAudioSupported(unknownCodec)) {
        levelParsed.audioCodec = audioCodec = audioCodec ? `${audioCodec},${unknownCodec}` : unknownCodec;
        unknownUnsupportedCodecCount--;
        sampleEntryCodesISO.audio[audioCodec.substring(0, 4)] = 2;
       } else if (this.isVideoSupported(unknownCodec)) {
        levelParsed.videoCodec = videoCodec = videoCodec ? `${videoCodec},${unknownCodec}` : unknownCodec;
        unknownUnsupportedCodecCount--;
        sampleEntryCodesISO.video[videoCodec.substring(0, 4)] = 2;
       }
      }
     }
     resolutionFound || (resolutionFound = !!(width && height));
     videoCodecFound || (videoCodecFound = !!videoCodec);
     audioCodecFound || (audioCodecFound = !!audioCodec);
     if (unknownUnsupportedCodecCount || (audioCodec && !this.isAudioSupported(audioCodec)) || (videoCodec && !this.isVideoSupported(videoCodec))) {
      this.log(`Some or all CODECS not supported "${attributes.CODECS}"`);
      return;
     }
     const { CODECS, 'FRAME-RATE': FRAMERATE, 'HDCP-LEVEL': HDCP, 'PATHWAY-ID': PATHWAY, RESOLUTION, 'VIDEO-RANGE': VIDEO_RANGE } = attributes;
     const contentSteeringPrefix = `${PATHWAY || '.'}-`;
     const levelKey = `${contentSteeringPrefix}${levelParsed.bitrate}-${RESOLUTION}-${FRAMERATE}-${CODECS}-${VIDEO_RANGE}-${HDCP}`;
     if (!redundantSet[levelKey]) {
      const level = this.createLevel(levelParsed);
      redundantSet[levelKey] = level;
      generatePathwaySet[levelKey] = 1;
      levels.push(level);
     } else if (redundantSet[levelKey].uri !== levelParsed.url && !levelParsed.attrs['PATHWAY-ID']) {
      // Assign Pathway IDs to Redundant Streams (default Pathways is ".". Redundant Streams "..", "...", and so on.)
      // Content Steering controller to handles Pathway fallback on error
      const pathwayCount = (generatePathwaySet[levelKey] += 1);
      levelParsed.attrs['PATHWAY-ID'] = new Array(pathwayCount + 1).join('.');
      const level = this.createLevel(levelParsed);
      redundantSet[levelKey] = level;
      levels.push(level);
     } else {
      redundantSet[levelKey].addGroupId('audio', attributes.AUDIO);
      redundantSet[levelKey].addGroupId('text', attributes.SUBTITLES);
     }
    });
    this.filterAndSortMediaOptions(levels, data, resolutionFound, videoCodecFound, audioCodecFound);
   }
   createLevel(levelParsed) {
    const level = new Level(levelParsed);
    const supplemental = levelParsed.supplemental;
    if (supplemental != null && supplemental.videoCodec && !this.isVideoSupported(supplemental.videoCodec)) {
     const error = new Error(`SUPPLEMENTAL-CODECS not supported "${supplemental.videoCodec}"`);
     this.log(error.message);
     level.supportedResult = getUnsupportedResult(error, []);
    }
    return level;
   }
   isAudioSupported(codec) {
    return areCodecsMediaSourceSupported(codec, 'audio', this.hls.config.preferManagedMediaSource);
   }
   isVideoSupported(codec) {
    return areCodecsMediaSourceSupported(codec, 'video', this.hls.config.preferManagedMediaSource);
   }
   filterAndSortMediaOptions(filteredLevels, data, resolutionFound, videoCodecFound, audioCodecFound) {
    let audioTracks = [];
    let subtitleTracks = [];
    let levels = filteredLevels;

    // remove audio-only and invalid video-range levels if we also have levels with video codecs or RESOLUTION signalled
    if ((resolutionFound || videoCodecFound) && audioCodecFound) {
     levels = levels.filter(({ videoCodec, videoRange, width, height }) => (!!videoCodec || !!(width && height)) && isVideoRange(videoRange));
    }
    if (levels.length === 0) {
     // Dispatch error after MANIFEST_LOADED is done propagating
     Promise.resolve().then(() => {
      if (this.hls) {
       let message = 'no level with compatible codecs found in manifest';
       let reason = message;
       if (data.levels.length) {
        reason = `one or more CODECS in variant not supported: ${stringify(data.levels.map((level) => level.attrs.CODECS).filter((value, index, array) => array.indexOf(value) === index))}`;
        this.warn(reason);
        message += ` (${reason})`;
       }
       const error = new Error(message);
       this.hls.trigger(Events.ERROR, {
        type: ErrorTypes.MEDIA_ERROR,
        details: ErrorDetails.MANIFEST_INCOMPATIBLE_CODECS_ERROR,
        fatal: true,
        url: data.url,
        error,
        reason,
       });
      }
     });
     return;
    }
    if (data.audioTracks) {
     audioTracks = data.audioTracks.filter((track) => !track.audioCodec || this.isAudioSupported(track.audioCodec));
     // Assign ids after filtering as array indices by group-id
     assignTrackIdsByGroup(audioTracks);
    }
    if (data.subtitles) {
     subtitleTracks = data.subtitles;
     assignTrackIdsByGroup(subtitleTracks);
    }
    // start bitrate is the first bitrate of the manifest
    const unsortedLevels = levels.slice(0);
    // sort levels from lowest to highest
    levels.sort((a, b) => {
     if (a.attrs['HDCP-LEVEL'] !== b.attrs['HDCP-LEVEL']) {
      return (a.attrs['HDCP-LEVEL'] || '') > (b.attrs['HDCP-LEVEL'] || '') ? 1 : -1;
     }
     // sort on height before bitrate for cap-level-controller
     if (resolutionFound && a.height !== b.height) {
      return a.height - b.height;
     }
     if (a.frameRate !== b.frameRate) {
      return a.frameRate - b.frameRate;
     }
     if (a.videoRange !== b.videoRange) {
      return VideoRangeValues.indexOf(a.videoRange) - VideoRangeValues.indexOf(b.videoRange);
     }
     if (a.videoCodec !== b.videoCodec) {
      const valueA = videoCodecPreferenceValue(a.videoCodec);
      const valueB = videoCodecPreferenceValue(b.videoCodec);
      if (valueA !== valueB) {
       return valueB - valueA;
      }
     }
     if (a.uri === b.uri && a.codecSet !== b.codecSet) {
      const valueA = codecsSetSelectionPreferenceValue(a.codecSet);
      const valueB = codecsSetSelectionPreferenceValue(b.codecSet);
      if (valueA !== valueB) {
       return valueB - valueA;
      }
     }
     if (a.averageBitrate !== b.averageBitrate) {
      return a.averageBitrate - b.averageBitrate;
     }
     return 0;
    });
    let firstLevelInPlaylist = unsortedLevels[0];
    if (this.steering) {
     levels = this.steering.filterParsedLevels(levels);
     if (levels.length !== unsortedLevels.length) {
      for (let i = 0; i < unsortedLevels.length; i++) {
       if (unsortedLevels[i].pathwayId === levels[0].pathwayId) {
        firstLevelInPlaylist = unsortedLevels[i];
        break;
       }
      }
     }
    }
    this._levels = levels;

    // find index of first level in sorted levels
    for (let i = 0; i < levels.length; i++) {
     if (levels[i] === firstLevelInPlaylist) {
      var _this$hls$userConfig;
      this._firstLevel = i;
      const firstLevelBitrate = firstLevelInPlaylist.bitrate;
      const bandwidthEstimate = this.hls.bandwidthEstimate;
      this.log(`manifest loaded, ${levels.length} level(s) found, first bitrate: ${firstLevelBitrate}`);
      // Update default bwe to first variant bitrate as long it has not been configured or set
      if (((_this$hls$userConfig = this.hls.userConfig) == null ? void 0 : _this$hls$userConfig.abrEwmaDefaultEstimate) === undefined) {
       const startingBwEstimate = Math.min(firstLevelBitrate, this.hls.config.abrEwmaDefaultEstimateMax);
       if (startingBwEstimate > bandwidthEstimate && bandwidthEstimate === this.hls.abrEwmaDefaultEstimate) {
        this.hls.bandwidthEstimate = startingBwEstimate;
       }
      }
      break;
     }
    }

    // Audio is only alternate if manifest include a URI along with the audio group tag,
    // and this is not an audio-only stream where levels contain audio-only
    const audioOnly = audioCodecFound && !videoCodecFound;
    const config = this.hls.config;
    const altAudioEnabled = !!(config.audioStreamController && config.audioTrackController);
    const edata = {
     levels,
     audioTracks,
     subtitleTracks,
     sessionData: data.sessionData,
     sessionKeys: data.sessionKeys,
     firstLevel: this._firstLevel,
     stats: data.stats,
     audio: audioCodecFound,
     video: videoCodecFound,
     altAudio: altAudioEnabled && !audioOnly && audioTracks.some((t) => !!t.url),
    };
    this.hls.trigger(Events.MANIFEST_PARSED, edata);
   }
   get levels() {
    if (this._levels.length === 0) {
     return null;
    }
    return this._levels;
   }
   get loadLevelObj() {
    return this.currentLevel;
   }
   get level() {
    return this.currentLevelIndex;
   }
   set level(newLevel) {
    const levels = this._levels;
    if (levels.length === 0) {
     return;
    }
    // check if level idx is valid
    if (newLevel < 0 || newLevel >= levels.length) {
     // invalid level id given, trigger error
     const error = new Error('invalid level idx');
     const fatal = newLevel < 0;
     this.hls.trigger(Events.ERROR, {
      type: ErrorTypes.OTHER_ERROR,
      details: ErrorDetails.LEVEL_SWITCH_ERROR,
      level: newLevel,
      fatal,
      error,
      reason: error.message,
     });
     if (fatal) {
      return;
     }
     newLevel = Math.min(newLevel, levels.length - 1);
    }
    const lastLevelIndex = this.currentLevelIndex;
    const lastLevel = this.currentLevel;
    const lastPathwayId = lastLevel ? lastLevel.attrs['PATHWAY-ID'] : undefined;
    const level = levels[newLevel];
    const pathwayId = level.attrs['PATHWAY-ID'];
    this.currentLevelIndex = newLevel;
    this.currentLevel = level;
    if (lastLevelIndex === newLevel && lastLevel && lastPathwayId === pathwayId) {
     return;
    }
    this.log(`Switching to level ${newLevel} (${level.height ? level.height + 'p ' : ''}${level.videoRange ? level.videoRange + ' ' : ''}${level.codecSet ? level.codecSet + ' ' : ''}@${level.bitrate})${pathwayId ? ' with Pathway ' + pathwayId : ''} from level ${lastLevelIndex}${lastPathwayId ? ' with Pathway ' + lastPathwayId : ''}`);
    const levelSwitchingData = {
     level: newLevel,
     attrs: level.attrs,
     details: level.details,
     bitrate: level.bitrate,
     averageBitrate: level.averageBitrate,
     maxBitrate: level.maxBitrate,
     realBitrate: level.realBitrate,
     width: level.width,
     height: level.height,
     codecSet: level.codecSet,
     audioCodec: level.audioCodec,
     videoCodec: level.videoCodec,
     audioGroups: level.audioGroups,
     subtitleGroups: level.subtitleGroups,
     loaded: level.loaded,
     loadError: level.loadError,
     fragmentError: level.fragmentError,
     name: level.name,
     id: level.id,
     uri: level.uri,
     url: level.url,
     urlId: 0,
     audioGroupIds: level.audioGroupIds,
     textGroupIds: level.textGroupIds,
    };
    this.hls.trigger(Events.LEVEL_SWITCHING, levelSwitchingData);
    // check if we need to load playlist for this level
    const levelDetails = level.details;
    if (!levelDetails || levelDetails.live) {
     // level not retrieved yet, or live playlist we need to (re)load it
     const hlsUrlParameters = this.switchParams(level.uri, lastLevel == null ? void 0 : lastLevel.details, levelDetails);
     this.loadPlaylist(hlsUrlParameters);
    }
   }
   get manualLevel() {
    return this.manualLevelIndex;
   }
   set manualLevel(newLevel) {
    this.manualLevelIndex = newLevel;
    if (this._startLevel === undefined) {
     this._startLevel = newLevel;
    }
    if (newLevel !== -1) {
     this.level = newLevel;
    }
   }
   get firstLevel() {
    return this._firstLevel;
   }
   set firstLevel(newLevel) {
    this._firstLevel = newLevel;
   }
   get startLevel() {
    // Setting hls.startLevel (this._startLevel) overrides config.startLevel
    if (this._startLevel === undefined) {
     const configStartLevel = this.hls.config.startLevel;
     if (configStartLevel !== undefined) {
      return configStartLevel;
     }
     return this.hls.firstAutoLevel;
    }
    return this._startLevel;
   }
   set startLevel(newLevel) {
    this._startLevel = newLevel;
   }
   get pathways() {
    if (this.steering) {
     return this.steering.pathways();
    }
    return [];
   }
   get pathwayPriority() {
    if (this.steering) {
     return this.steering.pathwayPriority;
    }
    return null;
   }
   set pathwayPriority(pathwayPriority) {
    if (this.steering) {
     const pathwaysList = this.steering.pathways();
     const filteredPathwayPriority = pathwayPriority.filter((pathwayId) => {
      return pathwaysList.indexOf(pathwayId) !== -1;
     });
     if (pathwayPriority.length < 1) {
      this.warn(`pathwayPriority ${pathwayPriority} should contain at least one pathway from list: ${pathwaysList}`);
      return;
     }
     this.steering.pathwayPriority = filteredPathwayPriority;
    }
   }
   onError(event, data) {
    if (data.fatal || !data.context) {
     return;
    }
    if (data.context.type === PlaylistContextType.LEVEL && data.context.level === this.level) {
     this.checkRetry(data);
    }
   }

   // reset errors on the successful load of a fragment
   onFragBuffered(event, { frag }) {
    if (frag !== undefined && frag.type === PlaylistLevelType.MAIN) {
     const el = frag.elementaryStreams;
     if (!Object.keys(el).some((type) => !!el[type])) {
      return;
     }
     const level = this._levels[frag.level];
     if (level != null && level.loadError) {
      this.log(`Resetting level error count of ${level.loadError} on frag buffered`);
      level.loadError = 0;
     }
    }
   }
   onLevelLoaded(event, data) {
    var _data$deliveryDirecti2;
    const { level, details } = data;
    const curLevel = data.levelInfo;
    if (!curLevel) {
     var _data$deliveryDirecti;
     this.warn(`Invalid level index ${level}`);
     if ((_data$deliveryDirecti = data.deliveryDirectives) != null && _data$deliveryDirecti.skip) {
      details.deltaUpdateFailed = true;
     }
     return;
    }

    // only process level loaded events matching with expected level or prior to switch when media playlist is loaded directly
    if (curLevel === this.currentLevel || data.withoutMultiVariant) {
     // reset level load error counter on successful level loaded only if there is no issues with fragments
     if (curLevel.fragmentError === 0) {
      curLevel.loadError = 0;
     }
     // Ignore matching details populated by loading a Media Playlist directly
     let previousDetails = curLevel.details;
     if (previousDetails === data.details && previousDetails.advanced) {
      previousDetails = undefined;
     }
     this.playlistLoaded(level, data, previousDetails);
    } else if ((_data$deliveryDirecti2 = data.deliveryDirectives) != null && _data$deliveryDirecti2.skip) {
     // received a delta playlist update that cannot be merged
     details.deltaUpdateFailed = true;
    }
   }
   loadPlaylist(hlsUrlParameters) {
    super.loadPlaylist();
    if (this.shouldLoadPlaylist(this.currentLevel)) {
     this.scheduleLoading(this.currentLevel, hlsUrlParameters);
    }
   }
   loadingPlaylist(currentLevel, hlsUrlParameters) {
    super.loadingPlaylist(currentLevel, hlsUrlParameters);
    const url = this.getUrlWithDirectives(currentLevel.uri, hlsUrlParameters);
    const currentLevelIndex = this.currentLevelIndex;
    const pathwayId = currentLevel.attrs['PATHWAY-ID'];
    const details = currentLevel.details;
    const age = details == null ? void 0 : details.age;
    this.log(`Loading level index ${currentLevelIndex}${(hlsUrlParameters == null ? void 0 : hlsUrlParameters.msn) !== undefined ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : ''}${pathwayId ? ' Pathway ' + pathwayId : ''}${age && details.live ? ' age ' + age.toFixed(1) + (details.type ? ' ' + details.type || 0 : '') : ''} ${url}`);
    this.hls.trigger(Events.LEVEL_LOADING, {
     url,
     level: currentLevelIndex,
     levelInfo: currentLevel,
     pathwayId: currentLevel.attrs['PATHWAY-ID'],
     id: 0,
     // Deprecated Level urlId
     deliveryDirectives: hlsUrlParameters || null,
    });
   }
   get nextLoadLevel() {
    if (this.manualLevelIndex !== -1) {
     return this.manualLevelIndex;
    } else {
     return this.hls.nextAutoLevel;
    }
   }
   set nextLoadLevel(nextLevel) {
    this.level = nextLevel;
    if (this.manualLevelIndex === -1) {
     this.hls.nextAutoLevel = nextLevel;
    }
   }
   removeLevel(levelIndex) {
    var _this$currentLevel;
    if (this._levels.length === 1) {
     return;
    }
    const levels = this._levels.filter((level, index) => {
     if (index !== levelIndex) {
      return true;
     }
     if (this.steering) {
      this.steering.removeLevel(level);
     }
     if (level === this.currentLevel) {
      this.currentLevel = null;
      this.currentLevelIndex = -1;
      if (level.details) {
       level.details.fragments.forEach((f) => (f.level = -1));
      }
     }
     return false;
    });
    reassignFragmentLevelIndexes(levels);
    this._levels = levels;
    if (this.currentLevelIndex > -1 && (_this$currentLevel = this.currentLevel) != null && _this$currentLevel.details) {
     this.currentLevelIndex = this.currentLevel.details.fragments[0].level;
    }
    if (this.manualLevelIndex > -1) {
     this.manualLevelIndex = this.currentLevelIndex;
    }
    const maxLevel = levels.length - 1;
    this._firstLevel = Math.min(this._firstLevel, maxLevel);
    if (this._startLevel) {
     this._startLevel = Math.min(this._startLevel, maxLevel);
    }
    this.hls.trigger(Events.LEVELS_UPDATED, {
     levels,
    });
   }
   onLevelsUpdated(event, { levels }) {
    this._levels = levels;
   }
   checkMaxAutoUpdated() {
    const { autoLevelCapping, maxAutoLevel, maxHdcpLevel } = this.hls;
    if (this._maxAutoLevel !== maxAutoLevel) {
     this._maxAutoLevel = maxAutoLevel;
     this.hls.trigger(Events.MAX_AUTO_LEVEL_UPDATED, {
      autoLevelCapping,
      levels: this.levels,
      maxAutoLevel,
      minAutoLevel: this.hls.minAutoLevel,
      maxHdcpLevel,
     });
    }
   }
  }
  function assignTrackIdsByGroup(tracks) {
   const groups = {};
   tracks.forEach((track) => {
    const groupId = track.groupId || '';
    track.id = groups[groupId] = groups[groupId] || 0;
    groups[groupId]++;
   });
  }

  function getSourceBuffer() {
   return self.SourceBuffer || self.WebKitSourceBuffer;
  }
  function isMSESupported() {
   const mediaSource = getMediaSource();
   if (!mediaSource) {
    return false;
   }

   // if SourceBuffer is exposed ensure its API is valid
   // Older browsers do not expose SourceBuffer globally so checking SourceBuffer.prototype is impossible
   const sourceBuffer = getSourceBuffer();
   return !sourceBuffer || (sourceBuffer.prototype && typeof sourceBuffer.prototype.appendBuffer === 'function' && typeof sourceBuffer.prototype.remove === 'function');
  }
  function isSupported() {
   if (!isMSESupported()) {
    return false;
   }
   const mediaSource = getMediaSource();
   return typeof (mediaSource == null ? void 0 : mediaSource.isTypeSupported) === 'function' && (['avc1.42E01E,mp4a.40.2', 'av01.0.01M.08', 'vp09.00.50.08'].some((codecsForVideoContainer) => mediaSource.isTypeSupported(mimeTypeForCodec(codecsForVideoContainer, 'video'))) || ['mp4a.40.2', 'fLaC'].some((codecForAudioContainer) => mediaSource.isTypeSupported(mimeTypeForCodec(codecForAudioContainer, 'audio'))));
  }
  function changeTypeSupported() {
   var _sourceBuffer$prototy;
   const sourceBuffer = getSourceBuffer();
   return typeof (sourceBuffer == null || (_sourceBuffer$prototy = sourceBuffer.prototype) == null ? void 0 : _sourceBuffer$prototy.changeType) === 'function';
  }

  const TICK_INTERVAL = 100; // how often to tick in ms

  class StreamController extends BaseStreamController {
   constructor(hls, fragmentTracker, keyLoader) {
    super(hls, fragmentTracker, keyLoader, 'stream-controller', PlaylistLevelType.MAIN);
    this.audioCodecSwap = false;
    this.level = -1;
    this._forceStartLoad = false;
    this._hasEnoughToStart = false;
    this.altAudio = 0;
    this.audioOnly = false;
    this.fragPlaying = null;
    this.fragLastKbps = 0;
    this.couldBacktrack = false;
    this.backtrackFragment = null;
    this.audioCodecSwitch = false;
    this.videoBuffer = null;
    this.onMediaPlaying = () => {
     // tick to speed up FRAG_CHANGED triggering
     this.tick();
    };
    this.onMediaSeeked = () => {
     const media = this.media;
     const currentTime = media ? media.currentTime : null;
     if (currentTime === null || !isFiniteNumber(currentTime)) {
      return;
     }
     this.log(`Media seeked to ${currentTime.toFixed(3)}`);

     // If seeked was issued before buffer was appended do not tick immediately
     if (!this.getBufferedFrag(currentTime)) {
      return;
     }
     const bufferInfo = this.getFwdBufferInfoAtPos(media, currentTime, PlaylistLevelType.MAIN, 0);
     if (bufferInfo === null || bufferInfo.len === 0) {
      this.warn(`Main forward buffer length at ${currentTime} on "seeked" event ${bufferInfo ? bufferInfo.len : 'empty'})`);
      return;
     }

     // tick to speed up FRAG_CHANGED triggering
     this.tick();
    };
    this.registerListeners();
   }
   registerListeners() {
    super.registerListeners();
    const { hls } = this;
    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);
    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.on(Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);
    hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
    hls.on(Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);
    hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);
   }
   unregisterListeners() {
    super.unregisterListeners();
    const { hls } = this;
    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);
    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);
    hls.off(Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);
    hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
    hls.off(Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);
    hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);
   }
   onHandlerDestroying() {
    // @ts-ignore
    this.onMediaPlaying = this.onMediaSeeked = null;
    this.unregisterListeners();
    super.onHandlerDestroying();
   }
   startLoad(startPosition, skipSeekToStartPosition) {
    if (this.levels) {
     const { lastCurrentTime, hls } = this;
     this.stopLoad();
     this.setInterval(TICK_INTERVAL);
     this.level = -1;
     if (!this.startFragRequested) {
      // determine load level
      let startLevel = hls.startLevel;
      if (startLevel === -1) {
       if (hls.config.testBandwidth && this.levels.length > 1) {
        // -1 : guess start Level by doing a bitrate test by loading first fragment of lowest quality level
        startLevel = 0;
        this.bitrateTest = true;
       } else {
        startLevel = hls.firstAutoLevel;
       }
      }
      // set new level to playlist loader : this will trigger start level load
      // hls.nextLoadLevel remains until it is set to a new value or until a new frag is successfully loaded
      hls.nextLoadLevel = startLevel;
      this.level = hls.loadLevel;
      this._hasEnoughToStart = !!skipSeekToStartPosition;
     }
     // if startPosition undefined but lastCurrentTime set, set startPosition to last currentTime
     if (lastCurrentTime > 0 && startPosition === -1 && !skipSeekToStartPosition) {
      this.log(`Override startPosition with lastCurrentTime @${lastCurrentTime.toFixed(3)}`);
      startPosition = lastCurrentTime;
     }
     this.state = State.IDLE;
     this.nextLoadPosition = this.lastCurrentTime = startPosition + this.timelineOffset;
     this.startPosition = skipSeekToStartPosition ? -1 : startPosition;
     this.tick();
    } else {
     this._forceStartLoad = true;
     this.state = State.STOPPED;
    }
   }
   stopLoad() {
    this._forceStartLoad = false;
    super.stopLoad();
   }
   doTick() {
    switch (this.state) {
     case State.WAITING_LEVEL: {
      const { levels, level } = this;
      const currentLevel = levels == null ? void 0 : levels[level];
      const details = currentLevel == null ? void 0 : currentLevel.details;
      if (details && (!details.live || (this.levelLastLoaded === currentLevel && !this.waitForLive(currentLevel)))) {
       if (this.waitForCdnTuneIn(details)) {
        break;
       }
       this.state = State.IDLE;
       break;
      } else if (this.hls.nextLoadLevel !== this.level) {
       this.state = State.IDLE;
       break;
      }
      break;
     }
     case State.FRAG_LOADING_WAITING_RETRY:
      {
       var _this$media;
       const now = self.performance.now();
       const retryDate = this.retryDate;
       // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading
       if (!retryDate || now >= retryDate || ((_this$media = this.media) != null && _this$media.seeking)) {
        const { levels, level } = this;
        const currentLevel = levels == null ? void 0 : levels[level];
        this.resetStartWhenNotLoaded(currentLevel || null);
        this.state = State.IDLE;
       }
      }
      break;
    }
    if (this.state === State.IDLE) {
     this.doTickIdle();
    }
    this.onTickEnd();
   }
   onTickEnd() {
    var _this$media2;
    super.onTickEnd();
    if ((_this$media2 = this.media) != null && _this$media2.readyState && this.media.seeking === false) {
     this.lastCurrentTime = this.media.currentTime;
    }
    this.checkFragmentChanged();
   }
   doTickIdle() {
    const { hls, levelLastLoaded, levels, media } = this;

    // if start level not parsed yet OR
    // if video not attached AND start fragment already requested OR start frag prefetch not enabled
    // exit loop, as we either need more info (level not parsed) or we need media to be attached to load new fragment
    if (levelLastLoaded === null || (!media && !this.primaryPrefetch && (this.startFragRequested || !hls.config.startFragPrefetch))) {
     return;
    }

    // If the "main" level is audio-only but we are loading an alternate track in the same group, do not load anything
    if (this.altAudio && this.audioOnly) {
     return;
    }
    const level = this.buffering ? hls.nextLoadLevel : hls.loadLevel;
    if (!(levels != null && levels[level])) {
     return;
    }
    const levelInfo = levels[level];

    // if buffer length is less than maxBufLen try to load a new fragment

    const bufferInfo = this.getMainFwdBufferInfo();
    if (bufferInfo === null) {
     return;
    }
    const lastDetails = this.getLevelDetails();
    if (lastDetails && this._streamEnded(bufferInfo, lastDetails)) {
     const data = {};
     if (this.altAudio === 2) {
      data.type = 'video';
     }
     this.hls.trigger(Events.BUFFER_EOS, data);
     this.state = State.ENDED;
     return;
    }
    if (!this.buffering) {
     return;
    }

    // set next load level : this will trigger a playlist load if needed
    if (hls.loadLevel !== level && hls.manualLevel === -1) {
     this.log(`Adapting to level ${level} from level ${this.level}`);
    }
    this.level = hls.nextLoadLevel = level;
    const levelDetails = levelInfo.details;
    // if level info not retrieved yet, switch state and wait for level retrieval
    // if live playlist, ensure that new playlist has been refreshed to avoid loading/try to load
    // a useless and outdated fragment (that might even introduce load error if it is already out of the live playlist)
    if (!levelDetails || this.state === State.WAITING_LEVEL || this.waitForLive(levelInfo)) {
     this.level = level;
     this.state = State.WAITING_LEVEL;
     this.startFragRequested = false;
     return;
    }
    const bufferLen = bufferInfo.len;

    // compute max Buffer Length that we could get from this load level, based on level bitrate. don't buffer more than 60 MB and more than 30s
    const maxBufLen = this.getMaxBufferLength(levelInfo.maxBitrate);

    // Stay idle if we are still with buffer margins
    if (bufferLen >= maxBufLen) {
     return;
    }
    if (this.backtrackFragment && this.backtrackFragment.start > bufferInfo.end) {
     this.backtrackFragment = null;
    }
    const targetBufferTime = this.backtrackFragment ? this.backtrackFragment.start : bufferInfo.end;
    let frag = this.getNextFragment(targetBufferTime, levelDetails);
    // Avoid backtracking by loading an earlier segment in streams with segments that do not start with a key frame (flagged by `couldBacktrack`)
    if (this.couldBacktrack && !this.fragPrevious && frag && isMediaFragment(frag) && this.fragmentTracker.getState(frag) !== FragmentState.OK) {
     var _this$backtrackFragme;
     const backtrackSn = ((_this$backtrackFragme = this.backtrackFragment) != null ? _this$backtrackFragme : frag).sn;
     const fragIdx = backtrackSn - levelDetails.startSN;
     const backtrackFrag = levelDetails.fragments[fragIdx - 1];
     if (backtrackFrag && frag.cc === backtrackFrag.cc) {
      frag = backtrackFrag;
      this.fragmentTracker.removeFragment(backtrackFrag);
     }
    } else if (this.backtrackFragment && bufferInfo.len) {
     this.backtrackFragment = null;
    }
    // Avoid loop loading by using nextLoadPosition set for backtracking and skipping consecutive GAP tags
    if (frag && this.isLoopLoading(frag, targetBufferTime)) {
     const gapStart = frag.gap;
     if (!gapStart) {
      // Cleanup the fragment tracker before trying to find the next unbuffered fragment
      const type = this.audioOnly && !this.altAudio ? ElementaryStreamTypes.AUDIO : ElementaryStreamTypes.VIDEO;
      const mediaBuffer = (type === ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;
      if (mediaBuffer) {
       this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.MAIN);
      }
     }
     frag = this.getNextFragmentLoopLoading(frag, levelDetails, bufferInfo, PlaylistLevelType.MAIN, maxBufLen);
    }
    if (!frag) {
     return;
    }
    if (frag.initSegment && !frag.initSegment.data && !this.bitrateTest) {
     frag = frag.initSegment;
    }
    this.loadFragment(frag, levelInfo, targetBufferTime);
   }
   loadFragment(frag, level, targetBufferTime) {
    // Check if fragment is not loaded
    const fragState = this.fragmentTracker.getState(frag);
    if (fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {
     if (!isMediaFragment(frag)) {
      this._loadInitSegment(frag, level);
     } else if (this.bitrateTest) {
      this.log(`Fragment ${frag.sn} of level ${frag.level} is being downloaded to test bitrate and will not be buffered`);
      this._loadBitrateTestFrag(frag, level);
     } else {
      super.loadFragment(frag, level, targetBufferTime);
     }
    } else {
     this.clearTrackerIfNeeded(frag);
    }
   }
   getBufferedFrag(position) {
    return this.fragmentTracker.getBufferedFrag(position, PlaylistLevelType.MAIN);
   }
   followingBufferedFrag(frag) {
    if (frag) {
     // try to get range of next fragment (500ms after this range)
     return this.getBufferedFrag(frag.end + 0.5);
    }
    return null;
   }

   /*
    on immediate level switch :
     - pause playback if playing
     - cancel any pending load request
     - and trigger a buffer flush
  */
   immediateLevelSwitch() {
    this.abortCurrentFrag();
    this.flushMainBuffer(0, Number.POSITIVE_INFINITY);
   }

   /**
    * try to switch ASAP without breaking video playback:
    * in order to ensure smooth but quick level switching,
    * we need to find the next flushable buffer range
    * we should take into account new segment fetch time
    */
   nextLevelSwitch() {
    const { levels, media } = this;
    // ensure that media is defined and that metadata are available (to retrieve currentTime)
    if (media != null && media.readyState) {
     let fetchdelay;
     const fragPlayingCurrent = this.getAppendedFrag(media.currentTime);
     if (fragPlayingCurrent && fragPlayingCurrent.start > 1) {
      // flush buffer preceding current fragment (flush until current fragment start offset)
      // minus 1s to avoid video freezing, that could happen if we flush keyframe of current video ...
      this.flushMainBuffer(0, fragPlayingCurrent.start - 1);
     }
     const levelDetails = this.getLevelDetails();
     if (levelDetails != null && levelDetails.live) {
      const bufferInfo = this.getMainFwdBufferInfo();
      // Do not flush in live stream with low buffer
      if (!bufferInfo || bufferInfo.len < levelDetails.targetduration * 2) {
       return;
      }
     }
     if (!media.paused && levels) {
      // add a safety delay of 1s
      const nextLevelId = this.hls.nextLoadLevel;
      const nextLevel = levels[nextLevelId];
      const fragLastKbps = this.fragLastKbps;
      if (fragLastKbps && this.fragCurrent) {
       fetchdelay = (this.fragCurrent.duration * nextLevel.maxBitrate) / (1000 * fragLastKbps) + 1;
      } else {
       fetchdelay = 0;
      }
     } else {
      fetchdelay = 0;
     }
     // this.log('fetchdelay:'+fetchdelay);
     // find buffer range that will be reached once new fragment will be fetched
     const bufferedFrag = this.getBufferedFrag(media.currentTime + fetchdelay);
     if (bufferedFrag) {
      // we can flush buffer range following this one without stalling playback
      const nextBufferedFrag = this.followingBufferedFrag(bufferedFrag);
      if (nextBufferedFrag) {
       // if we are here, we can also cancel any loading/demuxing in progress, as they are useless
       this.abortCurrentFrag();
       // start flush position is in next buffered frag. Leave some padding for non-independent segments and smoother playback.
       const maxStart = nextBufferedFrag.maxStartPTS ? nextBufferedFrag.maxStartPTS : nextBufferedFrag.start;
       const fragDuration = nextBufferedFrag.duration;
       const startPts = Math.max(bufferedFrag.end, maxStart + Math.min(Math.max(fragDuration - this.config.maxFragLookUpTolerance, fragDuration * (this.couldBacktrack ? 0.5 : 0.125)), fragDuration * (this.couldBacktrack ? 0.75 : 0.25)));
       this.flushMainBuffer(startPts, Number.POSITIVE_INFINITY);
      }
     }
    }
   }
   abortCurrentFrag() {
    const fragCurrent = this.fragCurrent;
    this.fragCurrent = null;
    this.backtrackFragment = null;
    if (fragCurrent) {
     fragCurrent.abortRequests();
     this.fragmentTracker.removeFragment(fragCurrent);
    }
    switch (this.state) {
     case State.KEY_LOADING:
     case State.FRAG_LOADING:
     case State.FRAG_LOADING_WAITING_RETRY:
     case State.PARSING:
     case State.PARSED:
      this.state = State.IDLE;
      break;
    }
    this.nextLoadPosition = this.getLoadPosition();
   }
   flushMainBuffer(startOffset, endOffset) {
    super.flushMainBuffer(startOffset, endOffset, this.altAudio === 2 ? 'video' : null);
   }
   onMediaAttached(event, data) {
    super.onMediaAttached(event, data);
    const media = data.media;
    addEventListener(media, 'playing', this.onMediaPlaying);
    addEventListener(media, 'seeked', this.onMediaSeeked);
   }
   onMediaDetaching(event, data) {
    const { media } = this;
    if (media) {
     removeEventListener(media, 'playing', this.onMediaPlaying);
     removeEventListener(media, 'seeked', this.onMediaSeeked);
    }
    this.videoBuffer = null;
    this.fragPlaying = null;
    super.onMediaDetaching(event, data);
    const transferringMedia = !!data.transferMedia;
    if (transferringMedia) {
     return;
    }
    this._hasEnoughToStart = false;
   }
   onManifestLoading() {
    super.onManifestLoading();
    // reset buffer on manifest loading
    this.log('Trigger BUFFER_RESET');
    this.hls.trigger(Events.BUFFER_RESET, undefined);
    this.couldBacktrack = false;
    this.fragLastKbps = 0;
    this.fragPlaying = this.backtrackFragment = null;
    this.altAudio = 0;
    this.audioOnly = false;
   }
   onManifestParsed(event, data) {
    // detect if we have different kind of audio codecs used amongst playlists
    let aac = false;
    let heaac = false;
    for (let i = 0; i < data.levels.length; i++) {
     const codec = data.levels[i].audioCodec;
     if (codec) {
      aac = aac || codec.indexOf('mp4a.40.2') !== -1;
      heaac = heaac || codec.indexOf('mp4a.40.5') !== -1;
     }
    }
    this.audioCodecSwitch = aac && heaac && !changeTypeSupported();
    if (this.audioCodecSwitch) {
     this.log('Both AAC/HE-AAC audio found in levels; declaring level codec as HE-AAC');
    }
    this.levels = data.levels;
    this.startFragRequested = false;
   }
   onLevelLoading(event, data) {
    const { levels } = this;
    if (!levels || this.state !== State.IDLE) {
     return;
    }
    const level = data.levelInfo;
    if (!level.details || (level.details.live && (this.levelLastLoaded !== level || level.details.expired)) || this.waitForCdnTuneIn(level.details)) {
     this.state = State.WAITING_LEVEL;
    }
   }
   onLevelLoaded(event, data) {
    var _curLevel$details;
    const { levels, startFragRequested } = this;
    const newLevelId = data.level;
    const newDetails = data.details;
    const duration = newDetails.totalduration;
    if (!levels) {
     this.warn(`Levels were reset while loading level ${newLevelId}`);
     return;
    }
    this.log(`Level ${newLevelId} loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''}, cc [${newDetails.startCC}, ${newDetails.endCC}] duration:${duration}`);
    const curLevel = data.levelInfo;
    const fragCurrent = this.fragCurrent;
    if (fragCurrent && (this.state === State.FRAG_LOADING || this.state === State.FRAG_LOADING_WAITING_RETRY)) {
     if (fragCurrent.level !== data.level && fragCurrent.loader) {
      this.abortCurrentFrag();
     }
    }
    let sliding = 0;
    if (newDetails.live || ((_curLevel$details = curLevel.details) != null && _curLevel$details.live)) {
     var _this$levelLastLoaded;
     this.checkLiveUpdate(newDetails);
     if (newDetails.deltaUpdateFailed) {
      return;
     }
     sliding = this.alignPlaylists(newDetails, curLevel.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);
    }
    // override level info
    curLevel.details = newDetails;
    this.levelLastLoaded = curLevel;
    if (!startFragRequested) {
     this.setStartPosition(newDetails, sliding);
    }
    this.hls.trigger(Events.LEVEL_UPDATED, {
     details: newDetails,
     level: newLevelId,
    });

    // only switch back to IDLE state if we were waiting for level to start downloading a new fragment
    if (this.state === State.WAITING_LEVEL) {
     if (this.waitForCdnTuneIn(newDetails)) {
      // Wait for Low-Latency CDN Tune-in
      return;
     }
     this.state = State.IDLE;
    }
    if (startFragRequested && newDetails.live) {
     this.synchronizeToLiveEdge(newDetails);
    }

    // trigger handler right now
    this.tick();
   }
   synchronizeToLiveEdge(levelDetails) {
    const { config, media } = this;
    if (!media) {
     return;
    }
    const liveSyncPosition = this.hls.liveSyncPosition;
    const currentTime = this.getLoadPosition();
    const start = levelDetails.fragmentStart;
    const end = levelDetails.edge;
    const withinSlidingWindow = currentTime >= start - config.maxFragLookUpTolerance && currentTime <= end;
    // Continue if we can seek forward to sync position or if current time is outside of sliding window
    if (liveSyncPosition !== null && media.duration > liveSyncPosition && (currentTime < liveSyncPosition || !withinSlidingWindow)) {
     // Continue if buffer is starving or if current time is behind max latency
     const maxLatency = config.liveMaxLatencyDuration !== undefined ? config.liveMaxLatencyDuration : config.liveMaxLatencyDurationCount * levelDetails.targetduration;
     if ((!withinSlidingWindow && media.readyState < 4) || currentTime < end - maxLatency) {
      if (!this._hasEnoughToStart) {
       this.nextLoadPosition = liveSyncPosition;
      }
      // Only seek if ready and there is not a significant forward buffer available for playback
      if (media.readyState) {
       this.warn(`Playback: ${currentTime.toFixed(3)} is located too far from the end of live sliding playlist: ${end}, reset currentTime to : ${liveSyncPosition.toFixed(3)}`);
       if (this.config.liveSyncMode === 'buffered') {
        var _bufferInfo$buffered;
        const bufferInfo = BufferHelper.bufferInfo(media, liveSyncPosition, 0);
        if (!((_bufferInfo$buffered = bufferInfo.buffered) != null && _bufferInfo$buffered.length)) {
         media.currentTime = liveSyncPosition;
         return;
        }
        const isLiveSyncInBuffer = bufferInfo.start <= currentTime;
        if (isLiveSyncInBuffer) {
         media.currentTime = liveSyncPosition;
         return;
        }
        const { nextStart } = BufferHelper.bufferedInfo(bufferInfo.buffered, currentTime, 0);
        if (nextStart) {
         media.currentTime = nextStart;
        }
       } else {
        media.currentTime = liveSyncPosition;
       }
      }
     }
    }
   }
   _handleFragmentLoadProgress(data) {
    var _frag$initSegment;
    const frag = data.frag;
    const { part, payload } = data;
    const { levels } = this;
    if (!levels) {
     this.warn(`Levels were reset while fragment load was in progress. Fragment ${frag.sn} of level ${frag.level} will not be buffered`);
     return;
    }
    const currentLevel = levels[frag.level];
    if (!currentLevel) {
     this.warn(`Level ${frag.level} not found on progress`);
     return;
    }
    const details = currentLevel.details;
    if (!details) {
     this.warn(`Dropping fragment ${frag.sn} of level ${frag.level} after level details were reset`);
     this.fragmentTracker.removeFragment(frag);
     return;
    }
    const videoCodec = currentLevel.videoCodec;

    // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)
    const accurateTimeOffset = details.PTSKnown || !details.live;
    const initSegmentData = (_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.data;
    const audioCodec = this._getAudioCodec(currentLevel);

    // transmux the MPEG-TS data to ISO-BMFF segments
    // this.log(`Transmuxing ${frag.sn} of [${details.startSN} ,${details.endSN}],level ${frag.level}, cc ${frag.cc}`);
    const transmuxer = (this.transmuxer = this.transmuxer || new TransmuxerInterface(this.hls, PlaylistLevelType.MAIN, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this)));
    const partIndex = part ? part.index : -1;
    const partial = partIndex !== -1;
    const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);
    const initPTS = this.initPTS[frag.cc];
    transmuxer.push(payload, initSegmentData, audioCodec, videoCodec, frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);
   }
   onAudioTrackSwitching(event, data) {
    const hls = this.hls;
    // if any URL found on new audio track, it is an alternate audio track
    const fromAltAudio = this.altAudio === 2;
    const altAudio = useAlternateAudio(data.url, hls);
    // if we switch on main audio, ensure that main fragment scheduling is synced with media.buffered
    // don't do anything if we switch to alt audio: audio stream controller is handling it.
    // we will just have to change buffer scheduling on audioTrackSwitched
    if (!altAudio) {
     if (this.mediaBuffer !== this.media) {
      this.log('Switching on main audio, use media.buffered to schedule main fragment loading');
      this.mediaBuffer = this.media;
      const fragCurrent = this.fragCurrent;
      // we need to refill audio buffer from main: cancel any frag loading to speed up audio switch
      if (fragCurrent) {
       this.log('Switching to main audio track, cancel main fragment load');
       fragCurrent.abortRequests();
       this.fragmentTracker.removeFragment(fragCurrent);
      }
      // destroy transmuxer to force init segment generation (following audio switch)
      this.resetTransmuxer();
      // switch to IDLE state to load new fragment
      this.resetLoadingState();
     } else if (this.audioOnly) {
      // Reset audio transmuxer so when switching back to main audio we're not still appending where we left off
      this.resetTransmuxer();
     }
     // If switching from alt to main audio, flush all audio and trigger track switched
     if (fromAltAudio) {
      this.fragmentTracker.removeAllFragments();
      hls.once(Events.BUFFER_FLUSHED, () => {
       if (!this.hls) {
        return;
       }
       this.hls.trigger(Events.AUDIO_TRACK_SWITCHED, data);
      });
      hls.trigger(Events.BUFFER_FLUSHING, {
       startOffset: 0,
       endOffset: Number.POSITIVE_INFINITY,
       type: null,
      });
      return;
     }
     hls.trigger(Events.AUDIO_TRACK_SWITCHED, data);
    } else {
     this.altAudio = 1;
    }
   }
   onAudioTrackSwitched(event, data) {
    const altAudio = useAlternateAudio(data.url, this.hls);
    if (altAudio) {
     const videoBuffer = this.videoBuffer;
     // if we switched on alternate audio, ensure that main fragment scheduling is synced with video sourcebuffer buffered
     if (videoBuffer && this.mediaBuffer !== videoBuffer) {
      this.log('Switching on alternate audio, use video.buffered to schedule main fragment loading');
      this.mediaBuffer = videoBuffer;
     }
    }
    this.altAudio = altAudio ? 2 : 0;
    this.tick();
   }
   onBufferCreated(event, data) {
    const tracks = data.tracks;
    let mediaTrack;
    let name;
    let alternate = false;
    for (const type in tracks) {
     const track = tracks[type];
     if (track.id === 'main') {
      name = type;
      mediaTrack = track;
      // keep video source buffer reference
      if (type === 'video') {
       const videoTrack = tracks[type];
       if (videoTrack) {
        this.videoBuffer = videoTrack.buffer;
       }
      }
     } else {
      alternate = true;
     }
    }
    if (alternate && mediaTrack) {
     this.log(`Alternate track found, use ${name}.buffered to schedule main fragment loading`);
     this.mediaBuffer = mediaTrack.buffer;
    } else {
     this.mediaBuffer = this.media;
    }
   }
   onFragBuffered(event, data) {
    const { frag, part } = data;
    const bufferedMainFragment = frag.type === PlaylistLevelType.MAIN;
    if (bufferedMainFragment) {
     if (this.fragContextChanged(frag)) {
      // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion
      // Avoid setting state back to IDLE, since that will interfere with a level switch
      this.warn(`Fragment ${frag.sn}${part ? ' p: ' + part.index : ''} of level ${frag.level} finished buffering, but was aborted. state: ${this.state}`);
      if (this.state === State.PARSED) {
       this.state = State.IDLE;
      }
      return;
     }
     const stats = part ? part.stats : frag.stats;
     this.fragLastKbps = Math.round((8 * stats.total) / (stats.buffering.end - stats.loading.first));
     if (isMediaFragment(frag)) {
      this.fragPrevious = frag;
     }
     this.fragBufferedComplete(frag, part);
    }
    const media = this.media;
    if (!media) {
     return;
    }
    if (!this._hasEnoughToStart && BufferHelper.getBuffered(media).length) {
     this._hasEnoughToStart = true;
     this.seekToStartPos();
    }
    if (bufferedMainFragment) {
     this.tick();
    }
   }
   get hasEnoughToStart() {
    return this._hasEnoughToStart;
   }
   onError(event, data) {
    var _data$context;
    if (data.fatal) {
     this.state = State.ERROR;
     return;
    }
    switch (data.details) {
     case ErrorDetails.FRAG_GAP:
     case ErrorDetails.FRAG_PARSING_ERROR:
     case ErrorDetails.FRAG_DECRYPT_ERROR:
     case ErrorDetails.FRAG_LOAD_ERROR:
     case ErrorDetails.FRAG_LOAD_TIMEOUT:
     case ErrorDetails.KEY_LOAD_ERROR:
     case ErrorDetails.KEY_LOAD_TIMEOUT:
      this.onFragmentOrKeyLoadError(PlaylistLevelType.MAIN, data);
      break;
     case ErrorDetails.LEVEL_LOAD_ERROR:
     case ErrorDetails.LEVEL_LOAD_TIMEOUT:
     case ErrorDetails.LEVEL_PARSING_ERROR:
      // in case of non fatal error while loading level, if level controller is not retrying to load level, switch back to IDLE
      if (!data.levelRetry && this.state === State.WAITING_LEVEL && ((_data$context = data.context) == null ? void 0 : _data$context.type) === PlaylistContextType.LEVEL) {
       this.state = State.IDLE;
      }
      break;
     case ErrorDetails.BUFFER_ADD_CODEC_ERROR:
     case ErrorDetails.BUFFER_APPEND_ERROR:
      if (data.parent !== 'main') {
       return;
      }
      if (this.reduceLengthAndFlushBuffer(data)) {
       this.resetLoadingState();
      }
      break;
     case ErrorDetails.BUFFER_FULL_ERROR:
      if (data.parent !== 'main') {
       return;
      }
      if (this.reduceLengthAndFlushBuffer(data)) {
       const isAssetPlayer = !this.config.interstitialsController && this.config.assetPlayerId;
       if (isAssetPlayer) {
        // Use currentTime in buffer estimate to prevent loading more until playback advances
        this._hasEnoughToStart = true;
       } else {
        this.flushMainBuffer(0, Number.POSITIVE_INFINITY);
       }
      }
      break;
     case ErrorDetails.INTERNAL_EXCEPTION:
      this.recoverWorkerError(data);
      break;
    }
   }
   onFragLoadEmergencyAborted() {
    this.state = State.IDLE;
    // if loadedmetadata is not set, it means that we are emergency switch down on first frag
    // in that case, reset startFragRequested flag
    if (!this._hasEnoughToStart) {
     this.startFragRequested = false;
     this.nextLoadPosition = this.lastCurrentTime;
    }
    this.tickImmediate();
   }
   onBufferFlushed(event, { type }) {
    if (type !== ElementaryStreamTypes.AUDIO || !this.altAudio) {
     const mediaBuffer = (type === ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;
     if (mediaBuffer) {
      this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.MAIN);
      this.tick();
     }
    }
   }
   onLevelsUpdated(event, data) {
    if (this.level > -1 && this.fragCurrent) {
     this.level = this.fragCurrent.level;
     if (this.level === -1) {
      this.resetWhenMissingContext(this.fragCurrent);
     }
    }
    this.levels = data.levels;
   }
   swapAudioCodec() {
    this.audioCodecSwap = !this.audioCodecSwap;
   }

   /**
    * Seeks to the set startPosition if not equal to the mediaElement's current time.
    */
   seekToStartPos() {
    const { media } = this;
    if (!media) {
     return;
    }
    const currentTime = media.currentTime;
    let startPosition = this.startPosition;
    // only adjust currentTime if different from startPosition or if startPosition not buffered
    // at that stage, there should be only one buffered range, as we reach that code after first fragment has been buffered
    if (startPosition >= 0 && currentTime < startPosition) {
     if (media.seeking) {
      this.log(`could not seek to ${startPosition}, already seeking at ${currentTime}`);
      return;
     }

     // Offset start position by timeline offset
     const timelineOffset = this.timelineOffset;
     if (timelineOffset && startPosition) {
      startPosition += timelineOffset;
     }
     const details = this.getLevelDetails();
     const buffered = BufferHelper.getBuffered(media);
     const bufferStart = buffered.length ? buffered.start(0) : 0;
     const delta = bufferStart - startPosition;
     const skipTolerance = Math.max(this.config.maxBufferHole, this.config.maxFragLookUpTolerance);
     if (this.config.startOnSegmentBoundary || (delta > 0 && (delta < skipTolerance || (this.loadingParts && delta < 2 * ((details == null ? void 0 : details.partTarget) || 0))))) {
      this.log(`adjusting start position by ${delta} to match buffer start`);
      startPosition += delta;
      this.startPosition = startPosition;
     }
     if (currentTime < startPosition) {
      this.log(`seek to target start position ${startPosition} from current time ${currentTime} buffer start ${bufferStart}`);
      media.currentTime = startPosition;
     }
    }
   }
   _getAudioCodec(currentLevel) {
    let audioCodec = this.config.defaultAudioCodec || currentLevel.audioCodec;
    if (this.audioCodecSwap && audioCodec) {
     this.log('Swapping audio codec');
     if (audioCodec.indexOf('mp4a.40.5') !== -1) {
      audioCodec = 'mp4a.40.2';
     } else {
      audioCodec = 'mp4a.40.5';
     }
    }
    return audioCodec;
   }
   _loadBitrateTestFrag(fragment, level) {
    fragment.bitrateTest = true;
    this._doFragLoad(fragment, level).then((data) => {
     const { hls } = this;
     const frag = data == null ? void 0 : data.frag;
     if (!frag || this.fragContextChanged(frag)) {
      return;
     }
     level.fragmentError = 0;
     this.state = State.IDLE;
     this.startFragRequested = false;
     this.bitrateTest = false;
     const stats = frag.stats;
     // Bitrate tests fragments are neither parsed nor buffered
     stats.parsing.start = stats.parsing.end = stats.buffering.start = stats.buffering.end = self.performance.now();
     hls.trigger(Events.FRAG_LOADED, data);
     frag.bitrateTest = false;
    });
   }
   _handleTransmuxComplete(transmuxResult) {
    const id = this.playlistType;
    const { hls } = this;
    const { remuxResult, chunkMeta } = transmuxResult;
    const context = this.getCurrentContext(chunkMeta);
    if (!context) {
     this.resetWhenMissingContext(chunkMeta);
     return;
    }
    const { frag, part, level } = context;
    const { video, text, id3, initSegment } = remuxResult;
    const { details } = level;
    // The audio-stream-controller handles audio buffering if Hls.js is playing an alternate audio track
    const audio = this.altAudio ? undefined : remuxResult.audio;

    // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.
    // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.
    if (this.fragContextChanged(frag)) {
     this.fragmentTracker.removeFragment(frag);
     return;
    }
    this.state = State.PARSING;
    if (initSegment) {
     const tracks = initSegment.tracks;
     if (tracks) {
      const mapFragment = frag.initSegment || frag;
      if (this.unhandledEncryptionError(initSegment, frag)) {
       return;
      }
      this._bufferInitSegment(level, tracks, mapFragment, chunkMeta);
      hls.trigger(Events.FRAG_PARSING_INIT_SEGMENT, {
       frag: mapFragment,
       id,
       tracks,
      });
     }
     const baseTime = initSegment.initPTS;
     const timescale = initSegment.timescale;
     const initPTS = this.initPTS[frag.cc];
     if (isFiniteNumber(baseTime) && (!initPTS || initPTS.baseTime !== baseTime || initPTS.timescale !== timescale)) {
      const trackId = initSegment.trackId;
      this.initPTS[frag.cc] = {
       baseTime,
       timescale,
       trackId,
      };
      hls.trigger(Events.INIT_PTS_FOUND, {
       frag,
       id,
       initPTS: baseTime,
       timescale,
       trackId,
      });
     }
    }

    // Avoid buffering if backtracking this fragment
    if (video && details) {
     if (audio && video.type === 'audiovideo') {
      this.logMuxedErr(frag);
     }
     const prevFrag = details.fragments[frag.sn - 1 - details.startSN];
     const isFirstFragment = frag.sn === details.startSN;
     const isFirstInDiscontinuity = !prevFrag || frag.cc > prevFrag.cc;
     if (remuxResult.independent !== false) {
      const { startPTS, endPTS, startDTS, endDTS } = video;
      if (part) {
       part.elementaryStreams[video.type] = {
        startPTS,
        endPTS,
        startDTS,
        endDTS,
       };
      } else {
       if (video.firstKeyFrame && video.independent && chunkMeta.id === 1 && !isFirstInDiscontinuity) {
        this.couldBacktrack = true;
       }
       if (video.dropped && video.independent) {
        // Backtrack if dropped frames create a gap after currentTime

        const bufferInfo = this.getMainFwdBufferInfo();
        const targetBufferTime = (bufferInfo ? bufferInfo.end : this.getLoadPosition()) + this.config.maxBufferHole;
        const startTime = video.firstKeyFramePTS ? video.firstKeyFramePTS : startPTS;
        if (!isFirstFragment && targetBufferTime < startTime - this.config.maxBufferHole && !isFirstInDiscontinuity) {
         this.backtrack(frag);
         return;
        } else if (isFirstInDiscontinuity) {
         // Mark segment with a gap to avoid loop loading
         frag.gap = true;
        }
        // Set video stream start to fragment start so that truncated samples do not distort the timeline, and mark it partial
        frag.setElementaryStreamInfo(video.type, frag.start, endPTS, frag.start, endDTS, true);
       } else if (isFirstFragment && startPTS - (details.appliedTimelineOffset || 0) > MAX_START_GAP_JUMP) {
        // Mark segment with a gap to skip large start gap
        frag.gap = true;
       }
      }
      frag.setElementaryStreamInfo(video.type, startPTS, endPTS, startDTS, endDTS);
      if (this.backtrackFragment) {
       this.backtrackFragment = frag;
      }
      this.bufferFragmentData(video, frag, part, chunkMeta, isFirstFragment || isFirstInDiscontinuity);
     } else if (isFirstFragment || isFirstInDiscontinuity) {
      // Mark segment with a gap to avoid loop loading
      frag.gap = true;
     } else {
      this.backtrack(frag);
      return;
     }
    }
    if (audio) {
     const { startPTS, endPTS, startDTS, endDTS } = audio;
     if (part) {
      part.elementaryStreams[ElementaryStreamTypes.AUDIO] = {
       startPTS,
       endPTS,
       startDTS,
       endDTS,
      };
     }
     frag.setElementaryStreamInfo(ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);
     this.bufferFragmentData(audio, frag, part, chunkMeta);
    }
    if (details && id3 != null && id3.samples.length) {
     const emittedID3 = {
      id,
      frag,
      details,
      samples: id3.samples,
     };
     hls.trigger(Events.FRAG_PARSING_METADATA, emittedID3);
    }
    if (details && text) {
     const emittedText = {
      id,
      frag,
      details,
      samples: text.samples,
     };
     hls.trigger(Events.FRAG_PARSING_USERDATA, emittedText);
    }
   }
   logMuxedErr(frag) {
    this.warn(`${isMediaFragment(frag) ? 'Media' : 'Init'} segment with muxed audiovideo where only video expected: ${frag.url}`);
   }
   _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {
    if (this.state !== State.PARSING) {
     return;
    }
    this.audioOnly = !!tracks.audio && !tracks.video;

    // if audio track is expected to come from audio stream controller, discard any coming from main
    if (this.altAudio && !this.audioOnly) {
     delete tracks.audio;
     if (tracks.audiovideo) {
      this.logMuxedErr(frag);
     }
    }
    // include levelCodec in audio and video tracks
    const { audio, video, audiovideo } = tracks;
    if (audio) {
     const levelCodec = currentLevel.audioCodec;
     let audioCodec = pickMostCompleteCodecName(audio.codec, levelCodec);
     // Add level and profile to make up for remuxer not being able to parse full codec
     // (logger warning "Unhandled audio codec...")
     if (audioCodec === 'mp4a') {
      audioCodec = 'mp4a.40.5';
     }
     // Handle `audioCodecSwitch`
     const ua = navigator.userAgent.toLowerCase();
     if (this.audioCodecSwitch) {
      if (audioCodec) {
       if (audioCodec.indexOf('mp4a.40.5') !== -1) {
        audioCodec = 'mp4a.40.2';
       } else {
        audioCodec = 'mp4a.40.5';
       }
      }
      // In the case that AAC and HE-AAC audio codecs are signalled in manifest,
      // force HE-AAC, as it seems that most browsers prefers it.
      // don't force HE-AAC if mono stream, or in Firefox
      const audioMetadata = audio.metadata;
      if (audioMetadata && 'channelCount' in audioMetadata && (audioMetadata.channelCount || 1) !== 1 && ua.indexOf('firefox') === -1) {
       audioCodec = 'mp4a.40.5';
      }
     }
     // HE-AAC is broken on Android, always signal audio codec as AAC even if variant manifest states otherwise
     if (audioCodec && audioCodec.indexOf('mp4a.40.5') !== -1 && ua.indexOf('android') !== -1 && audio.container !== 'audio/mpeg') {
      // Exclude mpeg audio
      audioCodec = 'mp4a.40.2';
      this.log(`Android: force audio codec to ${audioCodec}`);
     }
     if (levelCodec && levelCodec !== audioCodec) {
      this.log(`Swapping manifest audio codec "${levelCodec}" for "${audioCodec}"`);
     }
     audio.levelCodec = audioCodec;
     audio.id = PlaylistLevelType.MAIN;
     this.log(`Init audio buffer, container:${audio.container}, codecs[selected/level/parsed]=[${audioCodec || ''}/${levelCodec || ''}/${audio.codec}]`);
     delete tracks.audiovideo;
    }
    if (video) {
     video.levelCodec = currentLevel.videoCodec;
     video.id = PlaylistLevelType.MAIN;
     const parsedVideoCodec = video.codec;
     if ((parsedVideoCodec == null ? void 0 : parsedVideoCodec.length) === 4) {
      // Make up for passthrough-remuxer not being able to parse full codec
      // (logger warning "Unhandled video codec...")
      switch (parsedVideoCodec) {
       case 'hvc1':
       case 'hev1':
        video.codec = 'hvc1.1.6.L120.90';
        break;
       case 'av01':
        video.codec = 'av01.0.04M.08';
        break;
       case 'avc1':
        video.codec = 'avc1.42e01e';
        break;
      }
     }
     this.log(`Init video buffer, container:${video.container}, codecs[level/parsed]=[${currentLevel.videoCodec || ''}/${parsedVideoCodec}]${video.codec !== parsedVideoCodec ? ' parsed-corrected=' + video.codec : ''}${video.supplemental ? ' supplemental=' + video.supplemental : ''}`);
     delete tracks.audiovideo;
    }
    if (audiovideo) {
     this.log(`Init audiovideo buffer, container:${audiovideo.container}, codecs[level/parsed]=[${currentLevel.codecs}/${audiovideo.codec}]`);
     delete tracks.video;
     delete tracks.audio;
    }
    const trackTypes = Object.keys(tracks);
    if (trackTypes.length) {
     this.hls.trigger(Events.BUFFER_CODECS, tracks);
     if (!this.hls) {
      // Exit after fatal tracks error
      return;
     }
     // loop through tracks that are going to be provided to bufferController
     trackTypes.forEach((trackName) => {
      const track = tracks[trackName];
      const initSegment = track.initSegment;
      if (initSegment != null && initSegment.byteLength) {
       this.hls.trigger(Events.BUFFER_APPENDING, {
        type: trackName,
        data: initSegment,
        frag,
        part: null,
        chunkMeta,
        parent: frag.type,
       });
      }
     });
    }
    // trigger handler right now
    this.tickImmediate();
   }
   getMainFwdBufferInfo() {
    // Observe video SourceBuffer (this.mediaBuffer) only when alt-audio is used, otherwise observe combined media buffer
    const bufferOutput = this.mediaBuffer && this.altAudio === 2 ? this.mediaBuffer : this.media;
    return this.getFwdBufferInfo(bufferOutput, PlaylistLevelType.MAIN);
   }
   get maxBufferLength() {
    const { levels, level } = this;
    const levelInfo = levels == null ? void 0 : levels[level];
    if (!levelInfo) {
     return this.config.maxBufferLength;
    }
    return this.getMaxBufferLength(levelInfo.maxBitrate);
   }
   backtrack(frag) {
    this.couldBacktrack = true;
    // Causes findFragments to backtrack through fragments to find the keyframe
    this.backtrackFragment = frag;
    this.resetTransmuxer();
    this.flushBufferGap(frag);
    this.fragmentTracker.removeFragment(frag);
    this.fragPrevious = null;
    this.nextLoadPosition = frag.start;
    this.state = State.IDLE;
   }
   checkFragmentChanged() {
    const video = this.media;
    let fragPlayingCurrent = null;
    if (video && video.readyState > 1 && video.seeking === false) {
     const currentTime = video.currentTime;
     /* if video element is in seeked state, currentTime can only increase.
        (assuming that playback rate is positive ...)
        As sometimes currentTime jumps back to zero after a
        media decode error, check this, to avoid seeking back to
        wrong position after a media decode error
      */

     if (BufferHelper.isBuffered(video, currentTime)) {
      fragPlayingCurrent = this.getAppendedFrag(currentTime);
     } else if (BufferHelper.isBuffered(video, currentTime + 0.1)) {
      /* ensure that FRAG_CHANGED event is triggered at startup,
          when first video frame is displayed and playback is paused.
          add a tolerance of 100ms, in case current position is not buffered,
          check if current pos+100ms is buffered and use that buffer range
          for FRAG_CHANGED event reporting */
      fragPlayingCurrent = this.getAppendedFrag(currentTime + 0.1);
     }
     if (fragPlayingCurrent) {
      this.backtrackFragment = null;
      const fragPlaying = this.fragPlaying;
      const fragCurrentLevel = fragPlayingCurrent.level;
      if (!fragPlaying || fragPlayingCurrent.sn !== fragPlaying.sn || fragPlaying.level !== fragCurrentLevel) {
       this.fragPlaying = fragPlayingCurrent;
       this.hls.trigger(Events.FRAG_CHANGED, {
        frag: fragPlayingCurrent,
       });
       if (!fragPlaying || fragPlaying.level !== fragCurrentLevel) {
        this.hls.trigger(Events.LEVEL_SWITCHED, {
         level: fragCurrentLevel,
        });
       }
      }
     }
    }
   }
   get nextLevel() {
    const frag = this.nextBufferedFrag;
    if (frag) {
     return frag.level;
    }
    return -1;
   }
   get currentFrag() {
    var _this$media3;
    if (this.fragPlaying) {
     return this.fragPlaying;
    }
    const currentTime = ((_this$media3 = this.media) == null ? void 0 : _this$media3.currentTime) || this.lastCurrentTime;
    if (isFiniteNumber(currentTime)) {
     return this.getAppendedFrag(currentTime);
    }
    return null;
   }
   get currentProgramDateTime() {
    var _this$media4;
    const currentTime = ((_this$media4 = this.media) == null ? void 0 : _this$media4.currentTime) || this.lastCurrentTime;
    if (isFiniteNumber(currentTime)) {
     const details = this.getLevelDetails();
     const frag = this.currentFrag || (details ? findFragmentByPTS(null, details.fragments, currentTime) : null);
     if (frag) {
      const programDateTime = frag.programDateTime;
      if (programDateTime !== null) {
       const epocMs = programDateTime + (currentTime - frag.start) * 1000;
       return new Date(epocMs);
      }
     }
    }
    return null;
   }
   get currentLevel() {
    const frag = this.currentFrag;
    if (frag) {
     return frag.level;
    }
    return -1;
   }
   get nextBufferedFrag() {
    const frag = this.currentFrag;
    if (frag) {
     return this.followingBufferedFrag(frag);
    }
    return null;
   }
   get forceStartLoad() {
    return this._forceStartLoad;
   }
  }

  class KeyLoader {
   constructor(config) {
    this.config = void 0;
    this.keyUriToKeyInfo = {};
    this.emeController = null;
    this.config = config;
   }
   abort(type) {
    for (const uri in this.keyUriToKeyInfo) {
     const loader = this.keyUriToKeyInfo[uri].loader;
     if (loader) {
      var _loader$context;
      if (type && type !== ((_loader$context = loader.context) == null ? void 0 : _loader$context.frag.type)) {
       return;
      }
      loader.abort();
     }
    }
   }
   detach() {
    for (const uri in this.keyUriToKeyInfo) {
     const keyInfo = this.keyUriToKeyInfo[uri];
     // Remove cached EME keys on detach
     if (keyInfo.mediaKeySessionContext || keyInfo.decryptdata.isCommonEncryption) {
      delete this.keyUriToKeyInfo[uri];
     }
    }
   }
   destroy() {
    this.detach();
    for (const uri in this.keyUriToKeyInfo) {
     const loader = this.keyUriToKeyInfo[uri].loader;
     if (loader) {
      loader.destroy();
     }
    }
    this.keyUriToKeyInfo = {};
   }
   createKeyLoadError(frag, details = ErrorDetails.KEY_LOAD_ERROR, error, networkDetails, response) {
    return new LoadError({
     type: ErrorTypes.NETWORK_ERROR,
     details,
     fatal: false,
     frag,
     response,
     error,
     networkDetails,
    });
   }
   loadClear(loadingFrag, encryptedFragments, startFragRequested) {
    if (this.emeController && this.config.emeEnabled && !this.emeController.getSelectedKeySystemFormats().length) {
     // Access key-system with nearest key on start (loading frag is unencrypted)
     if (encryptedFragments.length) {
      for (let i = 0, l = encryptedFragments.length; i < l; i++) {
       const frag = encryptedFragments[i];
       // Loading at or before segment with EXT-X-KEY, or first frag loading and last EXT-X-KEY
       if ((loadingFrag.cc <= frag.cc && (!isMediaFragment(loadingFrag) || !isMediaFragment(frag) || loadingFrag.sn < frag.sn)) || (!startFragRequested && i == l - 1)) {
        return this.emeController.selectKeySystemFormat(frag).then((keySystemFormat) => {
         if (!this.emeController) {
          return;
         }
         frag.setKeyFormat(keySystemFormat);
         const keySystem = keySystemFormatToKeySystemDomain(keySystemFormat);
         if (keySystem) {
          return this.emeController.getKeySystemAccess([keySystem]);
         }
        });
       }
      }
     }
     if (this.config.requireKeySystemAccessOnStart) {
      const keySystemsInConfig = getKeySystemsForConfig(this.config);
      if (keySystemsInConfig.length) {
       return this.emeController.getKeySystemAccess(keySystemsInConfig);
      }
     }
    }
    return null;
   }
   load(frag) {
    if (!frag.decryptdata && frag.encrypted && this.emeController && this.config.emeEnabled) {
     // Multiple keys, but none selected, resolve in eme-controller
     return this.emeController.selectKeySystemFormat(frag).then((keySystemFormat) => {
      return this.loadInternal(frag, keySystemFormat);
     });
    }
    return this.loadInternal(frag);
   }
   loadInternal(frag, keySystemFormat) {
    var _keyInfo, _keyInfo2;
    if (keySystemFormat) {
     frag.setKeyFormat(keySystemFormat);
    }
    const decryptdata = frag.decryptdata;
    if (!decryptdata) {
     const error = new Error(keySystemFormat ? `Expected frag.decryptdata to be defined after setting format ${keySystemFormat}` : 'Missing decryption data on fragment in onKeyLoading');
     return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, error));
    }
    const uri = decryptdata.uri;
    if (!uri) {
     return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(`Invalid key URI: "${uri}"`)));
    }
    let keyInfo = this.keyUriToKeyInfo[uri];
    if ((_keyInfo = keyInfo) != null && _keyInfo.decryptdata.key) {
     decryptdata.key = keyInfo.decryptdata.key;
     return Promise.resolve({
      frag,
      keyInfo,
     });
    }
    // Return key load promise as long as it does not have a mediakey session with an unusable key status
    if ((_keyInfo2 = keyInfo) != null && _keyInfo2.keyLoadPromise) {
     var _keyInfo$mediaKeySess;
     switch ((_keyInfo$mediaKeySess = keyInfo.mediaKeySessionContext) == null ? void 0 : _keyInfo$mediaKeySess.keyStatus) {
      case undefined:
      case 'status-pending':
      case 'usable':
      case 'usable-in-future':
       return keyInfo.keyLoadPromise.then((keyLoadedData) => {
        // Return the correct fragment with updated decryptdata key and loaded keyInfo
        decryptdata.key = keyLoadedData.keyInfo.decryptdata.key;
        return {
         frag,
         keyInfo,
        };
       });
     }
     // If we have a key session and status and it is not pending or usable, continue
     // This will go back to the eme-controller for expired keys to get a new keyLoadPromise
    }

    // Load the key or return the loading promise
    keyInfo = this.keyUriToKeyInfo[uri] = {
     decryptdata,
     keyLoadPromise: null,
     loader: null,
     mediaKeySessionContext: null,
    };
    switch (decryptdata.method) {
     case 'ISO-23001-7':
     case 'SAMPLE-AES':
     case 'SAMPLE-AES-CENC':
     case 'SAMPLE-AES-CTR':
      if (decryptdata.keyFormat === 'identity') {
       // loadKeyHTTP handles http(s) and data URLs
       return this.loadKeyHTTP(keyInfo, frag);
      }
      return this.loadKeyEME(keyInfo, frag);
     case 'AES-128':
     case 'AES-256':
     case 'AES-256-CTR':
      return this.loadKeyHTTP(keyInfo, frag);
     default:
      return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(`Key supplied with unsupported METHOD: "${decryptdata.method}"`)));
    }
   }
   loadKeyEME(keyInfo, frag) {
    const keyLoadedData = {
     frag,
     keyInfo,
    };
    if (this.emeController && this.config.emeEnabled) {
     const keySessionContextPromise = this.emeController.loadKey(keyLoadedData);
     if (keySessionContextPromise) {
      return (keyInfo.keyLoadPromise = keySessionContextPromise.then((keySessionContext) => {
       keyInfo.mediaKeySessionContext = keySessionContext;
       return keyLoadedData;
      })).catch((error) => {
       // Remove promise for license renewal or retry
       keyInfo.keyLoadPromise = null;
       throw error;
      });
     }
    }
    return Promise.resolve(keyLoadedData);
   }
   loadKeyHTTP(keyInfo, frag) {
    const config = this.config;
    const Loader = config.loader;
    const keyLoader = new Loader(config);
    frag.keyLoader = keyInfo.loader = keyLoader;
    return (keyInfo.keyLoadPromise = new Promise((resolve, reject) => {
     const loaderContext = {
      keyInfo,
      frag,
      responseType: 'arraybuffer',
      url: keyInfo.decryptdata.uri,
     };

     // maxRetry is 0 so that instead of retrying the same key on the same variant multiple times,
     // key-loader will trigger an error and rely on stream-controller to handle retry logic.
     // this will also align retry logic with fragment-loader
     const loadPolicy = config.keyLoadPolicy.default;
     const loaderConfig = {
      loadPolicy,
      timeout: loadPolicy.maxLoadTimeMs,
      maxRetry: 0,
      retryDelay: 0,
      maxRetryDelay: 0,
     };
     const loaderCallbacks = {
      onSuccess: (response, stats, context, networkDetails) => {
       const { frag, keyInfo, url: uri } = context;
       if (!frag.decryptdata || keyInfo !== this.keyUriToKeyInfo[uri]) {
        return reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error('after key load, decryptdata unset or changed'), networkDetails));
       }
       keyInfo.decryptdata.key = frag.decryptdata.key = new Uint8Array(response.data);

       // detach fragment key loader on load success
       frag.keyLoader = null;
       keyInfo.loader = null;
       resolve({
        frag,
        keyInfo,
       });
      },
      onError: (response, context, networkDetails, stats) => {
       this.resetLoader(context);
       reject(
        this.createKeyLoadError(
         frag,
         ErrorDetails.KEY_LOAD_ERROR,
         new Error(`HTTP Error ${response.code} loading key ${response.text}`),
         networkDetails,
         _objectSpread2(
          {
           url: loaderContext.url,
           data: undefined,
          },
          response,
         ),
        ),
       );
      },
      onTimeout: (stats, context, networkDetails) => {
       this.resetLoader(context);
       reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_TIMEOUT, new Error('key loading timed out'), networkDetails));
      },
      onAbort: (stats, context, networkDetails) => {
       this.resetLoader(context);
       reject(this.createKeyLoadError(frag, ErrorDetails.INTERNAL_ABORTED, new Error('key loading aborted'), networkDetails));
      },
     };
     keyLoader.load(loaderContext, loaderConfig, loaderCallbacks);
    }));
   }
   resetLoader(context) {
    const { frag, keyInfo, url: uri } = context;
    const loader = keyInfo.loader;
    if (frag.keyLoader === loader) {
     frag.keyLoader = null;
     keyInfo.loader = null;
    }
    delete this.keyUriToKeyInfo[uri];
    if (loader) {
     loader.destroy();
    }
   }
  }

  function mapContextToLevelType(context) {
   const { type } = context;
   switch (type) {
    case PlaylistContextType.AUDIO_TRACK:
     return PlaylistLevelType.AUDIO;
    case PlaylistContextType.SUBTITLE_TRACK:
     return PlaylistLevelType.SUBTITLE;
    default:
     return PlaylistLevelType.MAIN;
   }
  }
  function getResponseUrl(response, context) {
   let url = response.url;
   // responseURL not supported on some browsers (it is used to detect URL redirection)
   // data-uri mode also not supported (but no need to detect redirection)
   if (url === undefined || url.indexOf('data:') === 0) {
    // fallback to initial URL
    url = context.url;
   }
   return url;
  }
  class PlaylistLoader {
   constructor(hls) {
    this.hls = void 0;
    this.loaders = Object.create(null);
    this.variableList = null;
    this.onManifestLoaded = this.checkAutostartLoad;
    this.hls = hls;
    this.registerListeners();
   }
   startLoad(startPosition) {}
   stopLoad() {
    this.destroyInternalLoaders();
   }
   registerListeners() {
    const { hls } = this;
    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);
    hls.on(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);
    hls.on(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);
    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
   }
   unregisterListeners() {
    const { hls } = this;
    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);
    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);
    hls.off(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);
    hls.off(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);
    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
   }

   /**
    * Returns defaults or configured loader-type overloads (pLoader and loader config params)
    */
   createInternalLoader(context) {
    const config = this.hls.config;
    const PLoader = config.pLoader;
    const Loader = config.loader;
    const InternalLoader = PLoader || Loader;
    const loader = new InternalLoader(config);
    this.loaders[context.type] = loader;
    return loader;
   }
   getInternalLoader(context) {
    return this.loaders[context.type];
   }
   resetInternalLoader(contextType) {
    if (this.loaders[contextType]) {
     delete this.loaders[contextType];
    }
   }

   /**
    * Call `destroy` on all internal loader instances mapped (one per context type)
    */
   destroyInternalLoaders() {
    for (const contextType in this.loaders) {
     const loader = this.loaders[contextType];
     if (loader) {
      loader.destroy();
     }
     this.resetInternalLoader(contextType);
    }
   }
   destroy() {
    this.variableList = null;
    this.unregisterListeners();
    this.destroyInternalLoaders();
   }
   onManifestLoading(event, data) {
    const { url } = data;
    this.variableList = null;
    this.load({
     id: null,
     level: 0,
     responseType: 'text',
     type: PlaylistContextType.MANIFEST,
     url,
     deliveryDirectives: null,
     levelOrTrack: null,
    });
   }
   onLevelLoading(event, data) {
    const { id, level, pathwayId, url, deliveryDirectives, levelInfo } = data;
    this.load({
     id,
     level,
     pathwayId,
     responseType: 'text',
     type: PlaylistContextType.LEVEL,
     url,
     deliveryDirectives,
     levelOrTrack: levelInfo,
    });
   }
   onAudioTrackLoading(event, data) {
    const { id, groupId, url, deliveryDirectives, track } = data;
    this.load({
     id,
     groupId,
     level: null,
     responseType: 'text',
     type: PlaylistContextType.AUDIO_TRACK,
     url,
     deliveryDirectives,
     levelOrTrack: track,
    });
   }
   onSubtitleTrackLoading(event, data) {
    const { id, groupId, url, deliveryDirectives, track } = data;
    this.load({
     id,
     groupId,
     level: null,
     responseType: 'text',
     type: PlaylistContextType.SUBTITLE_TRACK,
     url,
     deliveryDirectives,
     levelOrTrack: track,
    });
   }
   onLevelsUpdated(event, data) {
    // abort and delete loader of removed levels
    const loader = this.loaders[PlaylistContextType.LEVEL];
    if (loader) {
     const context = loader.context;
     if (context && !data.levels.some((lvl) => lvl === context.levelOrTrack)) {
      loader.abort();
      delete this.loaders[PlaylistContextType.LEVEL];
     }
    }
   }
   load(context) {
    var _context$deliveryDire;
    const config = this.hls.config;

    // logger.debug(`[playlist-loader]: Loading playlist of type ${context.type}, level: ${context.level}, id: ${context.id}`);

    // Check if a loader for this context already exists
    let loader = this.getInternalLoader(context);
    if (loader) {
     const logger = this.hls.logger;
     const loaderContext = loader.context;
     if (loaderContext && loaderContext.levelOrTrack === context.levelOrTrack && (loaderContext.url === context.url || (loaderContext.deliveryDirectives && !context.deliveryDirectives))) {
      // same URL can't overlap, or wait for blocking request
      if (loaderContext.url === context.url) {
       logger.log(`[playlist-loader]: ignore ${context.url} ongoing request`);
      } else {
       logger.log(`[playlist-loader]: ignore ${context.url} in favor of ${loaderContext.url}`);
      }
      return;
     }
     logger.log(`[playlist-loader]: aborting previous loader for type: ${context.type}`);
     loader.abort();
    }

    // apply different configs for retries depending on
    // context (manifest, level, audio/subs playlist)
    let loadPolicy;
    if (context.type === PlaylistContextType.MANIFEST) {
     loadPolicy = config.manifestLoadPolicy.default;
    } else {
     loadPolicy = _extends({}, config.playlistLoadPolicy.default, {
      timeoutRetry: null,
      errorRetry: null,
     });
    }
    loader = this.createInternalLoader(context);

    // Override level/track timeout for LL-HLS requests
    // (the default of 10000ms is counter productive to blocking playlist reload requests)
    if (isFiniteNumber((_context$deliveryDire = context.deliveryDirectives) == null ? void 0 : _context$deliveryDire.part)) {
     let levelDetails;
     if (context.type === PlaylistContextType.LEVEL && context.level !== null) {
      levelDetails = this.hls.levels[context.level].details;
     } else if (context.type === PlaylistContextType.AUDIO_TRACK && context.id !== null) {
      levelDetails = this.hls.audioTracks[context.id].details;
     } else if (context.type === PlaylistContextType.SUBTITLE_TRACK && context.id !== null) {
      levelDetails = this.hls.subtitleTracks[context.id].details;
     }
     if (levelDetails) {
      const partTarget = levelDetails.partTarget;
      const targetDuration = levelDetails.targetduration;
      if (partTarget && targetDuration) {
       const maxLowLatencyPlaylistRefresh = Math.max(partTarget * 3, targetDuration * 0.8) * 1000;
       loadPolicy = _extends({}, loadPolicy, {
        maxTimeToFirstByteMs: Math.min(maxLowLatencyPlaylistRefresh, loadPolicy.maxTimeToFirstByteMs),
        maxLoadTimeMs: Math.min(maxLowLatencyPlaylistRefresh, loadPolicy.maxTimeToFirstByteMs),
       });
      }
     }
    }
    const legacyRetryCompatibility = loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};
    const loaderConfig = {
     loadPolicy,
     timeout: loadPolicy.maxLoadTimeMs,
     maxRetry: legacyRetryCompatibility.maxNumRetry || 0,
     retryDelay: legacyRetryCompatibility.retryDelayMs || 0,
     maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0,
    };
    const loaderCallbacks = {
     onSuccess: (response, stats, context, networkDetails) => {
      const loader = this.getInternalLoader(context);
      this.resetInternalLoader(context.type);
      const string = response.data;

      // Validate if it is an M3U8 at all
      if (string.indexOf('#EXTM3U') !== 0) {
       this.handleManifestParsingError(response, context, new Error('no EXTM3U delimiter'), networkDetails || null, stats);
       return;
      }
      stats.parsing.start = performance.now();
      if (M3U8Parser.isMediaPlaylist(string) || context.type !== PlaylistContextType.MANIFEST) {
       this.handleTrackOrLevelPlaylist(response, stats, context, networkDetails || null, loader);
      } else {
       this.handleMasterPlaylist(response, stats, context, networkDetails);
      }
     },
     onError: (response, context, networkDetails, stats) => {
      this.handleNetworkError(context, networkDetails, false, response, stats);
     },
     onTimeout: (stats, context, networkDetails) => {
      this.handleNetworkError(context, networkDetails, true, undefined, stats);
     },
    };

    // logger.debug(`[playlist-loader]: Calling internal loader delegate for URL: ${context.url}`);

    loader.load(context, loaderConfig, loaderCallbacks);
   }
   checkAutostartLoad() {
    if (!this.hls) {
     return;
    }
    const {
     config: { autoStartLoad, startPosition },
     forceStartLoad,
    } = this.hls;
    if (autoStartLoad || forceStartLoad) {
     this.hls.logger.log(`${autoStartLoad ? 'auto' : 'force'} startLoad with configured startPosition ${startPosition}`);
     this.hls.startLoad(startPosition);
    }
   }
   handleMasterPlaylist(response, stats, context, networkDetails) {
    const hls = this.hls;
    const string = response.data;
    const url = getResponseUrl(response, context);
    const parsedResult = M3U8Parser.parseMasterPlaylist(string, url);
    if (parsedResult.playlistParsingError) {
     this.handleManifestParsingError(response, context, parsedResult.playlistParsingError, networkDetails, stats);
     return;
    }
    const { contentSteering, levels, sessionData, sessionKeys, startTimeOffset, variableList } = parsedResult;
    this.variableList = variableList;
    const { AUDIO: audioTracks = [], SUBTITLES: subtitles, 'CLOSED-CAPTIONS': captions } = M3U8Parser.parseMasterPlaylistMedia(string, url, parsedResult);
    if (audioTracks.length) {
     // check if we have found an audio track embedded in main playlist (audio track without URI attribute)
     const embeddedAudioFound = audioTracks.some((audioTrack) => !audioTrack.url);

     // if no embedded audio track defined, but audio codec signaled in quality level,
     // we need to signal this main audio track this could happen with playlists with
     // alt audio rendition in which quality levels (main)
     // contains both audio+video. but with mixed audio track not signaled
     if (!embeddedAudioFound && levels[0].audioCodec && !levels[0].attrs.AUDIO) {
      this.hls.logger.log('[playlist-loader]: audio codec signaled in quality level, but no embedded audio track signaled, create one');
      audioTracks.unshift({
       type: 'main',
       name: 'main',
       groupId: 'main',
       default: false,
       autoselect: false,
       forced: false,
       id: -1,
       attrs: new AttrList({}),
       bitrate: 0,
       url: '',
      });
     }
    }
    hls.trigger(Events.MANIFEST_LOADED, {
     levels,
     audioTracks,
     subtitles,
     captions,
     contentSteering,
     url,
     stats,
     networkDetails,
     sessionData,
     sessionKeys,
     startTimeOffset,
     variableList,
    });
   }
   handleTrackOrLevelPlaylist(response, stats, context, networkDetails, loader) {
    const hls = this.hls;
    const { id, level, type } = context;
    const url = getResponseUrl(response, context);
    const levelId = isFiniteNumber(level) ? level : isFiniteNumber(id) ? id : 0;
    const levelType = mapContextToLevelType(context);
    const levelDetails = M3U8Parser.parseLevelPlaylist(response.data, url, levelId, levelType, 0, this.variableList);

    // We have done our first request (Manifest-type) and receive
    // not a master playlist but a chunk-list (track/level)
    // We fire the manifest-loaded event anyway with the parsed level-details
    // by creating a single-level structure for it.
    if (type === PlaylistContextType.MANIFEST) {
     const singleLevel = {
      attrs: new AttrList({}),
      bitrate: 0,
      details: levelDetails,
      name: '',
      url,
     };
     levelDetails.requestScheduled = stats.loading.start + computeReloadInterval(levelDetails, 0);
     hls.trigger(Events.MANIFEST_LOADED, {
      levels: [singleLevel],
      audioTracks: [],
      url,
      stats,
      networkDetails,
      sessionData: null,
      sessionKeys: null,
      contentSteering: null,
      startTimeOffset: null,
      variableList: null,
     });
    }

    // save parsing time
    stats.parsing.end = performance.now();

    // extend the context with the new levelDetails property
    context.levelDetails = levelDetails;
    this.handlePlaylistLoaded(levelDetails, response, stats, context, networkDetails, loader);
   }
   handleManifestParsingError(response, context, error, networkDetails, stats) {
    this.hls.trigger(Events.ERROR, {
     type: ErrorTypes.NETWORK_ERROR,
     details: ErrorDetails.MANIFEST_PARSING_ERROR,
     fatal: context.type === PlaylistContextType.MANIFEST,
     url: response.url,
     err: error,
     error,
     reason: error.message,
     response,
     context,
     networkDetails,
     stats,
    });
   }
   handleNetworkError(context, networkDetails, timeout = false, response, stats) {
    let message = `A network ${timeout ? 'timeout' : 'error' + (response ? ' (status ' + response.code + ')' : '')} occurred while loading ${context.type}`;
    if (context.type === PlaylistContextType.LEVEL) {
     message += `: ${context.level} id: ${context.id}`;
    } else if (context.type === PlaylistContextType.AUDIO_TRACK || context.type === PlaylistContextType.SUBTITLE_TRACK) {
     message += ` id: ${context.id} group-id: "${context.groupId}"`;
    }
    const error = new Error(message);
    this.hls.logger.warn(`[playlist-loader]: ${message}`);
    let details = ErrorDetails.UNKNOWN;
    let fatal = false;
    const loader = this.getInternalLoader(context);
    switch (context.type) {
     case PlaylistContextType.MANIFEST:
      details = timeout ? ErrorDetails.MANIFEST_LOAD_TIMEOUT : ErrorDetails.MANIFEST_LOAD_ERROR;
      fatal = true;
      break;
     case PlaylistContextType.LEVEL:
      details = timeout ? ErrorDetails.LEVEL_LOAD_TIMEOUT : ErrorDetails.LEVEL_LOAD_ERROR;
      fatal = false;
      break;
     case PlaylistContextType.AUDIO_TRACK:
      details = timeout ? ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT : ErrorDetails.AUDIO_TRACK_LOAD_ERROR;
      fatal = false;
      break;
     case PlaylistContextType.SUBTITLE_TRACK:
      details = timeout ? ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT : ErrorDetails.SUBTITLE_LOAD_ERROR;
      fatal = false;
      break;
    }
    if (loader) {
     this.resetInternalLoader(context.type);
    }
    const errorData = {
     type: ErrorTypes.NETWORK_ERROR,
     details,
     fatal,
     url: context.url,
     loader,
     context,
     error,
     networkDetails,
     stats,
    };
    if (response) {
     const url = (networkDetails == null ? void 0 : networkDetails.url) || context.url;
     errorData.response = _objectSpread2(
      {
       url,
       data: undefined,
      },
      response,
     );
    }
    this.hls.trigger(Events.ERROR, errorData);
   }
   handlePlaylistLoaded(levelDetails, response, stats, context, networkDetails, loader) {
    const hls = this.hls;
    const { type, level, id, groupId, deliveryDirectives } = context;
    const url = getResponseUrl(response, context);
    const parent = mapContextToLevelType(context);
    const levelIndex = typeof context.level === 'number' && parent === PlaylistLevelType.MAIN ? level : undefined;
    if (!levelDetails.fragments.length) {
     const _error = (levelDetails.playlistParsingError = new Error('No Segments found in Playlist'));
     hls.trigger(Events.ERROR, {
      type: ErrorTypes.NETWORK_ERROR,
      details: ErrorDetails.LEVEL_EMPTY_ERROR,
      fatal: false,
      url,
      error: _error,
      reason: _error.message,
      response,
      context,
      level: levelIndex,
      parent,
      networkDetails,
      stats,
     });
     return;
    }
    if (!levelDetails.targetduration) {
     levelDetails.playlistParsingError = new Error('Missing Target Duration');
    }
    const error = levelDetails.playlistParsingError;
    if (error) {
     this.hls.logger.warn(`${error} ${levelDetails.url}`);
     if (!hls.config.ignorePlaylistParsingErrors) {
      hls.trigger(Events.ERROR, {
       type: ErrorTypes.NETWORK_ERROR,
       details: ErrorDetails.LEVEL_PARSING_ERROR,
       fatal: false,
       url,
       error,
       reason: error.message,
       response,
       context,
       level: levelIndex,
       parent,
       networkDetails,
       stats,
      });
      return;
     }
     levelDetails.playlistParsingError = null;
    }
    if (levelDetails.live && loader) {
     if (loader.getCacheAge) {
      levelDetails.ageHeader = loader.getCacheAge() || 0;
     }
     if (!loader.getCacheAge || isNaN(levelDetails.ageHeader)) {
      levelDetails.ageHeader = 0;
     }
    }
    switch (type) {
     case PlaylistContextType.MANIFEST:
     case PlaylistContextType.LEVEL:
      hls.trigger(Events.LEVEL_LOADED, {
       details: levelDetails,
       levelInfo: context.levelOrTrack || hls.levels[0],
       level: levelIndex || 0,
       id: id || 0,
       stats,
       networkDetails,
       deliveryDirectives,
       withoutMultiVariant: type === PlaylistContextType.MANIFEST,
      });
      break;
     case PlaylistContextType.AUDIO_TRACK:
      hls.trigger(Events.AUDIO_TRACK_LOADED, {
       details: levelDetails,
       track: context.levelOrTrack,
       id: id || 0,
       groupId: groupId || '',
       stats,
       networkDetails,
       deliveryDirectives,
      });
      break;
     case PlaylistContextType.SUBTITLE_TRACK:
      hls.trigger(Events.SUBTITLE_TRACK_LOADED, {
       details: levelDetails,
       track: context.levelOrTrack,
       id: id || 0,
       groupId: groupId || '',
       stats,
       networkDetails,
       deliveryDirectives,
      });
      break;
    }
   }
  }

  /**
   * The `Hls` class is the core of the HLS.js library used to instantiate player instances.
   * @public
   */
  class Hls {
   /**
    * Get the video-dev/hls.js package version.
    */
   static get version() {
    return version;
   }

   /**
    * Check if the required MediaSource Extensions are available.
    */
   static isMSESupported() {
    return isMSESupported();
   }

   /**
    * Check if MediaSource Extensions are available and isTypeSupported checks pass for any baseline codecs.
    */
   static isSupported() {
    return isSupported();
   }

   /**
    * Get the MediaSource global used for MSE playback (ManagedMediaSource, MediaSource, or WebKitMediaSource).
    */
   static getMediaSource() {
    return getMediaSource();
   }
   static get Events() {
    return Events;
   }
   static get MetadataSchema() {
    return MetadataSchema;
   }
   static get ErrorTypes() {
    return ErrorTypes;
   }
   static get ErrorDetails() {
    return ErrorDetails;
   }

   /**
    * Get the default configuration applied to new instances.
    */
   static get DefaultConfig() {
    if (!Hls.defaultConfig) {
     return hlsDefaultConfig;
    }
    return Hls.defaultConfig;
   }

   /**
    * Replace the default configuration applied to new instances.
    */
   static set DefaultConfig(defaultConfig) {
    Hls.defaultConfig = defaultConfig;
   }

   /**
    * Creates an instance of an HLS client that can attach to exactly one `HTMLMediaElement`.
    * @param userConfig - Configuration options applied over `Hls.DefaultConfig`
    */
   constructor(userConfig = {}) {
    /**
     * The runtime configuration used by the player. At instantiation this is combination of `hls.userConfig` merged over `Hls.DefaultConfig`.
     */
    this.config = void 0;
    /**
     * The configuration object provided on player instantiation.
     */
    this.userConfig = void 0;
    /**
     * The logger functions used by this player instance, configured on player instantiation.
     */
    this.logger = void 0;
    this.coreComponents = void 0;
    this.networkControllers = void 0;
    this._emitter = new EventEmitter();
    this._autoLevelCapping = -1;
    this._maxHdcpLevel = null;
    this.abrController = void 0;
    this.bufferController = void 0;
    this.capLevelController = void 0;
    this.latencyController = void 0;
    this.levelController = void 0;
    this.streamController = void 0;
    this.audioStreamController = void 0;
    this.subtititleStreamController = void 0;
    this.audioTrackController = void 0;
    this.subtitleTrackController = void 0;
    this.interstitialsController = void 0;
    this.gapController = void 0;
    this.emeController = void 0;
    this.cmcdController = void 0;
    this._media = null;
    this._url = null;
    this._sessionId = void 0;
    this.triggeringException = void 0;
    this.started = false;
    const logger = (this.logger = enableLogs(userConfig.debug || false, 'Hls instance', userConfig.assetPlayerId));
    const config = (this.config = mergeConfig(Hls.DefaultConfig, userConfig, logger));
    this.userConfig = userConfig;
    if (config.progressive) {
     enableStreamingMode(config, logger);
    }

    // core controllers and network loaders
    const { abrController: _AbrController, bufferController: _BufferController, capLevelController: _CapLevelController, errorController: _ErrorController, fpsController: _FpsController } = config;
    const errorController = new _ErrorController(this);
    const abrController = (this.abrController = new _AbrController(this));
    // FragmentTracker must be defined before StreamController because the order of event handling is important
    const fragmentTracker = new FragmentTracker(this);
    const _InterstitialsController = config.interstitialsController;
    const interstitialsController = _InterstitialsController ? (this.interstitialsController = new _InterstitialsController(this, Hls)) : null;
    const bufferController = (this.bufferController = new _BufferController(this, fragmentTracker));
    const capLevelController = (this.capLevelController = new _CapLevelController(this));
    const fpsController = new _FpsController(this);
    const playListLoader = new PlaylistLoader(this);
    const _ContentSteeringController = config.contentSteeringController;
    // Instantiate ConentSteeringController before LevelController to receive Multivariant Playlist events first
    const contentSteering = _ContentSteeringController ? new _ContentSteeringController(this) : null;
    const levelController = (this.levelController = new LevelController(this, contentSteering));
    const id3TrackController = new ID3TrackController(this);
    const keyLoader = new KeyLoader(this.config);
    const streamController = (this.streamController = new StreamController(this, fragmentTracker, keyLoader));
    const gapController = (this.gapController = new GapController(this, fragmentTracker));

    // Cap level controller uses streamController to flush the buffer
    capLevelController.setStreamController(streamController);
    // fpsController uses streamController to switch when frames are being dropped
    fpsController.setStreamController(streamController);
    const networkControllers = [playListLoader, levelController, streamController];
    if (interstitialsController) {
     networkControllers.splice(1, 0, interstitialsController);
    }
    if (contentSteering) {
     networkControllers.splice(1, 0, contentSteering);
    }
    this.networkControllers = networkControllers;
    const coreComponents = [abrController, bufferController, gapController, capLevelController, fpsController, id3TrackController, fragmentTracker];
    this.audioTrackController = this.createController(config.audioTrackController, networkControllers);
    const AudioStreamControllerClass = config.audioStreamController;
    if (AudioStreamControllerClass) {
     networkControllers.push((this.audioStreamController = new AudioStreamControllerClass(this, fragmentTracker, keyLoader)));
    }
    // Instantiate subtitleTrackController before SubtitleStreamController to receive level events first
    this.subtitleTrackController = this.createController(config.subtitleTrackController, networkControllers);
    const SubtitleStreamControllerClass = config.subtitleStreamController;
    if (SubtitleStreamControllerClass) {
     networkControllers.push((this.subtititleStreamController = new SubtitleStreamControllerClass(this, fragmentTracker, keyLoader)));
    }
    this.createController(config.timelineController, coreComponents);
    keyLoader.emeController = this.emeController = this.createController(config.emeController, coreComponents);
    this.cmcdController = this.createController(config.cmcdController, coreComponents);
    this.latencyController = this.createController(LatencyController, coreComponents);
    this.coreComponents = coreComponents;

    // Error controller handles errors before and after all other controllers
    // This listener will be invoked after all other controllers error listeners
    networkControllers.push(errorController);
    const onErrorOut = errorController.onErrorOut;
    if (typeof onErrorOut === 'function') {
     this.on(Events.ERROR, onErrorOut, errorController);
    }
    // Autostart load handler
    this.on(Events.MANIFEST_LOADED, playListLoader.onManifestLoaded, playListLoader);
   }
   createController(ControllerClass, components) {
    if (ControllerClass) {
     const controllerInstance = new ControllerClass(this);
     if (components) {
      components.push(controllerInstance);
     }
     return controllerInstance;
    }
    return null;
   }

   // Delegate the EventEmitter through the public API of Hls.js
   on(event, listener, context = this) {
    this._emitter.on(event, listener, context);
   }
   once(event, listener, context = this) {
    this._emitter.once(event, listener, context);
   }
   removeAllListeners(event) {
    this._emitter.removeAllListeners(event);
   }
   off(event, listener, context = this, once) {
    this._emitter.off(event, listener, context, once);
   }
   listeners(event) {
    return this._emitter.listeners(event);
   }
   emit(event, name, eventObject) {
    return this._emitter.emit(event, name, eventObject);
   }
   trigger(event, eventObject) {
    if (this.config.debug) {
     return this.emit(event, event, eventObject);
    } else {
     try {
      return this.emit(event, event, eventObject);
     } catch (error) {
      this.logger.error('An internal error happened while handling event ' + event + '. Error message: "' + error.message + '". Here is a stacktrace:', error);
      // Prevent recursion in error event handlers that throw #5497
      if (!this.triggeringException) {
       this.triggeringException = true;
       const fatal = event === Events.ERROR;
       this.trigger(Events.ERROR, {
        type: ErrorTypes.OTHER_ERROR,
        details: ErrorDetails.INTERNAL_EXCEPTION,
        fatal,
        event,
        error,
       });
       this.triggeringException = false;
      }
     }
    }
    return false;
   }
   listenerCount(event) {
    return this._emitter.listenerCount(event);
   }

   /**
    * Dispose of the instance
    */
   destroy() {
    this.logger.log('destroy');
    this.trigger(Events.DESTROYING, undefined);
    this.detachMedia();
    this.removeAllListeners();
    this._autoLevelCapping = -1;
    this._url = null;
    this.networkControllers.forEach((component) => component.destroy());
    this.networkControllers.length = 0;
    this.coreComponents.forEach((component) => component.destroy());
    this.coreComponents.length = 0;
    // Remove any references that could be held in config options or callbacks
    const config = this.config;
    config.xhrSetup = config.fetchSetup = undefined;
    // @ts-ignore
    this.userConfig = null;
   }

   /**
    * Attaches Hls.js to a media element
    */
   attachMedia(data) {
    if (!data || ('media' in data && !data.media)) {
     const error = new Error(`attachMedia failed: invalid argument (${data})`);
     this.trigger(Events.ERROR, {
      type: ErrorTypes.OTHER_ERROR,
      details: ErrorDetails.ATTACH_MEDIA_ERROR,
      fatal: true,
      error,
     });
     return;
    }
    this.logger.log(`attachMedia`);
    if (this._media) {
     this.logger.warn(`media must be detached before attaching`);
     this.detachMedia();
    }
    const attachMediaSource = 'media' in data;
    const media = attachMediaSource ? data.media : data;
    const attachingData = attachMediaSource
     ? data
     : {
        media,
       };
    this._media = media;
    this.trigger(Events.MEDIA_ATTACHING, attachingData);
   }

   /**
    * Detach Hls.js from the media
    */
   detachMedia() {
    this.logger.log('detachMedia');
    this.trigger(Events.MEDIA_DETACHING, {});
    this._media = null;
   }

   /**
    * Detach HTMLMediaElement, MediaSource, and SourceBuffers without reset, for attaching to another instance
    */
   transferMedia() {
    this._media = null;
    const transferMedia = this.bufferController.transferMedia();
    this.trigger(Events.MEDIA_DETACHING, {
     transferMedia,
    });
    return transferMedia;
   }

   /**
    * Set the source URL. Can be relative or absolute.
    */
   loadSource(url) {
    this.stopLoad();
    const media = this.media;
    const loadedSource = this._url;
    const loadingSource = (this._url = urlToolkitExports.buildAbsoluteURL(self.location.href, url, {
     alwaysNormalize: true,
    }));
    this._autoLevelCapping = -1;
    this._maxHdcpLevel = null;
    this.logger.log(`loadSource:${loadingSource}`);
    if (media && loadedSource && (loadedSource !== loadingSource || this.bufferController.hasSourceTypes())) {
     // Remove and re-create MediaSource
     this.detachMedia();
     this.attachMedia(media);
    }
    // when attaching to a source URL, trigger a playlist load
    this.trigger(Events.MANIFEST_LOADING, {
     url: url,
    });
   }

   /**
    * Gets the currently loaded URL
    */
   get url() {
    return this._url;
   }

   /**
    * Whether or not enough has been buffered to seek to start position or use `media.currentTime` to determine next load position
    */
   get hasEnoughToStart() {
    return this.streamController.hasEnoughToStart;
   }

   /**
    * Get the startPosition set on startLoad(position) or on autostart with config.startPosition
    */
   get startPosition() {
    return this.streamController.startPositionValue;
   }

   /**
    * Start loading data from the stream source.
    * Depending on default config, client starts loading automatically when a source is set.
    *
    * @param startPosition - Set the start position to stream from.
    * Defaults to -1 (None: starts from earliest point)
    */
   startLoad(startPosition = -1, skipSeekToStartPosition) {
    this.logger.log(`startLoad(${startPosition + (skipSeekToStartPosition ? ', <skip seek to start>' : '')})`);
    this.started = true;
    this.resumeBuffering();
    for (let i = 0; i < this.networkControllers.length; i++) {
     this.networkControllers[i].startLoad(startPosition, skipSeekToStartPosition);
     if (!this.started || !this.networkControllers) {
      break;
     }
    }
   }

   /**
    * Stop loading of any stream data.
    */
   stopLoad() {
    this.logger.log('stopLoad');
    this.started = false;
    for (let i = 0; i < this.networkControllers.length; i++) {
     this.networkControllers[i].stopLoad();
     if (this.started || !this.networkControllers) {
      break;
     }
    }
   }

   /**
    * Returns whether loading, toggled with `startLoad()` and `stopLoad()`, is active or not`.
    */
   get loadingEnabled() {
    return this.started;
   }

   /**
    * Returns state of fragment loading toggled by calling `pauseBuffering()` and `resumeBuffering()`.
    */
   get bufferingEnabled() {
    return this.streamController.bufferingEnabled;
   }

   /**
    * Resumes stream controller segment loading after `pauseBuffering` has been called.
    */
   resumeBuffering() {
    if (!this.bufferingEnabled) {
     this.logger.log(`resume buffering`);
     this.networkControllers.forEach((controller) => {
      if (controller.resumeBuffering) {
       controller.resumeBuffering();
      }
     });
    }
   }

   /**
    * Prevents stream controller from loading new segments until `resumeBuffering` is called.
    * This allows for media buffering to be paused without interupting playlist loading.
    */
   pauseBuffering() {
    if (this.bufferingEnabled) {
     this.logger.log(`pause buffering`);
     this.networkControllers.forEach((controller) => {
      if (controller.pauseBuffering) {
       controller.pauseBuffering();
      }
     });
    }
   }
   get inFlightFragments() {
    const inFlightData = {
     [PlaylistLevelType.MAIN]: this.streamController.inFlightFrag,
    };
    if (this.audioStreamController) {
     inFlightData[PlaylistLevelType.AUDIO] = this.audioStreamController.inFlightFrag;
    }
    if (this.subtititleStreamController) {
     inFlightData[PlaylistLevelType.SUBTITLE] = this.subtititleStreamController.inFlightFrag;
    }
    return inFlightData;
   }

   /**
    * Swap through possible audio codecs in the stream (for example to switch from stereo to 5.1)
    */
   swapAudioCodec() {
    this.logger.log('swapAudioCodec');
    this.streamController.swapAudioCodec();
   }

   /**
    * When the media-element fails, this allows to detach and then re-attach it
    * as one call (convenience method).
    *
    * Automatic recovery of media-errors by this process is configurable.
    */
   recoverMediaError() {
    this.logger.log('recoverMediaError');
    const media = this._media;
    const time = media == null ? void 0 : media.currentTime;
    this.detachMedia();
    if (media) {
     this.attachMedia(media);
     if (time) {
      this.startLoad(time);
     }
    }
   }
   removeLevel(levelIndex) {
    this.levelController.removeLevel(levelIndex);
   }

   /**
    * @returns a UUID for this player instance
    */
   get sessionId() {
    let _sessionId = this._sessionId;
    if (!_sessionId) {
     _sessionId = this._sessionId = uuid();
    }
    return _sessionId;
   }

   /**
    * @returns an array of levels (variants) sorted by HDCP-LEVEL, RESOLUTION (height), FRAME-RATE, CODECS, VIDEO-RANGE, and BANDWIDTH
    */
   get levels() {
    const levels = this.levelController.levels;
    return levels ? levels : [];
   }

   /**
    * @returns LevelDetails of last loaded level (variant) or `null` prior to loading a media playlist.
    */
   get latestLevelDetails() {
    return this.streamController.getLevelDetails() || null;
   }

   /**
    * @returns Level object of selected level (variant) or `null` prior to selecting a level or once the level is removed.
    */
   get loadLevelObj() {
    return this.levelController.loadLevelObj;
   }

   /**
    * Index of quality level (variant) currently played
    */
   get currentLevel() {
    return this.streamController.currentLevel;
   }

   /**
    * Set quality level index immediately. This will flush the current buffer to replace the quality asap. That means playback will interrupt at least shortly to re-buffer and re-sync eventually. Set to -1 for automatic level selection.
    */
   set currentLevel(newLevel) {
    this.logger.log(`set currentLevel:${newLevel}`);
    this.levelController.manualLevel = newLevel;
    this.streamController.immediateLevelSwitch();
   }

   /**
    * Index of next quality level loaded as scheduled by stream controller.
    */
   get nextLevel() {
    return this.streamController.nextLevel;
   }

   /**
    * Set quality level index for next loaded data.
    * This will switch the video quality asap, without interrupting playback.
    * May abort current loading of data, and flush parts of buffer (outside currently played fragment region).
    * @param newLevel - Pass -1 for automatic level selection
    */
   set nextLevel(newLevel) {
    this.logger.log(`set nextLevel:${newLevel}`);
    this.levelController.manualLevel = newLevel;
    this.streamController.nextLevelSwitch();
   }

   /**
    * Return the quality level of the currently or last (of none is loaded currently) segment
    */
   get loadLevel() {
    return this.levelController.level;
   }

   /**
    * Set quality level index for next loaded data in a conservative way.
    * This will switch the quality without flushing, but interrupt current loading.
    * Thus the moment when the quality switch will appear in effect will only be after the already existing buffer.
    * @param newLevel - Pass -1 for automatic level selection
    */
   set loadLevel(newLevel) {
    this.logger.log(`set loadLevel:${newLevel}`);
    this.levelController.manualLevel = newLevel;
   }

   /**
    * get next quality level loaded
    */
   get nextLoadLevel() {
    return this.levelController.nextLoadLevel;
   }

   /**
    * Set quality level of next loaded segment in a fully "non-destructive" way.
    * Same as `loadLevel` but will wait for next switch (until current loading is done).
    */
   set nextLoadLevel(level) {
    this.levelController.nextLoadLevel = level;
   }

   /**
    * Return "first level": like a default level, if not set,
    * falls back to index of first level referenced in manifest
    */
   get firstLevel() {
    return Math.max(this.levelController.firstLevel, this.minAutoLevel);
   }

   /**
    * Sets "first-level", see getter.
    */
   set firstLevel(newLevel) {
    this.logger.log(`set firstLevel:${newLevel}`);
    this.levelController.firstLevel = newLevel;
   }

   /**
    * Return the desired start level for the first fragment that will be loaded.
    * The default value of -1 indicates automatic start level selection.
    * Setting hls.nextAutoLevel without setting a startLevel will result in
    * the nextAutoLevel value being used for one fragment load.
    */
   get startLevel() {
    const startLevel = this.levelController.startLevel;
    if (startLevel === -1 && this.abrController.forcedAutoLevel > -1) {
     return this.abrController.forcedAutoLevel;
    }
    return startLevel;
   }

   /**
    * set  start level (level of first fragment that will be played back)
    * if not overrided by user, first level appearing in manifest will be used as start level
    * if -1 : automatic start level selection, playback will start from level matching download bandwidth
    * (determined from download of first segment)
    */
   set startLevel(newLevel) {
    this.logger.log(`set startLevel:${newLevel}`);
    // if not in automatic start level detection, ensure startLevel is greater than minAutoLevel
    if (newLevel !== -1) {
     newLevel = Math.max(newLevel, this.minAutoLevel);
    }
    this.levelController.startLevel = newLevel;
   }

   /**
    * Whether level capping is enabled.
    * Default value is set via `config.capLevelToPlayerSize`.
    */
   get capLevelToPlayerSize() {
    return this.config.capLevelToPlayerSize;
   }

   /**
    * Enables or disables level capping. If disabled after previously enabled, `nextLevelSwitch` will be immediately called.
    */
   set capLevelToPlayerSize(shouldStartCapping) {
    const newCapLevelToPlayerSize = !!shouldStartCapping;
    if (newCapLevelToPlayerSize !== this.config.capLevelToPlayerSize) {
     if (newCapLevelToPlayerSize) {
      this.capLevelController.startCapping(); // If capping occurs, nextLevelSwitch will happen based on size.
     } else {
      this.capLevelController.stopCapping();
      this.autoLevelCapping = -1;
      this.streamController.nextLevelSwitch(); // Now we're uncapped, get the next level asap.
     }
     this.config.capLevelToPlayerSize = newCapLevelToPlayerSize;
    }
   }

   /**
    * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)
    */
   get autoLevelCapping() {
    return this._autoLevelCapping;
   }

   /**
    * Returns the current bandwidth estimate in bits per second, when available. Otherwise, `NaN` is returned.
    */
   get bandwidthEstimate() {
    const { bwEstimator } = this.abrController;
    if (!bwEstimator) {
     return NaN;
    }
    return bwEstimator.getEstimate();
   }
   set bandwidthEstimate(abrEwmaDefaultEstimate) {
    this.abrController.resetEstimator(abrEwmaDefaultEstimate);
   }
   get abrEwmaDefaultEstimate() {
    const { bwEstimator } = this.abrController;
    if (!bwEstimator) {
     return NaN;
    }
    return bwEstimator.defaultEstimate;
   }

   /**
    * get time to first byte estimate
    * @type {number}
    */
   get ttfbEstimate() {
    const { bwEstimator } = this.abrController;
    if (!bwEstimator) {
     return NaN;
    }
    return bwEstimator.getEstimateTTFB();
   }

   /**
    * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)
    */
   set autoLevelCapping(newLevel) {
    if (this._autoLevelCapping !== newLevel) {
     this.logger.log(`set autoLevelCapping:${newLevel}`);
     this._autoLevelCapping = newLevel;
     this.levelController.checkMaxAutoUpdated();
    }
   }
   get maxHdcpLevel() {
    return this._maxHdcpLevel;
   }
   set maxHdcpLevel(value) {
    if (isHdcpLevel(value) && this._maxHdcpLevel !== value) {
     this._maxHdcpLevel = value;
     this.levelController.checkMaxAutoUpdated();
    }
   }

   /**
    * True when automatic level selection enabled
    */
   get autoLevelEnabled() {
    return this.levelController.manualLevel === -1;
   }

   /**
    * Level set manually (if any)
    */
   get manualLevel() {
    return this.levelController.manualLevel;
   }

   /**
    * min level selectable in auto mode according to config.minAutoBitrate
    */
   get minAutoLevel() {
    const {
     levels,
     config: { minAutoBitrate },
    } = this;
    if (!levels) return 0;
    const len = levels.length;
    for (let i = 0; i < len; i++) {
     if (levels[i].maxBitrate >= minAutoBitrate) {
      return i;
     }
    }
    return 0;
   }

   /**
    * max level selectable in auto mode according to autoLevelCapping
    */
   get maxAutoLevel() {
    const { levels, autoLevelCapping, maxHdcpLevel } = this;
    let maxAutoLevel;
    if (autoLevelCapping === -1 && levels != null && levels.length) {
     maxAutoLevel = levels.length - 1;
    } else {
     maxAutoLevel = autoLevelCapping;
    }
    if (maxHdcpLevel) {
     for (let i = maxAutoLevel; i--; ) {
      const hdcpLevel = levels[i].attrs['HDCP-LEVEL'];
      if (hdcpLevel && hdcpLevel <= maxHdcpLevel) {
       return i;
      }
     }
    }
    return maxAutoLevel;
   }
   get firstAutoLevel() {
    return this.abrController.firstAutoLevel;
   }

   /**
    * next automatically selected quality level
    */
   get nextAutoLevel() {
    return this.abrController.nextAutoLevel;
   }

   /**
    * this setter is used to force next auto level.
    * this is useful to force a switch down in auto mode:
    * in case of load error on level N, hls.js can set nextAutoLevel to N-1 for example)
    * forced value is valid for one fragment. upon successful frag loading at forced level,
    * this value will be resetted to -1 by ABR controller.
    */
   set nextAutoLevel(nextLevel) {
    this.abrController.nextAutoLevel = nextLevel;
   }

   /**
    * get the datetime value relative to media.currentTime for the active level Program Date Time if present
    */
   get playingDate() {
    return this.streamController.currentProgramDateTime;
   }
   get mainForwardBufferInfo() {
    return this.streamController.getMainFwdBufferInfo();
   }
   get maxBufferLength() {
    return this.streamController.maxBufferLength;
   }

   /**
    * Find and select the best matching audio track, making a level switch when a Group change is necessary.
    * Updates `hls.config.audioPreference`. Returns the selected track, or null when no matching track is found.
    */
   setAudioOption(audioOption) {
    var _this$audioTrackContr;
    return ((_this$audioTrackContr = this.audioTrackController) == null ? void 0 : _this$audioTrackContr.setAudioOption(audioOption)) || null;
   }
   /**
    * Find and select the best matching subtitle track, making a level switch when a Group change is necessary.
    * Updates `hls.config.subtitlePreference`. Returns the selected track, or null when no matching track is found.
    */
   setSubtitleOption(subtitleOption) {
    var _this$subtitleTrackCo;
    return ((_this$subtitleTrackCo = this.subtitleTrackController) == null ? void 0 : _this$subtitleTrackCo.setSubtitleOption(subtitleOption)) || null;
   }

   /**
    * Get the complete list of audio tracks across all media groups
    */
   get allAudioTracks() {
    const audioTrackController = this.audioTrackController;
    return audioTrackController ? audioTrackController.allAudioTracks : [];
   }

   /**
    * Get the list of selectable audio tracks
    */
   get audioTracks() {
    const audioTrackController = this.audioTrackController;
    return audioTrackController ? audioTrackController.audioTracks : [];
   }

   /**
    * index of the selected audio track (index in audio track lists)
    */
   get audioTrack() {
    const audioTrackController = this.audioTrackController;
    return audioTrackController ? audioTrackController.audioTrack : -1;
   }

   /**
    * selects an audio track, based on its index in audio track lists
    */
   set audioTrack(audioTrackId) {
    const audioTrackController = this.audioTrackController;
    if (audioTrackController) {
     audioTrackController.audioTrack = audioTrackId;
    }
   }

   /**
    * get the complete list of subtitle tracks across all media groups
    */
   get allSubtitleTracks() {
    const subtitleTrackController = this.subtitleTrackController;
    return subtitleTrackController ? subtitleTrackController.allSubtitleTracks : [];
   }

   /**
    * get alternate subtitle tracks list from playlist
    */
   get subtitleTracks() {
    const subtitleTrackController = this.subtitleTrackController;
    return subtitleTrackController ? subtitleTrackController.subtitleTracks : [];
   }

   /**
    * index of the selected subtitle track (index in subtitle track lists)
    */
   get subtitleTrack() {
    const subtitleTrackController = this.subtitleTrackController;
    return subtitleTrackController ? subtitleTrackController.subtitleTrack : -1;
   }
   get media() {
    return this._media;
   }

   /**
    * select an subtitle track, based on its index in subtitle track lists
    */
   set subtitleTrack(subtitleTrackId) {
    const subtitleTrackController = this.subtitleTrackController;
    if (subtitleTrackController) {
     subtitleTrackController.subtitleTrack = subtitleTrackId;
    }
   }

   /**
    * Whether subtitle display is enabled or not
    */
   get subtitleDisplay() {
    const subtitleTrackController = this.subtitleTrackController;
    return subtitleTrackController ? subtitleTrackController.subtitleDisplay : false;
   }

   /**
    * Enable/disable subtitle display rendering
    */
   set subtitleDisplay(value) {
    const subtitleTrackController = this.subtitleTrackController;
    if (subtitleTrackController) {
     subtitleTrackController.subtitleDisplay = value;
    }
   }

   /**
    * get mode for Low-Latency HLS loading
    */
   get lowLatencyMode() {
    return this.config.lowLatencyMode;
   }

   /**
    * Enable/disable Low-Latency HLS part playlist and segment loading, and start live streams at playlist PART-HOLD-BACK rather than HOLD-BACK.
    */
   set lowLatencyMode(mode) {
    this.config.lowLatencyMode = mode;
   }

   /**
    * Position (in seconds) of live sync point (ie edge of live position minus safety delay defined by ```hls.config.liveSyncDuration```)
    * @returns null prior to loading live Playlist
    */
   get liveSyncPosition() {
    return this.latencyController.liveSyncPosition;
   }

   /**
    * Estimated position (in seconds) of live edge (ie edge of live playlist plus time sync playlist advanced)
    * @returns 0 before first playlist is loaded
    */
   get latency() {
    return this.latencyController.latency;
   }

   /**
    * maximum distance from the edge before the player seeks forward to ```hls.liveSyncPosition```
    * configured using ```liveMaxLatencyDurationCount``` (multiple of target duration) or ```liveMaxLatencyDuration```
    * @returns 0 before first playlist is loaded
    */
   get maxLatency() {
    return this.latencyController.maxLatency;
   }

   /**
    * target distance from the edge as calculated by the latency controller
    */
   get targetLatency() {
    return this.latencyController.targetLatency;
   }
   set targetLatency(latency) {
    this.latencyController.targetLatency = latency;
   }

   /**
    * the rate at which the edge of the current live playlist is advancing or 1 if there is none
    */
   get drift() {
    return this.latencyController.drift;
   }

   /**
    * set to true when startLoad is called before MANIFEST_PARSED event
    */
   get forceStartLoad() {
    return this.streamController.forceStartLoad;
   }

   /**
    * ContentSteering pathways getter
    */
   get pathways() {
    return this.levelController.pathways;
   }

   /**
    * ContentSteering pathwayPriority getter/setter
    */
   get pathwayPriority() {
    return this.levelController.pathwayPriority;
   }
   set pathwayPriority(pathwayPriority) {
    this.levelController.pathwayPriority = pathwayPriority;
   }

   /**
    * returns true when all SourceBuffers are buffered to the end
    */
   get bufferedToEnd() {
    var _this$bufferControlle;
    return !!((_this$bufferControlle = this.bufferController) != null && _this$bufferControlle.bufferedToEnd);
   }

   /**
    * returns Interstitials Program Manager
    */
   get interstitialsManager() {
    var _this$interstitialsCo;
    return ((_this$interstitialsCo = this.interstitialsController) == null ? void 0 : _this$interstitialsCo.interstitialsManager) || null;
   }

   /**
    * returns mediaCapabilities.decodingInfo for a variant/rendition
    */
   getMediaDecodingInfo(level, audioTracks = this.allAudioTracks) {
    const audioTracksByGroup = getAudioTracksByGroup(audioTracks);
    return getMediaDecodingInfoPromise(level, audioTracksByGroup, navigator.mediaCapabilities);
   }
  }
  Hls.defaultConfig = void 0;

  //# sourceMappingURL=hls.mjs.map

  /***/
 },

 /***/ 47273: /***/ (__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {
  // EXPORTS
  __webpack_require__.d(__webpack_exports__, {
   lK: () => /* reexport */ MediaTracksMixin,
  }); // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/track-event.js

  // UNUSED EXPORTS: AudioRendition, AudioRenditionList, AudioTrack, AudioTrackList, RenditionEvent, TrackEvent, VideoRendition, VideoRenditionList, VideoTrack, VideoTrackList

  class TrackEvent extends Event {
   track;
   constructor(type, init) {
    super(type);
    this.track = init.track;
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/utils.js

  const privateProps = /* @__PURE__ */ new WeakMap();
  function getPrivate(instance) {
   return privateProps.get(instance) ?? setPrivate(instance, {});
  }
  function setPrivate(instance, props) {
   let saved = privateProps.get(instance);
   if (!saved) privateProps.set(instance, (saved = {}));
   return Object.assign(saved, props);
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/video-track-list.js

  function addVideoTrack(media, track) {
   const trackList = media.videoTracks;
   getPrivate(track).media = media;
   if (!getPrivate(track).renditionSet) {
    getPrivate(track).renditionSet = /* @__PURE__ */ new Set();
   }
   const trackSet = getPrivate(trackList).trackSet;
   trackSet.add(track);
   const index = trackSet.size - 1;
   if (!(index in VideoTrackList.prototype)) {
    Object.defineProperty(VideoTrackList.prototype, index, {
     get() {
      return [...getPrivate(this).trackSet][index];
     },
    });
   }
   queueMicrotask(() => {
    trackList.dispatchEvent(new TrackEvent('addtrack', { track }));
   });
  }
  function removeVideoTrack(track) {
   const trackList = getPrivate(track).media?.videoTracks;
   if (!trackList) return;
   const trackSet = getPrivate(trackList).trackSet;
   trackSet.delete(track);
   queueMicrotask(() => {
    trackList.dispatchEvent(new TrackEvent('removetrack', { track }));
   });
  }
  function selectedChanged(selected) {
   const trackList = getPrivate(selected).media.videoTracks ?? [];
   let hasUnselected = false;
   for (const track of trackList) {
    if (track === selected) continue;
    track.selected = false;
    hasUnselected = true;
   }
   if (hasUnselected) {
    if (getPrivate(trackList).changeRequested) return;
    getPrivate(trackList).changeRequested = true;
    queueMicrotask(() => {
     delete getPrivate(trackList).changeRequested;
     trackList.dispatchEvent(new Event('change'));
    });
   }
  }
  class VideoTrackList extends EventTarget {
   #addTrackCallback;
   #removeTrackCallback;
   #changeCallback;
   constructor() {
    super();
    getPrivate(this).trackSet = /* @__PURE__ */ new Set();
   }
   get #tracks() {
    return getPrivate(this).trackSet;
   }
   [Symbol.iterator]() {
    return this.#tracks.values();
   }
   get length() {
    return this.#tracks.size;
   }
   getTrackById(id) {
    return [...this.#tracks].find((track) => track.id === id) ?? null;
   }
   get selectedIndex() {
    return [...this.#tracks].findIndex((track) => track.selected);
   }
   get onaddtrack() {
    return this.#addTrackCallback;
   }
   set onaddtrack(callback) {
    if (this.#addTrackCallback) {
     this.removeEventListener('addtrack', this.#addTrackCallback);
     this.#addTrackCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#addTrackCallback = callback;
     this.addEventListener('addtrack', callback);
    }
   }
   get onremovetrack() {
    return this.#removeTrackCallback;
   }
   set onremovetrack(callback) {
    if (this.#removeTrackCallback) {
     this.removeEventListener('removetrack', this.#removeTrackCallback);
     this.#removeTrackCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#removeTrackCallback = callback;
     this.addEventListener('removetrack', callback);
    }
   }
   get onchange() {
    return this.#changeCallback;
   }
   set onchange(callback) {
    if (this.#changeCallback) {
     this.removeEventListener('change', this.#changeCallback);
     this.#changeCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#changeCallback = callback;
     this.addEventListener('change', callback);
    }
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/rendition-event.js

  class RenditionEvent extends Event {
   rendition;
   constructor(type, init) {
    super(type);
    this.rendition = init.rendition;
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/video-rendition-list.js

  function addRendition(track, rendition) {
   const renditionList = getPrivate(track).media.videoRenditions;
   getPrivate(rendition).media = getPrivate(track).media;
   getPrivate(rendition).track = track;
   const renditionSet = getPrivate(track).renditionSet;
   renditionSet.add(rendition);
   const index = renditionSet.size - 1;
   if (!(index in VideoRenditionList.prototype)) {
    Object.defineProperty(VideoRenditionList.prototype, index, {
     get() {
      return getCurrentRenditions(this)[index];
     },
    });
   }
   queueMicrotask(() => {
    if (!track.selected) return;
    renditionList.dispatchEvent(new RenditionEvent('addrendition', { rendition }));
   });
  }
  function removeRendition(rendition) {
   const renditionList = getPrivate(rendition).media.videoRenditions;
   const track = getPrivate(rendition).track;
   const renditionSet = getPrivate(track).renditionSet;
   renditionSet.delete(rendition);
   queueMicrotask(() => {
    const track2 = getPrivate(rendition).track;
    if (!track2.selected) return;
    renditionList.dispatchEvent(new RenditionEvent('removerendition', { rendition }));
   });
  }
  function video_rendition_list_selectedChanged(rendition) {
   const renditionList = getPrivate(rendition).media.videoRenditions;
   if (!renditionList || getPrivate(renditionList).changeRequested) return;
   getPrivate(renditionList).changeRequested = true;
   queueMicrotask(() => {
    delete getPrivate(renditionList).changeRequested;
    const track = getPrivate(rendition).track;
    if (!track.selected) return;
    renditionList.dispatchEvent(new Event('change'));
   });
  }
  function getCurrentRenditions(renditionList) {
   const media = getPrivate(renditionList).media;
   return [...media.videoTracks].filter((track) => track.selected).flatMap((track) => [...getPrivate(track).renditionSet]);
  }
  class VideoRenditionList extends EventTarget {
   #addRenditionCallback;
   #removeRenditionCallback;
   #changeCallback;
   [Symbol.iterator]() {
    return getCurrentRenditions(this).values();
   }
   get length() {
    return getCurrentRenditions(this).length;
   }
   getRenditionById(id) {
    return getCurrentRenditions(this).find((rendition) => `${rendition.id}` === `${id}`) ?? null;
   }
   get selectedIndex() {
    return getCurrentRenditions(this).findIndex((rendition) => rendition.selected);
   }
   set selectedIndex(index) {
    for (const [i, rendition] of getCurrentRenditions(this).entries()) {
     rendition.selected = i === index;
    }
   }
   get onaddrendition() {
    return this.#addRenditionCallback;
   }
   set onaddrendition(callback) {
    if (this.#addRenditionCallback) {
     this.removeEventListener('addrendition', this.#addRenditionCallback);
     this.#addRenditionCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#addRenditionCallback = callback;
     this.addEventListener('addrendition', callback);
    }
   }
   get onremoverendition() {
    return this.#removeRenditionCallback;
   }
   set onremoverendition(callback) {
    if (this.#removeRenditionCallback) {
     this.removeEventListener('removerendition', this.#removeRenditionCallback);
     this.#removeRenditionCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#removeRenditionCallback = callback;
     this.addEventListener('removerendition', callback);
    }
   }
   get onchange() {
    return this.#changeCallback;
   }
   set onchange(callback) {
    if (this.#changeCallback) {
     this.removeEventListener('change', this.#changeCallback);
     this.#changeCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#changeCallback = callback;
     this.addEventListener('change', callback);
    }
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/video-rendition.js

  class VideoRendition {
   src;
   id;
   width;
   height;
   bitrate;
   frameRate;
   codec;
   #selected = false;
   get selected() {
    return this.#selected;
   }
   set selected(val) {
    if (this.#selected === val) return;
    this.#selected = val;
    video_rendition_list_selectedChanged(this);
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/video-track.js

  const VideoTrackKind = {
   alternative: 'alternative',
   captions: 'captions',
   main: 'main',
   sign: 'sign',
   subtitles: 'subtitles',
   commentary: 'commentary',
  };
  class VideoTrack {
   id;
   kind;
   label = '';
   language = '';
   sourceBuffer;
   #selected = false;
   addRendition(src, width, height, codec, bitrate, frameRate) {
    const rendition = new VideoRendition();
    rendition.src = src;
    rendition.width = width;
    rendition.height = height;
    rendition.frameRate = frameRate;
    rendition.bitrate = bitrate;
    rendition.codec = codec;
    addRendition(this, rendition);
    return rendition;
   }
   removeRendition(rendition) {
    removeRendition(rendition);
   }
   get selected() {
    return this.#selected;
   }
   set selected(val) {
    if (this.#selected === val) return;
    this.#selected = val;
    if (val !== true) return;
    selectedChanged(this);
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/audio-rendition-list.js

  function audio_rendition_list_addRendition(track, rendition) {
   const renditionList = getPrivate(track).media.audioRenditions;
   getPrivate(rendition).media = getPrivate(track).media;
   getPrivate(rendition).track = track;
   const renditionSet = getPrivate(track).renditionSet;
   renditionSet.add(rendition);
   const index = renditionSet.size - 1;
   if (!(index in AudioRenditionList.prototype)) {
    Object.defineProperty(AudioRenditionList.prototype, index, {
     get() {
      return audio_rendition_list_getCurrentRenditions(this)[index];
     },
    });
   }
   queueMicrotask(() => {
    if (!track.enabled) return;
    renditionList.dispatchEvent(new RenditionEvent('addrendition', { rendition }));
   });
  }
  function audio_rendition_list_removeRendition(rendition) {
   const renditionList = getPrivate(rendition).media.audioRenditions;
   const track = getPrivate(rendition).track;
   const renditionSet = getPrivate(track).renditionSet;
   renditionSet.delete(rendition);
   queueMicrotask(() => {
    const track2 = getPrivate(rendition).track;
    if (!track2.enabled) return;
    renditionList.dispatchEvent(new RenditionEvent('removerendition', { rendition }));
   });
  }
  function audio_rendition_list_selectedChanged(rendition) {
   const renditionList = getPrivate(rendition).media.audioRenditions;
   if (!renditionList || getPrivate(renditionList).changeRequested) return;
   getPrivate(renditionList).changeRequested = true;
   queueMicrotask(() => {
    delete getPrivate(renditionList).changeRequested;
    const track = getPrivate(rendition).track;
    if (!track.enabled) return;
    renditionList.dispatchEvent(new Event('change'));
   });
  }
  function audio_rendition_list_getCurrentRenditions(renditionList) {
   const media = getPrivate(renditionList).media;
   return [...media.audioTracks].filter((track) => track.enabled).flatMap((track) => [...getPrivate(track).renditionSet]);
  }
  class AudioRenditionList extends EventTarget {
   #addRenditionCallback;
   #removeRenditionCallback;
   #changeCallback;
   [Symbol.iterator]() {
    return audio_rendition_list_getCurrentRenditions(this).values();
   }
   get length() {
    return audio_rendition_list_getCurrentRenditions(this).length;
   }
   getRenditionById(id) {
    return audio_rendition_list_getCurrentRenditions(this).find((rendition) => `${rendition.id}` === `${id}`) ?? null;
   }
   get selectedIndex() {
    return audio_rendition_list_getCurrentRenditions(this).findIndex((rendition) => rendition.selected);
   }
   set selectedIndex(index) {
    for (const [i, rendition] of audio_rendition_list_getCurrentRenditions(this).entries()) {
     rendition.selected = i === index;
    }
   }
   get onaddrendition() {
    return this.#addRenditionCallback;
   }
   set onaddrendition(callback) {
    if (this.#addRenditionCallback) {
     this.removeEventListener('addrendition', this.#addRenditionCallback);
     this.#addRenditionCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#addRenditionCallback = callback;
     this.addEventListener('addrendition', callback);
    }
   }
   get onremoverendition() {
    return this.#removeRenditionCallback;
   }
   set onremoverendition(callback) {
    if (this.#removeRenditionCallback) {
     this.removeEventListener('removerendition', this.#removeRenditionCallback);
     this.#removeRenditionCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#removeRenditionCallback = callback;
     this.addEventListener('removerendition', callback);
    }
   }
   get onchange() {
    return this.#changeCallback;
   }
   set onchange(callback) {
    if (this.#changeCallback) {
     this.removeEventListener('change', this.#changeCallback);
     this.#changeCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#changeCallback = callback;
     this.addEventListener('change', callback);
    }
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/audio-rendition.js

  class AudioRendition {
   src;
   id;
   bitrate;
   codec;
   #selected = false;
   get selected() {
    return this.#selected;
   }
   set selected(val) {
    if (this.#selected === val) return;
    this.#selected = val;
    audio_rendition_list_selectedChanged(this);
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/audio-track-list.js

  function addAudioTrack(media, track) {
   const trackList = media.audioTracks;
   getPrivate(track).media = media;
   if (!getPrivate(track).renditionSet) {
    getPrivate(track).renditionSet = /* @__PURE__ */ new Set();
   }
   const trackSet = getPrivate(trackList).trackSet;
   trackSet.add(track);
   const index = trackSet.size - 1;
   if (!(index in AudioTrackList.prototype)) {
    Object.defineProperty(AudioTrackList.prototype, index, {
     get() {
      return [...getPrivate(this).trackSet][index];
     },
    });
   }
   queueMicrotask(() => {
    trackList.dispatchEvent(new TrackEvent('addtrack', { track }));
   });
  }
  function removeAudioTrack(track) {
   const trackList = getPrivate(track).media?.audioTracks;
   if (!trackList) return;
   const trackSet = getPrivate(trackList).trackSet;
   trackSet.delete(track);
   queueMicrotask(() => {
    trackList.dispatchEvent(new TrackEvent('removetrack', { track }));
   });
  }
  function enabledChanged(track) {
   const trackList = getPrivate(track).media.audioTracks;
   if (!trackList || getPrivate(trackList).changeRequested) return;
   getPrivate(trackList).changeRequested = true;
   queueMicrotask(() => {
    delete getPrivate(trackList).changeRequested;
    trackList.dispatchEvent(new Event('change'));
   });
  }
  class AudioTrackList extends EventTarget {
   #addTrackCallback;
   #removeTrackCallback;
   #changeCallback;
   constructor() {
    super();
    getPrivate(this).trackSet = /* @__PURE__ */ new Set();
   }
   get #tracks() {
    return getPrivate(this).trackSet;
   }
   [Symbol.iterator]() {
    return this.#tracks.values();
   }
   get length() {
    return this.#tracks.size;
   }
   getTrackById(id) {
    return [...this.#tracks].find((track) => track.id === id) ?? null;
   }
   get onaddtrack() {
    return this.#addTrackCallback;
   }
   set onaddtrack(callback) {
    if (this.#addTrackCallback) {
     this.removeEventListener('addtrack', this.#addTrackCallback);
     this.#addTrackCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#addTrackCallback = callback;
     this.addEventListener('addtrack', callback);
    }
   }
   get onremovetrack() {
    return this.#removeTrackCallback;
   }
   set onremovetrack(callback) {
    if (this.#removeTrackCallback) {
     this.removeEventListener('removetrack', this.#removeTrackCallback);
     this.#removeTrackCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#removeTrackCallback = callback;
     this.addEventListener('removetrack', callback);
    }
   }
   get onchange() {
    return this.#changeCallback;
   }
   set onchange(callback) {
    if (this.#changeCallback) {
     this.removeEventListener('change', this.#changeCallback);
     this.#changeCallback = void 0;
    }
    if (typeof callback == 'function') {
     this.#changeCallback = callback;
     this.addEventListener('change', callback);
    }
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/audio-track.js

  const AudioTrackKind = {
   alternative: 'alternative',
   descriptions: 'descriptions',
   main: 'main',
   'main-desc': 'main-desc',
   translation: 'translation',
   commentary: 'commentary',
  };
  class AudioTrack {
   id;
   kind;
   label = '';
   language = '';
   sourceBuffer;
   #enabled = false;
   addRendition(src, codec, bitrate) {
    const rendition = new AudioRendition();
    rendition.src = src;
    rendition.codec = codec;
    rendition.bitrate = bitrate;
    audio_rendition_list_addRendition(this, rendition);
    return rendition;
   }
   removeRendition(rendition) {
    audio_rendition_list_removeRendition(rendition);
   }
   get enabled() {
    return this.#enabled;
   }
   set enabled(val) {
    if (this.#enabled === val) return;
    this.#enabled = val;
    enabledChanged(this);
   }
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/mixin.js

  const nativeVideoTracksFn = getBaseMediaTracksFn(globalThis.HTMLMediaElement, 'video');
  const nativeAudioTracksFn = getBaseMediaTracksFn(globalThis.HTMLMediaElement, 'audio');
  function MediaTracksMixin(MediaElementClass) {
   if (!MediaElementClass?.prototype) return MediaElementClass;
   const videoTracksFn = getBaseMediaTracksFn(MediaElementClass, 'video');
   if (!videoTracksFn || `${videoTracksFn}`.includes('[native code]')) {
    Object.defineProperty(MediaElementClass.prototype, 'videoTracks', {
     get() {
      return getVideoTracks(this);
     },
    });
   }
   const audioTracksFn = getBaseMediaTracksFn(MediaElementClass, 'audio');
   if (!audioTracksFn || `${audioTracksFn}`.includes('[native code]')) {
    Object.defineProperty(MediaElementClass.prototype, 'audioTracks', {
     get() {
      return getAudioTracks(this);
     },
    });
   }
   if (!('addVideoTrack' in MediaElementClass.prototype)) {
    MediaElementClass.prototype.addVideoTrack = function (kind, label = '', language = '') {
     const track = new VideoTrack();
     track.kind = kind;
     track.label = label;
     track.language = language;
     addVideoTrack(this, track);
     return track;
    };
   }
   if (!('removeVideoTrack' in MediaElementClass.prototype)) {
    MediaElementClass.prototype.removeVideoTrack = removeVideoTrack;
   }
   if (!('addAudioTrack' in MediaElementClass.prototype)) {
    MediaElementClass.prototype.addAudioTrack = function (kind, label = '', language = '') {
     const track = new AudioTrack();
     track.kind = kind;
     track.label = label;
     track.language = language;
     addAudioTrack(this, track);
     return track;
    };
   }
   if (!('removeAudioTrack' in MediaElementClass.prototype)) {
    MediaElementClass.prototype.removeAudioTrack = removeAudioTrack;
   }
   if (!('videoRenditions' in MediaElementClass.prototype)) {
    Object.defineProperty(MediaElementClass.prototype, 'videoRenditions', {
     get() {
      return initVideoRenditions(this);
     },
    });
   }
   const initVideoRenditions = (media) => {
    let renditions = getPrivate(media).videoRenditions;
    if (!renditions) {
     renditions = new VideoRenditionList();
     getPrivate(renditions).media = media;
     getPrivate(media).videoRenditions = renditions;
    }
    return renditions;
   };
   if (!('audioRenditions' in MediaElementClass.prototype)) {
    Object.defineProperty(MediaElementClass.prototype, 'audioRenditions', {
     get() {
      return initAudioRenditions(this);
     },
    });
   }
   const initAudioRenditions = (media) => {
    let renditions = getPrivate(media).audioRenditions;
    if (!renditions) {
     renditions = new AudioRenditionList();
     getPrivate(renditions).media = media;
     getPrivate(media).audioRenditions = renditions;
    }
    return renditions;
   };
   return MediaElementClass;
  }
  function getBaseMediaTracksFn(MediaElementClass, type) {
   if (MediaElementClass?.prototype) {
    return Object.getOwnPropertyDescriptor(MediaElementClass.prototype, `${type}Tracks`)?.get;
   }
  }
  function getVideoTracks(media) {
   let tracks = getPrivate(media).videoTracks;
   if (!tracks) {
    tracks = new VideoTrackList();
    getPrivate(media).videoTracks = tracks;
    if (nativeVideoTracksFn) {
     const nativeTracks = nativeVideoTracksFn.call(media.nativeEl ?? media);
     for (const nativeTrack of nativeTracks) {
      addVideoTrack(media, nativeTrack);
     }
     nativeTracks.addEventListener('change', () => {
      tracks.dispatchEvent(new Event('change'));
     });
     nativeTracks.addEventListener('addtrack', (event) => {
      if ([...tracks].some((t) => t instanceof VideoTrack)) {
       for (const nativeTrack of nativeTracks) {
        removeVideoTrack(nativeTrack);
       }
       return;
      }
      addVideoTrack(media, event.track);
     });
     nativeTracks.addEventListener('removetrack', (event) => {
      removeVideoTrack(event.track);
     });
    }
   }
   return tracks;
  }
  function getAudioTracks(media) {
   let tracks = getPrivate(media).audioTracks;
   if (!tracks) {
    tracks = new AudioTrackList();
    getPrivate(media).audioTracks = tracks;
    if (nativeAudioTracksFn) {
     const nativeTracks = nativeAudioTracksFn.call(media.nativeEl ?? media);
     for (const nativeTrack of nativeTracks) {
      addAudioTrack(media, nativeTrack);
     }
     nativeTracks.addEventListener('change', () => {
      tracks.dispatchEvent(new Event('change'));
     });
     nativeTracks.addEventListener('addtrack', (event) => {
      if ([...tracks].some((t) => t instanceof AudioTrack)) {
       for (const nativeTrack of nativeTracks) {
        removeAudioTrack(nativeTrack);
       }
       return;
      }
      addAudioTrack(media, event.track);
     });
     nativeTracks.addEventListener('removetrack', (event) => {
      removeAudioTrack(event.track);
     });
    }
   }
   return tracks;
  } // CONCATENATED MODULE: ./node_modules/.pnpm/media-tracks@0.3.3/node_modules/media-tracks/dist/index.js

  /***/
 },
};
